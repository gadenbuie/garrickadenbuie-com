[
  {
    "objectID": "talk/isg-2018/index.html",
    "href": "talk/isg-2018/index.html",
    "title": "Unsupervised behavior change detection using passive sensor systems in the homes of older adults",
    "section": "",
    "text": "Abstract\n\nPurpose\nGlobally and within the United States, we face well-known and documented challenges driven by growth within the elderly segments of our population. The majority of adults over 65 are healthy but managing one or more chronic illnesses, and older adults and their informal caregivers‚Äîsuch as family members and friends‚Äîrequire supportive technologies that assist in monitoring and managing these conditions1 as they strive to maintain independence at home. An important goal of lifestyle reassurance monitoring is to alert older adults and their caregivers to changes in behavior or routine. In contrast with traditional activity recognition algorithms that require labelled activity data that is both difficult and expensive to collect2, we present a method for unsupervised behavior change detection that does not require explicit, higher-level activity labels and is effective when applied to real-world, natural, smart home activity data.\n\n\nMethods\nIn this project, we developed a passive sensor system that has been installed to date in the homes of 14 community-dwelling, older adults (aged 68 and above) who live alone and were of good health at the time of installation. Participants responded to a bi-weekly survey tracking the occurrence of health changes. Included in the sensor network are motion sensors for the generalized detection of presence throughout the home, and magnetic contact sensors for detection of interaction with entrance and exit doors and routinely used objects. All sensors are wireless, use the Z-Wave protocol, and are readily available commercially. The basis of the behavior change algorithm is the use of a bag of event sequence n-grams representation3 to summarize daily activity patterns in an activity profile and a permutation-based change detection algorithm4 to compare activity profiles of multiple days (e.g.¬†a baseline period of activity) and individual or grouped activity profiles.\n\n\nResults and Discussion\nThe bag of event n-grams method was first validated as a supervised classification problem in which activity profiles were used to identify occupants from 6 homes with identical layouts. Activity profiles based on 4 and 6 weeks of activity led to correct identification of a given occupant for unlabelled days of activity with high accuracy (0.9593, 0.9624) and F1 (0.9590, 0.9621). The algorithm for unsupervised behavior change was applied to the activity data from four participants over a period of one year (one participant) or two years (three participants) who reported health changes ranging from acute episodes of illness to mobility restrictions leading to major surgery. Preliminary results reveal that comparison of activity profiles over time windows of 1 to 4 weeks reliably detects major shifts in behavior or other systematic disturbances such as guests in the home or sensor reliability issues. Linking the output of the algorithm to a notification system will alert family members, caregivers, and system administrators to trigger follow-up and review when such issues arise.\n\n\nReferences\n\nDemiris G, Hensel BK. Technologies for an aging society: A systematic review of ‚Äúsmart home‚Äù applications. Yearbook of medical informatics. 2008 Jan;33‚Äì40\nSzewcyzk S, Dwan K, Minor B, Swedlove B, Cook D. Annotating smart environment sensor data for activity learning. Technology and Health Care. 2009 Jan;17(3):161‚Äì169.\nHamid R, Johnson A, Batta S, Bobick A, Isbell C, Coleman G. Detection and explanation of anomalous activities: Representing activities as bags of event n-grams. Proceedings - 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, CVPR 2005. 2005;1031‚Äì1038.\nSprint G, Cook DJ, Schmitter-Edgecombe M. Unsupervised detection and analysis of changes in everyday physical activity data. Journal of Biomedical Informatics. 2016 Oct;63(Supplement C):54‚Äì65"
  },
  {
    "objectID": "talk/informs-2013/index.html",
    "href": "talk/informs-2013/index.html",
    "title": "Boosted Tree Ensembles for Predicting Postsurgical ICU Mortality",
    "section": "",
    "text": "Real-time monitoring of patient conditions in the ICU environment is essential in supporting clinical decisions and ensuring optimal allocation of medical resources. This study focuses on accurately predicting in-hospital ICU patient mortality utilizing functional profile data. We demonstrate that a boosted trees ensemble model is well suited for the diverse data typologies present in ICU data and provides an interpretable and accurate model to aid clinical experts in critical ICU decisions."
  },
  {
    "objectID": "talk/drake-intro-biodataclub/index.html",
    "href": "talk/drake-intro-biodataclub/index.html",
    "title": "Reproducible Data Workflows With Drake",
    "section": "",
    "text": "drake is an R package that provides a powerful, flexible workflow management tool for reproducible data analysis pipelines. drake alleviates the pain of managing large (and even small) data analyses, speeding up iteration and development while providing reproducibility guarantees that are essential for modern research.\nhttps://ropensci.github.io/drake/\nIn this session, we‚Äôll learn how to use drake to manage a data analysis workflow by writing functions that define the steps of the analysis. We‚Äôll then learn how drake can keep track of all of these steps, from start to finish, and intelligently update only the outdated steps when your data or code change.\n\nMeeting prerequisites\nWe‚Äôll work through a few examples together, so please bring a laptop with the drake and visNetwork packages installed. (If you don‚Äôt have a laptop you can share with someone who does at the session.) You would also benefit from installing the tidyverse package for the session. See the full requirements here.\nrequired_packages &lt;- c(\n  # \"tidyverse\",  #&lt;&lt; For data processing, etc. (you probably have this)\n  \"here\",         #&lt;&lt; For sane path management\n  \"cowplot\",      #&lt;&lt; For composing ggplot2 plots\n  \"visNetwork\",   #&lt;&lt; For visualizing drake plans\n  \"drake\"         #&lt;&lt; Because drake\n)\n\ninstall.packages(required_packages)\nNote: if you‚Äôve used drake before, please ensure that you have version 7.0.0 or later installed.\n\n\nMeeting materials\nThe slides from this talk are available online at https://pkg.garrickadenbuie.com/drake-intro/ and the drake source code and RStudio project are in available on GitHub at https://github.com/gadenbuie/drake-intro. There is also an RStudio Cloud project containing the drake project with all of the required dependencies pre-installed that you can use to explore and run the code from the talk."
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html",
    "href": "blog/xaringan-tip-logo-all-slides/index.html",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "",
    "text": "Here‚Äôs a quick tip to help solve a common xaringan problem: adding a logo to all of your slides.\nThe slightly problematic and somewhat annoying way to solve this problem is to add a logo to a series of slides using remarkjs‚Äô background-image and layout syntax.\nIt works‚Ä¶ as long as you don‚Äôt change your slide format or if you don‚Äôt mind repeating those 4 lines every time you need to reset your layout."
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html#a-logo-for-all-the-slides",
    "href": "blog/xaringan-tip-logo-all-slides/index.html#a-logo-for-all-the-slides",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "A logo for all the slides",
    "text": "A logo for all the slides\n\n\n\nThe xaringan logo appears on all the slides!\n\n\nüì∫ Demo Slides\nInstead, with a little bit of JavaScript and CSS, we can automatically insert a logo on all the slides in the presentation. Of course, we might not want a logo an all the slides, so we won‚Äôt add the logo to the .title-slide or any slide with class: hide-logo.\nIf you just want to jump straight to the solution, I‚Äôve created a template repository on GitHub that you can use to bootstrap your next set of xaringan slides.\nTo set everything up manually takes just a few steps.\n\nDownload your logo and save it in your slides directory. I‚Äôve used the xaringan hex logo: xaringan.png.\nDownload insert-logo.html into your slide directory, or copy the html described below into insert-logo.html.\nAdd insert-logo.html to your after_body includes in your slides‚Äô .Rmd file.\noutput:\nxaringan::moon_reader:\n  includes:\n    after_body: insert-logo.html\nEdit the .logo class in the CSS in insert-logo.html to use your logo image, and adjust the width, height and position (top, bottom, left, and/or right) as needed.\nUse class: hide-logo to hide your logo on individual slides. (The title slide is automatically excluded.)\n---\n\n# This slide has a logo\n\n---\nclass: inverse, hide-logo\n\n# This slide doesn't have a logo!\n\nAnd it's an inverse slide, too.\nHave fun looking üòé during your presentation!"
  },
  {
    "objectID": "blog/xaringan-tip-logo-all-slides/index.html#inside-insert-logo.html",
    "href": "blog/xaringan-tip-logo-all-slides/index.html#inside-insert-logo.html",
    "title": "xaringan Tip: Add A Logo to All of Your Slides",
    "section": "Inside insert-logo.html",
    "text": "Inside insert-logo.html\nThe insert-logo.html file is a simple snippet of CSS and a tiny bit of JavaScript. The CSS defines the .logo class that positions and sizes the logo, and the JavaScript inserts a &lt;div&gt; with class = \"logo\" into each slide.\n&lt;style&gt;\n.logo {\n  background-image: url(xaringan.png);\n  background-size: contain;\n  background-repeat: no-repeat;\n  position: absolute;\n  top: 1em;\n  right: 1em;\n  width: 110px;\n  height: 128px;\n  z-index: 0;\n}\n&lt;/style&gt;\n\n&lt;script&gt;\ndocument\n  .querySelectorAll(\n    '.remark-slide-content' +\n    ':not(.title-slide)' +\n    // add additional classes to exclude here, e.g.\n    // ':not(.inverse)' +\n    ':not(.hide-logo)'\n  )\n  .forEach(el =&gt; {\n    el.innerHTML += '&lt;div class=\"logo\"&gt;&lt;/div&gt;';\n  });\n&lt;/script&gt;\nIf you‚Äôd like to automatically keep the logo off certain slides, like the inverse slides, you can add additional :not(.class-to-exclude) to the CSS selector in the .querySelectorAll().\n\n\n\nThe xaringan logo appears on all the slides!"
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html",
    "title": "Use Google Forms and R to track data easily",
    "section": "",
    "text": "I‚Äôm going to show you a quick-and-dirty way to use Google Forms and a smartphone for in-the-field data collection. Of course, for me ‚Äúin-the-field data collection‚Äù really means keeping track of how much I weigh or how many cups of coffee I drank, but Google Forms is a powerful and versatile online form platform that can do a whole lot more.\nI‚Äôve tried other ‚Äúlife logging‚Äù apps, and while they‚Äôre useful at times, I‚Äôve found that all I really want is an easy to update spreadsheet. It turns out that a link to a Google Form on my iPhone is the perfect balance between ease and control.\nSo far, I‚Äôve used this method as a time card to track working hours, to track my daily weight, to stay on top of a group project, and to monitor the chemical balance and consumption of my pool. With Google Forms it‚Äôs easy to design a form that specifically fits your needs ‚Äì I‚Äôm sure there are a lot of other great ways this setup could be used."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#create-the-form",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#create-the-form",
    "title": "Use Google Forms and R to track data easily",
    "section": "Create the form",
    "text": "Create the form\nFire up Google Docs and create a new form from the ‚ÄúCreate‚Äù button. Give your form a name and pick a theme. The simpler themes tend to look better on mobile browsers; I tend to pick Dark Grey, but today I chose Magazine.\n\nGoogle will ask you if you want to save the responses in a separate spreadsheet, which seems like a good idea. Give the spreadsheet the name you want and move to the next step‚Ä¶ actually building the form.\nAdd the form items that you need, and try to find a balance between ease of collection and integrity of the data. I‚Äôve found that for numerical entries, the Plain Text format works best. If you want to allow multiple selections from a predetermined list, choose Checkboxes and then add your options. These will be stored in your spreadsheet as a single cell with a list of the selected options, ie: \"Option 1, Option 3\". You can also have a slider input on a scale of 1-5 or 0-10, but if precision is important ‚Äì eg. you might need to record 6.7 ‚Äì then skip this and use the plain text format.\n\nFor a the select only one option type item, the Choose from a list option works best, and shows up on the iPhone as a rolodex list. As an example, I‚Äôve added a question for the number of cups of coffee I‚Äôve had today.\n\nWhen you‚Äôre done with the questions, edit the form submitted confirmation response to something validating, like Good work, dude!, and decide if you want to allow edits. Then click Send Form and send the form to an email address that gets delivered to your phone."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#get-smart-with-your-phone",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#get-smart-with-your-phone",
    "title": "Use Google Forms and R to track data easily",
    "section": "Get smart with your phone",
    "text": "Get smart with your phone\nCheck your email on your phone and pull up the form you just created. It should look something like this.\n\nEnter your first data item. Here you can see the ‚Äúrolodex‚Äù selector is easy to use for a short list of about 5 or less options.\n\nIf you‚Äôre using Safari, then while you‚Äôre on the form page, tap the bookmark button and choose Add to Home Screen. Make sure you give the new link a short name so it displays nicely on the home screen. Now you‚Äôve got easy access to your form from your phone."
  },
  {
    "objectID": "blog/use-google-forms-and-r-to-track-data-easily/index.html#spreadsheets",
    "href": "blog/use-google-forms-and-r-to-track-data-easily/index.html#spreadsheets",
    "title": "Use Google Forms and R to track data easily",
    "section": "Spreadsheets",
    "text": "Spreadsheets\nNow that you‚Äôre set up with easy data collection from your phone, you‚Äôll want to do something with the data you‚Äôre collecting. All of the entries you submit are collected by Google into a spreadsheet you named at the beginning of the process.\n\nFrom here you can create graphs and charts, calculate summary statistics, etc. Everything a spreadsheet was meant to be. Of course, it‚Äôs best to do any calculations on a new sheet so that your work isn‚Äôt lost when new responses are recorded. One limitation I‚Äôve found is that columns are added to the spreadsheet as the items are added, so if you add a new item or rearrange questions in your form, the spreadsheet columns will be disorganized.\nOne of the greatest benefits of using Google Forms is that every entry is time stamped. Google‚Äôs timeline visualization is excellent, and once you have the data together it‚Äôs as easy as adding a chart."
  },
  {
    "objectID": "blog/up-and-running/index.html",
    "href": "blog/up-and-running/index.html",
    "title": "Up and running‚Ä¶",
    "section": "",
    "text": "Update: No more Wordpress! It‚Äôs all Octopress up in here now.\nLooks like I‚Äôve got my new webpage up and running now. I‚Äôm really liking this theme. Okay, productive procrastination time is over now, time to get back to the real work."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "",
    "text": "I‚Äôve recently taken a hard dive into the deeply fragmented world of plaintext formatted markup languages. I currently have about 90 tabs open, each a winding, twisting trail leading through the world of Markdown, Multimarkdown, Pandoc, LaTeX, MathML, MathJax, and the other 500 slightly tweaked variants thereof.\nThis post is more of a way for me to plot the easiest path to get to where I am now ‚Äî a reference for the next time I have to do this. Maybe you‚Äôll find it useful. The world of markup languages, apps, helpers, commandline tools and viewers is littered with github pages, scripts left in github gists and fixes mentioned deep in the comments of support threads.\nSo, in hopes that this helps somebody else out, here are the apps and languages I have settled into. Today at least. We‚Äôll see how long it all lasts."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#why-markdown-why-not-just-use-word-or-latex",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#why-markdown-why-not-just-use-word-or-latex",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "Why Markdown? Why not just use Word? Or LaTeX?",
    "text": "Why Markdown? Why not just use Word? Or LaTeX?\nBecause Word makes documents that look like shit. Because I put a lot of blood, tears and sweat into what I write and I‚Äôve seen too many hours lost to Word documents corrupted by one equation too many. Because Cambria Math makes equations that just look bad. Math is beautiful; I want a serious looking math font. Because you cannot change the default math font in Word (at least on Macs). Because writing should be easier.\nOn the flip side, when I write in LaTeX, I spend way too much time trying to figure out what commands will format text the way I want. Sure, the math is pretty and as long as I stick to the basic document classes things tend to look good. But the structure of Markdown is just so much easier that it gets out of the way of what I want to say. When you need the power of LaTeX, then it‚Äôs incredible. But mostly when I write in LaTeX I can‚Äôt help but constantly think of what could be."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-looking-for",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-looking-for",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "What I‚Äôm looking for",
    "text": "What I‚Äôm looking for\nSo now that I know what I don‚Äôt want, here‚Äôs the short list of what I do want. Note that these intersect with the latest discussions about scholarly markdown.\n\nPlays well with math\nCan handle citations (or not mess them up too bad)\nTables are a plus\nFootnotes etc are cool, but not necessary\nPorts nicely to LaTeX, HTML, PDF and docx\n\nThat last one is huge. I once spent ~24 hours converting a paper written in Word to LaTeX because the equations were crashing Word and corrupting the file. Only to find out two weeks later that the funding agency only accepted .docx formats. Not funny."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-using-now",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#what-im-using-now",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "What I‚Äôm using now",
    "text": "What I‚Äôm using now\nLet‚Äôs follow the writing flow.\n\nCreate the empty .mmd file somewhere where you want the file to be.\nText is written in plain text editor, preferably something that can highlight Markdown syntax. I‚Äôm using TextWrangler, but this choice is fluid.\nText is written in Pandoc extended markdown. Pandoc markdown lets you write LaTeX, and the benefits of being able to easily dump into .pdf, .docx, .tex, and .justaboutanything far outweigh the missing MultiMarkdown features.\nAs I write, I use the Marked.app to preview the document every time I hit ‚åò+s. But Marked doesn‚Äôt render Pandoc extended markdown. Luckily there‚Äôs a workaround that I‚Äôll talk about below.\nFinal versions can be turned into the right format using the pandoc command line. I haven‚Äôt learned the ins-and-outs of this yet, but the Pandoc demo page has cut-and-paste commands to do basically anything you can think of, at least in a basic version.\n\nThis is as far as I‚Äôve needed to go to date. There‚Äôs a lot more to learn, but this should be enough to get anybody started.\n\nWhat‚Äôs left to learn\n\nCitations\n\nI have a master .bib file for my citations so I can use any citekey from my library and know that they‚Äôll show up as long as I point pandoc to my bibtex file. That can be done using the following flag:--bibliography=/Users/.../Documents/PapersLibraryFull.bib\nDownload citation styles from zotero.org and save them somewhere safe. I‚Äôve created a folder in my home directory ~/.pandoc for storing these things, and I put my .csl files in ~/.pandoc/csl.To specify the citation style, use the --csl flag:--csl /Users/.../.pandoc/csl/ieee-with-url.csl\nIt‚Äôd be nice if the citation were inserted as a link to the full reference in the references section. This may be possible and I just haven‚Äôt figured it out yet.\n\nFormatting\n\nI know it‚Äôs possible to make very nice looking documents with pandoc templates. I just don‚Äôt know how to do this yet.\n\nEvernote\n\nI also need to figure out the best way to write text in this way and import into Evernote."
  },
  {
    "objectID": "blog/the-pandoc-markdown-rabbit-hole/index.html#pandoc-marked.app",
    "href": "blog/the-pandoc-markdown-rabbit-hole/index.html#pandoc-marked.app",
    "title": "The Pandoc Markdown rabbit hole",
    "section": "Pandoc + Marked.app",
    "text": "Pandoc + Marked.app\nBig thanks go to kjhealy for posting this shell script (and templates) to use Pandoc to render HTML in Marked.app.\nWhile I haven‚Äôt figured out how to use the pandoc templates he has developed, the shell script is phenomenal and works very well within Marked. I did make some changes to point pandoc to my Papers library bibtex file and to specify the citation style in advance.\n\nDownload and unzip the pandoc-templates package.\nOpen the preferences panel in Marked, and under the Styles tab add the .css files included in kjhealy‚Äôs package.\nThen, copy panmarked.sh somewhere central, like your home folder and open it in your favorite text editor.\nChange the bibliography flag to point at the right .bib file.\nAdd the --csl flag I mentioned above with the correct citation style.\nSave the edited file.\nIn the Behavior tab, enable Custom Markdown Processor and enter the full path to your edited panmarked.sh file.\nClick save.\nEnjoy beautifully rendered Pandoc markdown.\n\nYou can then edit panmarked.sh anytime to change the flags or arguments. You could also in theory copy the arguments into the Args box in the Marked app preference pane, but that box is small. Plus, it would have taken my way too long to figure that out from scratch, so big thanks again to kjhealy."
  },
  {
    "objectID": "blog/the-book-of-us/index.html",
    "href": "blog/the-book-of-us/index.html",
    "title": "The Book of Us",
    "section": "",
    "text": "My little sister got married in November (and then turned 24 in December), so I wrote her a birthday/belated wedding song for her and her new husband."
  },
  {
    "objectID": "blog/the-book-of-us/index.html#the-book-of-us",
    "href": "blog/the-book-of-us/index.html#the-book-of-us",
    "title": "The Book of Us",
    "section": "The Book of Us",
    "text": "The Book of Us\nThe book began as an empty page\nI held the pen in my hand like a weather vane\nThen you walked in to my masquerade\nAnd that‚Äôs where we begin\nOur chapter opens in a cave\nWhen you stepped in to get out of the rain\nI gave you a made up name\nBut you played me at my game\nWhen I turn the page, we‚Äôre in a park\nReading words written from the heart\nIn the setting sun I‚Äôm a question mark\nQuivering in the dark\nWill you set me free when you‚Äôre lying next to me?\nWill time step aside when you say that you are mine?\nWill I read it in your eyes?\nSuddenly my life is a cosmic blur\nOf the city streets that we explore\nDiscovering what the word love is for\nWhen I hold you in my arms\nThen our chapter comes to its end\nWith sad goodbyes and I‚Äôll see you when\nI‚Äôll hold you in my heart till then\nAnd we‚Äôll write our book again\nChorus\nBut time knows better than we do, we do\nI never lost my state of mind when I‚Äôm with you\nI will always find my way to you, find me way back to you\nHere you‚Äôre standing next to me, I pledge my life to you\nI read your words and know that‚Ä¶\nChorus"
  },
  {
    "objectID": "blog/shiny-tip-option-where-to-run/index.html",
    "href": "blog/shiny-tip-option-where-to-run/index.html",
    "title": "Shiny Tip: Choose Where to Run App with an Option",
    "section": "",
    "text": "When you‚Äôre running a Shiny app from a source file, like app.R in RStudio, you can choose to run the app in the Viewer Pane, a new Window, or in an External browser window.\nThis works well for typical Shiny apps in app.R or {global,ui,server}.R, but if you‚Äôre building a Shiny app inside an R package ‚Äî and if you are, then definitely check out ThinkR‚Äôs golem package ‚Äî then that little Run App button won‚Äôt be available to choose where to run your Shiny apps.\nThe Shiny runApp() help documentation mentions the global option shiny.launch.browser but this helpful StackOverflow answer provided a helpful hint as to how to actually pick the Viewer, Window or External location for newly launched Shiny apps.\nThe following options only work in RStudio, and definitely in RStudio 1.2 (I‚Äôm running 1.2.1511). If you want to set these options globally in your ~/.Rprofile, then I‚Äôd recommend adding a conditional guard to check that RStudio is running first."
  },
  {
    "objectID": "blog/shiny-tip-option-where-to-run/index.html#rstudio-shiny.launch.browser-options",
    "href": "blog/shiny-tip-option-where-to-run/index.html#rstudio-shiny.launch.browser-options",
    "title": "Shiny Tip: Choose Where to Run App with an Option",
    "section": "RStudio shiny.launch.browser Options",
    "text": "RStudio shiny.launch.browser Options\n\nRun in Viewer\noptions(shiny.launch.browser = .rs.invokeShinyPaneViewer)\n\n\nRun in Window\noptions(shiny.launch.browser = .rs.invokeShinyWindowViewer)\n\n\nRun in External Browser\noptions(shiny.launch.browser = .rs.invokeShinyWindowExternal)"
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html",
    "title": "Remember markdown compile commands with bash",
    "section": "",
    "text": "I write everything in markdown and use pandoc nearly daily. It‚Äôs fast, easy, powerful and highly customizable. It handles math like a pro, and the recent addition of YAML headers makes it easier than ever to write and compile well-formatted documents that I can easily send to the web, print, or email to collaborators still stuck in Word.\nBecause pandoc separates form from content, reformatting citations, for example is as simple as changing the command from pandoc ... --csl=bad_style.csl to pandoc ... --csl=good_style.csl. Changing templates and fonts and bibliography files are just as easy.\nWhat‚Äôs hard is remembering exactly what series of commands I used to compile a document when I come back to it to make changes a week or even a few days later.\nMatt Might recently posted an excellent guide to using Bash, the Unix scripting and terminal language. Bash can be odd, but it‚Äôs certainly powerful. In fact, I use it frequently to outsource my memory and only really use the first 1% of what he teaches in his blog post."
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html#it-gets-better",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html#it-gets-better",
    "title": "Remember markdown compile commands with bash",
    "section": "It gets better‚Ä¶",
    "text": "It gets better‚Ä¶\nAnother neat trick I picked up from this StackOverflow answer allows me to automate away all the typing out of extensions. With one additional line, the script below will strip the extension from the first argument, and add the second argument as the output extension. When combined with pandoc, this automatically sets the output type.\nTo compile 04-CHEM101-HW-BlahBlahBlah.markdown into PDF, simply run your compile script like this ./mycompile.sh 04-CHEM101-HW-BlahBlahBlah.markdown pdf. To compile again into Word format, just delete pdf and replace with docx.\nI am possibly too excited about this, but if you have any number of arguments in your pandoc script scrolling back through the lines of arguments is one more time suck you can avoid with a tiny bit of bash scripting. Love it.\n#!/bin/bash\n# input is ./script &lt;input file&gt; &lt;output extension&gt;\nname=`echo $1 | cut -f1 -d'.'`\npandoc $1 -o $name.$2 --bibliography=/path/to/library.bib --csl /path/to/citation_style.csl"
  },
  {
    "objectID": "blog/remember-markdown-compile-commands-with-bash/index.html#footnotes",
    "href": "blog/remember-markdown-compile-commands-with-bash/index.html#footnotes",
    "title": "Remember markdown compile commands with bash",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nUsually only when the working directory is not in my Dropbox folder. And also separately from any git repos.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/pupsters-at-the-window/index.html",
    "href": "blog/pupsters-at-the-window/index.html",
    "title": "The pupsters at the window",
    "section": "",
    "text": "The pupsters at the window.\n\n\n\n\n\nThe pupsters at the window."
  },
  {
    "objectID": "blog/new-website/index.html",
    "href": "blog/new-website/index.html",
    "title": "New Website",
    "section": "",
    "text": "Well hello there.\nI‚Äôm not exactly new to blogging. I‚Äôve started plenty of blogs in my life. Each new blog is an empty notebook, full of promise of a new project, a new stream of ideas, a new list of things to do, a new stream of creative surges and the vast empty space of 100 blank pages to hold them all.\nBut my notebooks are only half full. (Or is it half empty?) I never seem to make it all the way through before a new notebook comes along, or a new project or turn in my life creates a thematic change that requires breaking out of the old patterns of the old notebook.\nSo let‚Äôs hope this online notebook gets some notes. In the mean time, why not stalk me find out what I‚Äôm up to on twitter"
  },
  {
    "objectID": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html",
    "href": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html",
    "title": "Lookup Citation Counts with R and rcrossref",
    "section": "",
    "text": "An R script and function that takes a citation key as a unique identifier for a paper and outputs the paper‚Äôs citation count.\nTo make it work you need to have your references stored in a BibTeX file with DOIs. The script looks up the citation key in the BibTeX file, and uses rcrossref to look up the citation count on CrossRef.\n\nAnd here‚Äôs the link to the script as a GitHub Gist."
  },
  {
    "objectID": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html#footnotes",
    "href": "blog/lookup-citation-counts-with-r-and-rcrossref/index.html#footnotes",
    "title": "Lookup Citation Counts with R and rcrossref",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can download the code & files from the gist, or clone the gist from the command line by using: git clone https://gist.github.com/9b5609a6154753394f1a.git‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/educating-engineers-for-sustainability/index.html",
    "href": "blog/educating-engineers-for-sustainability/index.html",
    "title": "Educating Engineers for Sustainability",
    "section": "",
    "text": "I had the great pleasure of spending some time with Dr.¬†Richard Fenner, of the University of Cambridge, who is in the process of writing a new book on educating engineers for sustainability.\nThe talk was subtitled ‚ÄúPrinciples into Practice,‚Äù which is also the subtitle of his forthcoming book.\nI realized, through our talks and during his presentation, that while we have been very good as a culture at educating engineers in the application of scientific principles, we‚Äôve also created a breed of engineer that learns¬†how to solve a problem in a particular way‚Ä¶ at which point many new problems look like old problems and get solved in old, familiar ways.\nHe gave the example of the Army Corps of Engineers in the New Deal days, who were completely capable of damming rivers that had no business being dammed, only because they were good at building dams and had the money and skill to do so.\nI have friends who spend much of their lives lobbying for the removal of these dams. It turns out a dam that has no business being a dam is also highly detrimental to the local ecology.\nIt was great to hear his views on educating engineers in the new design criteria of sustainable development, and we had a few great conversations about what exactly sustainable actually means.\nHis program, like the masters program at the Patel School for Global Sustainability, trains students in critical sustainability practices, philosophies and ways of thinking. As an engineer ‚Äì or at least as a graduate of a highly engineering-focused school ‚Äì it was great to hear about new programs that build sustainability thinking on top of the foundation of engineering and ‚Äúhard science.‚Äù\nI look forward to reading Dr.¬†Fenner‚Äôs book when it is published ‚Äì I‚Äôll be sure to share it here."
  },
  {
    "objectID": "talk/sliding-in-style-south-coast-ma/index.html#abstract",
    "href": "talk/sliding-in-style-south-coast-ma/index.html#abstract",
    "title": "Sliding in Style",
    "section": "Abstract",
    "text": "Abstract\nThe xaringan package by YiHui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens.\nTogether we‚Äôll create a completely customized xaringan slide style with xaringanthemer, a package that lets you quickly create a complete slide theme from only a few color choices. Then we‚Äôll talk about how you can take your slide design one step further with just a little bit of CSS."
  },
  {
    "objectID": "talk/sliding-in-style-south-coast-ma/index.html#packages",
    "href": "talk/sliding-in-style-south-coast-ma/index.html#packages",
    "title": "Sliding in Style",
    "section": "Packages",
    "text": "Packages\n\nxaringan\nxaringanthemer\nxaringanExtra\nlorem\n\n# On CRAN\ninstall.packages(\"xaringan\")\ninstall.packages(\"xaringanthemer\", dependencies = TRUE)\n\n# From GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")\nremotes::install_github(\"gadenbuie/lorem\")\nIf you use [docker], you can get set up with an [environment for this presentation][docker-image] with:\ndocker run -d --rm -p 8787:8787 -e DISABLE_AUTH=true grrrck/sliding-in-style"
  },
  {
    "objectID": "talk/index.html",
    "href": "talk/index.html",
    "title": "Talks and Presentations",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n{epoxy}\n\n\n\n\n\n\nConference\n\n\n\nSuper glue for data-driven reports and Shiny apps. \n\n\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nSeamless data-driven reporting with {epoxy}\n\n\n\n\n\n\nConference\n\n\n\n{epoxy} is a new R package that allows report authors to seamlessly blend prose and data in markdown, HTML, and LaTeX reports. \n\n\n\n\n\nJun 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional, Polished, Presentable\n\n\nMaking great slides with xaringan\n\n\n\nWorkshop\n\n\n\nA useR!2021 tutorial about making great slides with xaringan. \n\n\n\n\n\nJul 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nSliding in Style\n\n\n\n\n\n\nTalk\n\n\n\nMake stylish slides with {xaringanthemer} and a little bit of CSS. \n\n\n\n\n\nApr 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Extra Great Slides\n\n\nWith xaringan, xaringanthemer, and xaringanExtra\n\n\n\nTalk\n\n\n\nA brief introduction to the {xaringan} package and how you can make your slides look great with {xaringanthemer} and stand out with {xaringanExtra}. \n\n\n\n\n\nMar 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown: An Incomplete History\n\n\n\n\n\n\nTalk\n\n\n\nAn incomplete history of the literate programming origins of R Markdown. Plus some cool things I‚Äôm tinkering with: {epoxy} and {shinyComponents}. \n\n\n\n\n\nFeb 11, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nxaringan Playground\n\n\n\n\n\n\nConference\n\n\n\nMaking slides with xaringan is a great way to learn more about CSS and web development. \n\n\n\n\n\nJan 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Your Own Universe\n\n\n\n\n\n\nConference\n\n\n\nScale high-quality research data provisioning with R packages package. \n\n\n\n\n\nAug 28, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nYour Slides are So Extra!\n\n\nExtra-Special Presentations with xaringanExtra\n\n\n\nConference\n\n\n\nA presentation writing and benefiting from programming with functions. \n\n\n\n\n\nJul 8, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n10,000 Reasons to Love Functions\n\n\n\n\n\n\nEducation\n\n\n\nA presentation writing and benefiting from programming with functions. \n\n\n\n\n\nMay 15, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nExtra Awesome xaringan Presentations\n\n\n\n\n\n\nTalk\n\n\n\nA brief introduction to the {xaringan} package and how you can make your slides look great with {xaringanthemer} and stand out with {xaringanExtra}. \n\n\n\n\n\nFeb 25, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nJavaScript for Shiny Users\n\n\n\n\n\n\nWorkshop\n\n\n\nA two-day workshop to get you up and running with JavaScript in Shiny and interactive R Markdown documents. \n\n\n\n\n\nJan 27, 2020\n\n\n\n\n\n\n\n\n\n\n\n\nReproducible Data Workflows With Drake\n\n\n\n\n\n\nEducation\n\n\n\nA gentle introduction to reproducible data workflows with the {drake} package. \n\n\n\n\n\nJul 19, 2019\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Guide to the Grammar of Graphics with ggplot2\n\n\n\n\n\n\nEducation\n\n\n\nAn intruction to data visualization with ggplot2 presented at the ‚ÄúWorkshop on Data Analysis Using R‚Äù hosted by the ASA student chapter at USF. \n\n\n\n\n\nNov 6, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nThe Passive Smart Home: Unobtrusive At-Home Behavior Monitoring\n\n\n\n\n\n\nConference\n\n\n\nPresented at the ‚ÄúUtilizing Technology for Data Collection and Intervention‚Äù mini-conference at Moffitt Cancer Center\n\n\n\n\n\nOct 29, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nUnsupervised behavior change detection using passive sensor systems in the homes of older adults\n\n\n\n\n\n\nConference\n\n\n\nPresented at the 11th World Conference of Gerontechnology in St.¬†Petersburg, FL.\n\n\n\n\n\nMay 7, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nA Gentle Guide to the Grammar of Graphics with ggplot2\n\n\n\n\n\n\nEducation\n\n\n\nAn introduction to data visualization using ggplot2 presented at the Tampa R Users Group on 2018-01-23. \n\n\n\n\n\nJan 23, 2018\n\n\n\n\n\n\n\n\n\n\n\n\nOccupant Activity Profiles from Smart Home Sensor Event Streams\n\n\n\n\n\n\nConference\n\n\n\n\n\n\n\n\n\nOct 25, 2017\n\n\n\n\n\n\n\n\n\n\n\n\ngetting staRted in R\n\n\n\n\n\n\nEducation\n\n\n\n\n\n\n\n\n\nMar 25, 2016\n\n\n\n\n\n\n\n\n\n\n\n\nAmbient Intelligence Applications in Healthcare\n\n\n\n\n\n\nConference\n\n\n\n\n\n\n\n\n\nFeb 6, 2015\n\n\n\n\n\n\n\n\n\n\n\n\nReporting Reproducible Research with R and Markdown\n\n\n\n\n\n\nEducation\n\n\n\n\n\n\n\n\n\nApr 11, 2014\n\n\n\n\n\n\n\n\n\n\n\n\nBoosted Tree Ensembles for Predicting Postsurgical ICU Mortality\n\n\n\n\n\n\nConference\n\n\n\n\n\n\n\n\n\nOct 7, 2013\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "talk/extra-great-slides-nyhackr/index.html#abstract",
    "href": "talk/extra-great-slides-nyhackr/index.html#abstract",
    "title": "Making Extra Great Slides",
    "section": "Abstract",
    "text": "Abstract\nThe xaringan package by YiHui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens.\nIn addition to demonstrating how to go from R Markdown to web-based slides with xaringan, in this talk I‚Äôll show you how to completely customize the appearance of your slides with xaringanthemer, a package that lets you quickly create a complete slide theme from only a few color choices.\nThen we‚Äôll go beyond appearances with a variety of addins and extensions from the xaringanExtra package, including: a tiled slide overview, editable slides, embedded webcam videos, tabbed panels, extra styles, shareable and embeddable slides, animations, and real time slide broadcasting."
  },
  {
    "objectID": "talk/extra-great-slides-nyhackr/index.html#packages",
    "href": "talk/extra-great-slides-nyhackr/index.html#packages",
    "title": "Making Extra Great Slides",
    "section": "Packages",
    "text": "Packages\n\nxaringan\nxaringanthemer\nxaringanExtra\nxaringanBuilder\nmetathis\n\n# On CRAN\ninstall.packages(\"xaringan\")\ninstall.packages(\"xaringanthemer\")\ninstall.packages(\"metathis\")\n\n# From GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")\nremotes::install_github(\"jhelvy/xaringanBuilder\")\nremotes::install_github(\"gadenbuie/countdown\")"
  },
  {
    "objectID": "talk/build-your-own-universe/index.html#abstract",
    "href": "talk/build-your-own-universe/index.html#abstract",
    "title": "Build Your Own Universe",
    "section": "Abstract",
    "text": "Abstract\n\nInstitutional honest brokers consolidate patient, clinical, and lab data from a variety of data sources in order to provide investigators with research-ready data sets. High-quality research data provisioning requires skilled navigation of heterogeneous software systems and a detailed understanding of data structure standards within each source. In this talk we discuss how we, as honest brokers at a large cancer center, have created a universe of internal R packages that simplify data access, store and present metadata, standardize best practices, support reproducibility and repeatability, apply branding styles to reports and visualizations, and facilitate communication with the research data end user. Our package ecosystem simplifies the workflow of honest brokers to scale curation and delivery of high-quality research data."
  },
  {
    "objectID": "project/xaringanthemer/index.html",
    "href": "project/xaringanthemer/index.html",
    "title": "üé® xaringanthemer",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\nGive your xaringan slides some style with xaringanthemer within your slides.Rmd file without (much) CSS."
  },
  {
    "objectID": "project/xaringanthemer/index.html#installation",
    "href": "project/xaringanthemer/index.html#installation",
    "title": "üé® xaringanthemer",
    "section": "Installation",
    "text": "Installation\nxaringanthemer currently lives on GitHub.\n# install.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/xaringanthemer\")\nRead on for a quick overview, or read through the xaringanthemer documentation for more information."
  },
  {
    "objectID": "project/xaringanthemer/index.html#usage",
    "href": "project/xaringanthemer/index.html#usage",
    "title": "üé® xaringanthemer",
    "section": "Usage",
    "text": "Usage\n\nFirst, add the xaringan-themer.css file to the YAML header of your xaringan slides.\noutput:\n  xaringan::moon_reader:\n    lib_dir: libs\n    css: xaringan-themer.css\nThen, in a hidden chunk just after the knitr setup chunk, load xaringanthemer and try one of the theme functions.\n```{r xaringan-themer, include = FALSE}`r \"\"`\nlibrary(xaringanthemer)\nmono_light(\n  base_color = \"#1c5253\",\n  header_font_google = google_font(\"Josefin Sans\"),\n  text_font_google   = google_font(\"Montserrat\", \"300\", \"300i\"),\n  code_font_google   = google_font(\"Droid Mono\")\n)\n```\n\n\n\nxaringanthemer example with mono_light theme\n\n\n\nTab Completion\nxaringanthemer is Tab friendly ‚Äì use autocomplete to explore the template variables that you can adjust in each of the themes!\n\n\n\nxaringanthemer rstudio autocompletion example\n\n\n\n\nR Markdown Template in RStudio\nYou can also skip the above and just create a Ninja Themed Presentation from the New R Markdown Document menu in RStudio.\n\n\n\n\nrstudio xaringanthemer rmarkdown template\n\n\n\n\nxaringanthemer was built by Garrick Aden-Buie (@grrrck).\nBig thank you to Yihui Xie, especially for xaringan. Also thanks to Ole Petter Bang for remark.js.\nFeel free to file an issue if you find a bug or have a theme suggestion ‚Äì or better yet, submit a pull request!"
  },
  {
    "objectID": "project/tidyexplain/index.html",
    "href": "project/tidyexplain/index.html",
    "title": "ü§π tidyexplain",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\n\nMutating Joins ‚Äî inner_join(), left_join(), right_join(), full_join()\nFiltering Joins ‚Äî semi_join(), anti_join()\nSet Operations ‚Äî union(), union_all(), intersect(), setdiff()\nTidy Data ‚Äî pivot_wider() and pivot_longer(), spread() and gather()\nLearn more about\n\nUsing the animations and images\nRelational Data\ngganimate"
  },
  {
    "objectID": "project/tidyexplain/index.html#tidy-animated-verbs",
    "href": "project/tidyexplain/index.html#tidy-animated-verbs",
    "title": "ü§π tidyexplain",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\n\nMutating Joins ‚Äî inner_join(), left_join(), right_join(), full_join()\nFiltering Joins ‚Äî semi_join(), anti_join()\nSet Operations ‚Äî union(), union_all(), intersect(), setdiff()\nTidy Data ‚Äî pivot_wider() and pivot_longer(), spread() and gather()\nLearn more about\n\nUsing the animations and images\nRelational Data\ngganimate"
  },
  {
    "objectID": "project/tidyexplain/index.html#background",
    "href": "project/tidyexplain/index.html#background",
    "title": "ü§π tidyexplain",
    "section": "Background",
    "text": "Background\n\nUsage\nPlease feel free to use these images for teaching or learning about action verbs from the tidyverse. You can directly download the original animations or static images in svg or png formats, or you can use the scripts to recreate the images locally.\nCurrently, the animations cover the dplyr two-table verbs and I‚Äôd like to expand the animations to include more verbs from the tidyverse. Suggestions are welcome!\n\n\nRelational Data\nThe Relational Data chapter of the R for Data Science book by Garrett Grolemund and Hadley Wickham is an excellent resource for learning more about relational data.\nThe dplyr two-table verbs vignette and Jenny Bryan‚Äôs Cheatsheet for dplyr join functions are also great resources.\n\n\ngganimate\nThe animations were made possible by the newly re-written gganimate package by Thomas Lin Pedersen (original by Dave Robinson). The package readme provides an excellent (and quick) introduction to gganimate.\n\n\nDynamic Animations\nThanks to an initial push by David Zimmermann, we have begun work towards functions that generate dynamic animations from users‚Äô actual data. Please visit the pkg branch of the tidyexplain repository for more information (or to contribute!)."
  },
  {
    "objectID": "project/tidyexplain/index.html#mutating-joins",
    "href": "project/tidyexplain/index.html#mutating-joins",
    "title": "ü§π tidyexplain",
    "section": "Mutating Joins",
    "text": "Mutating Joins\n\nA mutating join allows you to combine variables from two tables. It first matches observations by their keys, then copies across variables from one table to the other.\nR for Data Science: Mutating joins\n\n\nx\n#&gt; # A tibble: 3 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 x1   \n#&gt; 2     2 x2   \n#&gt; 3     3 x3\ny\n#&gt; # A tibble: 3 √ó 2\n#&gt;      id y    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 y1   \n#&gt; 2     2 y2   \n#&gt; 3     4 y4\n\nInner Join\n\nAll rows from x where there are matching values in y, and all columns from x and y.\n\n\ninner_join(x, y, by = \"id\")\n#&gt; # A tibble: 2 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2\n\n\nLeft Join\n\nAll rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns.\n\n\nleft_join(x, y, by = \"id\")\n#&gt; # A tibble: 3 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt;\n\n\nLeft Join (Extra Rows in y)\n\n‚Ä¶ If there are multiple matches between x and y, all combinations of the matches are returned.\n\n\ny_extra # has multiple rows with the key from `x`\n#&gt; # A tibble: 4 √ó 2\n#&gt;      id y    \n#&gt;   &lt;dbl&gt; &lt;chr&gt;\n#&gt; 1     1 y1   \n#&gt; 2     2 y2   \n#&gt; 3     4 y4   \n#&gt; 4     2 y5\nleft_join(x, y_extra, by = \"id\")\n#&gt; # A tibble: 4 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     2 x2    y5   \n#&gt; 4     3 x3    &lt;NA&gt;\n\n\nRight Join\n\nAll rows from y, and all columns from x and y. Rows in y with no match in x will have NA values in the new columns.\n\n\nright_join(x, y, by = \"id\")\n#&gt; # A tibble: 3 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     4 &lt;NA&gt;  y4\n\n\nFull Join\n\nAll rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing.\n\n\nfull_join(x, y, by = \"id\")\n#&gt; # A tibble: 4 √ó 3\n#&gt;      id x     y    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x1    y1   \n#&gt; 2     2 x2    y2   \n#&gt; 3     3 x3    &lt;NA&gt; \n#&gt; 4     4 &lt;NA&gt;  y4"
  },
  {
    "objectID": "project/tidyexplain/index.html#filtering-joins",
    "href": "project/tidyexplain/index.html#filtering-joins",
    "title": "ü§π tidyexplain",
    "section": "Filtering Joins",
    "text": "Filtering Joins\n\nFiltering joins match observations in the same way as mutating joins, but affect the observations, not the variables. ‚Ä¶ Semi-joins are useful for matching filtered summary tables back to the original rows. ‚Ä¶ Anti-joins are useful for diagnosing join mismatches.\nR for Data Science: Filtering Joins\n\n\nSemi Join\n\nAll rows from x where there are matching values in y, keeping just columns from x.\n\n\nsemi_join(x, y, by = \"id\")\n#&gt; # A tibble: 2 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     1 x1   \n#&gt; 2     2 x2\n\n\nAnti Join\n\nAll rows from x where there are not matching values in y, keeping just columns from x.\n\n\nanti_join(x, y, by = \"id\")\n#&gt; # A tibble: 1 √ó 2\n#&gt;      id x    \n#&gt;   &lt;int&gt; &lt;chr&gt;\n#&gt; 1     3 x3"
  },
  {
    "objectID": "project/tidyexplain/index.html#set-operations",
    "href": "project/tidyexplain/index.html#set-operations",
    "title": "ü§π tidyexplain",
    "section": "Set Operations",
    "text": "Set Operations\n\nSet operations are occasionally useful when you want to break a single complex filter into simpler pieces. All these operations work with a complete row, comparing the values of every variable. These expect the x and y inputs to have the same variables, and treat the observations like sets.\nR for Data Science: Set operations\n\n\nx\n#&gt; # A tibble: 3 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a\ny \n#&gt; # A tibble: 2 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 2     b\n\nUnion\n\nAll unique rows from x and y.\n\n\nunion(x, y)\n#&gt; # A tibble: 4 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a    \n#&gt; 4 2     b\n\nunion(y, x)\n#&gt; # A tibble: 4 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 2     b    \n#&gt; 3 1     b    \n#&gt; 4 2     a\n\n\nUnion All\n\nAll rows from x and y, keeping duplicates.\n\n\nunion_all(x, y)\n#&gt; # A tibble: 5 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a    \n#&gt; 2 1     b    \n#&gt; 3 2     a    \n#&gt; 4 1     a    \n#&gt; 5 2     b\n\n\nIntersection\n\nCommon rows in both x and y, keeping just unique rows.\n\n\nintersect(x, y)\n#&gt; # A tibble: 1 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     a\n\n\nSet Difference\n\nAll rows from x which are not also rows in y, keeping just unique rows.\n\n\nsetdiff(x, y)\n#&gt; # A tibble: 2 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 1     b    \n#&gt; 2 2     a\n\nsetdiff(y, x)\n#&gt; # A tibble: 1 √ó 2\n#&gt;   x     y    \n#&gt;   &lt;chr&gt; &lt;chr&gt;\n#&gt; 1 2     b"
  },
  {
    "objectID": "project/tidyexplain/index.html#tidy-data",
    "href": "project/tidyexplain/index.html#tidy-data",
    "title": "ü§π tidyexplain",
    "section": "Tidy Data",
    "text": "Tidy Data\nTidy data follows the following three rules:\n\nEach variable has its own column.\nEach observation has its own row.\nEach value has its own cell.\n\nMany of the tools in the tidyverse expect data to be formatted as a tidy dataset and the tidyr package provides functions to help you organize your data into tidy data.\n\nwide\n#&gt; # A tibble: 2 √ó 4\n#&gt;      id x     y     z    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 a     c     e    \n#&gt; 2     2 b     d     f\nlong\n#&gt; # A tibble: 6 √ó 3\n#&gt;      id key   val  \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x     a    \n#&gt; 2     2 x     b    \n#&gt; 3     1 y     c    \n#&gt; 4     2 y     d    \n#&gt; 5     1 z     e    \n#&gt; 6     2 z     f\n\nPivot Wider and Longer\npivot_wider() and pivot_longer() were introduced in tidyr version 1.0 (released in September 2019). They provide a more consistent and more powerful approach to changing the fundamental shape of the data and are ‚Äúmodern alternatives to spread() and gather().\nHere we show the very basic mechanics of pivoting, but there‚Äôs much more that the pivot functions can do. You can learn more about them in the Pivoting vignette in tidyr.\npivot_wider(data, names_from = key, values_from = val)\n\npivot_wider() ‚Äúwidens‚Äù data, increasing the number of columns and decreasing the number of rows.\n\npivot_longer(data, cols = x:y, names_to = \"key\", values_to = \"val\")\n\npivot_longer() ‚Äúlengthens‚Äù data, increasing the number of rows and decreasing the number of columns.\n\n\n\n\nSpread and Gather\nspread(data, key, value)\n\nSpread a key-value pair across multiple columns. Use it when an a column contains observations from multiple variables.\n\ngather(data, key = \"key\", value = \"value\", ...)\n\nGather takes multiple columns and collapses into key-value pairs, duplicating all other columns as needed. You use gather() when you notice that your column names are not names of variables, but values of a variable.\n\n\ngather(wide, key, val, x:z)\n#&gt; # A tibble: 6 √ó 3\n#&gt;      id key   val  \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 x     a    \n#&gt; 2     2 x     b    \n#&gt; 3     1 y     c    \n#&gt; 4     2 y     d    \n#&gt; 5     1 z     e    \n#&gt; 6     2 z     f\nspread(long, key, val)\n#&gt; # A tibble: 2 √ó 4\n#&gt;      id x     y     z    \n#&gt;   &lt;int&gt; &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;\n#&gt; 1     1 a     c     e    \n#&gt; 2     2 b     d     f"
  },
  {
    "objectID": "project/shrtcts/index.html",
    "href": "project/shrtcts/index.html",
    "title": "üç∞ shrtcts",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/shrtcts‚Ä¶"
  },
  {
    "objectID": "project/regexplain/index.html",
    "href": "project/regexplain/index.html",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork"
  },
  {
    "objectID": "project/regexplain/index.html#installation",
    "href": "project/regexplain/index.html#installation",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "Installation",
    "text": "Installation\nInstallation is easy with devtools\ndevtools::install_github(\"gadenbuie/regexplain\")\nor for hands-free installation\nsource(\"https://install-github.me/gadenbuie/regexplain\")"
  },
  {
    "objectID": "project/regexplain/index.html#demo",
    "href": "project/regexplain/index.html#demo",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "Try it out!",
    "text": "Try it out!\n\n#| standalone: true\n#| components: [viewer]\n#| viewerHeight: 550\n\nif (!requireNamespace(\"regexplain\", quietly = TRUE)) {\n  install.packages(\"regexplain\", repos = c(\n    \"https://gadenbuie.r-universe.dev\",\n    \"https://repo.r-wasm.org\"\n  ))\n}\n\nlibrary(shiny)\nlibrary(miniUI)\nlibrary(stringr)\nlibrary(regexplain)\n\n\nshinyApp(\n  ui = regexplain:::regexplain_gadget_ui(),\n  server = regexplain:::regexplain_gadget_server(NULL)\n)\n\nThe demo version of regexplain is running in your browser, thanks to shinylive for Quarto, r-wasm, and WASM binaries provided by r-universe.dev. You can also view the app in a separate window thanks to shinylive.io."
  },
  {
    "objectID": "project/regexplain/index.html#regexplain-in-action",
    "href": "project/regexplain/index.html#regexplain-in-action",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "RegExplain in Action",
    "text": "RegExplain in Action\n\nOverview\n\n\n\nRegExplain Selection\n\n\n\n\nRegular Expressions Library\n\n\n\nRegExplain Library\n\n\n\n\nTry the Built-In Examples\n\n\n\nRegExplain Examples"
  },
  {
    "objectID": "project/regexplain/index.html#rstudio-addin",
    "href": "project/regexplain/index.html#rstudio-addin",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "RStudio Addin",
    "text": "RStudio Addin\nThe main feature of this package is the RStudio Addin RegExplain Selection. Just select the text or object containing text (such as the variable name of a vector or a data.frame column) and run RegExplain Selection from the RStudio Addins dropdown.\n\nThe addin will open an interface with 4 panes where you can\n\nedit the text you‚Äôve imported\nbuild up a regex expression and interactively see it applied to your text\ntest the output of common string matching and replacement functions from base and stringr\nand refer to a helpful cheatsheet\n\n  \nWhen you‚Äôre done, click on the Send Regex to Console to send your regex expression to‚Ä¶ the console!\n&gt; pattern &lt;- \"\\\\b(red|orange|yellow|green|blue|purple|white|brown)(?:\\\\s(\\\\w+))?\"\nNotice that RegExplain handled the extra backslashes needed for storing the RegEx characters \\b, \\s, and \\w. Inside the gadget you can use regular old regular expressions as you found them in the wild (hello, Stack Overflow!).\n\nHelp and Cheat Sheet\nThe Help tab is full of resources, guides, and R packages and includes an easy-to-navigate reference of commonly used regular expression syntax.\n  \nOpen RegExplain Cheatsheet from the RStudio Addins drop down to open the regex reference page in the Viewer pane without blocking your current R session.\n\n\nImport Your Text\nThere are two ways to get your text into RegExplain. The first way was described above: select an object name or lines of text or code in the RStudio source pane and run RegExplain Selection. To import text from a file, use RegExplain File to you import the text you want to process with regular expressions.\nWhen importing text, RegExplain automatically reduces the text to the unique entries and limits the number of lines.\n  \n\n\nRegular Expressions Library\nThe RegExplain gadget includes a regular expressions library in the RegEx tab. The library features common regular expressions, sourced from qdapRegex and Regex Hub, with several additional patterns.\nThe full library is stored as a JSON file in inst/extdata/patterns.json, feel free to contribute patterns you find useful or use regularly via pull request."
  },
  {
    "objectID": "project/regexplain/index.html#view-static-regex-results",
    "href": "project/regexplain/index.html#view-static-regex-results",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "View Static Regex Results",
    "text": "View Static Regex Results\nRegExplain provides the function view_regex() that you can use as a stringr::str_view() replacement. In addition to highlighting matched portions of the text, view_regex() colorizes groups and attempts to colorize the regex expression itself as well.\ntext &lt;- c(\"breakfast=eggs;lunch=pizza\",\n          \"breakfast=bacon;lunch=spaghetti\",\n          \"no food here\")\npattern &lt;- \"((\\\\w+)=)(\\\\w+).+(ch=s?p)\"\n\nview_regex(text, pattern)\n  \nt_nested &lt;- \"anestedgroupwithingroupexample\"\nr_nested &lt;- \"(a(nested)(group(within(group))(example)))\"\nview_regex(t_nested, r_nested)"
  },
  {
    "objectID": "project/regexplain/index.html#notes",
    "href": "project/regexplain/index.html#notes",
    "title": "üïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain",
    "section": "Notes",
    "text": "Notes\nRegular expressions are nothing if not a collection of corner cases. Trying to pass regular expressions through Shiny and HTML inputs is a bit of a labyrinth. For now, assume any issues or oddities you experience with this addin are entirely my fault and have nothing to do with the fine packages this addin is built on. If you do find an issue, please file an issue. Pull requests are welcomed!"
  },
  {
    "objectID": "project/mc-test-analysis/index.html",
    "href": "project/mc-test-analysis/index.html",
    "title": "üìö MC Test Analysis",
    "section": "",
    "text": "Jump to: Try Online | Installation | Usage (app | report) | Data Format | Built With\nMany educators design multiple-choice question examination. How do we know that these tests are valid and reliable? How can we improve upon the test by way of modifying, revising and deleting items based on student responses?\nIn a paper in the highly regarded Journal of Engineering Education, Jorion, et al (2016) developed ‚Äúan analytical framework for evaluating the validity of concept inventory claims‚Äù. We believe that we can use this framework to help educators design their multiple-choice tests as well, especially, if they are designed as the final mastery examination in a course. An open source software to analyze a multiple-choice question examination would be encouraging to educators who have minimal programming experience and promising to contributors who would enhance the program.\nThis R package provides useful interfaces and functions to assist with the analysis of data from a typical multiple-choice test. The user needs only to provide an answer key that optionally identifies the concept or topic of each question and a table of responses given by each student to the questions in the test. MCTestAnalysis provides a Shiny web app interface and an automatic report-generation tool featuring concepts from Classical Test Theory (CTT), Item Response Theory (IRT) and structural analysis. We regard this package to be a work-in-progress and encourage contributions. At this time CTT results include item difficulty, item discrimination, Cronbach‚Äôs alpha, and alpha-with-item-deleted. Item response functions include model estimation and item characteristic curves. Tetrachoric and scree plots are included with an introductory exploratory factor analysis."
  },
  {
    "objectID": "project/mc-test-analysis/index.html#try-online",
    "href": "project/mc-test-analysis/index.html#try-online",
    "title": "üìö MC Test Analysis",
    "section": "Try Online",
    "text": "Try Online\nYou can try out the Shiny web interface online at https://apps.garrickadenbuie.com/mctestanalysis/, which demonstrates the test results explorer interface but cannot produce the PDF or HTML reports. For the complete features, you can install the package and use the interface locally (without have to upload your data) by following the instructions below."
  },
  {
    "objectID": "project/mc-test-analysis/index.html#installation",
    "href": "project/mc-test-analysis/index.html#installation",
    "title": "üìö MC Test Analysis",
    "section": "Installation",
    "text": "Installation\nFor more detailed installation requirements and usage instructions, see Get Started.\nIn general, the package can be installed using devtools via\ninstall.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/mctestanalysis\")"
  },
  {
    "objectID": "project/mc-test-analysis/index.html#usage",
    "href": "project/mc-test-analysis/index.html#usage",
    "title": "üìö MC Test Analysis",
    "section": "Usage",
    "text": "Usage\nOpen RStudio or R on the command line or GUI and run the following commands:\nlibrary(MCTestAnalysis)\n\n# Launch test exploration interface\nexplore()\n\n# Create a test analysis report\nreport()\nWhen running explore() a browser window will open with the MC Test Analysis exploration application. The report() function will launch a window within RStudio to guide the user through the creation of a PDF report.\n\nExplore: Shiny App for Interactive Multiple-Choice Test Analysis\nThe explore() function starts a local Shiny app. From this app, the user uploads their answer key and test data and then can view and explore the results of common test analysis methods.\nClick on the image thumbnails below to view examples of the various screens of the MCTestAnalysis explore() app.\n\n\n\n\n\nLoad Data\n\n\n \n\n\n\nClassic Test Theory\n\n\n \n\n\n\nItem Response Theory\n\n\n \n\n\n\nFactor Analysis\n\n\n \n\n\n\nDistractor Analysis\n\n\n \n\n\n\nExport Report\n\n\n\n\n\n\n\n\nReport: A Custom Multiple-Choice Test Analysis Report\nThe report() function opens a window in RStudio that allows the user to import their answer key and test results and quickly generate a custom multiple-choice test analysis as a PDF or HTML file. This report includes all of the information in the explore() app, in addition to helpful background information on the various statistics and visualizations in the report.\nClick here to view an example report (from synthetic data) or click the thumbnails below to view the report() app screens.\n\n\n\n\n\nImport Settings\n\n\n \n\n\n\nLoad Data\n\n\n \n\n\n\nGenerate Report"
  },
  {
    "objectID": "project/mc-test-analysis/index.html#data-format",
    "href": "project/mc-test-analysis/index.html#data-format",
    "title": "üìö MC Test Analysis",
    "section": "Data format",
    "text": "Data format\nThe MCTestAnalysis package requires both an Answer Key and a table of student responses, in other words the Test Data. An example of each table is provided, in the preferred format, in the inst/extdata folder of the repo, or from links on the ‚ÄúImport‚Äù tab of the explore() or report() interfaces.\nA detailed overview of the required data format is available at http://www.eng.usf.edu/~kaw/MCTestAnalysis/MCTestAnalysis_input.pdf. Additional example test results and answer key CSV files are also available.\n\nAnswer Key Format\nThe answer key is a .csv file with columns Question and Answer, with optional columns Title and Concept. The table below shows an example answer key with 5 questions.\n\n\n\nQuestion\nAnswer\nTitle\nConcept\n\n\n\n\nQ1\n3\nQuestion 1\nA\n\n\nQ2\n1\nQuestion 2\nB\n\n\nQ3\n3\nQuestion 3\nC\n\n\nQ4\n4\nQuestion 4\nD\n\n\nQ5\n4\nQuestion 5\nA\n\n\n\n\n\nTest Data Format\nThe test data is also a .csv file, where the first column is optionally the student ID and each column afterwards records the student‚Äôs answer to the test questions. The columns after the student ID need to be in the same order as the answer key. Here are the test responses for the first 5 students to the above example answer key.\n\n\n\nid\nQ1\nQ2\nQ3\nQ4\nQ5\n\n\n\n\nStudent 1\n3\n2\n3\n4\n1\n\n\nStudent 2\n3\n2\n3\n4\n1\n\n\nStudent 3\n3\n1\n3\n2\n4\n\n\nStudent 4\n4\n2\n4\n4\n4\n\n\nStudent 5\n3\n1\n3\n3\n4"
  },
  {
    "objectID": "project/mc-test-analysis/index.html#built-with",
    "href": "project/mc-test-analysis/index.html#built-with",
    "title": "üìö MC Test Analysis",
    "section": "Built on These Great Packages",
    "text": "Built on These Great Packages\nMCTestAnalysis was built by Garrick Aden-Buie and lead by Dr.¬†Autar Kaw. The package was built to be used with R and RStudio, using Shiny for the interactive apps, R Markdown for the custom reports, and ggplot2 for plots. Many test analysis functions used in this package were made available by other packages and R developers, including the following packages: psych, psychometric, ltm, shiny, dplyr, ggplot2, reshape2, rmarkdown, DT, tibble, gridExtra, miniUI."
  },
  {
    "objectID": "project/ggpomological/index.html",
    "href": "project/ggpomological/index.html",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork"
  },
  {
    "objectID": "project/ggpomological/index.html#a-brief-history",
    "href": "project/ggpomological/index.html#a-brief-history",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "A brief history",
    "text": "A brief history\nAron Atkins (@aronatkins) gave a great talk at rstudio::conf 2018 about a subject near and dear to my heart: parameterized RMarkdown. And apples.\n\nI did not know about R Markdown parameterized reports‚Ä¶just params in the YAML and boom! Repeated analyses without messing with the original report code. Also, @aronatkins really likes üçé #rstudioconf pic.twitter.com/g2OC2lTnJc\n‚Äî Larie (@lariebyrd) February 3, 2018\n\nIn his talk, he designed a parameterized RMarkdown report that would provide the user with a customized report for their selected fruit and pulling in images from the USDA Pomological Watercolor Collection. I had never heard of the pomological watercolors ‚Äì or the fan club twitter account @pomological ‚Äì until watching his talk. It‚Äôs a treasure trove of thousands of watercolor images of fruits; beautiful images with intricate details and a very unique and stunning palette. The perfect palette for a custom ggplot2 theme.\n\n\nThe collection spans the years 1886 to 1942. The majority of the paintings were created between 1894 and 1916. The plant specimens represented by these artworks originated in 29 countries and 51 states and territories in the U.S. There are 7,497 watercolor paintings, 87 line drawings, and 79 wax models created by approximately 21 artists. [USDA National Agricultural Library]\n\nI pulled together a small set of functions into a simple package called ggpomological that provides a custom, pomological-inspired ggplot2 theme.\nBefore reading more about ggpomological, you should really check out Aron‚Äôs talk or his slides."
  },
  {
    "objectID": "project/ggpomological/index.html#installation",
    "href": "project/ggpomological/index.html#installation",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Installation",
    "text": "Installation\nggpomological lives on GitHub for now (and probably ever), so you‚Äôll need to use the devtools (or similar) to install:\n# if you don't have devtools\ninstall.packages(\"devtools\")\n\ndevtools::install_github(\"gadenbuie/ggpomological\")"
  },
  {
    "objectID": "project/ggpomological/index.html#color-palette",
    "href": "project/ggpomological/index.html#color-palette",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Color Palette",
    "text": "Color Palette\nThe first thing I did after watching Aron‚Äôs talk was to browse through the pomological watercolors collection, downloading images of a wide variety of fruits. I didn‚Äôt do this in any systematic way, other than occasionally searching for a particular type of fruit, like ‚Äúgrape‚Äù or ‚Äúpapaya‚Äù.\nFrom these images, I used an application (that I installed forever ago and apparently is no longer around) called ColorSchemer Studio to pull out a set of colors that I felt represented the collection.\nI ended up with a lot of colors.\n\nFrom this list, I chose just a few that I thought worked well together for color and fill scales\n\nscales::show_col(ggpomological:::pomological_palette)\n\n\n\n\n\n\n\n\nand a few colors for the plot background and decoration\n\nscales::show_col(unlist(ggpomological:::pomological_base))"
  },
  {
    "objectID": "project/ggpomological/index.html#setup-theme-and-scales",
    "href": "project/ggpomological/index.html#setup-theme-and-scales",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Setup theme and scales",
    "text": "Setup theme and scales\nI created three variants of the theme-generating function theme_pomological().\n\ntheme_pomological() sets the plot theme to be representative of the paper and styling of the watercolors and includes a paper-colored background,\ntheme_pomological_plain() has the same styling, just with a transparent (or white) background,\ntheme_pomological_fancy() has the paper-colored background and defaults to a fancy handwritten font (Homemade Apple).\n\nFor color and fill scales, ggpomological provides scale_color_pomological() and scale_fill_pomological().\nIn the future, I might revisit this package to\n\nIncrease colors in discrete scale\nSetup paired color scales as there are lots of great color pairs in the extracted colors\nSet up continuous scale colors."
  },
  {
    "objectID": "project/ggpomological/index.html#fonts",
    "href": "project/ggpomological/index.html#fonts",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Fonts",
    "text": "Fonts\nTo get the fully authentic pomological look you really need a handwritten font style, and I found a few from Google Fonts that fit the bill.\n\nMr.¬†De Haviland\nHomemade Apple\nMarck Script\nMr.¬†Bedfort\n\nAlternatively, you can use something like calligrapher.com to create your own handwriting font!\nBut fonts can be painful in R, so the base functions ‚Äì theme_pomological() and theme_pomological_plain() ‚Äì don‚Äôt change the font by default. To opt into the full pomological effect, use theme_pomological_fancy() which is just an alias for theme_pomological(base_family = \"Homemade Apple\", base_size = 16)."
  },
  {
    "objectID": "project/ggpomological/index.html#add-paper-background",
    "href": "project/ggpomological/index.html#add-paper-background",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Add paper background!",
    "text": "Add paper background!\nGreat, but I want my plots to look even more pomological, you say?\nPerfect! ggpomological provides a function named paint_pomological that uses the magick package to add a pomological watercolor paper background and a subtle texture overlay."
  },
  {
    "objectID": "project/ggpomological/index.html#demo-time",
    "href": "project/ggpomological/index.html#demo-time",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Demo time!",
    "text": "Demo time!\nWe‚Äôll need ggplot2 (loaded with ggpomological) and dplyr\nlibrary(ggpomological)\nlibrary(dplyr)\n\nBasic iris plot\n\n# Base plot\nbasic_iris_plot &lt;- ggplot(iris) +\n  aes(x = Sepal.Length, y = Sepal.Width, color = Species) +\n  geom_point(size = 2)\n\n# Just your standard Iris plot\nbasic_iris_plot\n\n\n\n\n\n\n\n# With pomological colors\nbasic_iris_plot &lt;- basic_iris_plot + scale_color_pomological()\nbasic_iris_plot\n\n\n\n\n\n\n\n# With pomological theme\nbasic_iris_plot + theme_pomological()\n\n\n\n\n\n\n\n# With transparent background\nbasic_iris_plot + theme_pomological_plain()\n\n\n\n\n\n\n\n# Or with \"fancy\" pomological settings\npomological_iris &lt;- basic_iris_plot + theme_pomological_fancy()\npomological_iris\n\n\n\n\n\n\n\n# Painted!\npaint_pomological(pomological_iris, res = 110) %&gt;%\n  magick::image_write(set_filename(\"plot-demo-painted.png\"))\n\n\n\n\nStacked bar chart\n\nstacked_bar_plot &lt;- ggplot(diamonds) +\n  aes(price, fill = cut) +\n  geom_histogram(binwidth = 850) +\n  xlab('Price (USD)') +\n  ylab('Count') +\n  ggtitle(\"ggpomological\") +\n  scale_x_continuous(label = scales::dollar_format()) +\n  scale_fill_pomological()\n\nstacked_bar_plot + theme_pomological(\"Homemade Apple\", 16)\n\n\n\n\n\n\n\npaint_pomological(\n  stacked_bar_plot + theme_pomological_fancy(),\n  res = 110\n) %&gt;%\n  magick::image_write(set_filename(\"plot-bar-chart-painted.png\"))\n\n\n\n\nDensity Plot\n\ndensity_plot &lt;- mtcars %&gt;%\n  mutate(cyl = factor(cyl)) %&gt;%\n  ggplot() +\n  aes(mpg, fill = cyl, color = cyl)+\n  geom_density(alpha = 0.75) +\n  labs(fill = 'Cylinders', colour = 'Cylinders', x = 'MPG', y = 'Density') +\n  scale_color_pomological() +\n  scale_fill_pomological()\n\ndensity_plot + theme_pomological(\"Homemade Apple\", 16)\n\n\n\n\n\n\n\npaint_pomological(\n  density_plot + theme_pomological_fancy(),\n  res = 110\n) %&gt;%\n  magick::image_write(set_filename(\"plot-density-demo-painted.png\"))\n\n\n\n\nPoints and lines\nHere I‚Äôll use the txhousing data provided with ggplot2\n\nInformation about the housing market in Texas provided by the TAMU real estate center, http://recenter.tamu.edu/.\n\n\nbig_volume_cities &lt;- txhousing %&gt;%\n  group_by(city) %&gt;%\n  summarize(mean_volume = mean(volume, na.rm = TRUE)) %&gt;%\n  arrange(-mean_volume) %&gt;%\n  top_n(length(ggpomological:::pomological_palette)) %&gt;%\n  pull(city)\n\nfull_bar_stack_plot &lt;- txhousing %&gt;%\n  filter(city %in% big_volume_cities) %&gt;%\n  group_by(city, year) %&gt;%\n  summarize(mean_volume = mean(volume, na.rm = TRUE)) %&gt;%\n  ungroup %&gt;%\n  mutate(city = factor(city, big_volume_cities)) %&gt;%\n  ggplot() +\n  aes(year, mean_volume, fill = city, group = city) +\n  geom_col(position = 'fill', width = 0.9) +\n  labs(x = 'City', y = 'Mean Volume', color = 'City') +\n  theme(panel.grid.minor.x = element_blank()) +\n  scale_fill_pomological()\n\nfull_bar_stack_plot + theme_pomological(\"Homemade Apple\", 16)\n\n\n\n\n\n\n\npaint_pomological(\n  full_bar_stack_plot + theme_pomological_fancy(),\n  res = 110\n) %&gt;%\n  magick::image_write(set_filename(\"plot-full-bar-stack-painted.png\"))\n\n\n\n\nOne last plot\nThis last one is in my own handwriting.\n\nridges_pomological &lt;- ggplot(diamonds) +\n  aes(x = carat, y = clarity, color = clarity, fill = clarity) +\n  ggridges::geom_density_ridges(alpha = 0.75) +\n  theme_pomological(\n    base_family = 'gWriting',\n    base_size = 20,\n    base_theme = ggridges::theme_ridges()\n    ) +\n  scale_fill_pomological() +\n  scale_color_pomological()\n\npaint_pomological(ridges_pomological, res = 110) %&gt;%\n  magick::image_write(set_filename(\"plot-ridges-painted.png\"))"
  },
  {
    "objectID": "project/ggpomological/index.html#thanks-to-these-related-packages",
    "href": "project/ggpomological/index.html#thanks-to-these-related-packages",
    "title": "üçë ggpomological: A Pomological ggplot2 Theme",
    "section": "Thanks to these related packages",
    "text": "Thanks to these related packages\nI learned a lot about how to set up a ggplot2 package theme from @hrbrmstr‚Äôs hrbrthemes package. I highly recommend checking that out, in most cases you can just add + theme_ipsum() to your ggplot and get an amazingly good looking plot.\nI also recommend taking a look at ggthemes, ggthemr and the lato ggplot2 theme packages."
  },
  {
    "objectID": "project/epoxy/index.html",
    "href": "project/epoxy/index.html",
    "title": "{epoxy}",
    "section": "",
    "text": "Follow @gadenbuie\n{epoxy}\n\n\nextra-strength glue for scripts, reports, and apps.\n\n\n\n     \n\n\nepoxy is super glue\n\nIn R Markdown and Quarto reports\nUse epoxy chunks for extra-strength inline syntax. Just library(epoxy) in your R Markdown or Quarto document to get started. All epoxy chunks make it easy to transform values in place with a {cli}-inspired inline syntax described in ?epoxy_transform_inline.\n\n\nIn R scripts\nThe same functions that power epoxy chunks are availble in three flavors:\n\nepoxy() for markdown and general purpose outputs\nepoxy_html() for HTML outputs, with added support for HTML templating (see ?epoxy_transform_html)\nepoxy_latex() for LaTeX reports\n\nThese functions are accompanied by a robust system for chained glue-transformers powered by epoxy_transform().\n\n\nIn Shiny apps\nui_epoxy_html() makes it easy to update text or HTML dynamically, anywhere in your Shiny app‚Äôs UI. For more complicated situations, ui_epoxy_mustache() lets you turn any Shiny UI into a template that leverages the Mustache templating language.\n\n\n\nepoxy in R Markdown and Quarto documents\nIn R Markdown and Quarto documents, epoxy gives you an epoxy chunk where you can write in markdown, blending prose and data using glue‚Äôs template syntax.\nHere‚Äôs an example using a small list containing data about a movie (expand the section below to see the full code for movie). We can use the inline transformer to format the replacement text as we build up a description from this data.\n\n\nMovie data\n\nmovie &lt;- list(\n  year = 1989,\n  title = \"Back to the Future Part II\",\n  budget = 4e+07,\n  domgross = 118450002,\n  imdb_rating = 7.8,\n  actors = c(\n    \"Michael J. Fox\",\n    \"Christopher Lloyd\",\n    \"Lea Thompson\",\n    \"Thomas F. Wilson\"\n  ),\n  runtime = 108L\n)\n\n```{epoxy}\nThe movie {.emph {.titlecase movie$title}}\nwas released in {.strong movie$year}.\nIt earned {.dollar movie$domgross}\nwith a budget of {.dollar movie$budget},\nand it features movie stars\n{.and movie$actors}.\n```\n\nThe movie Back to the Future Part II was released in 1989. It earned $118,450,002 with a budget of $40,000,000, and it features movie stars Michael J. Fox, Christopher Lloyd, Lea Thompson, and Thomas F. Wilson.\n\nLearn more about epoxy chunks ‚Äì and its siblings epoxy_html and epoxy_latex ‚Äì in Getting Started. Or read more about epoxy‚Äôs inline formatting in ?epoxy_transform_inline.\n\n\nInstallation\nYou can install epoxy from CRAN:\ninstall.packages(\"epoxy\")\nYou can install the latest development version of epoxy with remotes\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/epoxy\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = \"https://gadenbuie.r-universe.dev/\",\n  getOption(\"repos\")\n))\n\ninstall.packages(\"epoxy\")\n\n\nSetup\nlibrary(epoxy)\nLoading epoxy adds four new knitr engines, or chunk types. Each type lets you intermix text with R code or data (expr in the table below), and each is geared toward a different output context.\n\n\n\nEngine\nOutput Context\nDelimiter\n\n\n\n\nepoxy\nall-purpose markdown\n{expr}\n\n\nepoxy_html\nHTML\n{expr}\n\n\nepoxy_latex\nLaTeX\n&lt;&lt;expr&gt;&gt;\n\n\nwhisker\nall-purpose\nmustache template language\n\n\n\n‚ö†Ô∏è Caution: Previously, epoxy provided a glue engine, but this conflicts with a similar chunk engine by the glue package. You can update existing documents to use the epoxy engine, or you can explicitly use epoxy‚Äôs glue chunk by including the following in your setup chunk.\nuse_epoxy_glue_engine()\n\n\nUse epoxy\nTo use epoxy in your R Markdown document, create a new chunk using the engine of your choice. In that chunk, write in markdown, HTML, or LaTeX as needed, wrapping R expressions inside the delimiters for the epoxy chunk.\n```{epoxy}\nThe average speed of the cars was **{mean(cars$speed)} mph.**\nBut on average the distance traveled was only _{mean(cars$dist)}_.\n```\nThe average speed of the cars was 15.4 mph. But on average the distance traveled was only 42.98 ft.\nepoxy is built around glue::glue(), which evaluates the R expressions in the { } and inserts the results into the string. The chunk above is equivalent to this call to glue::glue():\nglue::glue(\"The average speed of the cars was **{mean(cars$speed)} mph**.\nBut on average the distance traveled was only _{mean(cars$dist)} ft_.\")\n#&gt; The average speed of the cars was **15.4 mph**.\n#&gt; But on average the distance traveled was only _42.98 ft_.\nOne immediate advantage of using epoxy instead of glue::glue() is that RStudio‚Äôs autocompletion feature works inside epoxy chunks! Typing cars$ in the chunk will suggest the columns of cars.\n\n\nLearn more\nThere‚Äôs a whole lot more that epoxy can do! Learn more:\n\nepoxy Package Documentation\nGetting Started\nInline Reporting with epoxy\n\n\n\nCode of Conduct\nPlease note that the epoxy project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "project/epoxy/index.html#epoxy-is-super-glue",
    "href": "project/epoxy/index.html#epoxy-is-super-glue",
    "title": "{epoxy}",
    "section": "epoxy is super glue",
    "text": "epoxy is super glue\n\nIn R Markdown and Quarto reports\nUse epoxy chunks for extra-strength inline syntax. Just library(epoxy) in your R Markdown or Quarto document to get started. All epoxy chunks make it easy to transform values in place with a {cli}-inspired inline syntax described in ?epoxy_transform_inline.\n\n\nIn R scripts\nThe same functions that power epoxy chunks are availble in three flavors:\n\nepoxy() for markdown and general purpose outputs\nepoxy_html() for HTML outputs, with added support for HTML templating (see ?epoxy_transform_html)\nepoxy_latex() for LaTeX reports\n\nThese functions are accompanied by a robust system for chained glue-transformers powered by epoxy_transform().\n\n\nIn Shiny apps\nui_epoxy_html() makes it easy to update text or HTML dynamically, anywhere in your Shiny app‚Äôs UI. For more complicated situations, ui_epoxy_mustache() lets you turn any Shiny UI into a template that leverages the Mustache templating language."
  },
  {
    "objectID": "project/epoxy/index.html#epoxy-in-r-markdown-and-quarto-documents",
    "href": "project/epoxy/index.html#epoxy-in-r-markdown-and-quarto-documents",
    "title": "{epoxy}",
    "section": "epoxy in R Markdown and Quarto documents",
    "text": "epoxy in R Markdown and Quarto documents\nIn R Markdown and Quarto documents, epoxy gives you an epoxy chunk where you can write in markdown, blending prose and data using glue‚Äôs template syntax.\nHere‚Äôs an example using a small list containing data about a movie (expand the section below to see the full code for movie). We can use the inline transformer to format the replacement text as we build up a description from this data.\n\n\nMovie data\n\nmovie &lt;- list(\n  year = 1989,\n  title = \"Back to the Future Part II\",\n  budget = 4e+07,\n  domgross = 118450002,\n  imdb_rating = 7.8,\n  actors = c(\n    \"Michael J. Fox\",\n    \"Christopher Lloyd\",\n    \"Lea Thompson\",\n    \"Thomas F. Wilson\"\n  ),\n  runtime = 108L\n)\n\n```{epoxy}\nThe movie {.emph {.titlecase movie$title}}\nwas released in {.strong movie$year}.\nIt earned {.dollar movie$domgross}\nwith a budget of {.dollar movie$budget},\nand it features movie stars\n{.and movie$actors}.\n```\n\nThe movie Back to the Future Part II was released in 1989. It earned $118,450,002 with a budget of $40,000,000, and it features movie stars Michael J. Fox, Christopher Lloyd, Lea Thompson, and Thomas F. Wilson.\n\nLearn more about epoxy chunks ‚Äì and its siblings epoxy_html and epoxy_latex ‚Äì in Getting Started. Or read more about epoxy‚Äôs inline formatting in ?epoxy_transform_inline."
  },
  {
    "objectID": "project/epoxy/index.html#installation",
    "href": "project/epoxy/index.html#installation",
    "title": "{epoxy}",
    "section": "Installation",
    "text": "Installation\nYou can install epoxy from CRAN:\ninstall.packages(\"epoxy\")\nYou can install the latest development version of epoxy with remotes\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/epoxy\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = \"https://gadenbuie.r-universe.dev/\",\n  getOption(\"repos\")\n))\n\ninstall.packages(\"epoxy\")"
  },
  {
    "objectID": "project/epoxy/index.html#setup",
    "href": "project/epoxy/index.html#setup",
    "title": "{epoxy}",
    "section": "Setup",
    "text": "Setup\nlibrary(epoxy)\nLoading epoxy adds four new knitr engines, or chunk types. Each type lets you intermix text with R code or data (expr in the table below), and each is geared toward a different output context.\n\n\n\nEngine\nOutput Context\nDelimiter\n\n\n\n\nepoxy\nall-purpose markdown\n{expr}\n\n\nepoxy_html\nHTML\n{expr}\n\n\nepoxy_latex\nLaTeX\n&lt;&lt;expr&gt;&gt;\n\n\nwhisker\nall-purpose\nmustache template language\n\n\n\n‚ö†Ô∏è Caution: Previously, epoxy provided a glue engine, but this conflicts with a similar chunk engine by the glue package. You can update existing documents to use the epoxy engine, or you can explicitly use epoxy‚Äôs glue chunk by including the following in your setup chunk.\nuse_epoxy_glue_engine()"
  },
  {
    "objectID": "project/epoxy/index.html#use-epoxy",
    "href": "project/epoxy/index.html#use-epoxy",
    "title": "{epoxy}",
    "section": "Use epoxy",
    "text": "Use epoxy\nTo use epoxy in your R Markdown document, create a new chunk using the engine of your choice. In that chunk, write in markdown, HTML, or LaTeX as needed, wrapping R expressions inside the delimiters for the epoxy chunk.\n```{epoxy}\nThe average speed of the cars was **{mean(cars$speed)} mph.**\nBut on average the distance traveled was only _{mean(cars$dist)}_.\n```\nThe average speed of the cars was 15.4 mph. But on average the distance traveled was only 42.98 ft.\nepoxy is built around glue::glue(), which evaluates the R expressions in the { } and inserts the results into the string. The chunk above is equivalent to this call to glue::glue():\nglue::glue(\"The average speed of the cars was **{mean(cars$speed)} mph**.\nBut on average the distance traveled was only _{mean(cars$dist)} ft_.\")\n#&gt; The average speed of the cars was **15.4 mph**.\n#&gt; But on average the distance traveled was only _42.98 ft_.\nOne immediate advantage of using epoxy instead of glue::glue() is that RStudio‚Äôs autocompletion feature works inside epoxy chunks! Typing cars$ in the chunk will suggest the columns of cars."
  },
  {
    "objectID": "project/epoxy/index.html#learn-more",
    "href": "project/epoxy/index.html#learn-more",
    "title": "{epoxy}",
    "section": "Learn more",
    "text": "Learn more\nThere‚Äôs a whole lot more that epoxy can do! Learn more:\n\nepoxy Package Documentation\nGetting Started\nInline Reporting with epoxy"
  },
  {
    "objectID": "project/epoxy/index.html#code-of-conduct",
    "href": "project/epoxy/index.html#code-of-conduct",
    "title": "{epoxy}",
    "section": "Code of Conduct",
    "text": "Code of Conduct\nPlease note that the epoxy project is released with a Contributor Code of Conduct. By contributing to this project, you agree to abide by its terms."
  },
  {
    "objectID": "project/cleanrmd/index.html",
    "href": "project/cleanrmd/index.html",
    "title": "üßº cleanrmd",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\ncleanrmd\n\n\n\n   \n\n\ncleanrmd is a no-frills, lightweight HTML format for R Markdown, using class-less CSS.\nThis package was greatly inspired by Yuval Greenfield‚Äôs blog post: The Next CSS Frontier - Classless.\n\nInstallation\nYou can install the released version of cleanrmd from CRAN:\ninstall.packages(\"cleanrmd\")\nYou can install the latest development version from GitHub:\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/cleanrmd\")\nor from gadenbuie.r-universe.dev:\noptions(repos = c(\n  gadenbuie = 'https://gadenbuie.r-universe.dev',\n  CRAN = 'https://cloud.r-project.org'\n))\n\ninstall.packages('cleanrmd')\n\n\nUsage\n\ncleanrmd::html_document_clean\nCreate a new R Markdown document using the Clean HTML R Markdown template in RStudio, or add the following to your .Rmd YAML header to use cleanrmd::html_document_clean.\noutput: \n  cleanrmd::html_document_clean:\n    theme: no-class\nTo explore the available themes, set theme to NULL.\noutput: \n  cleanrmd::html_document_clean:\n    theme: NULL\nSyntax highlighting is provided by default by pandoc, where syntax highlighting is performed during during the render, minimizing dependencies. pandoc‚Äôs highlighting themes include pygments, tango, espresso, zenburn, kate, monochrome, breezedark, and haddock. The default highlighting theme is arrow, provided by the rmarkdown package in addition to the rstudio theme.\nhtml_document_clean() can also use Prism for highlighting. In this case, highlighting is performed in the browser and the dependencies are downloaded as needed. To use Prism, set theme: prism or use one of the following value to choose a specific Prism theme: prism-coy, prism-dark, prism-funky, prism-okaidia, prism-solarizedlight, prism-tomorrow, and prism-twilight.\nMathJax and FontAwesome are also available but disabled by default. To enable either feature, you can set mathjax to local or default, as in rmarkdown::html_document(). Set use_fontawesome to TRUE to enable Font Awesome icons.\noutput: \n  cleanrmd::html_document_clean:\n    mathjax: default\n    use_fontawesome: true\n\n\nJust the theme\nYou can also load the CSS theme dependencies in other places where htmltools can be used to provide HTML dependencies, such as Shiny apps.\nTo include a theme in your app or page, use\ncleanrmd::use_cleanrmd(theme = \"new.css\")\nTo view the list of theme options view the help pages of cleanrmd_themes() or use its output:\ncleanrmd::cleanrmd_themes()\n#&gt;  [1] \"almond\"            \"awsm.css\"          \"axist\"            \n#&gt;  [4] \"bamboo\"            \"bullframe\"         \"holiday\"          \n#&gt;  [7] \"kacit\"             \"latex.css\"         \"markdown-splendor\"\n#&gt; [10] \"markdown-retro\"    \"markdown-air\"      \"markdown-modest\"  \n#&gt; [13] \"marx\"              \"minicss\"           \"new.css\"          \n#&gt; [16] \"no-class\"          \"picocss\"           \"sakura\"           \n#&gt; [19] \"sakura-vader\"      \"semantic\"          \"simplecss\"        \n#&gt; [22] \"style-sans\"        \"style-serif\"       \"stylize\"          \n#&gt; [25] \"superstylin\"       \"tacit\"             \"vanilla\"          \n#&gt; [28] \"water\"             \"water-dark\"        \"writ\"\n\n\n\nThemes\nThe following CSS themes are included in this package and you can preview all 30 themes in one place here.\n\nalmond\nawsm.css\naxist\nbamboo\nbullframe\nholiday\nkacit\nlatex.css\nmarkdown-splendor\nmarkdown-retro\nmarkdown-air\nmarkdown-modest\nmarx\nminicss\nnew.css\nno-class\npicocss\nsakura\nsakura-vader\nsemantic\nsimplecss\nstyle-sans\nstyle-serif\nstylize\nsuperstylin\ntacit\nvanilla\nwater\nwater-dark\nwrit"
  },
  {
    "objectID": "project/cleanrmd/index.html#installation",
    "href": "project/cleanrmd/index.html#installation",
    "title": "üßº cleanrmd",
    "section": "Installation",
    "text": "Installation\nYou can install the released version of cleanrmd from CRAN:\ninstall.packages(\"cleanrmd\")\nYou can install the latest development version from GitHub:\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/cleanrmd\")\nor from gadenbuie.r-universe.dev:\noptions(repos = c(\n  gadenbuie = 'https://gadenbuie.r-universe.dev',\n  CRAN = 'https://cloud.r-project.org'\n))\n\ninstall.packages('cleanrmd')"
  },
  {
    "objectID": "project/cleanrmd/index.html#usage",
    "href": "project/cleanrmd/index.html#usage",
    "title": "üßº cleanrmd",
    "section": "Usage",
    "text": "Usage\n\ncleanrmd::html_document_clean\nCreate a new R Markdown document using the Clean HTML R Markdown template in RStudio, or add the following to your .Rmd YAML header to use cleanrmd::html_document_clean.\noutput: \n  cleanrmd::html_document_clean:\n    theme: no-class\nTo explore the available themes, set theme to NULL.\noutput: \n  cleanrmd::html_document_clean:\n    theme: NULL\nSyntax highlighting is provided by default by pandoc, where syntax highlighting is performed during during the render, minimizing dependencies. pandoc‚Äôs highlighting themes include pygments, tango, espresso, zenburn, kate, monochrome, breezedark, and haddock. The default highlighting theme is arrow, provided by the rmarkdown package in addition to the rstudio theme.\nhtml_document_clean() can also use Prism for highlighting. In this case, highlighting is performed in the browser and the dependencies are downloaded as needed. To use Prism, set theme: prism or use one of the following value to choose a specific Prism theme: prism-coy, prism-dark, prism-funky, prism-okaidia, prism-solarizedlight, prism-tomorrow, and prism-twilight.\nMathJax and FontAwesome are also available but disabled by default. To enable either feature, you can set mathjax to local or default, as in rmarkdown::html_document(). Set use_fontawesome to TRUE to enable Font Awesome icons.\noutput: \n  cleanrmd::html_document_clean:\n    mathjax: default\n    use_fontawesome: true\n\n\nJust the theme\nYou can also load the CSS theme dependencies in other places where htmltools can be used to provide HTML dependencies, such as Shiny apps.\nTo include a theme in your app or page, use\ncleanrmd::use_cleanrmd(theme = \"new.css\")\nTo view the list of theme options view the help pages of cleanrmd_themes() or use its output:\ncleanrmd::cleanrmd_themes()\n#&gt;  [1] \"almond\"            \"awsm.css\"          \"axist\"            \n#&gt;  [4] \"bamboo\"            \"bullframe\"         \"holiday\"          \n#&gt;  [7] \"kacit\"             \"latex.css\"         \"markdown-splendor\"\n#&gt; [10] \"markdown-retro\"    \"markdown-air\"      \"markdown-modest\"  \n#&gt; [13] \"marx\"              \"minicss\"           \"new.css\"          \n#&gt; [16] \"no-class\"          \"picocss\"           \"sakura\"           \n#&gt; [19] \"sakura-vader\"      \"semantic\"          \"simplecss\"        \n#&gt; [22] \"style-sans\"        \"style-serif\"       \"stylize\"          \n#&gt; [25] \"superstylin\"       \"tacit\"             \"vanilla\"          \n#&gt; [28] \"water\"             \"water-dark\"        \"writ\""
  },
  {
    "objectID": "project/cleanrmd/index.html#themes",
    "href": "project/cleanrmd/index.html#themes",
    "title": "üßº cleanrmd",
    "section": "Themes",
    "text": "Themes\nThe following CSS themes are included in this package and you can preview all 30 themes in one place here.\n\nalmond\nawsm.css\naxist\nbamboo\nbullframe\nholiday\nkacit\nlatex.css\nmarkdown-splendor\nmarkdown-retro\nmarkdown-air\nmarkdown-modest\nmarx\nminicss\nnew.css\nno-class\npicocss\nsakura\nsakura-vader\nsemantic\nsimplecss\nstyle-sans\nstyle-serif\nstylize\nsuperstylin\ntacit\nvanilla\nwater\nwater-dark\nwrit"
  },
  {
    "objectID": "blog/yule-rstudio-theme/index.html",
    "href": "blog/yule-rstudio-theme/index.html",
    "title": "A Holiday RStudio Theme",
    "section": "",
    "text": "Follow me¬† Star yule-rstudio"
  },
  {
    "objectID": "blog/yule-rstudio-theme/index.html#yule-rstudio",
    "href": "blog/yule-rstudio-theme/index.html#yule-rstudio",
    "title": "A Holiday RStudio Theme",
    "section": "",
    "text": "Follow me¬† Star yule-rstudio"
  },
  {
    "objectID": "blog/yule-rstudio-theme/index.html#tis-the-season-to-be-jolly",
    "href": "blog/yule-rstudio-theme/index.html#tis-the-season-to-be-jolly",
    "title": "A Holiday RStudio Theme",
    "section": "üéÖ ü§∂ ‚ÄôTis the season to be jolly!",
    "text": "üéÖ ü§∂ ‚ÄôTis the season to be jolly!\nBring yuletide cheer and seasons greetings to your favorite R IDE. Based on the Yule tmTheme and modified to fit in well with RStudio Dark Mode. It‚Äôs surprisingly pleasant and merrily festive!\n\nFeaturing magical additions such as a candy cane style line highlight and a blinking Christmas-light cursor:"
  },
  {
    "objectID": "blog/yule-rstudio-theme/index.html#installation",
    "href": "blog/yule-rstudio-theme/index.html#installation",
    "title": "A Holiday RStudio Theme",
    "section": "Installation",
    "text": "Installation\nYou‚Äôll need RStudio version 1.2. Grab the preview version here.\n\nRun the following code in RStudio to download and apply the theme.\nyule_theme &lt;- fs::path_temp(\"Yule-RStudio\", ext = \"rstheme\")\ndownload.file(\"https://git.io/yule-rstudio\", yule_theme)\nrstudioapi::addTheme(yule_theme, apply = TRUE)\n‚òï Make a cup of hot coco,\nüìª turn on SomaFM‚Äôs Christmas Lounge,\nüíª and enjoy coding by the open fire.\n\n\nManual Installation\nIf the steps above don‚Äôt work, you can manually download the Yule-RStudio.rstheme file and place it in .R/rstudio/themes in your R home directory (see path.expand(\"~\")). Then, in the RStudio appearance settings, select the Yule RStudio editor theme."
  },
  {
    "objectID": "blog/yule-rstudio-theme/index.html#how-i-made-this",
    "href": "blog/yule-rstudio-theme/index.html#how-i-made-this",
    "title": "A Holiday RStudio Theme",
    "section": "How I Made This",
    "text": "How I Made This\nI made this the way I do all web development: right-click on the thing I want to change, choose Inspect Element, and hack at it until it looks reasonable. Somehow this even works in RStudio! (It‚Äôs a web app underneath.)\nAs a starting point, though, I used found the Yule theme on the tmTheme Editor and fiddled with the base colors there until they worked well with RStudio‚Äôs blueish dark theme.\nThe upcoming 1.2 version of RStudio now supports adding themes, and .tmTheme files are converted automatically into RStudio‚Äôs .rstheme format. Turns out, an .rstheme is just CSS!\nThis got me half the way there, but there were still a number of missing elements that I wanted to tweak. Figuring out how tmTheme scopes get mapped to Ace CSS classes was painful trial and error. To get the theme all the way there, I went straight to the source. I opened up a few scripts and R Markdown documents, used Insepect Element to identify the appropriate Ace CSS class, and then fiddled until it looked great good enough.\nThe blinking Christmas-light cursor is just a CSS animation!\n.normal-mode .ace_cursor {\n  border: 0!important;\n  animation-name: color;\n  animation-duration: 10s;\n  animation-iteration-count: infinite;\n  animation-timing-function: step-start;\n  opacity: 0.75;\n}\n\n@keyframes color {\n  0% {\n    background-color: #ff00a9;\n  }\n  20% {\n    background-color: #7c3eff;\n  }\n  40% {\n    background-color: #64f3f0;\n  }\n  60% {\n    background-color: #4fe818;\n  }\n  80% {\n    background-color: #ffc400;\n  }\n  100 {\n    background-color: #ff0010;\n  }\n}\n\n‚ö†Ô∏è May waste some CPU cycles in the spirit of the holidays!\nThe animated christmas-light cursors may increase the CPU usage of RStudio. To disable the animations but still enjoy the theme, edit the theme file in ~/.R/rstudio/themes/Yule-RStudio.rstheme.\nrstudioapi::navigateToFile(\n  fs::path_home_r(\".R\", \"rstudio\", \"themes\", \"Yule-RStudio.rstheme\")\n)\nFind the CSS blocks for .ace_cursor and .normal-mode .ace_cursor and comment out the lines starting with animation-*.\n.ace_cursor {\n  color: #ff0010;\n  /*\n  animation-name: xmas-colors;\n  animation-duration: 30s;\n  animation-iteration-count: infinite;\n  animation-timing-function: steps;\n  */\n}"
  },
  {
    "objectID": "blog/xaringanextra-v0.6.0/index.html",
    "href": "blog/xaringanextra-v0.6.0/index.html",
    "title": "xaringanExtra v0.6.0 ‚Äî Now on CRAN!",
    "section": "",
    "text": "I‚Äôm delighted to announce that xaringanExtra is now available on CRAN! Bring something extra to your xaringan slides.\nThis is the first release available via install.packages() and it includes a new extra, plus some bug fixes. Read on to learn more!"
  },
  {
    "objectID": "blog/xaringanextra-v0.6.0/index.html#what-is-xaringanextra",
    "href": "blog/xaringanextra-v0.6.0/index.html#what-is-xaringanextra",
    "title": "xaringanExtra v0.6.0 ‚Äî Now on CRAN!",
    "section": "What is xaringanExtra?",
    "text": "What is xaringanExtra?\nWhat can xaringanExtra do for you and your xaringan slides? A whole lot! Here are all the things you can do with xaringanExtra:\n\nAdd an overview of your presentation with tile view\nMake your slides editable\nShare your slides in style with share again\nBroadcast your slides in real time to viewers with broadcast\nScribble on your slides during your presentation with scribble\nAnnounce slide changes with a subtle tone\nAnimate slide transitions with animate.css\nAdd tabbed panels to slides with panelset\nAdd a logo to all of your slides with logo\nAdd a top or bottom banner to all of your slides with banner\nAdd a search box to search through your slides with search\nUse the Tachyons CSS utility toolkit\nAdd a live video feed of your webcam\nAdd one-click code copying with clipboard\nAlways play gifs from the start with freezeframe\nFit your slides to fill the browser window\nAdd extra CSS styles\n\nBut wait, there‚Äôs more! These features aren‚Äôt limited to just xaringan slides. A bunch of the features can be used in regular R Markdown documents, in particular: panelset, animate.css, Tachyons, and clipboard."
  },
  {
    "objectID": "blog/xaringanextra-v0.6.0/index.html#installing-xaringanextra",
    "href": "blog/xaringanextra-v0.6.0/index.html#installing-xaringanextra",
    "title": "xaringanExtra v0.6.0 ‚Äî Now on CRAN!",
    "section": "Installing xaringanExtra",
    "text": "Installing xaringanExtra\nInstalling xaringanExtra is now a whole lot easier:\ninstall.packages(\"xaringanExtra\")\nAs always, you can still get the latest and greatest in-development versions from GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = 'https://gadenbuie.r-universe.dev',\n  CRAN = 'https://cloud.r-project.org'\n))\n\ninstall.packages('xaringanExtra')"
  },
  {
    "objectID": "blog/xaringanextra-v0.6.0/index.html#wait-its-on-cran-now",
    "href": "blog/xaringanextra-v0.6.0/index.html#wait-its-on-cran-now",
    "title": "xaringanExtra v0.6.0 ‚Äî Now on CRAN!",
    "section": "Wait, it‚Äôs on CRAN now?",
    "text": "Wait, it‚Äôs on CRAN now?\nYeah, can you believe it?!\nWhen I started working on xaringanExtra (checks notes) 943 days ago ‚Äî that‚Äôs 2 ¬Ω years or 13 pandemic years ago ‚Äî I never expected that xaringanExtra would ever be anything beyond a toy package I used for fun procrastination experiments while preparing slides for talks and workshops.\nI‚Äôm honored and grateful that so many other people have found the package helpful and have used it to make their presentations more engaging! I‚Äôm also humbled that when the Quarto team developed the next generation of slide-building tools, they made a point to ensure that Quarto presentations include, out-of-the-box, many of the features from xaringanExtra.\nI‚Äôd also like to thank the community of users and developers who have reported issues or shared xaringanExtra on social media or talked about it in workshops and talks. A big up-front thank you to Matt Warkentin for developing one of my favorite extras: üßë‚Äçüé® Scribble!\nSincerely, thank you to the 54 awesome people who contributed issues, advice, fixes or features since I started working on xaringanExtra:\n@albert-ying, @apreshill, @BerriJ, @brianmsm, @chainsawriot, @ColinConwell, @dataning, @dmi3kno, @drfurtado, @dunstone-a, @evanmorier, @giabaio, @GitHunter0, @gpapageorgiou, @gtalckmin, @howardm, @ignacio82, @issactoast, @jhelvy, @jmgirard, @jooyoungseo, @juandodyk, @jvcasillas, @kim-soo-hwan, @koliajaykr, @konstruktur, @LauraRK, @mattwarkentin, @MayaGans, @mchiapello, @mfherman, @mine-cetinkaya-rundel, @nithinmkp, @nucleic-acid, @pat-s, @pomang-211, @psads-git, @py9mrg, @realauggieheschmeyer, @RRMaximiliano, @rsimonmd, @ryanstraight, @SchmidtPaul, @simonedu, @skamper1, @spcanelon, @Sumidu, @tgerke, @TuQmano, @uriahf, @W-Mohammed, @yonicd, @youngwoos, and @yyzeng."
  },
  {
    "objectID": "blog/xaringanextra-v0.6.0/index.html#banner",
    "href": "blog/xaringanextra-v0.6.0/index.html#banner",
    "title": "xaringanExtra v0.6.0 ‚Äî Now on CRAN!",
    "section": "A new extra: banner!",
    "text": "A new extra: banner!\nOne new feature made it into this release: üì∞ banner!\nThe idea behind banner is simple. Sometimes you want to have some text appear on every slide in your presentation (or at least most of the slides).\nYou might want to show a short link to the slides being presented. Or you might want to add your name or talk title in the slide margin so that attendees who missed your intro or don‚Äôt have the conference schedule in front of them know who you are and what you‚Äôre talking about.\nxaringanExtra::use_banner() solves this problem. Just add a chunk like the one below to your slides\n```{r xaringan-banner, echo=FALSE}\nxaringanExtra::use_banner(\n  top_left = \"My Awesome Talk Title\",\n  top_right = \"Mr. Fancy Pants\",\n  bottom_left = \"bit.ly/my-awesome-talk\",\n  exclude = \"title-slide\"\n)\n```\nand you‚Äôll get slides that look kind of like this!"
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html",
    "href": "blog/wordle-guess-helper/index.html",
    "title": "Wordle Guess Helper",
    "section": "",
    "text": "Have you heard of Wordle? Who am I kidding, of course you‚Äôve heard of Wordle! In fact, I‚Äôm pretty certain we‚Äôre way past peak Wordle at this point.\nHere‚Äôs a Wordle helper that doesn‚Äôt completely take the fun out of the guessing, while also making sure you‚Äôve got a good chance at winning every time.\nType your guesses below and then use the buttons below each letter to report Wordle‚Äôs response. Press return to start the next guess. Use delete to remove letters or words you‚Äôve entered.\nAs soon as you add the results for a new word, the table of next guess candidates will update! Pick wisely."
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#intro",
    "href": "blog/wordle-guess-helper/index.html#intro",
    "title": "Wordle Guess Helper",
    "section": "Intro",
    "text": "Intro\nI started this post about a month ago, roughly at the same time that every other person with a blog about doing things with computers also decided to start writing a post about Wordle.\nI‚Äôve been tempted to just walk away from this post more than once. After all, since I‚Äôve started writing this post Wordle has been solved more than once, Winston Chang rewrote Wordle in Shiny, roughly 70 other people wrote Wordle clones or helper apps and packages in R alone. Felienne Hermans wrote a Twitter bot to guess the word from shared game emojis. Someone else wrote a bot to intentionally ruin everyone‚Äôs day by spoling the answer to the next day‚Äôs Wordle. (Both bots were eventually suspended by Twitter.) Oh and Wordle was bought for big money by the New York Times who fumbled the handoff and lost more than a few player‚Äôs word streaks in the transfer.\nI should admit up-front that I‚Äôve never really played Wordle. It‚Äôs exactly the kind of task that immediately cries out to be automated: I‚Äôd apparently much rather spend a month‚Äôs worth of after-hours tinkering time to think through and codify a decent strategy than to just think up some words on my own.\nAnd yet I love Wordle. I think it‚Äôs awesome. The rules are simple, but deceptively ambiguous. The game play is so concise it can fit in a tweet (even though that‚Äôs annoying for accessibility reasons). Still, the UI is simple, intuitive and fun without trying to hack your brain to be addictive. It‚Äôs a feel good game.\nAnother reason to love Wordle: there are so many great programming tasks around Wordle. It‚Äôs easy to describe the mechanics, to understand the game play, to look at the app and think: I can do that. Which is why, right now, programmers are hard at work tinkering over word lists or practicing web development in their favorite framework using Wordle.\nAs an educator, it means you can tailor a Wordle-based programming challenge to be as simple or complicated as needed. Once you start to break down the game, it‚Äôs more complicated than it appears at first glance, and there‚Äôs so much to choose from. State management, data structures, browser storage, game theory, CSS, user interface design, accessibility. You can go deep on any of these topics.\nSo if you have a Wordle idea you want to tinker with, I wholeheartedly encourage you to run with it. Let Wordle inspire you to practice using regular expressions with stringr, web scraping with httr, text processing with Python, working with Twitter data with rtweet, or making accessible plots with ggplot2.\nWhat follows here is a bit of a journey. It is not the best strategy for Wordle or even the best way to play. But along the way we‚Äôll learn a few text processing tricks, we‚Äôll write a few functions, and we‚Äôll learn how to move seamlessly from R to the browser in the same document or blog post. (The R code and data I write below create the word data used in the table and app above!)"
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#lets-look-at-some-words",
    "href": "blog/wordle-guess-helper/index.html#lets-look-at-some-words",
    "title": "Wordle Guess Helper",
    "section": "Let‚Äôs look at some words",
    "text": "Let‚Äôs look at some words\nLet‚Äôs dig in. To get started, I‚Äôm using a few of the usual suspects from the tidyverse package. Out of habit, I‚Äôll load the ones I want specifically. (I think I also used tidyr somewhere in here, too.)\n\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(stringr)\n\nNow we‚Äôre ready to load our word list. At first I started with Scrabble‚Äôs word list, but it turns out that Wordle included the complete word list in its source code. (You could call it a hack but only in the state of Missouri.)\nI used my elite hacker copy-and-paste skills to store Wordle‚Äôs word list as a JSON file (165K).\n\nwordle_words &lt;- jsonlite::fromJSON(\n  \"wordle.json\",\n  simplifyVector = TRUE\n)\n\nIt turns out that Wordle maintains two separate lists. One list contains the 2,315 words used as solutions\n\nsample(wordle_words$answers, 5)\n\n[1] \"daily\" \"lathe\" \"white\" \"unmet\" \"fiber\"\n\n\nand the other contains the 10,657 words that the game considers a valid guess.\n\nsample(wordle_words$words, 5)\n\n[1] \"twite\" \"defog\" \"cavie\" \"roric\" \"purty\"\n\n\nDo the two word lists overlap?\n\nwordle_words %&gt;%\n  reduce(intersect) %&gt;%\n  length()\n\n[1] 0\n\n\nNo, they do not (the intersection of the two word lists is empty). We could make things super easy for ourselves by only considering the words on the solution list, but that would really ruin the fun. So let‚Äôs combine the two lists.\n\nwords &lt;- unlist(wordle_words)\n\nNow lets turn those words into data we can work with."
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#a-letter-popularity-contest",
    "href": "blog/wordle-guess-helper/index.html#a-letter-popularity-contest",
    "title": "Wordle Guess Helper",
    "section": "A letter popularity contest",
    "text": "A letter popularity contest\n\nPopularity by word\nMy first thought (and I think it‚Äôs many people first thought) was to consider the probability that a letter appears in a word. In other words: does R appear in more words than F?\nTo answer this we can split each word into a vector of letters, take only the unique letters, and then count how many times each letter appears in a word.\nSplitting the word into a vector of letters is something we‚Äôll be doing a lot, and stringr::str_split() or strsplit() can help. The trick is to use an empty string as the split pattern to break apart each string character by character.\n\nstr_split(c(\"unhip\", \"jeans\"), \"\")\n\n[[1]]\n[1] \"u\" \"n\" \"h\" \"i\" \"p\"\n\n[[2]]\n[1] \"j\" \"e\" \"a\" \"n\" \"s\"\n\n\nNote that this process takes our vector and gives us a list of vectors, which means we‚Äôll be seeing a lot of purrr‚Äôs map() function in this post.\n\nletter_freq &lt;-\n  words %&gt;%\n  # Split each word into a vector of letters\n  str_split(\"\") %&gt;%\n  # Keep one of each letter per word\n  map(unique) %&gt;%\n  # Unlist into a big vector of letters\n  unlist() %&gt;%\n  # Count the letters (each appearance in a word)\n  table() %&gt;%\n  # Most popular letters first\n  sort(decreasing = TRUE) %&gt;%\n  # Turn into frequency table\n  `/`(length(words)) %&gt;%\n  # Remove attributes from table()\n  c()\n\nletter_freq\n\n          s           e           a           o           r           i \n0.457600987 0.439793401 0.410884983 0.301495529 0.301341351 0.276672834 \n          l           t           n           u           d           y \n0.240055504 0.233811286 0.214847364 0.187789084 0.177150786 0.156567993 \n          c           p           m           h           g           b \n0.148011101 0.145312982 0.144002467 0.131668208 0.118948504 0.117098366 \n          k           w           f           v           z           j \n0.111316682 0.079247610 0.076318224 0.051958064 0.030141844 0.022278754 \n          x           q \n0.022124576 0.008556892 \n\n\nNote that we only counted each letter once per word, so we now know that R appears in 30% of the words in the word list, while F appears in only 8%. A first guess that includes R would probably be better than one with an F.\n\n\nPopularity by position\nAnother way to look at letter frequency would be to consider the position of the letter in the word. What if we know that R and F are in the word: which is a more likely choice as the fourth letter?\nTo do this we‚Ä¶\n\nFirst turn the word list into a tibble with one row per word.\nThen, using tidyr::separate_rows(), we can add a new column with the letters in each word.\nGrouping by word and adding a row_number() gives us the position of each letter in the word.\nThen we can count the number of times each letter occurs in a given position with a new group_by() and summarize() (we could have used count() with another ungroup(), too).\nThen, if we re-use our letter-word counts from the last step, we can count the number of words that have a the letter in question so that our frequency is effectively given the letter R, how often does it appear as the fourth letter?\nFinally, tidyr::pivot_wider() moves the positions to the columns so the table is easier to read.\n\n\nletter_freq_pos &lt;-\n  tibble(word = words) %&gt;%\n  select(word) %&gt;%\n  mutate(letter = word) %&gt;%\n  tidyr::separate_rows(letter, sep = \"\") %&gt;%\n  filter(letter != \"\") %&gt;%\n  group_by(word) %&gt;%\n  mutate(position = row_number()) %&gt;%\n  group_by(letter, position) %&gt;%\n  summarize(n = n(), .groups = \"drop\") %&gt;%\n  mutate(\n    words = letter_freq[letter] * length(!!words),\n    freq = n / words\n  ) %&gt;%\n  select(-n, -words) %&gt;%\n  tidyr::pivot_wider(\n    names_from = position,\n    values_from = freq,\n    values_fill = 0,\n    names_prefix = \"p\"\n  )\n\nletter_freq_pos\n\n# A tibble: 26 √ó 6\n   letter     p1     p2     p3    p4     p5\n   &lt;chr&gt;   &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n 1 a      0.138  0.425  0.232  0.202 0.128 \n 2 b      0.598  0.0533 0.221  0.160 0.0388\n 3 c      0.480  0.0917 0.204  0.214 0.0661\n 4 d      0.298  0.0366 0.170  0.205 0.358 \n 5 e      0.0531 0.285  0.155  0.408 0.267 \n 6 f      0.604  0.0242 0.180  0.235 0.0828\n 7 g      0.413  0.0493 0.236  0.274 0.0927\n 8 h      0.286  0.320  0.0703 0.138 0.217 \n 9 i      0.0460 0.385  0.293  0.245 0.0780\n10 j      0.699  0.0381 0.159  0.100 0.0104\n# ‚Ä¶ with 16 more rows\n\n\nNow we can answer our question about R and F in the fourth position.\n\nletter_freq_pos %&gt;%\n  filter(letter %in% c(\"r\", 'f')) %&gt;%\n  select(letter, p4)\n\n# A tibble: 2 √ó 2\n  letter    p4\n  &lt;chr&gt;  &lt;dbl&gt;\n1 f      0.235\n2 r      0.184\n\n\nSo R is the fourth letter in 18% of the words containing R ‚Äî but F is the fourth letter in 24% of its words.\nIdeally this information will help us filter guesses when we know that a set of letters are in the solution, but we don‚Äôt yet know where."
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#first-choice",
    "href": "blog/wordle-guess-helper/index.html#first-choice",
    "title": "Wordle Guess Helper",
    "section": "First Choice",
    "text": "First Choice\nWhat word should we guess first? Ideally, we want a word whose answer gives us the most information. Intuitively, if we pick a word that has the most popular letters and each letter is different, we‚Äôll be able to discard or include the most words when Wordle tells us which letters are in or out.\nFormally, this calculation is called entropy. It measures how much information is contained in a particular instance of a random process. In this case, words with higher entropy give us more information because they encode more information.\nThis is all a little hand-wavy, so I‚Äôll just duck the details and call this number a score. The higher the score, the better the word choice.\nTo calculate the entropy score, we take a word, split it into it‚Äôs letters, and then get the probability of each letter appearing in the word. Duplicated letters don‚Äôt tell us much, so we set second appearances of a letter close to zero. And then we calculate entropy\n\\[-\\sum_{i=1}^{n} p_i \\log_2 p_i\\]\nwhich in R code is\n- sum(p * log(p, base = 2))\nwhere p is a vector of probabilities for a given outome.\nWe can wrap all of that up into a function score_entropy():\n\nscore_entropy &lt;- function(word) {\n  chars &lt;- str_split(word, \"\")[[1]]\n  p &lt;- letter_freq[chars]\n  # we learn something but not much from duplicated letters\n  p[duplicated(chars)] &lt;- min(letter_freq)\n  - sum(p * log(p, base = 2))\n}\n\nNotice that score_entropy() isn‚Äôt vectorized, so we‚Äôll have to use a map() function to call it over a vector of words. We can be even more specific and use map_dbl() since we know that score_entropy() returns a number.\n\nc(\"unhip\", \"jeans\", \"pools\") %&gt;%\n  set_names() %&gt;%\n  map_dbl(score_entropy)\n\n   unhip    jeans    pools \n2.232150 2.163479 1.994939 \n\n\nThis tells us, broadly, that unhip is a better choice than jeans and pools is worse than either. (Intuitively: you don‚Äôt learn much from the second O.)\nLet‚Äôs use this to create a table of words and their associated entropy scores. Taking a peek at the highest scoring words tells us‚Ä¶\n\nwords_first_choice &lt;-\n  tibble(word = words) %&gt;%\n  mutate(score = map_dbl(word, score_entropy)) %&gt;%\n  arrange(desc(score))\n\nwords_first_choice\n\n# A tibble: 12,972 √ó 2\n   word  score\n   &lt;chr&gt; &lt;dbl&gt;\n 1 arose  2.61\n 2 aeros  2.61\n 3 soare  2.61\n 4 arise  2.60\n 5 raise  2.60\n 6 aesir  2.60\n 7 reais  2.60\n 8 serai  2.60\n 9 osier  2.59\n10 realo  2.59\n# ‚Ä¶ with 12,962 more rows\n\n\n‚Ä¶ that according to this measure, the best first-choice words are arose, aeros, and soare. arose uses all five of the letters that most commonly appear in a word, and is also probably (okay, it is) on the answers list, so hello new first word choice!"
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#second-choice",
    "href": "blog/wordle-guess-helper/index.html#second-choice",
    "title": "Wordle Guess Helper",
    "section": "Second Choice",
    "text": "Second Choice\nAfter your first choice, you know up to three pieces of additional information. Some of the letters in your guess\n\n¬†dark square aren‚Äôt in the solution\n¬†yellow square are in the solution but not where you guessed\n¬†green square are in the solution and are where you guessed\n\n\nNone of the letters are in the solution\nWhat if you guessed arose and got five gray boxes telling you that none of those letters appear in the solution?\n  a (absent)   r (absent)   o (absent)   s (absent)   e (absent)  \nWe need to discard any words with a, r, o, s, or E in them. To do this, we‚Äôll write a small function str_has_none_of() that takes a vector of words and a vector of letters, and checks if any of the letters are in each of the words. Technically, we use our same str_split() trick to split each word into a vector of letters and then check that the intersection of word letters and unwanted letters is empty.\n\nstr_has_none_of &lt;- function(words, letters) {\n  words &lt;- str_split(words, \"\")\n  map_lgl(words, ~ length(intersect(letters, .x)) == 0)\n}\n\nUsing this function, we can quickly reduce our word list from 12,972 to 577 words.\n\nwords_first_choice %&gt;%\n  filter(str_has_none_of(word, c(\"a\", \"r\", \"o\", \"s\", \"e\")))\n\n# A tibble: 577 √ó 2\n   word  score\n   &lt;chr&gt; &lt;dbl&gt;\n 1 unlit  2.43\n 2 until  2.43\n 3 linty  2.39\n 4 clint  2.38\n 5 unlid  2.38\n 6 culti  2.36\n 7 tulip  2.35\n 8 uplit  2.35\n 9 unity  2.35\n10 lindy  2.34\n# ‚Ä¶ with 567 more rows\n\n\nThis new word list suggests that unlit or until would be a good next choice, so we‚Äôll go with until. And if none of the letters in arose and until appear in the solution‚Ä¶\n  a (absent)   r (absent)   o (absent)   s (absent)   e (absent)     u (absent)   n (absent)   t (absent)   i (absent)   l (absent)  \n\nletters_guess &lt;- str_split(\"arose until\", \"\")[[1]]\n\nwords_first_choice %&gt;%\n  filter(str_has_none_of(word, letters_guess))\n\n# A tibble: 3 √ó 2\n  word  score\n  &lt;chr&gt; &lt;dbl&gt;\n1 pygmy  1.65\n2 hyphy  1.33\n3 gyppy  1.31\n\n\nthen your answer is most definitely one of pygmy, hyphy, or gyppy.\n\n\nRight letter, wrong place\nIf you learn something from the guess, though, you can filter the word list based on the information you just learned.\n\nSay we guess arose and wordle reveals that R and O appear in the solution.\n  a (absent)   r (in solution, wrong position)   o (in solution, wrong position)   s (absent)   e (absent)  \nWe now know that the solution:\n\nDoesn‚Äôt have A, S or E\nDoes contain R and O\nDoesn‚Äôt have R as the 2nd letter or O as the 3rd.\n\nWe‚Äôve already implemented this the first step by discarding words with str_has_none_of(). We also need a similar version called str_has_all_of() to keep only words that have letters we know are in the solution.\n\nstr_has_all_of &lt;- function(words, letters) {\n  words &lt;- str_split(words, \"\")\n  map_lgl(words, ~ length(setdiff(letters, .x)) == 0)\n}\n\nstr_has_all_of(\"rhino\", c(\"r\", \"o\"))\n\n[1] TRUE\n\n\nAnd finally we can use regular expressions to keep track of the third piece of information:\n.[^r][^o]..\nA . means any letter at that spot in the word (other than the ones we‚Äôve excluded). The [] indicate a set of options that could be present at a location in the string. The opening ^ negates the selection, so [^r] means a character that isn‚Äôt r.\n\nwords_first_choice %&gt;%\n  filter(\n    str_has_none_of(word, c(\"a\", \"s\", \"e\")),\n    str_has_all_of(word, c(\"r\", \"o\")),\n    str_detect(word, \".[^r][^o]..\")\n  )\n\n# A tibble: 142 √ó 2\n   word  score\n   &lt;chr&gt; &lt;dbl&gt;\n 1 lirot  2.54\n 2 intro  2.52\n 3 nitro  2.52\n 4 nidor  2.47\n 5 roily  2.47\n 6 loric  2.46\n 7 toric  2.45\n 8 milor  2.45\n 9 corni  2.44\n10 porin  2.44\n# ‚Ä¶ with 132 more rows\n\n\nlirot is an unusual word, so let‚Äôs choose the next word on the list: intro.\n  a (absent)   r (in solution, wrong position)   o (in solution, wrong position)   s (absent)   e (absent)     i (absent)   n (absent)   t (correct)   r (in solution, wrong position)   o (in solution, wrong position)  \nWordle thinks and tells us that we have T in the right spot! Also, we now know that I and N aren‚Äôt in the solution, and we still haven‚Äôt got R and O in the right place.\n\n\nRight letter, right place\nWe can repeat the step above, but using a new regular expression:\n.[^r]t[^ro][^o]\nNotice that we know a little more about where R and O can‚Äôt be, but importantly the t in the middle letter ensures we find words with T in the right place.\nThis leaves us with a few good choices:\n\nwords_first_choice %&gt;%\n  filter(\n    str_has_none_of(word, c(\"a\", \"s\", \"e\", \"i\", \"n\")),\n    str_has_all_of(word, c(\"r\", \"o\", \"t\")),\n    str_detect(word, \".[^r]t[^r][^o]\")\n  )\n\n# A tibble: 4 √ó 2\n  word  score\n  &lt;chr&gt; &lt;dbl&gt;\n1 rotch  2.33\n2 tutor  2.05\n3 motor  1.99\n4 rotor  1.65\n\n\nrotch seems very unlikely, so we can pick from tutor, motor and rotor. But notice that the these include a small set of the same letters. In a sense, we might ask ourselves a new question ‚Äî which is the more likely starting combination: tu, mo or ro?\nAt this point, you could just guess. It is a game after all! But no, let‚Äôs power forward and add more complexity to this blog post.\nWhat if we switched our scoring at this point and considered the position of the letters in the candidate words? Doing something medium-naive, let‚Äôs frame this as: what‚Äôs the probability of T in the first position and U in the second and so on‚Ä¶\n\nscore_by_position &lt;- function(word) {\n  chars &lt;- str_split(word, \"\")[[1]]\n\n  res &lt;- c()\n  for (i in seq_along(chars)) {\n    pos_alpha &lt;- which(letters == chars[i])\n    p &lt;- letter_freq_pos[[str_c(\"p\", i)]][pos_alpha]\n    res &lt;- c(res, p)\n  }\n\n  prod(res)\n}\n\nwords_score_pos &lt;-\n  tibble(word = words) %&gt;%\n  mutate(\n    score_pos = map_dbl(word, score_by_position),\n    score_pos = score_pos / diff(range(score_pos))\n  ) %&gt;%\n  arrange(desc(score_pos))\n\nwords_score_pos\n\n# A tibble: 12,972 √ó 2\n   word  score_pos\n   &lt;chr&gt;     &lt;dbl&gt;\n 1 foxes     1.00 \n 2 boxes     0.991\n 3 jones     0.864\n 4 juves     0.808\n 5 coxes     0.795\n 6 faxes     0.792\n 7 poxes     0.754\n 8 fones     0.746\n 9 bones     0.739\n10 fixes     0.719\n# ‚Ä¶ with 12,962 more rows\n\n\nIf we join this with our ‚Äúnew information‚Äù score, we now have to scores to choose from:\n\nwords_first_choice %&gt;%\n  filter(\n    str_has_none_of(word, c(\"a\", \"s\", \"e\", \"i\", \"n\")),\n    str_has_all_of(word, c(\"r\", \"o\", \"t\")),\n    str_detect(word, \".[^r]t[^r][^o]\")\n  ) %&gt;%\n  left_join(words_score_pos) %&gt;%\n  arrange(desc(score_pos))\n\n# A tibble: 4 √ó 3\n  word  score score_pos\n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 motor  1.99    0.0304\n2 tutor  2.05    0.0200\n3 rotch  2.33    0.0199\n4 rotor  1.65    0.0132\n\n\nNow we see that motor and tutor are the most likely words based on their position. We guess motor‚Ä¶ and we‚Äôre right!\n  a (absent)   r (in solution, wrong position)   o (in solution, wrong position)   s (absent)   e (absent)     i (absent)   n (absent)   t (correct)   r (in solution, wrong position)   o (in solution, wrong position)     m (correct)   o (correct)   t (correct)   o (correct)   r (correct)  \nIt only took three guesses! It‚Äôs almost like I planned this example to work out just like I wanted."
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#generalizing",
    "href": "blog/wordle-guess-helper/index.html#generalizing",
    "title": "Wordle Guess Helper",
    "section": "Generalizing",
    "text": "Generalizing\nOkay, let‚Äôs do this for any number of guesses. First, let‚Äôs join our scored words into a single data frame.\n\nwords_scored &lt;-\n  left_join(\n    words_first_choice,\n    words_score_pos,\n    by = \"word\"\n  )\n\nThen, we need a function that takes our guesses and results and generalizes them into the pieces of information our guesses reveal about the solution. This function is going to take a vector of guesses and a vector of results. The guesses are just the words we guessed, but we‚Äôll need to invent a syntax to concicesly report the results. Here‚Äôs the syntax I decided to use:\n\n. means the letter is absent\n- means the letter is present (wrong place)\n+ means the letter is correct (right place)\n\nIn broad strokes, the function will take each guess and use the result\n\nPull out the correct letters and their positions in exact so we can pick out words with letters in those spots.\nPull out present letters and their positions into exclude so we can compose the regular expression to filter out words that have these letters in those places.\nAdd the present by wrong place letters to bucket_keep, a bucket of letters that we know are in the solution.\nAnd add any absent letters to bucket_dicard so we can filter out words that have any of these letters.\nThe last step is to compose the regular expression pattern from exact and exclude, and then return the regexp and the letters to keep and discard.\n\n\n#' @param guesses A vector of words that you have guessed\n#' @param result A vector of results for each guess using `.` for a miss, `-`\n#'   for a letter in the solution that isn't in the right place and `+` for a\n#'   letter that's in the right spot.\nsummarize_guesses &lt;- function(guesses, results) {\n  stopifnot(all(str_length(c(guesses, results)) == 5))\n\n  guesses &lt;- str_split(guesses, \"\")\n  results &lt;- str_split(results, \"\")\n\n  exclude &lt;- character(5)\n  exact &lt;- character(5)\n  bucket_keep &lt;- c()\n  bucket_discard &lt;- c()\n\n  for (i in seq_along(guesses)) {\n    g &lt;- guesses[[i]]\n    r &lt;- results[[i]]\n\n    if (any(r == \"+\")) {\n      exact[r == \"+\"] &lt;- g[r == \"+\"]\n      bucket_keep &lt;&lt;- c(bucket_keep, g[r == \"+\"])\n    }\n    if (any(r == \"-\")) {\n      bucket_keep &lt;- c(bucket_keep, g[r == \"-\"])\n      exclude[r == \"-\"] &lt;- paste0(exclude[r == \"-\"], g[r == \"-\"])\n    }\n    if (any(r == \".\")) {\n      bucket_discard &lt;- c(bucket_discard, g[r == \".\"])\n    }\n  }\n\n  exclude[exclude != \"\"] &lt;- paste0(\"[^\", exclude[exclude != \"\"], \"]\")\n  exact[exact == \"\"] &lt;- NA_character_\n  exclude[exclude == \"\"] &lt;- NA_character_\n\n  pattern &lt;- coalesce(coalesce(exact, exclude), \".\")\n\n  # Say you guess a word with two Ts,\n  # but there's only one T in the solution.\n  # T will appear on keep and discard bucket,\n  # so we need to explicitly keep it.\n  # (we could use that info, though, e.g. at most 1 T)\n  bucket_discard &lt;- setdiff(bucket_discard, bucket_keep)\n\n  list(\n    discard = unique(bucket_discard),\n    keep = unique(bucket_keep),\n    pattern = str_c(pattern, collapse = \"\")\n  )\n}\n\nRemember when we guessed arose and got this result?\n  a (absent)   r (in solution, wrong position)   o (in solution, wrong position)   s (absent)   e (absent)  \nOur new function summarizes the information we‚Äôve learned from this guess.\n\nsummarize_guesses(\n  guesses = \"arose\",\n  results = \".--..\"\n)\n\n$discard\n[1] \"a\" \"s\" \"e\"\n\n$keep\n[1] \"r\" \"o\"\n\n$pattern\n[1] \".[^r][^o]..\"\n\n\nThen we guessed intro and got this result.\n  a (absent)   r (in solution, wrong position)   o (in solution, wrong position)   s (absent)   e (absent)     i (absent)   n (absent)   t (correct)   r (in solution, wrong position)   o (in solution, wrong position)  \nAnd again we have this summary.\n\nguess_results &lt;-\n  summarize_guesses(\n    guesses = c(\"arose\", \"intro\"),\n    results = c(\".--..\", \"..+--\")\n  )\n\nguess_results\n\n$discard\n[1] \"a\" \"s\" \"e\" \"i\" \"n\"\n\n$keep\n[1] \"r\" \"o\"\n\n$pattern\n[1] \".[^r]t[^r][^o]\"\n\n\nTo get the remaining possible words, we can use this information to filter down to the words that\n\nhave none of the $discard letters\nhave all of the $keep letters\nmatch the regular expression $pattern.\n\n\nwords_scored %&gt;%\n  filter(\n    str_has_none_of(word, guess_results$discard),\n    str_has_all_of(word, guess_results$keep),\n    str_detect(word, guess_results$pattern)\n  )\n\n# A tibble: 4 √ó 3\n  word  score score_pos\n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 rotch  2.33    0.0199\n2 tutor  2.05    0.0200\n3 motor  1.99    0.0304\n4 rotor  1.65    0.0132\n\n\n\nAll together now\nNow that we know how to summarize and use the guess results to filter our next word choices, we can do this in one step with another small function, score_next_guess().\n\nscore_next_guess &lt;- function(guesses, results) {\n  guess_results &lt;- summarize_guesses(guesses, results)\n\n  words_scored %&gt;%\n    filter(\n      str_has_none_of(word, guess_results$discard),\n      str_has_all_of(word, guess_results$keep),\n      str_detect(word, guess_results$pattern)\n    )\n}\n\nHaving guessed arose and intro, what would happen if we guessed rotch1 next?\n\n\n\n\na\n(absent)\n\n\nr\n(in solution, wrong position)\n\n\no\n(in solution, wrong position)\n\n\ns\n(absent)\n\n\ne\n(absent)\n\n\n\n\ni\n(absent)\n\n\nn\n(absent)\n\n\nt\n(correct)\n\n\nr\n(in solution, wrong position)\n\n\no\n(in solution, wrong position)\n\n\n\n\nr\n(in solution, wrong position)\n\n\no\n(correct)\n\n\nt\n(correct)\n\n\nc\n(absent)\n\n\nh\n(absent)\n\n\n\n\n\nscore_next_guess(\n  guesses = c(\"arose\", \"intro\", \"rotch\"),\n  results = c(\".--..\", \"..+--\", \"-++..\")\n)\n\n# A tibble: 1 √ó 3\n  word  score score_pos\n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 motor  1.99    0.0304\n\n\nFrom rotch we learn that the first letter isn‚Äôt R, but the second letter is o, which leaves us just one choice: motor.\n  m (correct)   o (correct)   t (correct)   o (correct)   r (correct)"
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#guessing-wordle-words-in-real-life",
    "href": "blog/wordle-guess-helper/index.html#guessing-wordle-words-in-real-life",
    "title": "Wordle Guess Helper",
    "section": "Guessing Wordle words in real life",
    "text": "Guessing Wordle words in real life\n\nBeginner‚Äôs Luck\nI wrapped up the score_next_guess() function on January 16th, 2022, which happened to be the easiest Wordle day of any day I‚Äôve ‚Äúplayed‚Äù. But it was a nice motivator to feel like I had spent my Sunday tinkering time well.\nOpening with arose lead to a pleasant surprise.\n  a (in solution, wrong position)   r (in solution, wrong position)   o (in solution, wrong position)   s (in solution, wrong position)   e (absent)  \nFrom 12,972 words down to 37 words with our first guess. Nice!\n\n# 2022-01-16\nscore_next_guess(\n  guesses = c(\"arose\"),\n  results = c(\"----.\")\n)\n\n# A tibble: 37 √ó 3\n   word  score score_pos\n   &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 solar  2.58    0.0327\n 2 soral  2.58    0.0327\n 3 ratos  2.58    0.0404\n 4 rotas  2.58    0.0576\n 5 sorta  2.58    0.0401\n 6 taros  2.58    0.102 \n 7 toras  2.58    0.145 \n 8 sonar  2.56    0.0416\n 9 roans  2.56    0.0923\n10 roads  2.53    0.0669\n# ‚Ä¶ with 27 more rows\n\n\nLet‚Äôs just pick the first word on the list: solar.\n\n\n\n\na\n(in solution, wrong position)\n\n\nr\n(in solution, wrong position)\n\n\no\n(in solution, wrong position)\n\n\ns\n(in solution, wrong position)\n\n\ne\n(absent)\n\n\n\n\ns\n(correct)\n\n\no\n(correct)\n\n\nl\n(correct)\n\n\na\n(correct)\n\n\nr\n(correct)\n\n\n\n\nVery nice!\n\n\nProblematic words\nIn working on this, I ran into more than a few posts that had trouble with a few more obscure words, like igloo and ferry.\n\nigloo\nHow many guesses would it take for us to get to igloo?\n\n\nRound 1\n  a (absent)   r (absent)   o (in solution, wrong position)   s (absent)   e (absent)  \nOpening with arose is helpfulish.\n\nscore_next_guess(\n  guesses = c(\"arose\"),\n  results = c(\"..-..\")\n)\n\n# A tibble: 463 √ó 3\n   word  score score_pos\n   &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 doilt  2.46  0.0680  \n 2 indol  2.45  0.000646\n 3 tondi  2.44  0.0195  \n 4 lotic  2.43  0.00802 \n 5 noily  2.42  0.0711  \n 6 pilot  2.42  0.0501  \n 7 colin  2.41  0.0801  \n 8 nicol  2.41  0.00613 \n 9 tonic  2.41  0.0198  \n10 ontic  2.41  0.000670\n# ‚Ä¶ with 453 more rows\n\n\nMany of the words are obviously not the answer. Pilot is the first reasonable word on the list, and its score is relatively similar to the other top word choices, so I‚Äôd go with pilot.\n\n\nRound 2\n\n\n\n\na\n(absent)\n\n\nr\n(absent)\n\n\no\n(in solution, wrong position)\n\n\ns\n(absent)\n\n\ne\n(absent)\n\n\n\n\np\n(absent)\n\n\ni\n(in solution, wrong position)\n\n\nl\n(correct)\n\n\no\n(correct)\n\n\nt\n(absent)\n\n\n\n\nPicking pilot is a good choice!\n\nscore_next_guess(\n  guesses = c(\"arose\", \"pilot\"),\n  results = c(\"..-..\", \".-++.\")\n)\n\n# A tibble: 1 √ó 3\n  word  score score_pos\n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 igloo  1.95  0.000268\n\n\n\n\nRound 3\n\n\n\n\na\n(absent)\n\n\nr\n(absent)\n\n\no\n(in solution, wrong position)\n\n\ns\n(absent)\n\n\ne\n(absent)\n\n\n\n\np\n(absent)\n\n\ni\n(in solution, wrong position)\n\n\nl\n(correct)\n\n\no\n(correct)\n\n\nt\n(absent)\n\n\n\n\ni\n(correct)\n\n\ng\n(correct)\n\n\nl\n(correct)\n\n\no\n(correct)\n\n\no\n(correct)\n\n\n\n\n:tada: Great work!\n\n\n\n\nferry\nApparently there was a general furor about ferry when it was the Wordle solution of the day. Let‚Äôs see how long it takes us to get to that word.\n\n\nRound 1\n  a (absent)   r (in solution, wrong position)   o (absent)   s (absent)   e (in solution, wrong position)  \nOpening with arose narrows down our word choices to 357 words.\n\nscore_next_guess(\n  guesses = c(\"arose\"),\n  results = c(\".-..-\")\n)\n\n# A tibble: 357 √ó 3\n   word  score score_pos\n   &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 liter  2.54  0.0250  \n 2 relit  2.54  0.0180  \n 3 tiler  2.54  0.0485  \n 4 liner  2.53  0.0425  \n 5 inert  2.52  0.000951\n 6 inter  2.52  0.00199 \n 7 niter  2.52  0.0157  \n 8 uteri  2.50  0.000332\n 9 idler  2.49  0.000788\n10 riled  2.49  0.0604  \n# ‚Ä¶ with 347 more rows\n\n\nliter is both a word and at the top of our list, so it‚Äôs an easy next choice.\n\n\nRound 2\n\n\n\n\na\n(absent)\n\n\nr\n(in solution, wrong position)\n\n\no\n(absent)\n\n\ns\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\n\n\nl\n(absent)\n\n\ni\n(absent)\n\n\nt\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\nr\n(in solution, wrong position)\n\n\n\n\nThe word list is now full of words with similar patterns, so let‚Äôs sort by position score to help us choose.\n\nscore_next_guess(\n  guesses = c(\"arose\", \"liter\"),\n  results = c(\".-..-\", \"...--\")\n) %&gt;%\n  arrange(desc(score_pos))\n\n# A tibble: 50 √ó 3\n   word  score score_pos\n   &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 jerky  1.94     0.334\n 2 ferny  2.22     0.235\n 3 perky  2.22     0.218\n 4 jerry  1.64     0.177\n 5 query  1.97     0.153\n 6 ferry  1.80     0.153\n 7 berry  1.88     0.151\n 8 pervy  2.09     0.145\n 9 perdy  2.31     0.128\n10 kerky  1.87     0.125\n# ‚Ä¶ with 40 more rows\n\n\n\n\nRound 3\n\n\n\n\na\n(absent)\n\n\nr\n(in solution, wrong position)\n\n\no\n(absent)\n\n\ns\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\n\n\nl\n(absent)\n\n\ni\n(absent)\n\n\nt\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\nr\n(in solution, wrong position)\n\n\n\n\nj\n(absent)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nk\n(absent)\n\n\ny\n(correct)\n\n\n\n\nNow we‚Äôre down to 17 words to choose from. Still complicated. But if we arrange by position score, our top two choices are ferny and ferry.\nYou can see where this is headed, but let‚Äôs pretend we had no idea. Which would you pick?\n\nscore_next_guess(\n  guesses = c(\"arose\", \"liter\", \"jerky\"),\n  results = c(\".-..-\", \"...--\", \".++.+\")\n) %&gt;%\n  arrange(desc(score_pos))\n\n# A tibble: 17 √ó 3\n   word  score score_pos\n   &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1 ferny  2.22    0.235 \n 2 ferry  1.80    0.153 \n 3 berry  1.88    0.151 \n 4 pervy  2.09    0.145 \n 5 perdy  2.31    0.128 \n 6 germy  2.23    0.122 \n 7 derny  2.38    0.116 \n 8 perry  1.92    0.115 \n 9 mercy  2.27    0.109 \n10 merry  1.92    0.0937\n11 verry  1.74    0.0907\n12 derry  1.96    0.0753\n13 herry  1.91    0.0723\n14 derby  2.27    0.0655\n15 herby  2.21    0.0629\n16 nervy  2.16    0.0371\n17 nerdy  2.38    0.0328\n\n\n\n\nRound 4\n\n\n\n\na\n(absent)\n\n\nr\n(in solution, wrong position)\n\n\no\n(absent)\n\n\ns\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\n\n\nl\n(absent)\n\n\ni\n(absent)\n\n\nt\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\nr\n(in solution, wrong position)\n\n\n\n\nj\n(absent)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nk\n(absent)\n\n\ny\n(correct)\n\n\n\n\nf\n(correct)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nn\n(absent)\n\n\ny\n(correct)\n\n\n\n\nNow we‚Äôre down to 1 words to choose from.\n\nscore_next_guess(\n  guesses = c(\"arose\", \"liter\", \"jerky\", \"ferny\"),\n  results = c(\".-..-\", \"...--\", \".++.+\", \"+++.+\")\n) %&gt;%\n  arrange(desc(score_pos))\n\n# A tibble: 1 √ó 3\n  word  score score_pos\n  &lt;chr&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 ferry  1.80     0.153\n\n\n\n\nRound 5\n\n\n\n\na\n(absent)\n\n\nr\n(in solution, wrong position)\n\n\no\n(absent)\n\n\ns\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\n\n\nl\n(absent)\n\n\ni\n(absent)\n\n\nt\n(absent)\n\n\ne\n(in solution, wrong position)\n\n\nr\n(in solution, wrong position)\n\n\n\n\nj\n(absent)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nk\n(absent)\n\n\ny\n(correct)\n\n\n\n\nf\n(correct)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nn\n(absent)\n\n\ny\n(correct)\n\n\n\n\nf\n(correct)\n\n\ne\n(correct)\n\n\nr\n(correct)\n\n\nr\n(correct)\n\n\ny\n(correct)\n\n\n\n\n:tada: We did it! 5 isn‚Äôt bad, especially considering the terrible choices we had in round 3."
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#make-it-an-app",
    "href": "blog/wordle-guess-helper/index.html#make-it-an-app",
    "title": "Wordle Guess Helper",
    "section": "Make it an app",
    "text": "Make it an app\nIt‚Äôs awesome being able to run R code to test things out, but it‚Äôs also a little tedious. Since we‚Äôve done the heavy lifting of prepping and scoring words, it‚Äôd be great if we could have a little web app that would help us\n\nInput our guesses and results\nShow us possible words after each round\n\nAnd since I‚Äôm writing this blog post in R Markdown via blogdown, I can do it all right here!\n\nMove the data from R to the web\nThe first thing we need to do is save our data in a way that it can be accessed by JavaScript in the browser. To do this, we‚Äôll take our words_scored table and use jsonlite::write_json() to save the data frame as JSON.\n\nwords_scored %&gt;%\n  mutate(across(starts_with(\"score\"), round, digits = 2)) %&gt;%\n  jsonlite::write_json(\"wordle-scored.json\")\n\nNow we have the data in a JSON file (that you can download if you want).\nBut to make life even easier, I‚Äôm going to use a trick I learned from htmlwidgets. What we can do is embed in the JSON file, which is only 589K, in a &lt;script type=\"application/json\"&gt; tag with a specific id that makes it easy to find later on.\n\nhtmltools::tags$script(\n  id = \"words-scored\",\n  type = \"application/json\",\n  readLines(\"wordle-scored.json\")\n)\n\n\n\n\nNow that we have the data in a place where we can get it, let‚Äôs switch gears and write some JavaScript!\n\n\nStart working in JavaScript\nHere‚Äôs the cool thing: from here on out, the actual computation of the rest of the blog post is done in your browser. To facilitate this, I‚Äôll use an extension I built for knitr for literate JavaScript programming with the js4shiny package.\n\njs4shiny\nSetting up literate JavaScript in blogdown is pretty straight-forward thanks to a little helper function from js4shiny.\n\njs4shiny::html_setup_blogdown(stylize = \"none\")\n\n\n\n\n\n\ntidyjs\nThe other cool thing we‚Äôll use is tidyjs. It‚Äôs a really neat JavaScript library that makes it easy to work with data frames in the browser. If you squint really hard, it‚Äôs remarkably similar to the tidyverse, just with a JavaScript spin.\nI wrapped tidyjs in an R package that automatically stays up to date with the latest version of tidyjs. To use tidyjs, we just need to call use_tidyjs().\n\ntidyjs::use_tidyjs()\n\n\n\n\nNow that we‚Äôve included tidyjs in this page, we can finally switch to writing JavaScript instead of R.\nFirst, we need to import a couple of functions from tidyjs that we‚Äôre going to want to use. With tidyjs, all transformations are wrapped in a call tidy(), so we have to import tidy. We also need filter() and sliceMax() for easy filtering.\n\nconst { tidy, filter, sliceMax } = Tidy\n\n\n\n\nLoad our data\nThe next step is to find the JSON data that we just serialized and stashed in our page. We can use document.getElementById() to find the element with the id 'words-scored', and then grab the JSON text itself from the .innerText property of that object. Finally, we call JSON.parse() on the json text to parse it into a JavaScript object.\n\nwordsScored = JSON.parse(\n  document.getElementById('words-scored').innerText\n)\n\n\n\n\nPreview the data\nHere‚Äôs a quick preview of the data. In tidyjs you wrap a pipeline in tidy() and then each additional argument to tidy() is the next step in the pipe. To make it look a little more familiar to R users, I‚Äôve added the %&gt;% in the comments.\n\ntidy(\n  wordsScored, // %&gt;%\n  sliceMax(5, 'score')\n)\n\n\n\n\n\n\n\n\nSame song, different dance\n\nSummarizing guesses\nNext, we translate summarize_guesses() from R to summarizeGuesses() in JavaScript.\n\nfunction summarizeGuesses ({ guesses, results }) {\n  // Check that all guesses and results have 5 characters\n  const allComplete = [...guesses, ...results].every(s =&gt; s.length == 5)\n  if (!allComplete) {\n    console.error('All guesses and results must have 5 characters.')\n    return\n  }\n\n  // R: str_split(x, '')\n  guesses = guesses.map(s =&gt; s.split(''))\n  results = results.map(s =&gt; s.split(''))\n\n  let exclude = Array(5).fill('')\n  let exact = Array(5).fill('')\n  let keep = []\n  let discard = []\n\n  for (i = 0; i &lt; guesses.length; i++) {\n    let g = guesses[i] // g: an array of 5 letters of a guess\n    let r = results[i] // r: an array of 5 letters of the result\n\n    for (j = 0; j &lt; r.length; j++) {\n      if (r[j] == '+') {\n        // this letter is exactly right\n        exact[j] = g[j]\n        keep.push(g[j])\n      } else if (r[j] == '-') {\n        // this letter is included, wrong place\n        keep.push(g[j])\n        // so exclude it from this position\n        exclude[j] += g[j]\n      } else {\n        // this letter isn't in the solution\n        discard.push(g[j])\n      }\n    }\n  }\n\n  // build up the regex pattern blending `exact` and `exclude`\n  const pattern = Array(5).fill('.')\n  for (i = 0; i &lt; 5; i++) {\n    if (exact[i] != '') {\n      pattern[i] = exact[i]\n    } else if (exclude[i] != '') {\n      pattern[i] = `[^${exclude[i]}]`\n    }\n  }\n\n  discard = discard.filter(x =&gt; !keep.includes(x))\n  return {discard, keep, pattern: pattern.join('')}\n}\n\n\nHere‚Äôs a quick preview of summarizeGuesses().\n\nlet summary = summarizeGuesses({\n  guesses: [\"arose\", \"indol\"],\n  results: [\"..-..\", \"+..+-\"]\n})\nconsole.log(summary)\n\n\n\n\n\n\n\nSearching for the next word\nAnd then we need to do the same for score_next_guess(). Of course, at this point I‚Äôm older and wiser and choose a better name: searchNextGuess().\n\nfunction searchNextGuess ({ guesses, results }) {\n  const guessResult = summarizeGuesses({guesses, results})\n\n  return tidy(\n    wordsScored,\n    // discard words that contain a letter in the discard pile\n    filter(d =&gt; !guessResult.discard.some(l =&gt; d.word.includes(l))),\n    // keep only words that have all letters in the keep pile\n    filter(d =&gt; guessResult.keep.every(l =&gt; d.word.includes(l))),\n    // keep words that are consistent with results to date\n    filter(d =&gt; RegExp(guessResult.pattern).test(d.word))\n  )\n}\n\n\nLet‚Äôs prove to ourselves that these functions work.\n\nlet next = searchNextGuess({\n  guesses: [\"arose\", \"indol\"],\n  results: [\"..-..\", \"+..+-\"]\n})\n\nconsole.log(`There is ${next.length} word available for our next guess:`)\nconsole.table(next[0])\n\n\n\n\n\nLet‚Äôs try again. What if we chose a different second guess?\n\nlet rounds = {\n  guesses: [\"arose\", \"intro\"],\n  results: [\".--..\", \"..+--\"]\n}\nlet next = searchNextGuess(rounds)\n\nconsole.log('Guess summary ----')\nconsole.log(summarizeGuesses(rounds))\n\nconsole.log('Next word choices ----')\nnext.forEach(ws =&gt; console.log(`${ws.word} (${ws.score})`))\n\n\n\n\n\n\n\n\nNow build the rest of the owl\nOkay, this is the point where I confess that I went way off-track in building the little app at the top of this post. I fully intended to write about that part too, but honestly I‚Äôve done a good job curing myself of the Wordle bug with this post.\nFor the curious, all the JavaScript code for the guess helper lives in wordle-component.js. Or, right click on this page and pick Inspect Element and find your way to the Sources or Debugger tab for a better look. It‚Äôs all vanilla JavaScript.\nAlso a quick shout-out to gridjs, which turned out to be a very easy way to create the table of sorted words.\n&lt;script src=\"https://unpkg.com/gridjs/dist/gridjs.umd.js\"&gt;&lt;/script&gt;\n&lt;link href=\"https://unpkg.com/gridjs/dist/theme/mermaid.min.css\" rel=\"stylesheet\" /&gt;"
  },
  {
    "objectID": "blog/wordle-guess-helper/index.html#footnotes",
    "href": "blog/wordle-guess-helper/index.html#footnotes",
    "title": "Wordle Guess Helper",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWhat does rotch mean? Is it even a word? No, it is not. It‚Äôs a surname for a few Americans: a meteorologist, an architect, a tennis player, two politicians and a pediatrician.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html",
    "href": "blog/tweet-poll-programming-languages/index.html",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "",
    "text": "An informal poll about experiences with programming languages has been making the rounds on Twitter this week. It all started with this tweet from @cotufa82:\nThe tweet caught on within a few days and there are now more than 16,840 replies and quote tweets from developers and programmers sharing their own experiences.\nMy interest in the poll was piqued by another tweet by @edsu sharing a Jupyter notebook analyzing the tweeted responses. I thought it would be interesting to do a similar analysis using R, initially thinking I could compare the R and Python versions.\nWhat I should have done is to have used both R and Python (because they‚Äôre friends and language wars are silly), but instead I ended up going down the endless rabbit hole of regular expressions and free-form informal survey results."
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html#gather-the-tweets",
    "href": "blog/tweet-poll-programming-languages/index.html#gather-the-tweets",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "Gather the Tweets",
    "text": "Gather the Tweets\nI gathered all tweets containing \"first language\", \"most used\", and \"most loved\" using the excellent rtweet package by Mike Kearney.\ntweets &lt;- rtweet::search_tweets(\n  '\"first language\" AND \"most used\" AND \"most loved\"',\n  n = 18000,\n  include_rts = FALSE\n)\nYou can download a CSV with the processed tweets. The .csv doesn‚Äôt include the full tweet data, but it does include status_id so that you can recover the tweet data with rtweet::lookup_statuses()."
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html#whose-tweets-were-the-most-popular",
    "href": "blog/tweet-poll-programming-languages/index.html#whose-tweets-were-the-most-popular",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "Whose Tweets Were The Most Popular?",
    "text": "Whose Tweets Were The Most Popular?\nThere were 16,840 responses to the poll and 89% or 15,025 of them are replies to or quotes of another tweet. Here are the top contributors to the popularity of the poll, in the form of the top 10 recipients of a reply or quote tweet.\n\n\n\n\n\n\n\n\n\n\n\nClick on dot in plot to view tweet..."
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html#our-experience-with-programming-languages",
    "href": "blog/tweet-poll-programming-languages/index.html#our-experience-with-programming-languages",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "Our Experience with Programming Languages",
    "text": "Our Experience with Programming Languages\nLet‚Äôs dive into the results. If you‚Äôre interested in taking a peek behind the regular expressions curtain, I‚Äôve included a code walkthrough below.\nThe original tweet asked for six categories: First language, Had difficulties, Most used, Totally hate, Most loved, For beginners. Replies to this tweet were‚Ä¶ creative. The category names and formatting were hand-typed, so flexible and prone to spelling errors and permutations.\nTo get the broadest range of answers possible, I used flexible regular expressions to accept a variety of formatting choices, and I also widened the categories to encompass the same core themes. For example, first love, secret love, and mostly loved all were added to the Most loved category, which I called, simply, love.\nI also captured multiple programming languages in each category (even the original tweet had multiple answers for first language (Basic/Java) and a few other categories).\nEach of the following plots shows the top 20 responses in each category.\n\nFirst Language vs.¬†Recommended First Language\nHow do the first languages learned by programmers compare to the languages they would recommend to others to learn first? Many people started with older languages like Basic, C, Pascal, C++ and Java but would recommend new programmers start with Python, JavaScript, Ruby and also C or Java.\n     \n\n\nLove It or Hate It\nWhich programming languages are loved and which languages are not? The world seems to have a love/hate relationship with JavaScript, but Python is much more loved than hated. Likewise Swift, Ruby, and Go are significantly more positive than negative, C++ is also a bit love/hate, and PHP certainly isn‚Äôt feeling the love.\n     \n\n\nMost Used or Had Difficulties\nWhich languages are most used compared with those that have caused difficulties? JavaScript is eating the world, and plenty of people are using workhorse languages like Python, Java and C#/C++. (And a quite a few are using PHP presumably because they have to.) Still, JavaScript‚Äôs love/hate relationship continues as many people indicated that it caused them problems. I‚Äôm not surprised to see C++, C, and Java on the had difficulties list. Interestingly, Haskell shows up in the loved list but seems to also be tricky to learn.\n     \n\n\nFeelings about #rstats\nHow do developers feel about my favorite language? R isn‚Äôt a typical first language, but it is among the top 20 recommended to new programmers to learn first. It‚Äôs also the 12th most used language.\n\n\n\n\n\n\n\n\n\n\nCategory\nRank\nTotal\n\n\n\n\nmost used\n12\n1456\n\n\nlove\n15\n2067\n\n\nhad difficulties\n19\n2092\n\n\nhate\n16\n2641\n\n\nbeginner\n17\n2296\n\n\nfirst language\n28\n1508\n\n\ncurious\n15\n207\n\n\ncurrently\n2\n63\n\n\nnext\n3\n50\n\n\nhonerable mention\n8\n98\n\n\nchronology\n25\n29\n\n\nalso used, eager to learn, frenemy, never studied, on my list, to learn, totally meh, willing to learn"
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html#code-walkthrough",
    "href": "blog/tweet-poll-programming-languages/index.html#code-walkthrough",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "Code Walkthrough",
    "text": "Code Walkthrough\nAt a high level, the process for cleaning and standardizing the tweet repsonses looks like this. I abstracted some of the larger steps in the pipeline into separate functions.\n\nPre-clean the tweet text, including remove_unused_text()\nSeparate tweets so that each line or item of the tweet is in its own row using tidyr::separate_rows()\n\nItems are indicated by N., N), N:, or N-, or just appear on a new line without numbering.\n\nRemove whitespace and any numbering from each line\nSeparate each line into a question category and answer pair by splitting on : using tidyr::separate()\nFilter out empty answers and convert everything to lower case\nUse a set of regular expressions to process_answer() into individual languages\nUse more regular expressions to recode_answer() and recode_category(), fixing spelling mistakes and combining overlapping groups\nCount the number of replies mentioning each programming language by category\n\nThe whole pipeline is summarized below, including the function to plot response counts by category.\n\nRemove Unused Text\nThis little function removes usernames (@user), URLs, parenthetical comments, and turns #hashtag into hashtag because many people specified their choices using language hashtags, like #rstats instead of r.\n\nremove_unused_text &lt;- function(text) {\n  text %&gt;%\n    # strip usernames\n    str_remove_all(\"@\\\\w+\\\\s*\") %&gt;%\n    # strip URLs\n    str_remove_all(\"\\\\s*http[^ ]+\\\\s*\") %&gt;%\n    # remove parentheticals\n    str_remove_all(\"\\\\s*\\\\(.+?\\\\)( |\\n|$)\") %&gt;%\n    # replace \"#hashtag\" with \"hashtag\"\n    str_replace_all(\"#(\\\\w)\", \"\\\\1\")\n}\n\n\n\nProcess Answer\nThe goal in processing the answers is to transform each answer to a single string of comma separated languages. In doing this, common variations of language lists should result in the same final answers. For example, Python and R, Python/R, and Python or R should all be handled similarly. To help with this process I created a list of common languages that frequently appear in the answers.\n\ncommon_langs &lt;- c(\n  # c, c#, c++, and .net are manually included later\n  \"css\", \"html\", \"python\", \"javascript\", \"x86\", \"java\", \"ruby\", \"pascal\", \"php\",\n  \"matlab\", \"perl\", \"fortran\", \"logo\", \"actionscript\", \"lua\", \"assembly\",\n  \"delphi\", \"js\", \"scheme\", \"scratch\", \"go\", \"typescript\", \"clojure\", \"elixr\",\n  \"kotlin\", \"ocaml\", \"rust\", \"mathematica\", \"matlab\", \"dart\", \"flutter\", \"groovy\",\n  \"flash\", \"bash\", \"shell\", \"sql\", \"haskell\", \"lisp\", \"scala\", \"sas\",\n  \"rstats\", \"golang\"\n)\n\nThen, with a bit of regex kung fu, the responses are converted from Python and R to python,r.\n\nprocess_answer &lt;- function(answer, common_langs) {\n  answer %&gt;%\n    # Aggresively remove unusual characters\n    str_replace_all(\"[^\\\\w\\\\d#+., ]\", \" \") %&gt;%\n    # Remove leading character if it's a `,`\n    str_replace_all(\"^,\", \" \") %&gt;%\n    # Remove `.` at end of string\n    str_remove_all(\"[.]$\") %&gt;%\n    # Replace and, or with space (prep for next step)\n    str_replace_all(\"\\\\b(and|or|also|amp)\\\\b\", \" \") %&gt;%\n    # Remove qualifiers\n    str_remove_all(\"\\\\b(maybe|now)\\\\b\") %&gt;%\n    # Multiple languages may be listed separated by spaces, if so add comma\n    str_replace_all(\n      pattern = paste0(\"\\\\b(\", paste(common_langs, collapse = \"|\"), \")\\\\b\\\\s*\"),\n      replacement = \"\\\\1,\"\n    ) %&gt;%\n    gsub(\"c\\\\+\\\\+\\\\d+\", \"c++\", .) %&gt;%\n    # Comma separate languages that are tough to regex\n    gsub(\"c \", \"c,\", ., fixed = TRUE) %&gt;%\n    gsub(\".net \", \".net,\", ., fixed = TRUE) %&gt;%\n    gsub(\"c# \", \"c#,\", ., fixed = TRUE) %&gt;%\n    gsub(\"c++ \", \"c++,\", ., fixed = TRUE) %&gt;%\n    # No trailing punctuation\n    str_remove(\"[.,!?/=&lt;&gt;;:]+$\")\n}\n\n\n\nRecode Answer\nThere are a number of programming languages that have multiple variants or are commonly referred to by shorthand names ‚Äî rstats for R or golang for go, for example. This function recodes the programming language answers that I noticed while working with the data (but it‚Äôs admitedly not complete).\n\nrecode_answer &lt;- function(answer) {\n  # Recode Basic Variants\n  answer &lt;- recode(answer, \"vb\" = \"visual basic\")\n  answer &lt;- if_else(str_detect(answer, \"visual.*basic\"), \"visual basic\", answer)\n  answer &lt;- if_else(str_detect(answer, \"q.*basic\"), \"qbasic\", answer)\n  answer &lt;- if_else(str_detect(answer, \"gw.*basic\"), \"gw basic\", answer)\n  answer &lt;- if_else(str_detect(answer, \"(?&lt;!(visual|q|gw)\\\\s?)basic\"), \"basic\", answer)\n  # Recode Pascal variants\n  answer &lt;- if_else(str_detect(answer, \"pascal\"), \"pascal\", answer)\n  # Recode js vs Javascript\n  answer &lt;- recode(answer, \"js\" = \"javascript\")\n  # Recode golang to go\n  answer &lt;- recode(answer, \"golang\" = \"go\")\n  # Recode rstats as r\n  recode(answer, \"rstats\" = \"r\")\n}\n\n\n\nRecode Category\nAs you might imagine with a free-form survey where users manually enter both the question and the answer, there is a large amount of variation in the spelling and categories used.\nI broadly grouped many of the variations into common themes, primarily working to fit the original prompt. There are many, many interesting created categories, like best dead language, didn't spark joy, or latest crush. Here are two additional categories that I created, curious and interesting.\n     \n\nrecode_category &lt;- function(category) {\n  case_when(\n    str_detect(category, \"first.+lang(uage)?|firstlanguage\") ~ \"first language\",\n    str_detect(category, \"^first$\") ~ \"first language\",\n    str_detect(category, \"b(e|i)ginn?e|new dev|newb|starter|noob|brginners|begginners|begginers\") ~ \"beginner\",\n    str_detect(category, \"want|would|wish|wanna|curious|desire|(like.+learn)|curios|(like to try)\") ~ \"curious\",\n    str_detect(category, \"m[ou]st?(ly)? ?used?\") ~ \"most used\",\n    str_detect(category, \"diff?.+c.+lt|diificulties|difficulies|difficuties|difficulities\") ~ \"had difficulties\",\n    str_detect(category, \"love\") ~ \"love\",\n    str_detect(category, \"hate|dislike|avoid|(don.?t.+like)\") ~ \"hate\",\n    str_detect(category, \"promis|interest|exotic|esoter|(most excited)|(weird)\") ~ \"interesting\",\n    str_detect(category, \"honou?rable mention\") ~ \"honerable mention\",\n    str_detect(category, \"next|need to learn\") ~ \"next\",\n    str_detect(category, \"others used|other lang|dabbl\") ~ \"others used\",\n    str_detect(category, \"current\") ~ \"currently\",\n    TRUE ~ category\n  )\n}\n\n\n\nPoll Processing Pipeline\nFinally, here is the full pipeline to go from raw tweets to poll results.\n\ntweets_lang_poll &lt;-\n  tweets %&gt;%\n  select(status_id, created_at, user_id, screen_name, text) %&gt;%\n  # Remove tweets with \"English\" because that's probably a different thread\n  filter(!str_detect(text, \"[eE]nglish\")) %&gt;%\n  mutate(\n    # Backup original tweet text\n    text_og = text,\n    # Remove unused text from tweets\n    text = remove_unused_text(text)\n  ) %&gt;%\n  # Split text into question/answer pairs,\n  # splitting on newline or one of: `N.`, `N)`, `N:`, or `N-`\n  separate_rows(text, sep = \"\\n|\\\\d\\\\s*[.):-]\") %&gt;%\n  # Remove whitespace and `N.` numbers from start of text\n  mutate(text = str_remove_all(text, \"^\\\\s*(\\\\d[.):-])?\\\\s*\")) %&gt;%\n  # Seperate question/answer into category, answer columns, splitting on colon `:`\n  separate(\n    col = text,\n    into = c(\"category\", \"answer\"),\n    sep = \"\\\\s*:\\\\s*\",\n    remove = FALSE\n  ) %&gt;%\n  # Remove nothing answers or answers without any letters\n  filter(\n    !is.na(answer),\n    str_detect(answer, \"[[:alnum:]]\")\n  ) %&gt;%\n  # Re-encode category, answer as UTF-8 (:shrug:) and lowercase\n  mutate_at(vars(category, answer), stringi::stri_enc_toutf8) %&gt;%\n  mutate_at(vars(category, answer), tolower) %&gt;%\n  # Category: Remove leading non-alpha characters and squish whitespace\n  mutate(\n    category = str_remove(category, \"^[^[:alpha:]]+\"),\n    category = str_squish(category)\n  ) %&gt;%\n  # Process answer as well as we can programmatically\n  mutate(answer = process_answer(answer, common_langs)) %&gt;%\n  # Separate into one language per row\n  separate_rows(answer, sep = \"\\\\s*[,/]\\\\s*\") %&gt;%\n  # Squish the strings\n  mutate_at(vars(answer), str_squish) %&gt;%\n  mutate(\n    answer = recode_answer(answer),\n    category2 = recode_category(category)\n  ) %&gt;%\n  # Filter out empty category, answer fields\n  filter(!str_detect(answer, \"^\\\\s*$\")) %&gt;%\n  filter(\n    nchar(answer) &gt; 0,\n    nchar(category) &gt; 4\n  )\n\nAnd then to aggregate and count programming language mentions per category.\n\ntweets_lang_counted &lt;-\n  tweets_lang_poll %&gt;%\n  count(category2, answer, sort = TRUE)\n\n\n\nPlot Language Counts by Category\nLast, but not least, this function creates the plots for requested categories. One key detail is that bars are ordered within each facet using tidytext‚Äôs reorder_within() function. Check out Julia Silge‚Äôs excellent blog post on this function: Reordering and facetting for ggplot2.\nWhile the bars are ordered in descending order, I wanted the bar fill color to be consistent across facets to facilitate comparison between the two categories. The color palette is ocean.deep from the pals package, which I found by looking through Emil Hvitfeldt‚Äôs Comprehensive list of color palettes in R.\n\nplot_tweets_by_category &lt;- function(\n  tweets_lang_counted,\n  categories,\n  ncol = 2,\n  min_count = 10\n) {\n  tweets_lang_counted %&gt;%\n    filter(category2 %in% categories) %&gt;%\n    mutate_at(vars(category2), factor, levels = categories) %&gt;%\n    group_by(category2) %&gt;%\n    arrange(desc(n)) %&gt;%\n    filter(n &gt;= min_count) %&gt;%\n    top_n(20, n) %&gt;%\n    ungroup() %&gt;%\n    arrange(category2, answer, desc(n)) %&gt;%\n    mutate(\n      answer_within = tidytext::reorder_within(answer, n, category2),\n      answer = fct_reorder(answer, n, first)\n    ) %&gt;%\n    ggplot() +\n    aes(answer_within, n, fill = answer) +\n    geom_col() +\n    coord_flip() +\n    tidytext::scale_x_reordered(expand = c(0, 0)) +\n    discrete_scale(\"fill\", \"ocean\", function(n) rev(pals::ocean.deep(n + 10))[6:(n+5)]) +\n    guides(fill = FALSE) +\n    labs(x = NULL, y = NULL) +\n    facet_wrap(~ category2, scales = \"free\", ncol = ncol) +\n    theme_minimal(base_family = \"PT Sans\", base_size = 18) +\n    theme(\n      plot.margin = margin(20, 20, 20, 20),\n      panel.grid.major.y = element_blank(),\n      panel.grid.minor.x = element_blank(),\n      axis.ticks.y = element_blank(),\n      axis.text.x = element_text(family = \"PT Sans Narrow\"),\n      axis.text.y.left = element_text(margin = margin()),\n      panel.spacing.x = unit(3, \"line\"),\n      panel.spacing.y = unit(2, \"line\")\n    )\n}"
  },
  {
    "objectID": "blog/tweet-poll-programming-languages/index.html#what-about-you",
    "href": "blog/tweet-poll-programming-languages/index.html#what-about-you",
    "title": "Twitter‚Äôs Feelings About Programming Languages",
    "section": "What About You?",
    "text": "What About You?\nIf you made it this far, share your programming experiences on Twitter!\nThanks for reading and feel free to share feedback, thoughts, or questions with me on Twitter at @grrrck."
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "",
    "text": "Cryptographically sign all of your commits with a GPG key managed by Keybase, proving to GitHub and the world that you are a real person who really wrote your code and getting that neat Verified badge next to all of your commits.\nAlong the way, we‚Äôll also make sure everything is set up in a way that plays nicely with RStudio."
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html#overview",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html#overview",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "Overview",
    "text": "Overview\nDid you know it‚Äôs incredibly easy to spoof commit authors with git? Basically, you only need to tell git you‚Äôre a different person.\ngit config --global user.email \"hadley@...\"\ngit config --glboal user.name \"Hadley Wickham\"\n\n# pretend to commit as Hadley\ngit commit -m \"Fix recode() arguments to new = old\"\ngit doesn‚Äôt do anything to verify the commit author and, while GitHub will try a little harder than git, it‚Äôs surprisingly easy to pretend to be somewhere else in a git repo.\nThis can obviously lead to problems (that are admittedly mostly theoretical in my daily life) and there‚Äôs a relatively easy solution: signed commits. With signed commits, you cryptographically sign each commit with your private key that only you own, and GitHub (and others) will verify your signature with the public key pair. When GitHub knows that the real you made the commit, it adds the green  badge.\nIn this post, I‚Äôll show you how to use Keybase to create your own GPG key. Then we‚Äôll set up git to use this key to sign your commits, and along the way we‚Äôll configure git to work with RStudio, too. I‚Äôm using a Mac, but the process is very similar for Linux/Unix machines1."
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html#set-up-signed-and-verified-commits",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html#set-up-signed-and-verified-commits",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "Set up signed and verified commits",
    "text": "Set up signed and verified commits\n\nInstall Keybase and GPG\nWe need at least four pieces of software to make this work. I‚Äôm hoping you have git2 and RStudio installed; the two new things you‚Äôll probably need are Keybase and gpg.\nThe easiest way to install both is with the MacOS package manager, homebrew. (If homebrew is new to you, head over to https://brew.sh/ to learn more and to grab the installation command.)\nbrew install gpg\nbrew install --cask keybase\nThe first line installs gpg, the GNU Privacy Guard command line tool. It manages the cryptographic steps: signing or encoding files with your personal GPG key.\nKeybase is key directory that maps social media identities to encryption keys in a publicly auditable manner3. In other words, Keybase is place to store encryption keys and to link your identity (and those keys) to your public identities such as your accounts on Twitter or GitHub. One advantage of Keybase is that its app and command line tool make it relatively easy to generate and store GPG keys. It‚Äôs also a great way to share that key between your own computers.\n\n\nCreate a GPG key with Keybase\nIf you don‚Äôt have a Keybase account, open the Keybase app that we installed with brew. Their app will guide you through the process of creating an account.\nOnce you have a Keybase account, head back to the command line4 to create a new GPG key. Note that the keybase cli uses the pgp command, but we‚Äôve been talking about GPG keys. To most people, the terms GPG and PGP are functionally interchangeable: GPG is the GNU Privacy Guard which is an open-source version of PGP (Pretty Good Privacy).\nkeybase pgp gen --multi\nEnter your real name, which will be publicly visible in your new key: Garrick Aden-Buie\nEnter a public email address for your key: garrick@adenbuie.com\nEnter another email address (or &lt;enter&gt; when done):\nPush an encrypted copy of your new secret key to the Keybase.io server? [Y/n] Y\nWhen exporting to the GnuPG keychain, encrypt private keys with a passphrase? [Y/n] Y\n‚ñ∂ INFO PGP User ID: Garrick Aden-Buie &lt;garrick@adenbuie.com&gt; [primary]\n‚ñ∂ INFO Generating primary key (4096 bits)\n‚ñ∂ INFO Generating encryption subkey (4096 bits)\n‚ñ∂ INFO Generated new PGP key:\n‚ñ∂ INFO   user: Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\n‚ñ∂ INFO  4096-bit RSA key, ID B606B038A1A5CE20, created 2021-09-12\n‚ñ∂ INFO Exported new key to the local GPG keychain\nTo recap the process:\n\nkeybase will first ask you for your real name and email address. Make sure these match your identity on GitHub, or at least a verified email that you use on GitHub.\nThen choose Y to push a copy of the key to Keybase and Y again to add give your private key a passphrase.\nAfter a few seconds, Keybase asks for your account password and then prompts you to enter a passphrase for your GPG key.\n\nAt the end of the output, note your key‚Äôs ID ‚Äî in my case, B606B038A1A5CE20. You should also be able to find your key on your Keybase profile, or list your local keys that gpg knows about with\ngpg --list-secret-keys --keyid-format LONG\n/Users/garrick/.gnupg/pubring.kbx\n---------------------------------\nsec   rsa4096/B606B038A1A5CE20 2021-09-13 [SC] [expires: 2037-09-09]\n      87888BBEBC09E6093A8310F9B606B038A1A5CE20\nuid                 [ unknown] Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\nssb   rsa4096/F4435076C9C363BD 2021-09-13 [E] [expires: 2037-09-09]\nNotice that we again see our key id, B606B038A1A5CE20, in the third line of the output. There‚Äôs also the [ unknown] on line 5 next to our name. This indicates that gpg isn‚Äôt totally confident about this key yet and we need to tell gpg that it can be trusted.\n\n\nTrust your own key, ultimately\nOpen the gpg interactive prompt to edit your key, then run trust, choose I trust ultimately and finally run save.\ngpg --edit-key B606B038A1A5CE20\ngpg&gt; trust\n# Please decide how far you trust this user to correctly verify other users' keys\n# (by looking at passports, checking fingerprints from different sources, etc.)\n#\n#   1 = I don't know or won't say\n#   2 = I do NOT trust\n#   3 = I trust marginally\n#   4 = I trust fully\n#   5 = I trust ultimately\n#   m = back to the main menu\n#\n# Your decision? 5\n# Do you really want to set this key to ultimate trust? (y/N) y\n\ngpg&gt; save\n# Key not changed so no update needed.\nNow if you run gpg --list-secret-keys again, you‚Äôll see [ultimate] next to your name.\ngpg --list-secret-keys --keyid-format LONG\n/Users/garrick/.gnupg/pubring.kbx\n---------------------------------\nsec   rsa4096/B606B038A1A5CE20 2021-09-13 [SC] [expires: 2037-09-09]\n      87888BBEBC09E6093A8310F9B606B038A1A5CE20\nuid                 [ultimate] Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\nssb   rsa4096/F4435076C9C363BD 2021-09-13 [E] [expires: 2037-09-09]\n\n\nConfigure git to always sign your commits\nSetting git to always sign your commits is straightforward. Update the git global config to sign commits using your default key with the following two commands, replacing my key id in the first command with your key id.\ngit config --global user.signingkey B606B038A1A5CE20\ngit config --global commit.gpgsign true\n\n\nAdd your key to GitHub\nNow you need to tell GitHub about your new GPG key. Using your key id, ask Keybase to export the public key that matches your private GPG key. Here we‚Äôll pipe it to pbcopy to copy it into the system clipboard.\nkeybase pgp export -q B606B038A1A5CE20 | pbcopy\nThen head over to github.com/settings/keys, click on New GPG key, and paste and add your key into GitHub.\n\n\nCheck your signed commit powers\nAt this point, git will try to sign your commits, but if you‚Äôre also using MacOS like me there‚Äôs a good chance you‚Äôll run into a problem when you try to commit a file.\n# in a git repo\ntouch test.txt\ngit add test.txt\ngit commit -m \"test signed commits\"\n# error: gpg failed to sign the data\n# fatal: failed to write commit object\nThis error message isn‚Äôt entirely helpful, but you can try to sign some random text with gpg to expose the underlying error.\necho \"test\" | gpg --clear-sign\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\ntest\ngpg: signing failed: Inappropriate ioctl for device\ngpg: [stdin]: clear-sign failed: Inappropriate ioctl for device\nThe problem in my case is that I have an ‚ÄúInappropriate ioctl for device‚Äù. Take that error to your favorite web search engine and you‚Äôll find a resolution. If you also run into this ioctl error, you need to add the following line to ~/.zshrc (if you‚Äôre using Z shell, the latest default on MacOS) or ~/.profile:\nexport GPG_TTY=$(tty)\nSave the file and then close and re-open your terminal window. When you test gpg signing again, you should be prompted with a full-terminal prompt to enter your password.\necho \"test\" | gpg --clear-sign\n\n ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n ‚îÇ Please enter the passphrase to unlock the OpenPGP secret key: ‚îÇ\n ‚îÇ \"Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\"                    ‚îÇ\n ‚îÇ 4096-bit RSA key, ID B606B038A1A5CE20,                        ‚îÇ\n ‚îÇ created 2021-09-13.                                           ‚îÇ\n ‚îÇ                                                               ‚îÇ\n ‚îÇ                                                               ‚îÇ\n ‚îÇ Passphrase: _________________________________________________ ‚îÇ\n ‚îÇ                                                               ‚îÇ\n ‚îÇ         &lt;OK&gt;                                   &lt;Cancel&gt;       ‚îÇ\n ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n\nEnter your key‚Äôs passphrase and, if everything works, you should see a message like this:\n-----BEGIN PGP SIGNED MESSAGE-----\nHash: SHA256\n\ntest\n-----BEGIN PGP SIGNATURE-----\n\niQIzBAEBCAAdFiEEh4iLvrwJ5gk6gxD5tgawOKGlziAFAmE/UYkACgkQtgawOKGl\nziAzgg/7Bl6cCapi+k2OrxPafl811G4x7fC4PQWCJKWXinUjkZK/8+o6jM+ZQp+4\ngc1wv0gBfNyKNkTmMg/qiQhuLYiujSH9pyjaoMgO9QoYvUuPituSjV7RQOfAhlHD\nN+wgkACPd3PH2kQVFj8Jw3Nkesrpgby9t/S6sSiLZf284rMfx31ua1/l4tsHWowP\n5a+FRujDtarWJ1/zL9pgMkr9kkWEejqpzGVLrVKrB3xsPLyGnPf8BW+an7CwkkDS\numJulX3Ck1u14DRgIyj4VdwfCkkCle0uyZcLorZsqDP5GC/3ZKcpDe6XgSSKz0O0\nHVvm4bTqBBmesVNWHVuFmYGmmXFU/sYvYoHOy3wvLiCu/hbRhBvboUcogW79/PWR\nGw/DYln5W1ClIKH9LsU0GpydSTMMhXZySEp+r1OCl4sQqKCe6Ka3ex+3lOHyym7F\nU5rgfH6tmu6U2Jtn8QEFg106vxQDQ76TIRVS9xvicH98PJQnhoyg3jtu5tMbITz1\noev0Z11vq76mw3MFmVx455AVqxplGM/4qB9HsmNWTsi0fGoFa/vlbBN3vJQn0xaX\n2PSXKWlkZiyd+WplWsOH2OnZ8V8s2cHNxlKsSPrWQNflYsDtO8vANwAFjiJK2Bkq\nYLPCcwzEVSwFrLRRXt5Crcpc/32ZqrfvcLe0G+ACWQYAhktwJnQ=\n=S1iU\n-----END PGP SIGNATURE-----\nAnd if you try to git commit again, it should work!\ngit commit -m \"test signed commits\"\n[main (root-commit) 4c4573f] test signed commits\n 1 file changed, 0 insertions(+), 0 deletions(-)\n create mode 100644 test.txt\nNote that you can be extra sure by looking at the git log with signatures.\ngit log --show-signature\ncommit 4c4573f2fbed44eab6c0f4a08a38a9f8292580cf (HEAD -&gt; main)\ngpg: Signature made Mon Sep 13 09:34:59 2021 EDT\ngpg:                using RSA key 87888BBEBC09E6093A8310F9B606B038A1A5CE20\ngpg: Good signature from \"Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\" [ultimate]\nAuthor: Garrick Aden-Buie &lt;garrick@adenbuie.com&gt;\nDate:   Mon Sep 13 09:34:59 2021 -0400\n\n    test signed commits\n\n\nInstall a pinentry app\nRemember that console dialog that appeared when we committed our test commit above? Yes, it‚Äôs fun and retro, but it isn‚Äôt going to work inside RStudio when the IDE runs git commands for you to commit your files.\nIn this step, we‚Äôll install pinentry-mac, a modern method for providing a passphrase for your key, that also integrates with MacOS‚Äôs Keychain so you don‚Äôt have to enter the passphrase with every commit.\nIf you‚Äôre using Windows, you might want to check out the Gpg4win app. On Linux, you may want to use pinentry-gnome3. Finally, you could also configure gpg-agent to cache your passphrase if none of the above options work for you.\nInstalling pinentry-mac is easy with brew:\nbrew install pinentry-mac\nThen we need to configure gpg to use pinentry-mac for its passphrase needs. Add the line below to ~/.gnupg/gpg-agent.conf:\n# vim ~/.gnupg/gpg-agent.conf\npinentry-program /usr/local/bin/pinentry-mac\nOr you can create the file and add the line in one command:\necho \"pinentry-program /usr/local/bin/pinentry-mac\" &gt;&gt; ~/.gnupg/gpg-agent.conf\nFinally, restart the gpg-agent so that pinentry-mac is used for passphrase entry.\ngpgconf --kill gpg-agent\nWhen you create your next commit in RStudio, you‚Äôll be prompted with a dialog box to enter your passphrase. If you select the Save in Keychain option, you won‚Äôt be prompted again; gpg and git will use the passphrase in your Keychain to sign your commit with the GPG key you created with Keybase!\n\n\n\nThe pinentry-mac dialog window asking for the GPG key passphrase when signing a commit for the first time.\n\n\n\n\nImport your GPG key on another computer\nIf you‚Äôd like to use the same GPG key on another computer, first make sure that you have Keybase and gpg installed. Then you can export the existing key (both its public and secret versions) from Keybase into gpg:\nkeybase pgp export -q B606B038A1A5CE20 | gpg --import\nkeybase pgp export -q B606B038A1A5CE20 --secret | gpg --allow-secret-key-import --import\nAgain, you‚Äôll want to tell gpg to trust this key ultimately.\ngpg --edit-key B606B038A1A5CE20\ngpg&gt; trust\n# pick \"5 = I trust ultimately\"\ngpg&gt; save"
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html#links-and-resources",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html#links-and-resources",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "Links and Resources",
    "text": "Links and Resources\nHere‚Äôs a short list of links that were helpful to me while figuring out this process. Hopefully, everything above just works for you, but if not then maybe the posts below will help you out:\n\npstadler/keybase-gpg-github: Step-by-step guide on how to create a GPG key on keybase.io, adding it to a local GPG setup and use it with Git and GitHub.\nSign Git Commits With A Keybase GPG Key ‚Äì Stephen‚Äôs Thoughts\nSign commits with a GPG key using a passphrase with pinentry-mac | By Parker\ngnupg2: gpg: public key decryption failed: Inappropriate ioctl for device ¬∑ Issue #14737 ¬∑ Homebrew/homebrew-core\nSupport signing of git commits ¬∑ Issue #1865 ¬∑ rstudio/rstudio"
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html#appendix",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html#appendix",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "Appendix",
    "text": "Appendix\n\nUse gpg-agent to cache your passphrase without a pinentry GUI\nIf you don‚Äôt want to or can‚Äôt install a pinentry app, you can get gpg-agent to cache your passphrase for a fixed period of time, say 8 hours.\nWhen you start your day ‚Äî or when the cache expires ‚Äî you‚Äôll need to sign something or commit once from the command line to re-enter your passphrase.\nThe first step is to configure gpg-agent to remember your key‚Äôs password for the day (8 hours or 28,800 seconds).\n# ~/.gnupg/gpg-agent.conf\ndefault-cache-ttl 28800\nmax-cache-ttl 28800\nYou‚Äôll need to restart gpg-agent so that it picks up the new configuration.\ngpgconf --kill gpg-agent\nAt this point, any git commit will automatically be signed using your default key. The first commit of the day will require you to enter your password, which does mean that the RStudio Git UI won‚Äôt be able to sign the first commit until you‚Äôve asked gpg to sign something for you.\nTo get around this, you can unlock your gpg key by signing anything at the start of your work day or whenever the 8 hour time limit runs out.\necho \"open sesame\" | gpg -s &gt; /dev/null\n# prompt for password\n\n\n\nA verified commit on GitHub with the green Verified badge.\nThe pinentry-mac dialog window asking for the GPG key passphrase when signing a commit for the first time."
  },
  {
    "objectID": "blog/signed-verified-git-commits-keybase-rstudio/index.html#footnotes",
    "href": "blog/signed-verified-git-commits-keybase-rstudio/index.html#footnotes",
    "title": "Signed and verified: signed git commits with Keybase and RStudio",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWindows users, I‚Äôm sorry! I don‚Äôt own anything that runs Windows. üòí‚Ü©Ô∏é\nYou‚Äôll need git version 2.0 or later. Check with git --version or upgrade git to the latest version with brew install git.‚Ü©Ô∏é\nhttps://en.wikipedia.org/wiki/Keybase‚Ü©Ô∏é\nYou could also create a GPG/PGP key in the Keybase app in the identities section of your profile, but I‚Äôm using the command line so it‚Äôs easier to copy-paste.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html",
    "href": "blog/shrtcts-reprex-to-issue/index.html",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "",
    "text": "Have you ever spent a few minutes hours turning a bug in your code into a reprex ‚Äì a minimal reproducible example?\nGetting to a reprex is 90% of the challenge. Most of the time, I find my mistake in the journey to a reprex. But sometimes, I find a legitimate bug and in those cases, I want to quickly turn my reprex into a GitHub issue.\nHere‚Äôs a quick way to get there using an RStudio addin and shrtcts."
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html#reprex-is-awesome",
    "href": "blog/shrtcts-reprex-to-issue/index.html#reprex-is-awesome",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "reprex is awesome",
    "text": "reprex is awesome\nThe reprex package is awesome. If you‚Äôve never used it before, I highly recommend that you stop reading this blog and go watch Sharla Gelfand‚Äôs make a reprex‚Ä¶ please (or read the slides from the talk).\nYour goal when making a reprex is to come up with a short bit of code that demonstrates the problem you‚Äôve experienced and that is as self-contained as possible.\nTo disentangle your problem from your personal R environment, reprex takes your code, runs it in an isolated environment, and returns a rendered version of your code that‚Äôs ready to be copy-pasted into a text box on a number of common websites where R users go for help.\nThis last feature is one of my favorites: the rendered format of a reprex is the perfect way to start crafting a GitHub issue. Typically, I‚Äôll work out the reprex locally, then use the Reprex selection RStudio addin to render the code, and finally jump over to the issues tab of a GitHub repo to paste the code right there.\nHere‚Äôs an example reprex from Sharla‚Äôs talk. We start with plain R code. reprex renders the R code with additional information about my session and shows me a preview. And finally it also copies the markdown I need in order to paste the reprex into a GitHub issue or other online location.\n\n\nR Code\n\nlibrary(tidyverse)\n\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n\n\n\nReprex Preview\nlibrary(tidyverse)\n\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n#&gt; Error in `mutate()`:\n#&gt; ! Problem while computing `year = case_when(...)`.\n#&gt; Caused by error in `case_when()`:\n\n#&gt; Backtrace:\n#&gt;      ‚ñÜ\n#&gt;   1. ‚îú‚îÄtibble(date = \"2020-01-01\") %&gt;% ...\n#&gt;   2. ‚îú‚îÄdplyr::mutate(...)\n#&gt;   3. ‚îú‚îÄdplyr:::mutate.data.frame(...)\n#&gt;   4. ‚îÇ ‚îî‚îÄdplyr:::mutate_cols(.data, dplyr_quosures(...), caller_env = caller_env())\n#&gt;   5. ‚îÇ   ‚îú‚îÄbase::withCallingHandlers(...)\n#&gt;   6. ‚îÇ   ‚îî‚îÄmask$eval_all_mutate(quo)\n#&gt;   7. ‚îî‚îÄdplyr::case_when(...)\n#&gt;   8.   ‚îî‚îÄdplyr:::replace_with(...)\n#&gt;   9.     ‚îî‚îÄdplyr:::check_type(val, x, name, error_call = error_call)\n#&gt;  10.       ‚îî‚îÄrlang::abort(msg, call = error_call)\nCreated on 2023-02-12 with reprex v2.0.2\n\n\nSession info\n\nsessioninfo::session_info()\n#&gt; ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  setting  value\n#&gt;  version  R version 4.2.2 (2022-10-31)\n#&gt;  os       macOS Big Sur ... 10.16\n#&gt;  system   x86_64, darwin17.0\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  en_US.UTF-8\n#&gt;  ctype    en_US.UTF-8\n#&gt;  tz       America/New_York\n#&gt;  date     2023-02-12\n#&gt;  pandoc   2.18 @ /usr/local/bin/ (via rmarkdown)\n#&gt; \n#&gt; ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  package     * version    date (UTC) lib source\n#&gt;  assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n#&gt;  cli           3.6.0      2023-01-09 [1] CRAN (R 4.2.0)\n#&gt;  colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n#&gt;  DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n#&gt;  digest        0.6.31     2022-12-11 [1] CRAN (R 4.2.0)\n#&gt;  dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n#&gt;  evaluate      0.19       2022-12-13 [1] CRAN (R 4.2.0)\n#&gt;  fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n#&gt;  fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n#&gt;  forcats     * 0.5.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  fs            1.5.2      2021-12-08 [1] CRAN (R 4.2.0)\n#&gt;  generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n#&gt;  ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n#&gt;  gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  hms           1.1.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  htmltools     0.5.4      2022-12-07 [1] CRAN (R 4.2.0)\n#&gt;  knitr         1.42       2023-01-25 [1] CRAN (R 4.2.0)\n#&gt;  lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.0)\n#&gt;  lubridate   * 1.9.0      2022-11-06 [1] CRAN (R 4.2.0)\n#&gt;  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n#&gt;  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n#&gt;  pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n#&gt;  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n#&gt;  purrr       * 1.0.1      2023-01-10 [1] CRAN (R 4.2.0)\n#&gt;  R.cache       0.15.0     2021-04-30 [1] CRAN (R 4.2.0)\n#&gt;  R.methodsS3   1.8.1      2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.oo          1.24.0     2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.utils       2.11.0     2021-09-26 [1] CRAN (R 4.2.0)\n#&gt;  R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n#&gt;  readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n#&gt;  reprex        2.0.2      2022-08-17 [1] CRAN (R 4.2.0)\n#&gt;  rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.0)\n#&gt;  rmarkdown     2.20       2023-01-19 [1] CRAN (R 4.2.0)\n#&gt;  scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n#&gt;  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n#&gt;  stringi       1.7.12     2023-01-11 [1] CRAN (R 4.2.0)\n#&gt;  stringr     * 1.5.0      2022-12-02 [1] CRAN (R 4.2.0)\n#&gt;  styler        1.7.0      2022-03-13 [1] CRAN (R 4.2.0)\n#&gt;  tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n#&gt;  tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n#&gt;  tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.0)\n#&gt;  tidyverse   * 1.3.2.9000 2023-01-28 [1] Github (tidyverse/tidyverse@53199b7)\n#&gt;  timechange  * 0.1.1      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  tzdb          0.3.0      2022-03-28 [1] CRAN (R 4.2.0)\n#&gt;  utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n#&gt;  vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.0)\n#&gt;  withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.0)\n#&gt;  xfun          0.36       2022-12-21 [1] CRAN (R 4.2.0)\n#&gt;  yaml          2.3.6      2022-10-18 [1] CRAN (R 4.2.0)\n#&gt; \n#&gt;  [1] /Users/garrick/Library/R/x86_64/4.2/library\n#&gt;  [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n#&gt; \n#&gt; ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\nClipboard\n``` r\nlibrary(tidyverse)\n\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n#&gt; Error in `mutate()`:\n#&gt; ! Problem while computing `year = case_when(...)`.\n#&gt; Caused by error in `case_when()`:\n\n#&gt; Backtrace:\n#&gt;      ‚ñÜ\n#&gt;   1. ‚îú‚îÄtibble(date = \"2020-01-01\") %&gt;% ...\n#&gt;   2. ‚îú‚îÄdplyr::mutate(...)\n#&gt;   3. ‚îú‚îÄdplyr:::mutate.data.frame(...)\n#&gt;   4. ‚îÇ ‚îî‚îÄdplyr:::mutate_cols(.data, dplyr_quosures(...), caller_env = caller_env())\n#&gt;   5. ‚îÇ   ‚îú‚îÄbase::withCallingHandlers(...)\n#&gt;   6. ‚îÇ   ‚îî‚îÄmask$eval_all_mutate(quo)\n#&gt;   7. ‚îî‚îÄdplyr::case_when(...)\n#&gt;   8.   ‚îî‚îÄdplyr:::replace_with(...)\n#&gt;   9.     ‚îî‚îÄdplyr:::check_type(val, x, name, error_call = error_call)\n#&gt;  10.       ‚îî‚îÄrlang::abort(msg, call = error_call)\n```\n\n&lt;sup&gt;Created on 2023-02-12 with [reprex v2.0.2](https://reprex.tidyverse.org)&lt;/sup&gt;\n\n&lt;details style=\"margin-bottom:10px;\"&gt;\n&lt;summary&gt;\nSession info\n&lt;/summary&gt;\n\n``` r\nsessioninfo::session_info()\n#&gt; ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  setting  value\n#&gt;  version  R version 4.2.2 (2022-10-31)\n#&gt;  os       macOS Big Sur ... 10.16\n#&gt;  system   x86_64, darwin17.0\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  en_US.UTF-8\n#&gt;  ctype    en_US.UTF-8\n#&gt;  tz       America/New_York\n#&gt;  date     2023-02-12\n#&gt;  pandoc   2.18 @ /usr/local/bin/ (via rmarkdown)\n#&gt; \n#&gt; ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  package     * version    date (UTC) lib source\n#&gt;  assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n#&gt;  cli           3.6.0      2023-01-09 [1] CRAN (R 4.2.0)\n#&gt;  colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n#&gt;  DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n#&gt;  digest        0.6.31     2022-12-11 [1] CRAN (R 4.2.0)\n#&gt;  dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n#&gt;  evaluate      0.19       2022-12-13 [1] CRAN (R 4.2.0)\n#&gt;  fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n#&gt;  fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n#&gt;  forcats     * 0.5.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  fs            1.5.2      2021-12-08 [1] CRAN (R 4.2.0)\n#&gt;  generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n#&gt;  ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n#&gt;  gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  hms           1.1.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  htmltools     0.5.4      2022-12-07 [1] CRAN (R 4.2.0)\n#&gt;  knitr         1.42       2023-01-25 [1] CRAN (R 4.2.0)\n#&gt;  lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.0)\n#&gt;  lubridate   * 1.9.0      2022-11-06 [1] CRAN (R 4.2.0)\n#&gt;  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n#&gt;  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n#&gt;  pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n#&gt;  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n#&gt;  purrr       * 1.0.1      2023-01-10 [1] CRAN (R 4.2.0)\n#&gt;  R.cache       0.15.0     2021-04-30 [1] CRAN (R 4.2.0)\n#&gt;  R.methodsS3   1.8.1      2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.oo          1.24.0     2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.utils       2.11.0     2021-09-26 [1] CRAN (R 4.2.0)\n#&gt;  R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n#&gt;  readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n#&gt;  reprex        2.0.2      2022-08-17 [1] CRAN (R 4.2.0)\n#&gt;  rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.0)\n#&gt;  rmarkdown     2.20       2023-01-19 [1] CRAN (R 4.2.0)\n#&gt;  scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n#&gt;  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n#&gt;  stringi       1.7.12     2023-01-11 [1] CRAN (R 4.2.0)\n#&gt;  stringr     * 1.5.0      2022-12-02 [1] CRAN (R 4.2.0)\n#&gt;  styler        1.7.0      2022-03-13 [1] CRAN (R 4.2.0)\n#&gt;  tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n#&gt;  tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n#&gt;  tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.0)\n#&gt;  tidyverse   * 1.3.2.9000 2023-01-28 [1] Github (tidyverse/tidyverse@53199b7)\n#&gt;  timechange  * 0.1.1      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  tzdb          0.3.0      2022-03-28 [1] CRAN (R 4.2.0)\n#&gt;  utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n#&gt;  vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.0)\n#&gt;  withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.0)\n#&gt;  xfun          0.36       2022-12-21 [1] CRAN (R 4.2.0)\n#&gt;  yaml          2.3.6      2022-10-18 [1] CRAN (R 4.2.0)\n#&gt; \n#&gt;  [1] /Users/garrick/Library/R/x86_64/4.2/library\n#&gt;  [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n#&gt; \n#&gt; ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n```\n\n&lt;/details&gt;"
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html#but-wait-theres-more",
    "href": "blog/shrtcts-reprex-to-issue/index.html#but-wait-theres-more",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "But wait, there‚Äôs more!",
    "text": "But wait, there‚Äôs more!\nWhen you‚Äôre working on debugging something, going from code in your RStudio IDE to something you can share with others is huge. But reprex can do more!\nBecause reprex uses knitr::spin() ‚Äî knitr‚Äôs best hidden gem according to Dean Attali ‚Äî to turn R code into an R Markdown document, you have a few more options.\nknitr::spin() has a cool feature that lets you write markdown in an R script. You can check out Dean Attali‚Äôs post for more details, but the gist is this: any text on a line starting with a special comment format #' becomes markdown.\nThis means we can add text directly to our reprex using these comments! Below you can see that I‚Äôve added some exposition around the problematic code.\n\n\nR Code\n\n#' I'm using the latest version of the `tidyverse`,\n#' freshly installed.\nlibrary(tidyverse)\n\n#' Suppose we have a data frame with a date column.\n#' The date is stored as a _character_ vector, and\n#' I'd like to convert it to a _year_ with a simple\n#' comparison. The first function I thought of was\n#' `case_when()`, but it doesn't seem to be doing\n#' what I expect. Why am I getting this error?\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n\n\n\nReprex Preview\nI‚Äôm using the latest version of the tidyverse, freshly installed.\nlibrary(tidyverse)\nSuppose we have a data frame with a date column. The date is stored as a character vector, and I‚Äôd like to convert it to a year with a simple comparison. The first function I thought of was case_when(), but it doesn‚Äôt seem to be doing what I expect. Why am I getting this error?\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n#&gt; Error in `mutate()`:\n#&gt; ! Problem while computing `year = case_when(...)`.\n#&gt; Caused by error in `case_when()`:\n\n#&gt; Backtrace:\n#&gt;      ‚ñÜ\n#&gt;   1. ‚îú‚îÄtibble(date = \"2020-01-01\") %&gt;% ...\n#&gt;   2. ‚îú‚îÄdplyr::mutate(...)\n#&gt;   3. ‚îú‚îÄdplyr:::mutate.data.frame(...)\n#&gt;   4. ‚îÇ ‚îî‚îÄdplyr:::mutate_cols(.data, dplyr_quosures(...), caller_env = caller_env())\n#&gt;   5. ‚îÇ   ‚îú‚îÄbase::withCallingHandlers(...)\n#&gt;   6. ‚îÇ   ‚îî‚îÄmask$eval_all_mutate(quo)\n#&gt;   7. ‚îî‚îÄdplyr::case_when(...)\n#&gt;   8.   ‚îî‚îÄdplyr:::replace_with(...)\n#&gt;   9.     ‚îî‚îÄdplyr:::check_type(val, x, name, error_call = error_call)\n#&gt;  10.       ‚îî‚îÄrlang::abort(msg, call = error_call)\nCreated on 2023-02-12 with reprex v2.0.2\n\n\nSession info\n\nsessioninfo::session_info()\n#&gt; ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  setting  value\n#&gt;  version  R version 4.2.2 (2022-10-31)\n#&gt;  os       macOS Big Sur ... 10.16\n#&gt;  system   x86_64, darwin17.0\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  en_US.UTF-8\n#&gt;  ctype    en_US.UTF-8\n#&gt;  tz       America/New_York\n#&gt;  date     2023-02-12\n#&gt;  pandoc   2.18 @ /usr/local/bin/ (via rmarkdown)\n#&gt; \n#&gt; ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  package     * version    date (UTC) lib source\n#&gt;  assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n#&gt;  cli           3.6.0      2023-01-09 [1] CRAN (R 4.2.0)\n#&gt;  colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n#&gt;  DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n#&gt;  digest        0.6.31     2022-12-11 [1] CRAN (R 4.2.0)\n#&gt;  dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n#&gt;  evaluate      0.19       2022-12-13 [1] CRAN (R 4.2.0)\n#&gt;  fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n#&gt;  fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n#&gt;  forcats     * 0.5.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  fs            1.5.2      2021-12-08 [1] CRAN (R 4.2.0)\n#&gt;  generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n#&gt;  ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n#&gt;  gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  hms           1.1.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  htmltools     0.5.4      2022-12-07 [1] CRAN (R 4.2.0)\n#&gt;  knitr         1.42       2023-01-25 [1] CRAN (R 4.2.0)\n#&gt;  lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.0)\n#&gt;  lubridate   * 1.9.0      2022-11-06 [1] CRAN (R 4.2.0)\n#&gt;  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n#&gt;  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n#&gt;  pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n#&gt;  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n#&gt;  purrr       * 1.0.1      2023-01-10 [1] CRAN (R 4.2.0)\n#&gt;  R.cache       0.15.0     2021-04-30 [1] CRAN (R 4.2.0)\n#&gt;  R.methodsS3   1.8.1      2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.oo          1.24.0     2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.utils       2.11.0     2021-09-26 [1] CRAN (R 4.2.0)\n#&gt;  R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n#&gt;  readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n#&gt;  reprex        2.0.2      2022-08-17 [1] CRAN (R 4.2.0)\n#&gt;  rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.0)\n#&gt;  rmarkdown     2.20       2023-01-19 [1] CRAN (R 4.2.0)\n#&gt;  scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n#&gt;  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n#&gt;  stringi       1.7.12     2023-01-11 [1] CRAN (R 4.2.0)\n#&gt;  stringr     * 1.5.0      2022-12-02 [1] CRAN (R 4.2.0)\n#&gt;  styler        1.7.0      2022-03-13 [1] CRAN (R 4.2.0)\n#&gt;  tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n#&gt;  tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n#&gt;  tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.0)\n#&gt;  tidyverse   * 1.3.2.9000 2023-01-28 [1] Github (tidyverse/tidyverse@53199b7)\n#&gt;  timechange  * 0.1.1      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  tzdb          0.3.0      2022-03-28 [1] CRAN (R 4.2.0)\n#&gt;  utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n#&gt;  vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.0)\n#&gt;  withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.0)\n#&gt;  xfun          0.36       2022-12-21 [1] CRAN (R 4.2.0)\n#&gt;  yaml          2.3.6      2022-10-18 [1] CRAN (R 4.2.0)\n#&gt; \n#&gt;  [1] /Users/garrick/Library/R/x86_64/4.2/library\n#&gt;  [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n#&gt; \n#&gt; ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n\n\n\nClipboard\nI‚Äôm using the latest version of the `tidyverse`,\nfreshly installed.\n\n``` r\nlibrary(tidyverse)\n```\n\nSuppose we have a data frame with a date column.\nThe date is stored as a *character* vector, and\nI‚Äôd like to convert it to a *year* with a simple\ncomparison. The first function I thought of was\n`case_when()`, but it doesn‚Äôt seem to be doing\nwhat I expect. Why am I getting this error?\n\n``` r\ntibble(date = \"2020-01-01\") %&gt;%\n  mutate(year = case_when(\n    date &lt;= \"2020-12-31\" & date &gt;= \"2020-01-01\" ~ 2020,\n    is.na(date) ~ NA\n  ))\n#&gt; Error in `mutate()`:\n#&gt; ! Problem while computing `year = case_when(...)`.\n#&gt; Caused by error in `case_when()`:\n\n#&gt; Backtrace:\n#&gt;      ‚ñÜ\n#&gt;   1. ‚îú‚îÄtibble(date = \"2020-01-01\") %&gt;% ...\n#&gt;   2. ‚îú‚îÄdplyr::mutate(...)\n#&gt;   3. ‚îú‚îÄdplyr:::mutate.data.frame(...)\n#&gt;   4. ‚îÇ ‚îî‚îÄdplyr:::mutate_cols(.data, dplyr_quosures(...), caller_env = caller_env())\n#&gt;   5. ‚îÇ   ‚îú‚îÄbase::withCallingHandlers(...)\n#&gt;   6. ‚îÇ   ‚îî‚îÄmask$eval_all_mutate(quo)\n#&gt;   7. ‚îî‚îÄdplyr::case_when(...)\n#&gt;   8.   ‚îî‚îÄdplyr:::replace_with(...)\n#&gt;   9.     ‚îî‚îÄdplyr:::check_type(val, x, name, error_call = error_call)\n#&gt;  10.       ‚îî‚îÄrlang::abort(msg, call = error_call)\n```\n\n&lt;sup&gt;Created on 2023-02-12 with [reprex v2.0.2](https://reprex.tidyverse.org)&lt;/sup&gt;\n\n&lt;details style=\"margin-bottom:10px;\"&gt;\n&lt;summary&gt;\nSession info\n&lt;/summary&gt;\n\n``` r\nsessioninfo::session_info()\n#&gt; ‚îÄ Session info ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  setting  value\n#&gt;  version  R version 4.2.2 (2022-10-31)\n#&gt;  os       macOS Big Sur ... 10.16\n#&gt;  system   x86_64, darwin17.0\n#&gt;  ui       X11\n#&gt;  language (EN)\n#&gt;  collate  en_US.UTF-8\n#&gt;  ctype    en_US.UTF-8\n#&gt;  tz       America/New_York\n#&gt;  date     2023-02-12\n#&gt;  pandoc   2.18 @ /usr/local/bin/ (via rmarkdown)\n#&gt; \n#&gt; ‚îÄ Packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt;  package     * version    date (UTC) lib source\n#&gt;  assertthat    0.2.1      2019-03-21 [1] CRAN (R 4.2.0)\n#&gt;  cli           3.6.0      2023-01-09 [1] CRAN (R 4.2.0)\n#&gt;  colorspace    2.0-3      2022-02-21 [1] CRAN (R 4.2.0)\n#&gt;  DBI           1.1.3      2022-06-18 [1] CRAN (R 4.2.0)\n#&gt;  digest        0.6.31     2022-12-11 [1] CRAN (R 4.2.0)\n#&gt;  dplyr       * 1.0.10     2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  ellipsis      0.3.2      2021-04-29 [1] CRAN (R 4.2.0)\n#&gt;  evaluate      0.19       2022-12-13 [1] CRAN (R 4.2.0)\n#&gt;  fansi         1.0.3      2022-03-24 [1] CRAN (R 4.2.0)\n#&gt;  fastmap       1.1.0      2021-01-25 [1] CRAN (R 4.2.0)\n#&gt;  forcats     * 0.5.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  fs            1.5.2      2021-12-08 [1] CRAN (R 4.2.0)\n#&gt;  generics      0.1.3      2022-07-05 [1] CRAN (R 4.2.0)\n#&gt;  ggplot2     * 3.4.0      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  glue          1.6.2      2022-02-24 [1] CRAN (R 4.2.0)\n#&gt;  gtable        0.3.1      2022-09-01 [1] CRAN (R 4.2.0)\n#&gt;  hms           1.1.2      2022-08-19 [1] CRAN (R 4.2.0)\n#&gt;  htmltools     0.5.4      2022-12-07 [1] CRAN (R 4.2.0)\n#&gt;  knitr         1.42       2023-01-25 [1] CRAN (R 4.2.0)\n#&gt;  lifecycle     1.0.3      2022-10-07 [1] CRAN (R 4.2.0)\n#&gt;  lubridate   * 1.9.0      2022-11-06 [1] CRAN (R 4.2.0)\n#&gt;  magrittr      2.0.3      2022-03-30 [1] CRAN (R 4.2.0)\n#&gt;  munsell       0.5.0      2018-06-12 [1] CRAN (R 4.2.0)\n#&gt;  pillar        1.8.1      2022-08-19 [1] CRAN (R 4.2.1)\n#&gt;  pkgconfig     2.0.3      2019-09-22 [1] CRAN (R 4.2.0)\n#&gt;  purrr       * 1.0.1      2023-01-10 [1] CRAN (R 4.2.0)\n#&gt;  R.cache       0.15.0     2021-04-30 [1] CRAN (R 4.2.0)\n#&gt;  R.methodsS3   1.8.1      2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.oo          1.24.0     2020-08-26 [1] CRAN (R 4.2.0)\n#&gt;  R.utils       2.11.0     2021-09-26 [1] CRAN (R 4.2.0)\n#&gt;  R6            2.5.1      2021-08-19 [1] CRAN (R 4.2.0)\n#&gt;  readr       * 2.1.3      2022-10-01 [1] CRAN (R 4.2.0)\n#&gt;  reprex        2.0.2      2022-08-17 [1] CRAN (R 4.2.0)\n#&gt;  rlang         1.0.6      2022-09-24 [1] CRAN (R 4.2.0)\n#&gt;  rmarkdown     2.20       2023-01-19 [1] CRAN (R 4.2.0)\n#&gt;  scales        1.2.1      2022-08-20 [1] CRAN (R 4.2.1)\n#&gt;  sessioninfo   1.2.2      2021-12-06 [1] CRAN (R 4.2.0)\n#&gt;  stringi       1.7.12     2023-01-11 [1] CRAN (R 4.2.0)\n#&gt;  stringr     * 1.5.0      2022-12-02 [1] CRAN (R 4.2.0)\n#&gt;  styler        1.7.0      2022-03-13 [1] CRAN (R 4.2.0)\n#&gt;  tibble      * 3.1.8      2022-07-22 [1] CRAN (R 4.2.0)\n#&gt;  tidyr       * 1.2.1      2022-09-08 [1] CRAN (R 4.2.0)\n#&gt;  tidyselect    1.2.0      2022-10-10 [1] CRAN (R 4.2.0)\n#&gt;  tidyverse   * 1.3.2.9000 2023-01-28 [1] Github (tidyverse/tidyverse@53199b7)\n#&gt;  timechange  * 0.1.1      2022-11-04 [1] CRAN (R 4.2.0)\n#&gt;  tzdb          0.3.0      2022-03-28 [1] CRAN (R 4.2.0)\n#&gt;  utf8          1.2.2      2021-07-24 [1] CRAN (R 4.2.0)\n#&gt;  vctrs         0.5.1      2022-11-16 [1] CRAN (R 4.2.0)\n#&gt;  withr         2.5.0      2022-03-03 [1] CRAN (R 4.2.0)\n#&gt;  xfun          0.36       2022-12-21 [1] CRAN (R 4.2.0)\n#&gt;  yaml          2.3.6      2022-10-18 [1] CRAN (R 4.2.0)\n#&gt; \n#&gt;  [1] /Users/garrick/Library/R/x86_64/4.2/library\n#&gt;  [2] /Library/Frameworks/R.framework/Versions/4.2/Resources/library\n#&gt; \n#&gt; ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n```\n\n&lt;/details&gt;"
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html#there-should-be-a-shortcut",
    "href": "blog/shrtcts-reprex-to-issue/index.html#there-should-be-a-shortcut",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "There should be a shortcut",
    "text": "There should be a shortcut\nKick-starting an issue report using a reprex right from within my RStudio session is great, but there‚Äôs still the part where I have to slog out of my IDE, into a browser, and find my way to the repo where this issue should go.\nMost of the time, though, I‚Äôm already in the repo. And usethis has a helpful function to get me right to the issues page:\n\nusethis::browse_github_issues()\n\nBut there‚Äôs too much typing. I want reprex to issue, with magic üßô ‚ú®.\nSo that‚Äôs what we‚Äôll do! In the rest of this post, we‚Äôll use reprex and the rstudioapi package to automatically go from code to GitHub issue. Then we‚Äôll wrap that logic into a function and turn it into an RStudio Addin with my package, shrtcts."
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html#from-reprex-to-issue",
    "href": "blog/shrtcts-reprex-to-issue/index.html#from-reprex-to-issue",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "From reprex to issue",
    "text": "From reprex to issue\nSuppose we have some input code and a target repo. Maybe we have a classic missing argument error and we want to send the issue to gadenbuie/shrtcts (please don‚Äôt!).\n\ninput &lt;- \"runif(min = 0, max = 10)\\n\"\nrepo &lt;- \"gadenbuie/shrtcts\"\n\n\nPrepare the issue body\nOur goal is to render the reprex into an issue body and then we‚Äôll put together a URL that takes us to GitHub‚Äôs new issue page for the repo with the issue body pre-filled when we get there.\n\nbody &lt;- \"... reprex body goes here ...\"\nurl_new_issue &lt;- glue::glue(\"https://github.com/{repo}/issues/new?body={body}\")\nbrowseURL(url_new_issue)\n\nThe trick here is that you can create a new issue by going to github.com/{owner}/{repo}/issues/new and we‚Äôre sending along the initial body using the query string ?body={body}.\nTo put together the body, we first render the input using reprex::reprex()\n\nbody &lt;- reprex::reprex(input = input, venue = \"gh\", html_preview = TRUE)\n\nwhere we‚Äôve asked for a reprex for GitHub ‚Äî venue = \"gh\" ‚Äî and a local HTML preview ‚Äî html_preview = TRUE. You can adjust the arguments to reprex() to fit your needs, of course.\nUnfortunately, reprex::repex() is only half the work‚Ä¶\n\nbody &lt;- reprex::reprex(input = input, venue = \"gh\", html_preview = TRUE)\nbody\n\n[1] \"``` r\"                                                                           \n[2] \"runif(min = 0, max = 10)\"                                                        \n[3] \"#&gt; Error in runif(min = 0, max = 10): argument \\\"n\\\" is missing, with no default\"\n[4] \"```\"                                                                             \n\n\nNotice that it returns a character vector with one item per line of the rendered reprex. We need to collapse it all into a single string.\n\nbody &lt;- paste(body, collapse = \"\\n\")\n\n\n\n[1] \"``` r\\nrunif(min = 0, max = 10)\\n#&gt; Error in runif(min = 0, max = 10): argument \\\"n\\\" is missing, with no default\\n```\"\n\n\nBut this still won‚Äôt fit in a URL because it contains spaces, new lines, and other characters URLs don‚Äôt like. So we need to use the base R function URLencode() to turn the body text into something readable only by machines.\n\nbody &lt;- URLencode(body, reserved = TRUE)\n\n\n\n[1] \"%60%60%60%20r%0Arunif%28min%20%3D%200%2C%20max%20%3D%2010%29%0A%23%3E%20Error%20in%20runif%28min%20%3D%200%2C%20max%20%3D%2010%29%3A%20argument%20%22n%22%20is%20missing%2C%20with%20no%20default%0A%60%60%60\"\n\n\nFinally, we can make our new issue URL.\n\nurl_new_issue &lt;- glue::glue(\"https://github.com/{repo}/issues/new?body={body}\")\nurl_new_issue\n\nhttps://github.com/gadenbuie/shrtcts/issues/new?body=%60%60%60%20r%0Arunif%28min%20%3D%200%2C%20max%20%3D%2010%29%0A%23%3E%20Error%20in%20runif%28min%20%3D%200%2C%20max%20%3D%2010%29%3A%20argument%20%22n%22%20is%20missing%2C%20with%20no%20default%0A%60%60%60\n\n\nI didn‚Äôt make the link clickable, but if you were to follow it, you‚Äôd find a brand new issue page ready for you.\n\n\n\nA new GitHub issue page with our reprex as the issue body\n\n\n\n\nGrab the input from the user\nOf course, we don‚Äôt want to have to define input manualy every time we run this function. Instead, we‚Äôd rather get the input code from\n\nthe current selection in RStudio\nor the clipboard if nothing is selected\n\nTo make things easy, we‚Äôll ignore the fact that RStudio has a multiple cursors feature, and we‚Äôll just get the first selection of code. We‚Äôll use the getSourceEditorContext() to get the currently open text file, then we can grab the text from the first selection in that editor window.\n\nctx &lt;- rstudioapi::getSourceEditorContext()\nselection &lt;- ctx$selection[[1]]$text\n\nIf nothing is selected, selection will be an empty string, \"\", in which case we‚Äôd prefer to leave input as NULL so that reprex() will look in the clipboard for our input. We also need to make sure that input is a character vector so that reprex() knows that input contains the reprex code and not a path to a file.\n\ninput &lt;- if (nzchar(selection)) {\n  c(strsplit(selection, \"\\n\")[[1]], \"\")\n}\n\nWe‚Äôll be wrapping this up in a function where input might be provided by the user, so we‚Äôll only want to check for a selection if input is NULL.\n\nif (is.null(input)) {\n  ctx &lt;- rstudioapi::getSourceEditorContext()\n  selection &lt;- ctx$selection[[1]]$text\n  input &lt;- if (nzchar(selection)) {\n    c(strsplit(selection, \"\\n\")[[1]], \"\")\n  }\n}\n\n\n\nPick the repository\nOften, I‚Äôll be working in the repository where I want to create the issue. usethis does a great job guessing the repository from the information in a local copy of the repo. Rather than spending forever writing our own version, let‚Äôs just reach into usethis with ::: to call target_repo_spec().\nThe function returns the current repo in the form \"owner/repo\", but since it isn‚Äôt designed to be user-facing it throws an unusual error when called from outside a git repository. We can soften this edge by catching the error with tryCatch() and replacing the error with a NULL value.\n\nrepo_guess &lt;- tryCatch(\n  usethis:::target_repo_spec(\"source\", FALSE),\n  error = function(err) NULL\n)\n\nOf course, maybe I‚Äôll want to create a reprex in another repository that isn‚Äôt the one I‚Äôm currently working in. So we can follow up with a prompt asking for the repo, using our guess from usethis. The prompt is created with the showPrompt() function from rstudioapi.\n\nrepo &lt;- rstudioapi::showPrompt(\n  title = \"Which repository?\",\n  message = \"Where should we create the issue? (owner/repo)\",\n  default = repo_guess\n)\n\n\n\n\nFinally, the function we‚Äôre putting together will also take a repo argument that might be provided when we call it. In that case, we‚Äôd wouldn‚Äôt need to guess or ask for a repo.\n\nif (is.null(repo)) {\n  repo_guess &lt;- tryCatch(\n    usethis:::target_repo_spec(\"source\", FALSE),\n    error = function(err) NULL\n  )\n\n  repo &lt;- rstudioapi::showPrompt(\n    title = \"Which repository?\",\n    message = \"Where should we create the issue? (owner/repo)\",\n    default = repo_guess\n  )\n}"
  },
  {
    "objectID": "blog/shrtcts-reprex-to-issue/index.html#make-it-a-shortcut",
    "href": "blog/shrtcts-reprex-to-issue/index.html#make-it-a-shortcut",
    "title": "Create a GitHub issue from a reprex with shrtcts",
    "section": "Make it a shortcut",
    "text": "Make it a shortcut\nThe last step in our process is to make it easy to run this code in RStudio, ideally as an RStudio addin that we can activate from the addins menu or the command palette.\nThis is the exact goal of the shrtcts package: shrtcts lets you turn any function into an RStudio addin.\n\nSet up shrtcts\nIf you‚Äôve never used shrtcts before, you need to do two things to get started. First, install the package, from my R-universe or from GitHub.\n\n\nR-universe\n\n# Add my universe to your list of repos\noptions(repos = c(\n  gadenbuie = \"https://gadenbuie.r-universe.dev\",\n  getOption(\"repos\")\n))\n\ninstall.package(\"shrtcts\")\n\n\n\nGitHub\n\n# install.packages(\"remotes\")\n\nremotes::install_github(\"gadenbuie/shrtcts\")\n\n\n\nThe next thing to do is to open a .shrtcts.R file where we‚Äôll add our new shortcut. This is easy to do with shrtcts::edit_shortcuts(), which will offer to create the .shrtcts.R file if it doesn‚Äôt exit.\n\nshrtcts::edit_shortcuts()\n\nWould you like to create a new shrtcts file at\n'~/Library/Application Support/shrtcts/.shrtcts.R' (Yes/no/cancel) yes\n\n\nCreating a shortcut function\nWe‚Äôll write R functions in the .shrtcts.R file and turn them into RStudio addins by annotating those functions with roxygen-style comments.\nWe start with a skeleton of a function that takes two arguments: input and repo, neither of which are required. Inside the function, we‚Äôll do all the steps from above, which we‚Äôll fill in in a second.\n\ncreate_issue_from_reprex &lt;- function(input = NULL, repo = NULL) {\n  # guess or ask for repo\n  # get current selection, if available\n  # render reprex\n  # compose new issue URL\n  # go to the new issue page!\n}\n\nOur next step is to turn this function into a shortcut. Using roxygen2 documentation syntax, we give the function a title and description ‚Äî these will be used as the title and description of the shortcut. We can also use the @shortcut tag to set a keyboard shortcut (if you want), and the @interactive tag lets shortcuts know that the addin should be run interactively rather than in the background.\n\n#' Create issue from reprex\n#'\n#' Creates an issue from the selected or copied reprex.\n#'\n#' @shortcut Cmd+Ctrl+Shift+R\n#' @interactive\ncreate_issue_from_reprex &lt;- function(input = NULL, repo = NULL) {\n  # guess or ask for repo\n  # get current selection, if available\n  # render reprex\n  # compose new issue URL\n  # go to the new issue page!\n}\n\nFinally, we can replace our placeholder comments with all of the code we wrote above.\n\n#' Create issue from reprex\n#'\n#' Creates an issue from the selected or copied reprex.\n#'\n#' @shortcut Cmd+Ctrl+Shift+R\n#' @interactive\ncreate_issue_from_reprex &lt;- function(input = NULL, repo = NULL) {\n  if (is.null(repo)) {\n    repo_guess &lt;- tryCatch(\n      usethis:::target_repo_spec(\"source\", FALSE),\n      error = function(err) NULL\n    )\n  \n    repo &lt;- rstudioapi::showPrompt(\n      title = \"Which repository?\",\n      message = \"Where should we create the issue? (owner/repo)\",\n      default = repo_guess\n    )\n  }\n\n  if (is.null(input)) {\n    ctx &lt;- rstudioapi::getSourceEditorContext()\n    selection &lt;- ctx$selection[[1]]$text\n    input &lt;- if (nzchar(selection)) {\n      c(strsplit(selection, \"\\n\")[[1]], \"\")\n    }\n  }\n\n  body &lt;- reprex::reprex(input = input, venue = \"gh\", html_preview = TRUE)\n  body &lt;- paste(body, collapse = \"\\n\")\n  body &lt;- URLencode(body, reserved = TRUE)\n  url_new_issue &lt;- glue::glue(\"https://github.com/{repo}/issues/new?body={body}\")\n  browseURL(url_new_issue)\n  invisible(url_new_issue)\n}\n\nLoad your shortcuts and restart your R session to activate the addin and you‚Äôll be ready to jump from reprex to GitHub issue in no time!\n\nshrtcts::add_rstudio_shortcuts(set_keyboard_shortcuts = TRUE)\n\n\n\n\nThe reprex to GitHub issue shortcut in action.\n\n\n\n\n\n\n\n\n\n\nA new GitHub issue page with our reprex as the issue body"
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#upgrade-to-big-sur",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#upgrade-to-big-sur",
    "title": "Setting up a new MacBook Pro",
    "section": "Upgrade to Big Sur",
    "text": "Upgrade to Big Sur\n11:05amI‚Äôve got a new work laptop! I‚Äôm going to try to track my setup process and the software and tools I install in this thread\n\n11:05amStep #1, wait‚Ä¶\n\n11:08amOh wow, I really jumped the gun on this thread\n\n11:17amin the mean time, I guess I‚Äôll tidy the dock\n\n11:27amHere‚Äôs something I do on every machine I use: turn Caps Lock into Escape. It‚Äôs only annoying when I write SQL but it saves so much finger and hand movement. Essential for vim mode.\n\n11:42amLooking for other things I can tweak while I wait. Hot corners?\n‚ÜóÔ∏è Mission Control\n‚ÜòÔ∏è Desktop\n‚ÜôÔ∏è Application Windows\n‚ÜñÔ∏è Put Display to Sleep (and add require password immediately)\n\n11:47amOkay, Big Sur Install Time has arrived. After these messages, we‚Äôll be right back.\nüçé 1 minute remaining‚Ä¶\nüçé About 17 minutes remaining‚Ä¶\nüçé About 26 minutes remaining‚Ä¶\nüçé About 9 minutes remaining‚Ä¶\n*reboots*\nüçé (no time estimate)\n12:04pmAfter a reboot, all is quiet. The screen is black. I move the mouse. A login screen! That was fast!\nI login. I‚Äôve entered a time loop. Tuesday starts again.\n\n12:07pmI guess we‚Äôre downloading Big Sur again. I feel like I did this before‚Ä¶\n\n12:42pmDownload complete ‚Ä¶ now this looks legit. Wish me luck!"
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#critical-first-steps",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#critical-first-steps",
    "title": "Setting up a new MacBook Pro",
    "section": "Critical First Steps",
    "text": "Critical First Steps\n02:33pmAnd we‚Äôre back! I am‚Ä¶ not sure how I feel about the new look of Big Sur\n\n\n02:41pmJust in case you or I get lost, I took some notes while I was waiting for Big Sur to install. Here‚Äôs my general install plan\nhttps://gist.github.com/gadenbuie/a14cab3d075901d8b25cbaf9e1f1fa7d\n02:42pmFirst things first I need a good terminal and iTerm2 is my favorite\nhttps://iterm2.com/\n02:47pmNow that I have iTerm2, I need Apple‚Äôs Command Line Tools. Open up iTerm2 and run\nxcode-select --install\nHopefully this won‚Äôt take long‚Ä¶\n\n\n02:48pmThat was pleasantly fast. Next up: homebrew.\nHomebrew makes it easy to install software, even apps. I‚Äôm just going to copy the install code from https://brew.sh/ and run it\n02:56pmHomebrew‚Äôs ready, so let‚Äôs put it to use. I use @alfredapp to switch between apps, files, etc. so I‚Äôll use brew to install it:\nbrew cask install Alfred\nbrew install &lt;x&gt; usually installs command line utility &lt;x&gt;. Apps with interfaces need ‚Äúcask‚Äù.\nhttps://www.alfredapp.com/\n02:57pmIf you use Alfred, @hadleywickham has an awesome tip to let Alfred find @rstudio .Rproj project files.\n\nI've documented my workflow for opening @RStudio projects (using on @alfredapp) in this short video: https://t.co/XvmRyGSsol #rstats\n‚Äî Hadley Wickham (@hadleywickham) February 27, 2018\n\n02:59pmAnd if you purchase Alfred‚Äôs powerpack features, @pjs_228 has a collection of helpful R workflows\n\nAre you an @alfredapp and #rstats user?\n\nI‚Äôve created an alfred workflow for R which might be helpful.https://t.co/GrsIbCqaBT\n\nFeedback welcome.\n‚Äî Patrick Schratz (@patscli) November 19, 2020\n\n03:06pmAfter jumping through a few permission hoops to give Alfred access to everything, we‚Äôre in business.\nI remap Alt + Space to Spotlight (Mac‚Äôs quick finder) and make Alfred Cmd + space.\n\n03:10pmNext up, my browser. I use and love Firefox on all devices and my daily driver is the Firefox Developer Edition\nhttps://www.mozilla.org/en-US/firefox/developer/\n03:11pmI‚Äôve been informed by homebrew that\nbrew cask install &lt;app&gt;\nhas been deprecated in favor of\nbrew install --cask &lt;app&gt;\n03:13pmAfter a short digression, I got Firefox to install with brew\nbrew tap homebrew/cask-version\n\nbrew install --cask firefox-developer-edition\n\n03:19pmMy favorite part of installing @firefox: login to Firefox Sync and all of my bookmarks, extensions, preferences, etc. all magically appear in my new browser\n\n03:22pmAnother short digression, I use these extensions every day:\n\nLastPass https://lastpass.com\nRefined Github https://github.com/sindresorhus/refined-github\nDark Reader https://darkreader.org/\nCopy as Markdown https://addons.mozilla.org/en-US/firefox/addon/copy-as-markdown/"
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#install-r-and-friends",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#install-r-and-friends",
    "title": "Setting up a new MacBook Pro",
    "section": "Install R and Friends",
    "text": "Install R and Friends\n03:26pmOkay, with the critical bits done, it‚Äôs time to install #rstats!\nI‚Äôm going to install both 3.6.3 and 4.0.3 (and maybe eventually devel). Yes, you have multiple versions of R on your machine at once (more on that in a second)\nhttps://cran.r-project.org/src/base/R-4\nhttps://cran.r-project.org/src/base/R-3\n03:30pmYikes! Those are not the links I want. How many other people click the wrong links on the front page of https://www.r-project.org ?\n\n03:33pmIt takes a surprising number of clicks to get to where I can download the macOS R binaries. I mostly just click things but I‚Äôm sure this process is very confusing for many people. The page is loaded in an iframe, which makes deep-linking hard: https://cloud.r-project.org/bin/macosx/\n\n03:39pmI picked the signed 3.6.3 binary but I still had to go through macOS security steps. When it doesn‚Äôt open, open System Preferences &gt; Security and Privacy &gt; General and then, while second-guessing yourself, click ‚ÄúOpen Anyway‚Äù\n\n\n03:51pmWhich R installs faster? It‚Äôs a race (to see if I can remember my new password)\n\n03:53pmNow that I have more than one version of R installed, Bob Rudis‚Äô RSwitch utility is essential. Easily switch between versions of R from the menu bar!\nhttps://rud.is/rswitch/\n03:54pmIt also makes it easy to grab the latest preview version of @rstudio which you can also find online https://dailies.rstudio.com/\n\n03:58pmMy little laptop is growing up so fast\n\n04:07pmOkay, I need R packages now. To get them fast, I‚Äôll install pak, which requires a little setup, and then I‚Äôll kick off an install of tidyverse\ninstall.packages(\"pak\", repos = \"https://r-lib.github.io/p/pak/dev/\")\n\npak::pak_setup()\n\npak::pkg_install(\"tidyverse\")\n16 seconds later üéâ\n\n04:16pmWow pak is fast. These packages installed in literal seconds.\nMostly just basics I know I‚Äôll want, other things to customize @rstudio\nI ran this code for both R 3.6.3 and 4.0.3\n\n04:17pmLike it‚Äôs actually kind of fun to watch pak install your packages."
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#utility-mac-apps",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#utility-mac-apps",
    "title": "Setting up a new MacBook Pro",
    "section": "Utility Mac Apps",
    "text": "Utility Mac Apps\n04:19pmThat‚Äôs it for R, here come a bunch of utility apps for Macs. These all make life a little easier, more productive. Fitter, happier.\nThese all worked on Catalina so I guess I‚Äôll find out soon if they work for Big Sur‚Ä¶\n04:22pmFlycut is a clipboard manager that adds history to your clipboard. Copy several things from here, paste them there. Reuse old clips. I can‚Äôt even without this.\nhttps://github.com/TermiT/Flycut#readme\n04:24pmKap records your screen, converts movies to gifs and has powered half of this thread so far.\nbrew install --cask kap  \nhttps://getkap.co/\n04:26pmRectangle is another absolutely essential mac app. Easily resize windows to fill parts of the screen with many keyboard shortcuts. Rectangle replaces Spectacle and adds snap zones.\nbrew install --cask rectangle  \nhttps://rectangleapp.com/\n04:28pmAltTab adds window previews to the window switcher. Thanks @PeeltothePithy for the tip!\nbrew install --cask alt-tab  \nhttps://alt-tab-macos.netlify.app/\n04:30pmKeyCastr show key presses on-screen, perfect for demonstrating cool RStudio keyboard shortcuts\nbrew install --cask keycastr  \nhttp://github.com/keycastr/keycastr\n04:31pmPock puts the dock in the touchbar. I appreciate this whenever my laptop isn‚Äôt docked.\nhttps://pock.dev/\n04:33pmAmphetamine keeps your laptop awake for a certain amount of time. Useful for long running #rstats scripts, turn on amphetamine, turn off the monitor, walk away knowing your script is still going.\nhttps://apps.apple.com/us/app/amphetamine/id937984704\n04:34pmIf you‚Äôve ever wanted to open certain links in *certain* browsers, Finicky can help.\nbrew install --cask finicky  \nhttps://github.com/johnste/finicky\n04:35pmI‚Äôve had enough of the default Big Sur desktop background. Luckily there‚Äôs Irvue ‚Äì an hourly wallpaper refresh using pictures from @unsplash https://irvue.tumblr.com/\n04:37pmIf you use, work with, or collect colors, Culr looks awesome. I haven‚Äôt used it much but I have a feeling I‚Äôll use it frequently.\nhttps://culrs.app/\n04:39pmAnd now that I just installed a dozen menu-bar apps, I don‚Äôt want to have to look at them all the time.\nHello dozer, a little app that hides the clutter!\nbrew install --cask dozer  \nhttps://github.com/Mortennn/Dozer\n\n04:42pmThat‚Äôs it for menu bar apps, let‚Äôs move on to big apps!\n\n04:44pmFirst up, essential work apps, slack and spotify.\nDid you know you can install both with brew at the same time?\nbrew install --cask spotify slack\n04:46pmI don‚Äôt always use editors that aren‚Äôt RStudio to edit code‚Ä¶\nbut when I do I use Visual Studio Code.\nbrew install --cask visual-studio-code  \nhttps://code.visualstudio.com/\n04:48pmThere are a lot of cool things going on with R and vscode. If you want a little intro to some good vscode extensions for web dev and more, I put together a list for #js4shiny\nhttps://js4shiny.com/resources/setup/extras/#visual-studio-code\n04:49pmI recently started using @NotionHQ for collecting all of my random thoughts, outline writing, keep track of links and more.\nhttps://www.notion.so/\n04:50pmIt pairs nicely with Agenda, which is an app for date-linked notes and perfect for meeting notes.\nhttps://www.agenda.com/\n04:52pmAnother awesome app is Figma. Great for bits of design, testing app layouts, drawing diagrams and a whole lot more. The desktop app is slick.\nhttps://www.figma.com/\n04:53pmMy favorite app for working with big and complicated git repos is Fork. The visual history and diff features have saved me many times.\nhttps://fork.dev/home\n04:55pmI wasn‚Äôt sure where to put Docker in the lineup, but it‚Äôll be a good segue into command line apps.\nAnd I always have to click around a bunch to find the download: https://hub.docker.com/editions/community/docker-ce-desktop-mac/\n04:57pmWhat‚Äôs cooler than docker? Rocker! üë©‚Äçüé§\nThe rocker project provides a ton of r-based docker images, ranging from bare bones to ready for publication or geospatial analysis. Thank you @cboettig, @eddelbuettel and @noamross for your awesome work!\nhttps://www.rocker-project.org/"
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#command-line-utilities",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#command-line-utilities",
    "title": "Setting up a new MacBook Pro",
    "section": "Command Line Utilities",
    "text": "Command Line Utilities\n05:02pmAnd now we‚Äôre moving into a new category: command line apps.\nI know what you‚Äôre thinking, but these aren‚Äôt your mother‚Äôs command line apps. Command line apps have gotten really pleasant to use lately. They even have color! üåà\n\n05:04pmMy recent new favorite is @github‚Äôs command line tool. It makes it surprisingly easy to create issues, review PRs, and generally interact with my work on GitHub.\nbrew install gh  \nhttps://cli.github.com/\n05:06pmSpeaking of git, bit is a fun CLI that smooths out some of git‚Äôs rougher edges.\nbrew install bit-git  \nhttps://github.com/chriswalz/bit\n\n05:10pmTwo more rhyming CLIs:\n\nbat makes it easy to see inside files\nnat makes it easy to see inside directories\n\nbrew install bat nat  \nhttps://github.com/sharkdp/bat\nhttps://github.com/willdoescode/nat\n\n\n05:12pmOops nat needs a little more to install:\nbrew tap willdoescode/homebrew-natls\n\nbrew install natls\n05:14pmI love the idea of this one. Forget how tar works? tldr\nbrew install tldr  \nhttps://tldr.sh/\n\n05:18pmI can‚Äôt believe how much of the stuff in this thread I‚Äôve been able to install with brew. Did you know you can use it to install fonts?\nbrew tap homebrew/cask-fonts\nThen install fonts with\nbrew install --cask font-incosolata\nor find fonts\nbrew search font-\n05:20pmbrew can even install node and then you can use npm to install even more things!\nbrew install node  \nhttps://nodejs.dev/\n05:21pmDo you ever write JavaScript and want it to look great without doing any extra work? StandardJS makes this happen.\nnpm install --global standard  \nhttps://standardjs.com/\n05:24pmAnother fun node package and CLI that I like a lot is gitmoji\nnpm install --global gitmoji-cli\nSemantic emoji for git commit messages! ü§™\nhttps://gitmoji.carloscuesta.me/"
  },
  {
    "objectID": "blog/setting-up-a-new-macbook-pro/index.html#fish-shell",
    "href": "blog/setting-up-a-new-macbook-pro/index.html#fish-shell",
    "title": "Setting up a new MacBook Pro",
    "section": "Fish Shell",
    "text": "Fish Shell\n05:27pmIf you hung with me this far, I hope you don‚Äôt mind if I go extra geeky and talk about shells. Terminal shells. Like, a totally new command prompt, but one that helps finish your thoughts like fish\nhttps://fishshell.com/\n05:29pmYou can install fish from brew, and then it‚Äôs a good idea to install fisher, too. It‚Äôs a plugin manager for your shell.\nbrew install fish\nfisher install instructions: https://github.com/jorgebucaran/fisher\n05:30pmThen you can install plugins, like this sweet prompt theme called tide\nfish # to start the fish shell\n\nfisher install IlanCosman/tide  \nhttps://github.com/IlanCosman/tide#readme\n05:32pmtide has a sweet configuration menu that it walks you through, but of course I forgot that to make cool prompts like this work you need to install a Nerd Font\nhttps://github.com/ryanoasis/nerd-fonts\n05:38pmI‚Äôll just pick one to make it work\nbrew install --cask font-hasklug-nerd-font\nand then configure iTerm to use ‚ÄúHasklug Nerd‚Äù‚Ä¶\nBoom, fancy prompt with icons!\n\n05:40pmOne more fish thing‚Ä¶ there‚Äôs a utility called ‚Äúz‚Äù\nfisher install jethrokuan/z\nz uses a list of frequent and recent directories to make it easy to move around your computer. After using it a bit you can type z doc and jump to ~/Documents\nhttps://github.com/jethrokuan/z\n05:44pmFinal fish point. The docs are awesome and there are some great extensions out there.\nhttps://fishshell.com/docs/current/index.html\nhttps://github.com/jorgebucaran/awesome.fish\n05:46pmOkay, at this point, my machine should be ready to use! And if not, it‚Äôs time for dinner anyway.\nThanks for reading! Let me know if I missed your favorite app anywhere üòâ\nSo long and thanks for all the fish!\n\n05:56pmomg I still have so many things to log into and configure"
  },
  {
    "objectID": "blog/remark-img-overflow/index.html",
    "href": "blog/remark-img-overflow/index.html",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "",
    "text": "I‚Äôm a long-time fan of using the xaringan package to create slides1 (as you might know from my blog). I‚Äôve always appreciated that you can use R Markdown (or just regular markdown) to write your slides, but you can also use HTML, CSS and JavaScript to customize your slides. You can write in plain text, or you can turn each slide into a small web project.\nWeb-based slides can be shared with others online and tend to be more accessible than traditional slide formats. And with packages like renderthis ‚Äì a package by John Helveston and me ‚Äì you can even get PDF and other formats easily."
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#plain-text-slides",
    "href": "blog/remark-img-overflow/index.html#plain-text-slides",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "",
    "text": "I‚Äôm a long-time fan of using the xaringan package to create slides1 (as you might know from my blog). I‚Äôve always appreciated that you can use R Markdown (or just regular markdown) to write your slides, but you can also use HTML, CSS and JavaScript to customize your slides. You can write in plain text, or you can turn each slide into a small web project.\nWeb-based slides can be shared with others online and tend to be more accessible than traditional slide formats. And with packages like renderthis ‚Äì a package by John Helveston and me ‚Äì you can even get PDF and other formats easily."
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#pdf-slides-and-the-case-of-the-missing-images",
    "href": "blog/remark-img-overflow/index.html#pdf-slides-and-the-case-of-the-missing-images",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "PDF slides and the case of the missing images",
    "text": "PDF slides and the case of the missing images\nBut PDF slides come with a few challenges of their own, most of which are related to the fact that you‚Äôre essentially using the browser‚Äôs printing features to print your slides to PDF.\nThe one that I‚Äôve seen most often in PDFs is that images that happily render in the browser can suddenly disappear from the PDF version of the slides. Here‚Äôs how I described the problem in an issue in renderthis:\n\nChrome‚Äôs printing algorithm‚Ä¶excludes images that extend beyond the visible margin from printing. I‚Äôm sure [there‚Äôs a reason for this that] makes sense for general webpage printing, but it does cause problems for slides.\nIt can be hard to tell visually if the plot extends past the margins of the slide because the actual image may include empty space that you can‚Äôt see.\n\nOften plots and other images include some empty space at the edges that can overflow the slide in a non-obvious way. The trick I tend to use is to add a red outline around all the images in the slides during development (or just before publishing the slides):\nimg, svg {\n  outline: 1px solid red;\n}"
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#more-slides-more-problems",
    "href": "blog/remark-img-overflow/index.html#more-slides-more-problems",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "More slides, more problems",
    "text": "More slides, more problems\nThat little CSS trick works well enough if you‚Äôre in the middle of writing the slides, but it‚Äôd be a pretty terrible process to have to do this manually for, say, 530 slides a dozen times or more over the next three months.\nIf that sounds like an oddly specific example, that‚Äôs because it is. I was reminded of this problem by Greg Wilson‚Äôs recent bat signal toot:\n\nplea for help; macOS; open source; command-line; PDF\ndear lazyweb: is there a command-line tool for macos that will take a PDF and produce a 4-up or 6-up PDF? I need to check the layout of a bunch of slides (because I haven‚Äôt figured out how to get the remark slideshow tool to tell me when an SVG image in a slide overflows, so I‚Äôm going to have to eyeball ‚Äôem). thank you\nGreg Wilson @gvwilson@mastodon.social ‚Äì Jul 20, 2023, 19:24\n\nThis is exactly the kind of task I would want to automate, and it‚Äôs an exquisitely designed and irresistible nerd snipe. I‚Äôve used chromote (and headless Chrome) before to automate printing complex xaringan slides, so I know there‚Äôs a good chance its doable.\nSo the rest of this post is a quick exploration of how to use a remote-controlled browser (via chromote) to load the slides and detect any images that are clipped."
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#example-slides",
    "href": "blog/remark-img-overflow/index.html#example-slides",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "Example slides",
    "text": "Example slides\nI‚Äôve created a small example slide deck that has a few slides with images that ‚Äúaccidentally‚Äù go beyond the edges of the slides. We‚Äôll use this as our test case.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSource\n\n\n\n\n\n---\ntitle: Image overflow example\noutput:\n  xaringan::moon_reader:\n    seal: false\n    self_contained: false\n---\n\nclass: center middle\n\n# First slide\n\n```{r}\n#| echo: false\nxaringanExtra::use_share_again()\nxaringanExtra::style_share_again(share_buttons = \"none\")\n```\n\n---\n\n# Slide with clipped plot\n\nThis slide makes a plot that won't fit on the slide.\n\n```{r plot, results=\"hide\"}\nhist(faithful$waiting)\n```\n\n---\nclass: bottom right\n\n# Absolutely positioned plot\n\n&lt;img src=\"`r knitr::fig_chunk(\"plot\", ext = \"png\")`\" style=\"position: absolute; top: -2px; left: -20px;\"&gt;\n\n---\n\n# SVG too big!\n\n&lt;svg xmlns=\"http://www.w3.org/2000/svg\" width=\"800\" height=\"800\" fill=\"currentColor\" class=\"bi bi-bug\" viewBox=\"0 0 16 16\"&gt;&lt;path d=\"M4.355.522a.5.5 0 0 1 .623.333l.291.956A4.979 4.979 0 0 1 8 1c1.007 0 1.946.298 2.731.811l.29-.956a.5.5 0 1 1 .957.29l-.41 1.352A4.985 4.985 0 0 1 13 6h.5a.5.5 0 0 0 .5-.5V5a.5.5 0 0 1 1 0v.5A1.5 1.5 0 0 1 13.5 7H13v1h1.5a.5.5 0 0 1 0 1H13v1h.5a1.5 1.5 0 0 1 1.5 1.5v.5a.5.5 0 1 1-1 0v-.5a.5.5 0 0 0-.5-.5H13a5 5 0 0 1-10 0h-.5a.5.5 0 0 0-.5.5v.5a.5.5 0 1 1-1 0v-.5A1.5 1.5 0 0 1 2.5 10H3V9H1.5a.5.5 0 0 1 0-1H3V7h-.5A1.5 1.5 0 0 1 1 5.5V5a.5.5 0 0 1 1 0v.5a.5.5 0 0 0 .5.5H3c0-1.364.547-2.601 1.432-3.503l-.41-1.352a.5.5 0 0 1 .333-.623zM4 7v4a4 4 0 0 0 3.5 3.97V7H4zm4.5 0v7.97A4 4 0 0 0 12 11V7H8.5zM12 6a3.989 3.989 0 0 0-1.334-2.982A3.983 3.983 0 0 0 8 2a3.983 3.983 0 0 0-2.667 1.018A3.989 3.989 0 0 0 4 6h8z\"/&gt;&lt;/svg&gt;\n\n---\n\nThis little CSS can help during development,\nnot so much once you've built out all of your slides.\n\n```{css eval = FALSE}\nimg, svg { outline: 2px solid red; }\n```\n\n```{css echo = FALSE}\n/* this is the real css I applied\n   to avoid red outlines in the share bar */\n:not(.shareagain-button) &gt; :is(img, svg) {\n  outline: 2px solid red;\n}\n```"
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#automate-it",
    "href": "blog/remark-img-overflow/index.html#automate-it",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "Automate it!",
    "text": "Automate it!\nI absolutely love taking an annoying manual process and turning it into runnable, repeatable code. Automate all the things!\nWe can automate slide-image overflow with these 4 steps:\n\nFire up headless Chrome and load the slides in the virtual, remote-controllable browser.\nDetermine the natural desired size of the slides (in pixels) and then set the virtual browser window to this size. This isn‚Äôt strictly necessary, but it makes the math much easier later on, so it‚Äôs worth it.\nMake all of slides visible at once. Otherwise, remark (the JavaScript library that powers the slides) hides all of the slides except the current slide. Elements that are hidden from the browser don‚Äôt have a size, ruining our ability to detect overflow.\nFinally, find all of the images in the slides and check if any escape the slide (browser window) boundaries.\n\n\nWith chromote\nNow we get to the fun part. First we need to start up chromote and initialize a new browser session.\n\nlibrary(chromote)\n\nchrome &lt;- ChromoteSession$new()\n\nI‚Äôve stored the example slide deck in a folder called example-slide, and I‚Äôve already rendered it from index.Rmd to index.html. To load the file in Chrome, we need the full path to the file, prefixed with file://, e.g.¬†file:///Users/garrick/.../example-slide/index.html.\n\nslide_path &lt;- file.path(\"example-slide\", \"index.html\")\nslide_path_uri &lt;- file.path(\"file:/\", normalizePath(slide_path))\n\nNow we can load the slides in Chrome. I‚Äôm using a small trick here to make sure that the R session waits for the browser to load the page. The trick is to request the Page.loadEventFired event via chromote asynchronously (wait_ = FALSE), then load the page, after which the we block the R session until the page load event fires.\n\npl &lt;- chrome$Page$loadEventFired(wait_ = FALSE)\nchrome$Page$navigate(slide_path_uri, wait_ = FALSE)\n#&gt; &lt;Promise [pending]&gt;\n\n# Block until the page load event fires\nchrome$wait_for(pl)\n#&gt; $timestamp\n#&gt; [1] 195025.8\n\nThat‚Äôs not something you usually have to do with chromote when you‚Äôre interacting with pages on the web (because those take long enough to load), but local pages load very quickly, sometimes faster than the R expressions are evaluated. (In other words, if you execute the navigate command and then wait for page load event, you might miss it.)\n\n\nMatch window size to slide size\nNow that we have our slides loaded in the headless browser, we need to figure out what size they are. remark uses some rather random pixels values based on the specified slide ratio, so the easiest thing to do is find the first visible slide and figure out what size remark used.\nHere‚Äôs a small JavaScript function that will do that for us:\n\nfunction get_slide_size() {\n  // Find the first visible slide in the deck\n  const visible_slide = document\n    .querySelector('.remark-visible .remark-slide-scaler')\n\n  // and inspect it's width and height\n  // knowing that remark will set these values\n  const {width, height} = visible_slide.style\n\n  return {\n    width: parseInt(width),\n    height: parseInt(height)\n  }\n}\n\nWe the use the $Runtime$evaluate() methods of the chromote object to run the JavaScript function definition, by passing the JS code as a string2.\n\n\nLoading the function in the browser via chromote\nchrome$Runtime$evaluate(\"\nfunction get_slide_size() {\n  // Find the first visible slide in the deck\n  const visible_slide = document\n    .querySelector('.remark-visible .remark-slide-scaler')\n\n  // and inspect it's width and height\n  // knowing that remark will set these values\n  const {width, height} = visible_slide.style\n\n  return {\n    width: parseInt(width),\n    height: parseInt(height)\n  }\n}\n\")\n\n\nNow that we‚Äôve loaded the function in the browser, we can call it to get the size of the slides. Here we again use $Runtime$evaluate(), but I‚Äôve added returnByValue = TRUE to the call to get the result of the JS expression back in R.\n\nslide_size &lt;-\n  chrome$Runtime$evaluate(\n    \"get_slide_size()\",\n    wait_ = TRUE,\n    returnByValue = TRUE\n  )\n\n# Extract the result we want from Chrome's response\nslide_size &lt;- slide_size$result$value\nslide_size\n#&gt; $width\n#&gt; [1] 908\n#&gt; \n#&gt; $height\n#&gt; [1] 681\n\nWith the slide size in hand, we can set the size of the virtual browser window using the $Emulation$setVisibleSize() method.\n\nchrome$Emulation$setVisibleSize(\n  height = slide_size$height,\n  width = slide_size$width\n)\n\nIf you wanted to be certain everything is set up correctly, you could call chrome$view() now and see the slides your browser‚Äôs seeing.\n\n\n\nThe headless Chrome preview of the slides in a Chrome window.\n\n\n\n\nMake all slides visible\nWith our slides loaded in the browser, we need to make them all visible. This trick involves finding all of the slides in the deck ‚Äì using the .remark-slides-area .remark-slide-container selector ‚Äì and then add the remark-visible class to each slide. This is the class that remark toggles to show and hide the slides when you move through them.\n\ndocument\n  .querySelectorAll('.remark-slides-area .remark-slide-container')\n  .forEach(slide =&gt; slide.classList.add('remark-visible'))\n\n\n\nDetect clipped elements\nDetecting if an element is clipped is easy now that we‚Äôve made all the slides visible and set the browser window to match the slide size exactly.\nThe core idea in this function is to use the getBoundingClientRect() method to get the position of the element relative to the browser window. If any side of the element is outside of the window, then the element is clipped.\n\nfunction is_element_clipped(el) {\n  const { top, left, bottom, right  } = el.getBoundingClientRect()\n  return top &lt; 0 ||\n    left &lt; 0 ||\n    right &gt; window.innerWidth ||\n    bottom &gt; window.innerHeight\n}\n\nIf we hadn‚Äôt resized the virtual browser window to match the slide size, then we would have to do figure out the slide‚Äôs size and the element‚Äôs relative position within it to determine if the element is clipped.\nIf we‚Äôve found a clipped element, we can extract some useful information about it that we‚Äôll use in R to learn about our problematic images. I also threw in a console.log() element so that, you if were to use this code in a head-full browser, you‚Äôd get a nice console message about the clipped image.\n\nfunction clipped_img_info(el) {\n    // If you're looking at the slides in the browser,\n    // this will logged the clipped images in the console.\n    console.log(\"clipped image\", el)\n\n    return {\n      img_tag: el.tagName,\n      img_src: /^data:/.test(el.src) ? el.src.slice(0, 32) : el.src,\n      img_class: el.classList.toString(),\n      slide_heading: el.closest('.remark-slide')\n        .querySelector('h1, h2, h3, h4, h5, h6')\n        ?.innerText,\n      slide_text: el.closest('.remark-slide').innerText,\n    }\n  }\n\nNow we‚Äôre at the best part. We use .querySelectorAll() to find all images (or SVGs) in our slides, filter them to include only those that are clipped, and then extract the information we need about the clipped images.\n\ndocument\n  .querySelectorAll(\n    '.remark-slides-area .remark-slide :is(img, svg)'\n  )\n  .filter(is_element_clipped)\n  .map(clipped_img_info)\n\n\n\nFind all the clipped images\nTo make life a little easier, I wrote all of the above JavaScript code into a file called find-bad-images.js. If you want, you can download that file and use it directly. Here, I‚Äôll read the contents and pass the string of JavaScript to chromote to get the results.\n\nbad_images &lt;-\n  chrome$Runtime$evaluate(\n    paste(readLines(\"find-bad-images.js\"), collapse = \"\\n\"),\n    wait_ = TRUE,\n    returnByValue = TRUE\n  )\n\nWith a little bit of data reshaping, we‚Äôve got a nice table of all the images we need to fix in our slides.\n\nbad_images$result$value |&gt;\n  purrr::map_dfr(~ .) |&gt;\n  dplyr::mutate(img_src = basename(img_src))\n#&gt; # A tibble: 3 √ó 5\n#&gt;   img_tag img_src    img_class   slide_heading              slide_text          \n#&gt;   &lt;chr&gt;   &lt;chr&gt;      &lt;chr&gt;       &lt;chr&gt;                      &lt;chr&gt;               \n#&gt; 1 IMG     plot-1.png \"\"          Slide with clipped plot    \"Slide with clipped‚Ä¶\n#&gt; 2 IMG     plot-1.png \"\"          Absolutely positioned plot \"Absolutely positio‚Ä¶\n#&gt; 3 svg     &lt;NA&gt;       \"bi bi-bug\" SVG too big!               \"SVG too big!\\n4 / ‚Ä¶\n\n\n\n\n\n\n\nThe headless Chrome preview of the slides in a Chrome window."
  },
  {
    "objectID": "blog/remark-img-overflow/index.html#footnotes",
    "href": "blog/remark-img-overflow/index.html#footnotes",
    "title": "Automated Image Overflow Detection for xaringan or remark Slides",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nR users know of these slides as xaringan slides, but the underlying technology is remark, a JavaScript library for creating slides from plain text.‚Ü©Ô∏é\nMy least favorite way to write code of any language is inside a string literal of another language. ü§™‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html",
    "href": "blog/recursive-xml-workout/index.html",
    "title": "XML: The Recursive Programming Workout",
    "section": "",
    "text": "I had no choice today but to work with raw XML data and let me just say: it‚Äôs been a workout."
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#an-example-xml-file",
    "href": "blog/recursive-xml-workout/index.html#an-example-xml-file",
    "title": "XML: The Recursive Programming Workout",
    "section": "An example XML file",
    "text": "An example XML file\nThe XML file I‚Äôm working with primarily stores the data I need in node-level attributes, similar to the data below that I modified from an example on oracle-base.\n\nxml_text &lt;- '\n&lt;company&gt;\n  &lt;employees company=\"MacroSoft\" division=\"Sales\"&gt;\n    &lt;employee empno=\"7369\" ename=\"SMITH\" job=\"CLERK\" hiredate=\"17-DEC-1980\"/&gt;\n    &lt;employee empno=\"7499\" ename=\"ALLEN\" job=\"SALESMAN\" hiredate=\"20-FEB-1981\"/&gt;\n    &lt;employee empno=\"7521\" ename=\"WARD\" job=\"SALESMAN\" hiredate=\"22-FEB-1981\"/&gt;\n    &lt;employee empno=\"7566\" ename=\"JONES\" job=\"MANAGER\" hiredate=\"02-APR-1981\"/&gt;\n    &lt;employee empno=\"7654\" ename=\"MARTIN\" job=\"SALESMAN\" hiredate=\"28-SEP-1981\"/&gt;\n  &lt;/employees&gt;\n  &lt;employees company=\"MacroSoft\" division=\"Research\"&gt;\n    &lt;employee empno=\"7698\" ename=\"BLAKE\" job=\"MANAGER\" hiredate=\"01-MAY-1981\"/&gt;\n    &lt;employee empno=\"7782\" ename=\"CLARK\" job=\"MANAGER\" hiredate=\"09-JUN-1981\"/&gt;\n    &lt;employee empno=\"7788\" ename=\"SCOTT\" job=\"ANALYST\" hiredate=\"19-APR-1987\"/&gt;\n    &lt;employee empno=\"7839\" ename=\"KING\" job=\"PRESIDENT\" hiredate=\"17-NOV-1981\"/&gt;\n    &lt;employee empno=\"7844\" ename=\"TURNER\" job=\"SALESMAN\" hiredate=\"08-SEP-1981\"/&gt;\n    &lt;employee empno=\"7876\" ename=\"ADAMS\" job=\"CLERK\" hiredate=\"23-MAY-1987\"/&gt;\n    &lt;employee empno=\"7900\" ename=\"JAMES\" job=\"CLERK\" hiredate=\"03-DEC-1981\"/&gt;\n    &lt;employee empno=\"7902\" ename=\"FORD\" job=\"ANALYST\" hiredate=\"03-DEC-1981\"/&gt;\n    &lt;employee empno=\"7934\" ename=\"MILLER\" job=\"CLERK\" hiredate=\"23-JAN-1982\"/&gt;\n  &lt;/employees&gt;\n&lt;/company&gt;\n'"
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#from-xml-to-a-list",
    "href": "blog/recursive-xml-workout/index.html#from-xml-to-a-list",
    "title": "XML: The Recursive Programming Workout",
    "section": "From XML to a list()",
    "text": "From XML to a list()\nWith the xml2 package and two tiny lines of R code we have the XML file as a list in R.\n\nraw_xml &lt;- xml2::read_xml(xml_text)\nlist_xml &lt;- xml2::as_list(raw_xml)\n\nstr(list_xml, max.level = 2)\n\nList of 1\n $ company:List of 2\n  ..$ employees:List of 5\n  .. ..- attr(*, \"company\")= chr \"MacroSoft\"\n  .. ..- attr(*, \"division\")= chr \"Sales\"\n  ..$ employees:List of 9\n  .. ..- attr(*, \"company\")= chr \"MacroSoft\"\n  .. ..- attr(*, \"division\")= chr \"Research\"\n\n\nBut as you can see from the preview above, when converted to a list, xml2 stores attributes at each node, like company=\"MacroSoft\", as R attributes() associated with the corresponding list item.\n\nstr(list_xml[[1]][[1]][1])\n\nList of 1\n $ employee: list()\n  ..- attr(*, \"empno\")= chr \"7369\"\n  ..- attr(*, \"ename\")= chr \"SMITH\"\n  ..- attr(*, \"job\")= chr \"CLERK\"\n  ..- attr(*, \"hiredate\")= chr \"17-DEC-1980\""
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#promote-attributes-to-list-items",
    "href": "blog/recursive-xml-workout/index.html#promote-attributes-to-list-items",
    "title": "XML: The Recursive Programming Workout",
    "section": "Promote attributes to list items",
    "text": "Promote attributes to list items\nI want to extract these attributes and promote them to list-level named entries. To do this I‚Äôll use a recursive function, meaning a function that calls itself. When approaching writing a recursive function, it‚Äôs useful to think of the base case ‚Äî when we have or can get the answer that we‚Äôre looking for ‚Äî and the recursion case ‚Äî or when we need to move further down the tree by calling the function again on a smaller unit.\n\nBase case\nThe base case of the recursive function is when we have an empty list that has attributes. In that case, we just return the attributes. A good example of the base case from our example XML is the list_xml[[1]][[1]][[1]] we see above.\n\nattributes(list_xml[[1]][[1]][[1]])\n\n$empno\n[1] \"7369\"\n\n$ename\n[1] \"SMITH\"\n\n$job\n[1] \"CLERK\"\n\n$hiredate\n[1] \"17-DEC-1980\"\n\n\n\n\nRecursive case\nIf, on the other hand, we find that we have a list that contains both items and attributes we do three things. First, we keep a copy of the attributes of the list at the current level that we‚Äôll use later. Second, we look inside each of the items in the list we currently have to see if we can promote their attributes. This triggers the recursion, so this function will keep calling itself on smaller and smaller units until eventually it reaches a list with no items and only attributes. At that point, it returns the attributes as a list.\nThe third and final step is to take the attribute list at the original level and concatenate the list returned from the lower level.\nWhen thinking about programming the recusive case, I usually try to think about one step above the base case. That is, what would I do if I‚Äôm one level above the base case. For this, we can use list_xml[[1]][[1]], and, in essence, we want to perform this action:\n\nthis_attr &lt;- attributes(list_xml[[1]][[1]])\nlower_level &lt;- purrr::map(list_xml[[1]][[1]], attributes)\nstr(lower_level)\n\nList of 5\n $ employee:List of 4\n  ..$ empno   : chr \"7369\"\n  ..$ ename   : chr \"SMITH\"\n  ..$ job     : chr \"CLERK\"\n  ..$ hiredate: chr \"17-DEC-1980\"\n $ employee:List of 4\n  ..$ empno   : chr \"7499\"\n  ..$ ename   : chr \"ALLEN\"\n  ..$ job     : chr \"SALESMAN\"\n  ..$ hiredate: chr \"20-FEB-1981\"\n $ employee:List of 4\n  ..$ empno   : chr \"7521\"\n  ..$ ename   : chr \"WARD\"\n  ..$ job     : chr \"SALESMAN\"\n  ..$ hiredate: chr \"22-FEB-1981\"\n $ employee:List of 4\n  ..$ empno   : chr \"7566\"\n  ..$ ename   : chr \"JONES\"\n  ..$ job     : chr \"MANAGER\"\n  ..$ hiredate: chr \"02-APR-1981\"\n $ employee:List of 4\n  ..$ empno   : chr \"7654\"\n  ..$ ename   : chr \"MARTIN\"\n  ..$ job     : chr \"SALESMAN\"\n  ..$ hiredate: chr \"28-SEP-1981\"\n\nstr(c(this_attr, lower_level), max.level = 1)\n\nList of 8\n $ names   : chr [1:5] \"employee\" \"employee\" \"employee\" \"employee\" ...\n $ company : chr \"MacroSoft\"\n $ division: chr \"Sales\"\n $ employee:List of 4\n $ employee:List of 4\n $ employee:List of 4\n $ employee:List of 4\n $ employee:List of 4"
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#a-recursive-attribute-promotor-function",
    "href": "blog/recursive-xml-workout/index.html#a-recursive-attribute-promotor-function",
    "title": "XML: The Recursive Programming Workout",
    "section": "A recursive attribute-promotor function",
    "text": "A recursive attribute-promotor function\nThe final step is to put this all together inside a function that handles the base case or recurses to iterate over list items further down the tree.\nBut first‚Ä¶ did you notice this line above?\n\n\nList of 1\n $ names: chr [1:5] \"employee\" \"employee\" \"employee\" \"employee\" ...\n\n\nWe have also included the names of the sub-list items in our new list! This is because R uses named attributes to keep track of things like \"names\", \"class\", \"dimnames\" etc. If the XML node has an attribute called names=\"foo\", xml2 will store that attribute-value pair as .names. I don‚Äôt mind having .names entries in my lists (I can take care of that downstream), but I don‚Äôt want to keep attributes namednames or class etc., because those are reserved for special R functionality.\nHere‚Äôs a small function that removes reserved R attributes from the attributes list.\n\nremove_reserved &lt;- function(this_attr) {\n  reserved_attr &lt;- c(\"class\", \"comment\", \"dim\", \"dimnames\", \"names\", \"row.names\", \"tsp\")\n  if (!any(reserved_attr %in% names(this_attr))) {\n    return(this_attr)\n  }\n  for (reserved in reserved_attr) {\n    if (!is.null(this_attr[[reserved]])) this_attr[[reserved]] &lt;- NULL\n  }\n  this_attr\n}\n\nFinally, we can combine everything in a recursive function I‚Äôll call promote_attr().\n\npromote_attr &lt;- function(ll) {\n  this_attr &lt;- attributes(ll)\n  this_attr &lt;- remove_reserved(this_attr)\n  if (length(ll)) {\n    # recursive case\n    c(this_attr, purrr::map(ll, promote_attr))\n  } else {\n    # base case (no sub-items)\n    this_attr\n  }\n}\n\nQuick aside: this function makes very strong assumptions that every item in the list we‚Äôre recursing over is also a list, all the way down. In this example processing a list derived from an XML document, it‚Äôs a reasonable assumption, but one that we should check. For other lists of mixed types, a whole lot more type checking will be required."
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#the-end-result-for-now",
    "href": "blog/recursive-xml-workout/index.html#the-end-result-for-now",
    "title": "XML: The Recursive Programming Workout",
    "section": "The end result (for now)",
    "text": "The end result (for now)\nIn the end, by mapping promote_attr() over list_xml, we get a nice, tidy-ish list. This setup might not work for your XML data, but recursive programming can be a huge help when working with lists and tree structures.\n\ntidy_xml &lt;- purrr::map(list_xml, promote_attr)\nlistviewer::jsonedit(tidy_xml)"
  },
  {
    "objectID": "blog/recursive-xml-workout/index.html#further-reading",
    "href": "blog/recursive-xml-workout/index.html#further-reading",
    "title": "XML: The Recursive Programming Workout",
    "section": "Further Reading",
    "text": "Further Reading\nIf you‚Äôd like to read more about purrr or about rectangling tangled tree-like lists, I highly recommend Jenny Bryan‚Äôs excellent repurrrsive tutorial and package. With many great practice data sets, challenges, and tips, it‚Äôs an excellent and highly recommended read!"
  },
  {
    "objectID": "blog/r-colors-css/index.html",
    "href": "blog/r-colors-css/index.html",
    "title": "R Colors in CSS for R Markdown HTML Documents",
    "section": "",
    "text": "A modular collection of CSS stylesheets that lets you use any of R‚Äôs named colors in your xaringan slides, blogdown pages, Shiny apps‚Ä¶ in short in any R Markdown HTML documents.\n pkg.garrickadenbuie.com/r-colors-css"
  },
  {
    "objectID": "blog/r-colors-css/index.html#rs-named-colors",
    "href": "blog/r-colors-css/index.html#rs-named-colors",
    "title": "R Colors in CSS for R Markdown HTML Documents",
    "section": "R‚Äôs Named Colors",
    "text": "R‚Äôs Named Colors\n\n\n\nR ships with a list of colors with wonderful names, like lightgoldenrod3 and firebrick2. I don‚Äôt know all of the names and used to turn to an online list of colors so often that I put it on a mug.\nIn R, you can reference the color by name in nearly any function that applies to colors. They‚Äôre particularly easy to use in visualizations, like those made with ggplot2, because there are 657 colors and many have 4 variations on the same color hue, indexed by suffixes 1 to 4. For example, there are 4 variations of palevioletred that I‚Äôm using in the following plot for each of 4 years of Austin housing sales data.\n\ng_austin_housing +\n  ## A basic ggplot of home sale prices in Austin\n  ## over 4 years, using the ggplot2::txhousing data\n  scale_color_manual(\n    values = c(\n      \"palevioletred1\",\n      \"palevioletred2\",\n      \"palevioletred3\",\n      \"palevioletred4\",\n    )\n  )"
  },
  {
    "objectID": "blog/r-colors-css/index.html#utility-css",
    "href": "blog/r-colors-css/index.html#utility-css",
    "title": "R Colors in CSS for R Markdown HTML Documents",
    "section": "Utility CSS",
    "text": "Utility CSS\nIf you‚Äôre used to working with R‚Äôs color names, they unfortunately don‚Äôt align with HTML‚Äôs named colors, which means that you can‚Äôt write a CSS rule like\n\nh3.plot-title {\n  color: palevioletred1;\n}\n\nbecause palevioletred1 isn‚Äôt a valid HTML color. This causes problems if you use an R color name in a function that write CSS files.\nI‚Äôve also been interested lately in utility CSS frameworks, like Tailwinds CSS and Tachyons. What‚Äôs awesome about these frameworks is that they use small, single-purpose CSS classes ‚Äî called utility classes ‚Äî that can be flexibly applied to your HTML elements. I do most, if not all, of my writing in some variant of markdown, and utility classes let me build small components or slightly adjust appearances without having to write a whole lot of CSS.\nTailwinds looks amazing, but it requires a moderately complicated build setup, so I‚Äôve settled on using Tachyons. In particular, it integrates nicely with xaringan and other R Markdown outputs where a complete CSS framework is in use (like R Markdown with bootstrap). For that reason, I‚Äôve included it in xaringanExtra, and you can add Tachyons to any R Markdown document with xaringanExtra::use_tachyons().\nHere‚Äôs an example of what you can do with utility CSS. If I want to create a simple box with‚Ä¶\n\na border\n\non all sides (.ba)\nthat‚Äôs gray (.b--gray)\nwith a medium line width (.bw2),\n\nmedium exterior margin (.ma2),\nlarge interior padding (.pa4),\nand a box shadow (.shadow-1)\n\n‚Ä¶I can use those classes on the same element. Here are four markdown syntax variations that use those classes.\n\n\n\nxaringan\n\n.b--gray.ba.bw2.ma2.pa4.shadow-1[\nTalent is a pursued interest.\nAnything that you're willing to practice, you can do.\n\n‚ÄîBob Ross\n]\n\n\n\nR Markdown\n\n::: {.b--gray .ba .bw2 .ma2 .pa4 .shadow-1}\nTalent is a pursued interest.\nAnything that you're willing to practice, you can do.\n\n‚ÄîBob Ross\n:::\n\n\n\nHTML\n\n&lt;div class=\"b--gray ba bw2 ma2 pa4 shadow-1\"&gt;\n&lt;p&gt;Talent is a pursued interest.\nAnything that you're willing to practice, you can do.\n&lt;/p&gt;\n&lt;p&gt;‚ÄîBob Ross&lt;/p&gt;\n&lt;/div&gt;\n\n\n\nhtmltools (R)\n\nhtmltools::div(\n  class = \"b--gray ba bw2 ma2 pa4 shadow-1\",\n  htmltools::p(\n    \"Talent is a pursued interest.\",\n    \"Anything that you're willing to practice, you can do.\",\n  ),\n  htmltools::p(\"‚ÄîBob Ross\")\n)\n\n\n\nCSS\n\nNote: this isn‚Äôt the exact CSS from Tachyons, but it‚Äôs very similar.\n\n.b--gray {\n  border-color: #888888;\n}\n.ba {\n  border-style: solid;\n}\n.bw2 {\n  border-width: .25em;\n}\n.ma2 {\n  margin: 1.5em;\n}\n.pa4 {\n  padding: 2em;\n}\n.shadow-1 {\n  box-shadow: 4px 4px 8px 0 rgba(0,0,0,.2);\n}\n\n\n\n\n\nTalent is a pursued interest. Anything that you‚Äôre willing to practice, you can do.\n‚ÄîBob Ross"
  },
  {
    "objectID": "blog/r-colors-css/index.html#r-colors-in-css",
    "href": "blog/r-colors-css/index.html#r-colors-in-css",
    "title": "R Colors in CSS for R Markdown HTML Documents",
    "section": "R Colors in CSS",
    "text": "R Colors in CSS\nWouldn‚Äôt it be great to have utility CSS classes that you could use in xaringan slides and other R Markdown outputs?\n\n@grrrck First of all, I üòª `xaringanExtra`!\n\nI am looking at the tachyons colors and can't help but think that the palette is rather limited. https://t.co/0BUPGnkrb4\n\nIs there a way to intercept a tachyon with a named R color and generate a proper css with the correct hex code?\n‚Äî Deemah üá∫üá¶ üá≥üá¥ üá∏üá™ (@dmi3k) September 10, 2020\n\nI thought this was a great idea, so I put together a set of stylesheets with all of R‚Äôs named colors as CSS classes. You can choose any or all of the three stylesheets, depending on your needs, they each work independently.\n\nr-colors.css Classes for setting foreground and background colors\n\n.palevioletred1 sets the foreground color\n.bg-palevioletred1 sets the background color\n\nr-colors.hover.css Classes for setting foreground and background colors on hover\n\n.palevioletred1-hover sets the foreground color on hover\n.bg-palevioletred1-hover sets the background color on hover\n\nr-colors.vars.css CSS variables for each color name\n\nvar(--palevioletred1) for use in other CSS properties\n\n\nFor more on how to use the stylesheets, including a searchable table with all of the colors and an interactive color preview, check out the documentation page.\nAs an example, let‚Äôs update the box example above with some color from R. I used the color picker table in the documentation to pick out an interesting color combination.\n\n\n\nCSS\n\nI used the CSS variables stylesheet to add a new CSS rule in addition to the CSS in the example above. This class sets the border color for the box to paleturquoise4.\n\n\n\n\n.b--paleturquoise4 {\n  border-color: var(--paleturquoise4);\n}\n\n\nThe other colors used are steelblue4 (text), mintcream (background), and mediumvioletred (text on hover, from the hover classes stylesheet).\n\n\n\nxaringan\n\n.b--gray.ba.bw2.ma2.pa4.shadow-1.steelblue4.bg-mintcream.mediumvioletred-hover.b--paleturquoise4[\nTalent is a pursued interest.\nAnything that you're willing to practice, you can do.\n\n‚ÄîBob Ross\n]\n\n\n\nR Markdown\n\n::: {.b--gray .ba .bw2 .ma2 .pa4 .shadow-1 .steelblue4 .bg-mintcream .mediumvioletred-hover .b--paleturquoise4}\nTalent is a pursued interest.\nAnything that you're willing to practice, you can do.\n\n‚ÄîBob Ross\n:::\n\n\n\nHTML\n\n&lt;div class=\"b--gray ba bw2 ma2 pa4 shadow-1 steelblue4 bg-mintcream mediumvioletred-hover b--paleturquoise4\"&gt;\n&lt;p&gt;Talent is a pursued interest.\nAnything that you're willing to practice, you can do.\n&lt;/p&gt;\n&lt;p&gt;‚ÄîBob Ross&lt;/p&gt;\n&lt;/div&gt;\n\n\n\nhtmltools (R)\n\nhtmltools::div(\n  class = paste(\n    \"b--gray ba bw2 ma2 pa4 shadow-1 steelblue4\",\n    \"bg-mintcream mediumvioletred-hover b--paleturquoise4\"\n  ),\n  htmltools::p(\n    \"Talent is a pursued interest.\",\n    \"Anything that you're willing to practice, you can do.\",\n  ),\n  htmltools::p(\"‚ÄîBob Ross\")\n)\n\n\n\nTalent is a pursued interest. Anything that you‚Äôre willing to practice, you can do.\n‚ÄîBob Ross"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html",
    "href": "blog/pull-request-flow-usethis/index.html",
    "title": "Pull Request Flow with usethis",
    "section": "",
    "text": "A flow chart for the pull request functions in the usethis R package."
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#introduction",
    "href": "blog/pull-request-flow-usethis/index.html#introduction",
    "title": "Pull Request Flow with usethis",
    "section": "Introduction",
    "text": "Introduction\nThe usethis package is full of incredibly helpful functions that make life as an R developer easier. A lot of the package‚Äôs functions target R package maintainers, but there‚Äôs a small cluster of functions that are life changing for anyone who uses git or collaborates with others via GitHub1.\nThese pull request helpers all start with the pr_ prefix, but I initially found them a little confusing to use since they‚Äôre each designed to be called in a specific context ‚Äî for example, when you have local work that isn‚Äôt associated with a PR or when a PR exists but you don‚Äôt have the work locally on your computer.\nOnce I wrapped my head around the functions, though, using them has utterly transformed my day-to-day workflow. I can move in and out of collaborative work seamlessly. The flow chart above is my personal mental model of this cluster of functions and I hope it helps you make sense of them, too.\nThere are other great resources available in the usethis documentation. Beyond the function documentation, there‚Äôs also the great Pull request helpers article. That article walks through a pull request from the perspective of a contributor and a package maintainer.\nIn this blog post, however, you get to play both roles and choose your own adventure!"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#intro",
    "href": "blog/pull-request-flow-usethis/index.html#intro",
    "title": "Pull Request Flow with usethis",
    "section": "Choose your own pull request adventure",
    "text": "Choose your own pull request adventure\nWelcome to this choose-your-own-adventure blog post. You don‚Äôt need to read this one from top to bottom. Instead, jumping around is encouraged!\nLook for the Decision time: icon. It tells you that it‚Äôs time for you make a choice. But don‚Äôt worry, there‚Äôs no wrong choice: if you take a wrong turn you can always use your browser‚Äôs back button to retrace your steps.\n\nDecision time: Ready to get started?\n\n\n\nYes, I‚Äôm ready to go!"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#prep-work",
    "href": "blog/pull-request-flow-usethis/index.html#prep-work",
    "title": "Pull Request Flow with usethis",
    "section": "Prep work",
    "text": "Prep work\n\nLet‚Äôs get started\nYou open your project in RStudio (or the editor of your choice). You make a note to yourself to come up with a better name for your package ‚Äî for now you‚Äôre calling it acme because it‚Äôs mostly a collection of random functions you‚Äôve written.\nAnyway, you‚Äôre thankful that you closed all of your open files the last time you were working, but now the empty console beckons. You‚Äôre ready to do some work.\nWhere do you begin? With usethis of course.\n\nlibrary(usethis)\n\n\nDecision time: That was easy! Lets do some work now.\n\n\n\nWhat‚Äôs next?\n\nDecision time: Now you face a tough decision: what do you actually do next?\n\nStart new work\nPick up something you were working on\nReview or collaborate with someone else‚Äôs work\nClean up after a PR that‚Äôs been merged\n\n\n\n\nStart new work\nTime to start something new. You scan your project board, issues list, JIRA tickets, slack messages, emails, and post-it notes and finally settle on something to work on. Your task: add an example to the documentation for a function you‚Äôve been working on.\nYou want to start your work in a new branch, so you call pr_init(), giving it the name of your new branch.\n\npr_init(\"add-example\")\n\n‚úì Setting active project to '/Users/garrick/work/acme'\n‚Ñπ Pulling changes from 'upstream/main'\n‚úì Creating and switching to local branch 'add-example'\n‚óè Use `pr_push()` to create PR.\nThe console output reminds you that usethis updated your local repo and created and switched to a new branch for you.\n\nDecision time: You‚Äôre ready to do some work.\n\n\n\nPick up something you were working on\nYou‚Äôre ready to get back to that thing you were working on. Which was what again? You should probably have another sip of your coffee. You were doing some work in a branch in your local of the project‚Ä¶\n\nDecision time: Do you remember the name of the branch?\n\nI don‚Äôt remember, remind me\nI remember, it‚Äôs the add-example branch\n\n\n\n\nGet to a local branch\ngit branches, you‚Äôve made a few. But which one you do you want to work in?\n\nDecision time: Do you remember the name of the branch?\n\nI don‚Äôt remember, remind me\nI remember, it‚Äôs the add-example branch\n\n\n\n\nChoose a branch and resume working\nDon‚Äôt worry, usethis has your back. Just run pr_resume() without any arguments to get a list of local branches available to you. pr_resume() helpfully sorts the branches by recency of work and tells you if any of the branches are related to pull requests.\n\npr_resume()\n\n‚Ñπ No branch specified ... looking up local branches and associated PRs\nWhich branch do you want to checkout? (0 to exit)\n\n1:         add-example --&gt; #11 ('@gadenbuie'): Add an example\n2: feature-exploration\n\nSelection: 1\n‚úì Switching to branch 'add-example'\n‚úì Pulling from 'origin/add-example'\n‚Ä¢ Use `pr_push()` to create or update PR.\nWe picked option 1 to keep working in our add-example branch. Notice that, since add-example is related to PR #11, pr_resume() also did you the extra favor of making sure that your local copy is up-to-date.\n\nDecision time: Rock and roll, you‚Äôre ready to get back to work.\n\n\n\nGet back to the branch\nLook at you, smarty pants. You remember your git branch names! I‚Äôm proud of you.\nGood news, pr_resume() can switch to the \"add-example\" branch for you and it also makes sure that your local copy is up-to-date!\n\npr_resume(\"add-example\")\n\n‚úì Switching to branch 'add-example'\n‚úì Pulling from 'origin/add-example'\n‚Ä¢ Use `pr_push()` to create or update PR.\n\nDecision time: Sweat deal! Okay, you‚Äôre ready to keep on working.\n\n\n\nReview or collaborate with someone else‚Äôs work\nVersion control software like git and collaborative coding platforms like GitHub are plenty of fun when you‚Äôre working on your own. But they really start to shine when you use them to collaborate with others.\nThe same is true for the usethis PR helper functions. Setting up your local repo to pull down the changes from a collaborator ‚Äì changes that probably live in a branch in their copy of the repo ‚Äì can be a frustrating experience full of online searching to remember the specific incantations required to get your collaborators onto your computer and open in front of you.\nBut have no fear, pr_fetch() does all of this for you, in just one command in your R console.\n\nDecision time: Do you know the pull request number?\n\nI don‚Äôt remember, remind me\nI remember, it‚Äôs PR #14\n\n\n\n\nOpen a remote branch, locally\nThe pull request is open on GitHub and you can see the changes there, but you just can‚Äôt interact with the code in the same way through the browser. You have to bring that code into your local IDE where you can hold it in your hand and poke it with debuggers.\n\nDecision time: Do you know the pull request number?\n\nI don‚Äôt remember, remind me.\nI remember, it‚Äôs PR #14.\n\n\n\n\nChoose a PR and bring the changes onto your computer\nYour friend, who affectionately calls themselves @wileycoyote on GitHub, helpfully contributed a new function to your bag of tricks package, acme. They sent you a message on Slack letting you know they submitted a PR, but they didn‚Äôt mention the PR number.\nNo big deal ‚Äî you can call pr_fetch() from your local repository without any arguments and pr_fetch() will look up any open pull requests and give you the option to pick the one you want.\n\npr_fetch()\n\n‚Ñπ No PR specified ... looking up open PRs\nWhich PR are you interested in? (0 to exit)\n\n1: 'gadenbuie/acme/#11' (@gadenbuie): 'Add an example'\n2: 'gadenbuie/acme/#14' (@wileycoyote): 'Model tuning features'\n\nSelection: 2\n‚úì Checking out PR 'gadenbuie/acme/#14' (@wileycoyote): 'Model tuning features'\n‚úì Adding remote 'wileycoyote' as 'git@github.com:wileycoyote/acme.git'\n‚úì Creating and switching to local branch 'wileycoyote-toone-model'\n‚úì Setting 'wileycoyote/toone-model' as remote tracking branch\nYou find your friend‚Äôs PR in the list and choose selection 2. Next time you can perform the same steps by providing the PR number ‚Äî pr_fetch(14) ‚Äî or you can use the menu again. Who has time or brain space to memorize pull request numbers?\nNow that you have the code from the PR available to you locally, you‚Äôre free to poke around to try out the code and review it.\n\nDecision time: Okay, you‚Äôve had a chance to look at the code, what do you want to do next?\n\nI want to make some changes to add to the PR.\nI reviewed the code and left comments for the PR author in the pull request.\n\nI‚Äôm done with this branch.\nI‚Äôm done for now, but I‚Äôll probably come back to this branch later.\n\n\n\n\n\nOpen a PR locally\nYou‚Äôve been working with your friend, @wileycoyote, on a new set of model tuning functions. They‚Äôve helpfully started working on a PR, but since you‚Äôve been reviewing the code carefully with them over the past few days, you actually remember the pull request number. Lucky number 14.\n\npr_fetch(14)\n\n‚úì Checking out PR 'gadenbuie/acme/#14' (@wileycoyote): 'Model tuning features'\n‚úì Switching to branch 'wileycoyote-toone-model'\nYou already have a copy of the PR branch in your local project, so pr_fetch() simply switched you into the wileycoyote-toone-model branch that it created when you first fetched the PR.\nBecause you might have been doing some work here before, pr_fetch() does not try to update your local branch. But you haven‚Äôt done any work yet other than looking at the code, so you follow up with pr_pull() to pull the latest changes into your project.\n\npr_pull()\n\n‚úì Pulling from 'wileycoyote/toone-model'\n\nDecision time: Now that you have the latest PR code, what do you want to do next?\n\nI want to make some changes to add to the PR.\nI reviewed the code and left comments for the PR author in the pull request.\n\nI‚Äôm done with this branch.\nI‚Äôm done for now, but I‚Äôll probably come back to this branch later.\n\n\n\n\n\nOpen your PR on GitHub\nYou can jump straight to the GitHub pull request page for the branch you‚Äôre in with pr_view()!\n\npr_view()\n\n‚Ñπ Current branch ('add-example') is connected to PR #11\n‚úì Opening URL 'https://github.com/gadenbuie/acme/pull/11'\n\nDecision time: When you‚Äôre done with the PR on GitHub, come back here to decide where you‚Äôre headed next.\n\nThat‚Äôs it for now, I‚Äôm ready to start the next thing.\nHang on, I found something I need to fix.\nGood news, the pull request was merged and I‚Äôm done with this work.\nChanges were made in the PR and now I need to update my local copy.\nThere were updates in the main branch and now I want to bring them into my PR branch.\nActually, the pull request was closed and I can forget about this work.\n\n\n\n\nOpen their PR on GitHub\nYou can jump straight to the GitHub pull request page for the branch you‚Äôre in with pr_view()!\n\npr_view()\n\n‚Ñπ Current branch ('wileycoyote-toone-models') is connected to PR #14\n‚úì Opening URL 'https://github.com/gadenbuie/acme/pull/14'\n\nDecision time: Welcome back to your project, I hope everything went well over on GitHub. Where to next?\n\nI‚Äôm done here for now, let‚Äôs start the next thing.\nShoot, I saw something I need to fix.\nNothing more with this branch, I can forget all about this PR.\nChanges were made in the PR and now I need to update my local copy.\nThere were updates in the main branch and now I want to bring them into my PR branch.\nThe PR was merged so I‚Äôm all done with this work."
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#do-update",
    "href": "blog/pull-request-flow-usethis/index.html#do-update",
    "title": "Pull Request Flow with usethis",
    "section": "Update your local copy",
    "text": "Update your local copy\n\nUpdate your local copy with a reviewer‚Äôs changes\nMaybe a reviewer suggested changes and you merged them from the PR page on GitHub. Maybe a GitHub actions workflow automatically re-styled your code. Or maybe you did a little side-project updating on your work computer.\nHowever the changes happened, the code in the PR branch has changed, and now you want to pr_pull() those changes into your local copy.\n\npr_pull()\n\n‚úì Pulling from 'origin/add-example'\n\nDecision time: That was easy! What‚Äôs next?\n\nI‚Äôm going to write some code in this branch.\nI‚Äôm going to put this down and work on something else.\nI just merged this pull request and I‚Äôm all done with this work.\n\n\n\n\nUpdate your local copy with someone else‚Äôs changes\nChanges were made and hopefully the code has been improved, but you‚Äôd like to run through the changes yourself to make sure it works as expected.\nUse pr_pull() to get the latest changes from the PR branch into your local copy.\n\npr_pull()\n\n‚úì Pulling from 'wileycoyote/toone-model'\n\nDecision time: That was easy! What‚Äôs next?\n\nI‚Äôm going to write some code in this branch.\nI‚Äôm going to put this down and work on something else.\nThat‚Äôs all I wanted to do, I can forget about this PR now.\nI just merged this pull request and I‚Äôm all done with this work.\n\n\n\n\nBring your work up to date with the main branch\nWhile you were working on adding a new example to the documentation, your friend @wileycoyote went and submitted a PR that changes the function you‚Äôre working on.\nYou found out when you looked at your pull request on GitHub and it said\n\nCaution: This branch has conflicts that must be resolved.\n\nUsually two people can work in the same project on two different areas without running into each other, but when both you and someone else want to change the same lines of code, you run into this issue.\nHelpfully, pr_merge_main() can get the latest changes from the main branch of your project into your current pull request!\n\npr_merge_main()\n\n‚úì Pulling changes from 'origin/main' (default branch of source repo)\nThere are 1 conflicted files:\n* R/atom_arranger.R\n\nAre you ready to sort this out?\nIf so, we will open the conflicted files for you to edit.\n\n1: Yes, I'm ready to resolve the merge conflicts.\n2: No, I want to abort this merge.\n\nSelection: 1\nPlease fix each conflict, save, stage, and commit.\nTo back out of this merge, run `gert::git_merge_abort()` (in R) or `git merge --abort` (in the shell).\nIf you need to fix any merge conflicts, pr_merge_main() will alert you that there are conflicts that need to be addressed. It also opens the files for you if you want it to, or you can choose to abort the merge and find another way to resolve the conflicts.\nYou want to resolve the conflicts, so you picked selection 1 to open the conflicted file where you start looking for blocks in the source code that look like this:\n&lt;&lt;&lt;&lt;&lt;&lt;&lt; add-example\nCode in the first section appears in\nour *current* version in the `add-example` branch\n=======\nCode in the second section appears in\nthe *incoming* version, i.e. the `main` branch\n&gt;&gt;&gt;&gt;&gt;&gt;&gt; main\nTo resolve the conflict, you\n\nEdit from &lt;&lt;&lt;&lt;&lt;&lt;&lt; to &gt;&gt;&gt;&gt;&gt;&gt;&gt; choosing one or the other or a blend of the two versions\nSave the file and stage it with gert::git_add()\nRepeat for other files with merge conflicts\nCommit the updated files with gert::git_commit() or git commit in the command line\n\n\nDecision time: Great, your branch is up to date with the main branch!\n\nI‚Äôm going to write some code in this branch.\nI want to update the pull request on GitHub with these changes.\n\n\n\n\nBring their work up to date with the main branch\nWhile you and @wileycoyote have been working together on this new feature, you‚Äôve been doing some work in other areas of the package. Since that other work has been added to the main branch, you might want to make sure that everything is up to date in @wileycoyote‚Äôs toone-model branch.\nTo do this, run pr_merge_main(). It makes sure your default branch is up to date and then merges any changes into the current branch.\n\npr_merge_main()\n\n‚úì Pulling changes from 'origin/main' (default branch of source repo)\nMerged origin/main into wileycoyote-toone-model\nIf there aren‚Äôt any merge conflicts, you‚Äôll get a nice, quick confirmation that the merge went well.\n\nDecision time: Great, @wileycote‚Äôs branch is up to date with the main branch!\n\nI‚Äôm going to write some code in this branch.\nI want to update the pull request on GitHub with these changes.\n\n\n\n\nGet to the right place\nLet‚Äôs make sure we‚Äôre in the right branch in your local project.\n\nDecision time: Which branch do you want to work with right now?\n\nThe one I‚Äôm in right now, so I‚Äôm ready to get to work!\nA local branch, but not the one I‚Äôm in now\nA pull request branch I was looking at on GitHub"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#work",
    "href": "blog/pull-request-flow-usethis/index.html#work",
    "title": "Pull Request Flow with usethis",
    "section": "Work",
    "text": "Work\n\nDo some work\nYou take a sip of your coffee (or the beverage of your choice), turn up your favorite music to write code to playlist on Spotify, and line up 25 minutes in your Pomodoro app.\nYou‚Äôre ready to get something done! Go write some code. ‚è≤Ô∏è üßë‚Äçüíª üéß\n\nDecision time: Sweet! Now that you feel good about your work, you‚Äôre ready to take a snapshot of your updates.\n\n\n\nKeep doing some work\n\nTaking breaks and resting is important!\nLast night I got caught up in a nested #RStats list problem and couldn‚Äôt solve it.\nWrote the code this morning first shot.\nTake breaks! You need them!\n‚Äî Nicholas Tierney (@nj_tierney) April 16,2019\n\nSometimes the best thing you can do to solve a problem is give it some time. Go for a walk, read something engaging, talk to a friend, take a shower.\nAnd now you‚Äôre back with fresh eyes, more energy, and a full cup of coffee. This time, things go better! You fall easily into a flow and start writing some code. As you go, you periodically pause to stage files with gert::git_add() or to commit batches of changes with gert::git_commit().\nAfter a bit you surprise yourself when you realize that the thing you couldn‚Äôt figure out when you were tired yesterday you‚Äôve knocked out in an hour.\n\nDecision time: Happy with your progress, you‚Äôre ready update the PR with your latest changes.\n\n\n\nCollaborate with someone else\nThis is exciting! Your friend ‚Äî which feels like a totally natural way to describe @wileycoyote, a person you know primarily from Twitter ‚Äî had a pretty cool idea and you‚Äôre feeling the buzz of inspiration. Even though they started the pull request, you‚Äôre about to riff on the ideas they started laying down.\nYou pick out your favorite RStudio theme and turn up your favorite dance-slash-coding-slash-singing-out-loud music.\nAs you work, you pause occasionally to stage files with gert::git_add() and to commit them with gert::git_commit(). Since you‚Äôre working with someone else, you remember to write good commit messages, but since you‚Äôre having fun you also use gitmoji to give each commit a good emoji.\nIt‚Äôs a lot later than you expect when you start wrapping up. That‚Äôs okay, @wileycoyote is going to be stoked to see what you‚Äôve been working on!\n\nDecision time: Go head and update the PR with your latest changes.\n\n\n\nTake a snapshot of your work\nIf you like it then you shoulda made a git commit.\nThere are two parts to taking a snapshot of your code. And really, it‚Äôs less like taking a picture and more like sending yourself an email with a copy of your files.\nFirst, you‚Äôll pick the files that you want to add to the snapshot (or commit). You can do this in the R console using git_add() from the gert package. Give the function a vector with the paths to the files you changed.\n\ngert::git_add(c(\"R/atom_arranger.R\", \"man/atom_arranger.Rd\"))\n\nIn git-speak, git_add() adds the changes in the listed files to a staging area. Running this command is like dragging a file into the email you‚Äôre writing. We haven‚Äôt officially sent that email yet, but we have a copy ready to go. By the way, you can still make more changes to the file knowing that there‚Äôs a temporary copy in that email draft in case anything goes wrong.\nThen, once all the files you want to commit have been added, you commit the changes. In our email metaphor, committing is a lot like pressing send on the email.\nAnd just like an email, the commit includes a message where you can describe the updates you made to the files in the email (commit).\nFor this step you can use git_commit() (also from the gert package) which takes the commit message as a parameter. Think of this message like the subject of an email to your future self.\n\ngert::git_commit(\"Add an example to ?atom_arranger()\")\n\nP.S. You can do this adding-and-committing dance in the Git pane in RStudio, too.\n\nDecision time: Are you ready to share your work?\n\nYes! I‚Äôm ready to push my changes out into the world.\nNot yet, I want to keep on working on this.\nActually, I don‚Äôt think I‚Äôm on the right track here. I‚Äôd rather back out of this branch and forget all about it.\n\n\n\n\nFix something\nOh no, you need to fix something! I hope it‚Äôs just a typo and not a big scary error! But first‚Ä¶\n\nDecision time: This thing that needs to be fixed ‚Äî what branch is it in?\n\n\n\nFix something\nOh no, you need to fix something! I hope it‚Äôs just a typo and not a big scary error! But first‚Ä¶\n\nDecision time: This thing that needs to be fixed ‚Äî what branch is it in?\n\nThe one I‚Äôm in right now, so I‚Äôm ready to get to work!\nA local branch, but not the one I‚Äôm in now.\nA pull request branch I was looking at on GitHub.\n\n\n\n\nFix something\nOh no, you need to fix something! I hope it‚Äôs just a typo and not a big scary error! But first‚Ä¶\n\nDecision time: This thing that needs to be fixed ‚Äî what branch is it in?\n\nThe one I‚Äôm in right now, so I‚Äôm ready to get to work!\nA local branch, but not the one I‚Äôm in now\nA pull request branch I was looking at on GitHub"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#share-your-work",
    "href": "blog/pull-request-flow-usethis/index.html#share-your-work",
    "title": "Pull Request Flow with usethis",
    "section": "Share your work",
    "text": "Share your work\nFantastic! Your work is awesome and everyone is going to be happy to try it out.\n\nDecision time: Let‚Äôs get your work off of your computer and out into the world.\n\nThis new work you‚Äôre sharing for the first time.\nI‚Äôm updating a pull request that I created.\nI‚Äôm updating a pull request from someone else.\n\n\n\nCreate a new pull request\nFantastic! Your work is awesome and everyone is going to be happy to try it out.\nLet‚Äôs get your work off of your computer and out into the world. To create a new pull request, you call pr_push().\n\npr_push()\n\n‚úî Pushing local 'add-example' branch to 'origin:add-example'\n‚úî Setting upstream tracking branch for 'add-example' to 'origin/add-example'\n‚úî Create PR at link given below\n‚úî Opening URL 'https://github.com/gadenbuie/acme/compare/add-example'\npr_push() sends the local changes in your new branch to GitHub, and opens a browser window where you can review your changes once more. If everything looks good, go ahead click the Create Pull Request button.\n\nDecision time: Good job! How are you feeling now?\n\nI‚Äôm on a roll, let‚Äôs start the next thing.\nI‚Äôd want to open the PR on GitHub again.\nOh shoot, I saw something I need to fix.\nGreat, that pull request was just merged and I‚Äôm done with this work.\nChanges were made in the PR and now I need to update my local copy.\nThere were updates in the main branch and now I want to bring them into my PR branch.\nActually, the pull request was closed and I can forget about this work.\n\n\n\n\nUpdate your existing pull request\nYou just made and committed some changes to an existing PR you created, and now you‚Äôd like to update that PR on GitHub. pr_push() also does this for you! Helpfully, before it pushes it checks to make sure your local branch is up-to-date.\n\npr_push()\n\n‚úî Checking that local branch 'add-example' has the changes in 'origin/add-example'\n‚úî Pushing local 'add-example' branch to 'origin:add-example'\n‚úî View PR at 'https://github.com/gadenbuie/acme/pull/10' or call `pr_view()`\n\nDecision time: Phenomenal! What do you want to do next?\n\nI want to take a look at the PR on GitHub.\nRock on! I‚Äôm moving on to start the next thing.\nWait a second, I saw something I need to fix.\nChanges were made in the PR and now I need to update my local copy.\nThere were updates in the main branch and now I want to bring them into my PR branch.\nThe PR has been merged and I‚Äôm all done with this work.\nNever mind, my PR was closed and I‚Äôd like to forget about this work.\n\n\n\n\nUpdate someone else‚Äôs pull request\nAt this point, you have changes in your local copy of your PR branch that you need to push out to the source branch for the PR, which happens to be in @wileycoyote‚Äôs fork of your repo.\npr_push() is very smart and knows how to send the changes to the correct repository, pushing to the toone-model in the wileycoyote/acme.\n\npr_push()\n\n‚úî Checking that local branch 'wileycoyote-toone-model' has the changes in 'wileycoyote/toone-model'\n‚úî Pushing local 'wileycoyote-toone-model' branch to 'wilecoyote:toone-model'\n‚úî View PR at 'https://github.com/gadenbuie/acme/pull/14' or call `pr_view()`\n\nDecision time: Phenomenal! What do you want to do next?\n\nI want to take a look at the PR on GitHub.\nBeep, beep! I‚Äôm moving on to start the next thing.\nHang on, I saw something I need to fix.\nThat‚Äôs all I wanted to do, I can forget about this PR now.\nChanges were made in the PR and now I need to update my local copy.\nThere were updates in the main branch and now I want to bring them into my PR branch.\nI just merged this pull request and I‚Äôm all done with this work."
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#wrap-up",
    "href": "blog/pull-request-flow-usethis/index.html#wrap-up",
    "title": "Pull Request Flow with usethis",
    "section": "Wrap Up",
    "text": "Wrap Up\n\nPause your work\nYou‚Äôre done but you have a feeling you‚Äôll be back here again soon. What you need is a little pause.\nCall pr_pause() to switch from the current branch back to the default branch, and to make sure you‚Äôve got the latest changes in the default branch. Don‚Äôt worry, the work will be waiting patiently for you in a local branch when you‚Äôre ready to come back to it.\n\npr_pause()\n\n‚úì Switching back to default branch ('main')\n‚úì Pulling changes from 'origin/main'\n\nDecision time: Go back to Start to decide to decide what‚Äôs next in your adventure.\n\n\n\nFinish up your work\nHooray! A PR was merged and the new code is now in the default branch. That‚Äôs one less branch you need to keep around on your computer.\n\nDecision time: Was this PR yours?\n\nYes, and‚Ä¶\n\nI‚Äôm still in the PR branch in my local project\nI‚Äôm in the main branch now, but I have the PR branch here somewhere\n\nNo, and‚Ä¶\n\nI‚Äôm still in the PR branch in my local project\nI‚Äôm in the main branch now, but I have the PR branch here somewhere\n\n\n\n\n\nFinish your work\nCongrats! Your pull request was merged! That‚Äôs awesome. Now it‚Äôs time to wrap things up by calling pr_finish().\n\npr_finish()\n\n‚úì Checking that remote branch 'origin/add-example' has the changes in 'add-example'\n‚úì Switching back to default branch ('main')\n‚Ñπ Pulling changes from 'origin/main'\n‚úì Deleting local 'add-example' branch\n\nDecision time: Go back to Start to decide what‚Äôs next in your adventure.\n\n\n\nFinish your work\nWell done, your collaboration with @wileycoyote is complete and their PR is merged! That‚Äôs awesome. Now it‚Äôs time to wrap things up by calling pr_finish().\n\npr_finish()\n\n‚úî Checking that remote branch 'wileycoyote/toone-model' has the changes in 'local/wileycoyote-toone-model'\n‚úî Switching back to 'main' branch\n‚úî Pulling changes from GitHub source repo 'origin/main'\n‚úî Deleting local 'wileycoyote-toone-model' branch\n‚úî Removing remote 'wileycoyote'\nNotice that pr_finish() does quite a lot! It makes sure that you don‚Äôt accidentally leave behind some changes in your local branch that might have forgotten to push. Then it switches back to main and makes sure that‚Äôs up to date, too. Finally we forget all about @wileycote‚Äôs branch and forked repo.\n\nDecision time: That‚Äôs all folks! Head back to the beginning to choose your next adventure.\n\n\n\nClean up now that the PR has been merged\nYou don‚Äôt have to be in your local copy of the PR branch if you know the PR number. Give the number to pr_finish() and it will do the rest for you: it moves back to the default branch, updates your local copy, and deletes the old PR branch.\n\npr_finish(11)\n\n‚úì Checking that remote branch 'origin/add-example' has the changes in 'add-example'\n‚úì Switching back to default branch ('main')\n‚Ñπ Pulling changes from 'origin/main'\n‚úì Deleting local 'add-example' branch\n\nDecision time: Go back to Start to decide what‚Äôs next in your adventure.\n\n\n\nForget about your work\nWell that was fun. But now you‚Äôre done with this branch and you call pr_forget() to delete it from your local copy.\n\npr_forget()\n\nLocal branch 'add-example' has no associated remote branch.\nIf we delete 'add-example', any work that exists only on this branch work may be hard for you to recover.\nProceed anyway?\n\n1: No way\n2: Not now\n3: Yes\n\nSelection: 3\n‚úì Switching back to default branch ('main')\n‚úì Pulling changes from 'origin/main'\n‚úì Deleting local 'add-example' branch\nNotice that pr_forget() warns you about any work you might lose and gives you a chance to rethink it.\n\nDecision time: Go back to Start to decide what‚Äôs next in your adventure.\n\n\n\nForget about their work\nYour work here is done and you‚Äôd like to move on with your life. pr_forget() lets you put this branch behind you. And while it‚Äôs in there, it also cleans up your repo, deleting the local copy of the PR branch and removing the PR author‚Äôs repo fork from the list of remote repositories your git project could sync with.\n\npr_forget()\n\n‚úì Switching back to default branch ('main')\n‚úì Pulling changes from 'origin/main'\n‚úì Deleting local 'wileycoyote-toone-models' branch\n‚úì Removing remote 'wileycoyote'\nThat was smooth! Notice that pr_forget() moved you into the default branch of your repo, main, and it even made sure that branch is up to date.\npr_forget() is safe and cautious. If your local wileycoyote-toone-models branch had had any changes in it that you might have lost, pr_forget() would have warned you. You also know that you can get back to the PR branch any time using pr_fetch().\n\nDecision time: Worry and care-free, you head back to the beginning to decide what‚Äôs next in your adventure."
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#section",
    "href": "blog/pull-request-flow-usethis/index.html#section",
    "title": "Pull Request Flow with usethis",
    "section": "",
    "text": "Start over"
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#download",
    "href": "blog/pull-request-flow-usethis/index.html#download",
    "title": "Pull Request Flow with usethis",
    "section": "Download the usethis pr_*() flow chart",
    "text": "Download the usethis pr_*() flow chart\n\nSmall JPG Image (190 KB)\nMedium JPG Image (511 KB)\nLarge JPG Image (1.36 MB)\nSVG (40 KB)\nSVG, Editable (40 KB)\nSource File .drawio (4 KB)\n\n\n\n  \n\n\n  Pull Request Flow with usethis\n\nby\n\nGarrick Aden-Buie\n is licensed under a\nCreative Commons Attribution 4.0 International License.\n\n\n\n\n\nA flow chart for the pull request functions in the usethis R package."
  },
  {
    "objectID": "blog/pull-request-flow-usethis/index.html#footnotes",
    "href": "blog/pull-request-flow-usethis/index.html#footnotes",
    "title": "Pull Request Flow with usethis",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI primarily use GitHub, but I think these functions will generally work for other code-hosting platforms as well, like GitLab or others.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html",
    "href": "blog/print-xaringan-chromote/index.html",
    "title": "Printing xaringan slides with chromote",
    "section": "",
    "text": "There are a number of options for producing PDF versions of xaringan slides, provided you use the standard xaringan features.\nIf you add interactive elements, like panelsets from xaringanExtra, printing your slides to convert them to PDF may not capture everything in your slides.\nThis post demonstrates a function that uses chromote to print xaringan slides to PDF files that should give better results, in particular when using panelsets."
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html#the-problem",
    "href": "blog/print-xaringan-chromote/index.html#the-problem",
    "title": "Printing xaringan slides with chromote",
    "section": "The Problem",
    "text": "The Problem\nTypically, it‚Äôs fairly easy to convert xaringan slides to PDF. There are three methods that I‚Äôve used that each work well and produce relatively similar results:\n\nPrint the slides from a browser. Typically this works best in Chrome.\nUse xaringan::decktape() to virtually print the slides to PDF. This requires docker or an installed version of the decktape.js utility.\nUse pagedown::chrome_print(). This is similar to the first option, but uses a headless version of Chrome to do the printing behind the scenes.\n\nThese methods all work well but have one significant drawback: they don‚Äôt work well with xaringanExtra‚Äôs panelsets. The problem with the panelsets is that they essentially add ‚Äúwithin-slide‚Äù slides. All of the panels are contained in a single slide, so when printed, only the first panel in the panelset is shown."
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html#the-idea",
    "href": "blog/print-xaringan-chromote/index.html#the-idea",
    "title": "Printing xaringan slides with chromote",
    "section": "The Idea",
    "text": "The Idea\nThe solution is easy but took me a bit of fiddling to figure out: we use chromote to control our own headless version of Chrome. Then we ask a programmatic monkey to push the ‚Üí button repeatedly, once per second(-ish), to advance through the slides, printing each slide to its own PDF.\nOnce all the slides are printed, we ask our monkey assistant to please staple the slides together into one (big) PDF file. All of this happens inside a headless Chrome browser controlled by chromote.\nThat‚Äôs it! And okay, the monkey assistant is actually a little bit of JavaScript that mashes a virtual right arrow key. And the stapler is actually the fantastic pdftools package.\nOh, and headless isn‚Äôt as spooky as it sounds. Basically it‚Äôs Chrome without the chrome. In other words, it‚Äôs a version of Chrome that runs as a command line utility and doesn‚Äôt have a user interface that you can click around in. Instead, you communicate with the browser by sending it commands, all of which are made easier by chromote."
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html#the-solution",
    "href": "blog/print-xaringan-chromote/index.html#the-solution",
    "title": "Printing xaringan slides with chromote",
    "section": "The Solution",
    "text": "The Solution\nI‚Äôve written a function, xaringan_to_pdf(), that you can point either at your slides online or your at local rendered slides (which may require file:// before the full path to the .html file).\nYou can copy the code below, or you can source it from this gist using the code and shortlink below1. Please check the source before you run it!\nsource(\"https://git.io/xaringan2pdf\")\nRunning xaringan_to_pdf() will walk through your slides, printing them one-by-one, and returning one big PDF file. I‚Äôm not linking one here because they can be big."
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html#the-code",
    "href": "blog/print-xaringan-chromote/index.html#the-code",
    "title": "Printing xaringan slides with chromote",
    "section": "The Code",
    "text": "The Code\nBefore you can print your slides with xaringan_to_pdf(), you‚Äôll need a few things:\n\nGoogle Chrome\nThe chromote package, which isn‚Äôt on CRAN yet:\n\nremotes::install_github(\"rstudio/chromote\")\n\nA few other packages that you can get from CRAN:\n\ninstall.packages(c(\"progress\", \"jsonlite\", \"pdftools\", \"digest\"))\n\n\nOnce you have those things installed and ready to go, copy the source code below and then run xaringan_to_pdf() to print your slides!\nIf you have any problems with the code, feel free to leave a comment on the gist.\n\n\n\n#' Print xaringan slides to PDF\n#'\n#' Prints xaringan slides to a PDF file, even complicated slides\n#' with panelsets or other html widgets or advanced features.\n#' Requires a local installation of Chrome.\n#'\n#' @param input Path to Rmd or html file of xaringan slides.\n#' @param output_file The name of the output file. If using NULL then\n#'   the output filename will be based on filename for the input file.\n#'   If a filename is provided, a path to the output file can also be provided.\n#' @param delay Seconds of delay between advancing to and printing\n#'   a new slide.\n#' @param include_partial_slides Should partial (continuation) slides be\n#'   included in the output? If `FALSE`, the default, only the complete slide\n#'   is included in the PDF.\nxaringan_to_pdf &lt;- function(\n  input,\n  output_file = NULL,\n  delay = 1,\n  include_partial_slides = FALSE\n) {\n  if (!requireNamespace(\"chromote\", quietly = TRUE)) {\n    stop(\"`chromote` is required: devtools::install_github('rstudio/chromote')\")\n  }\n  required_packages &lt;- c(\"progress\", \"jsonlite\", \"pdftools\", \"digest\", \"fs\")\n  for (pkg in required_packages) {\n    if (!requireNamespace(pkg, quietly = TRUE)) {\n      stop(\"`\", pkg, \"` is required: install.packages('\", pkg, \"')\")\n    }\n  }\n\n  is_url &lt;- grepl(\"^(ht|f)tp\", tolower(input))\n\n  if (is.null(output_file)) {\n    if (is_url) {\n      output_file &lt;- fs::path_ext_set(fs::path_file(input), \"pdf\")\n    } else {\n      output_file &lt;- fs::path_ext_set(input, \"pdf\")\n    }\n  }\n\n  if (!is_url && !grepl(\"^file://\", input)) {\n    if (!tolower(fs::path_ext(input)) %in% c(\"htm\", \"html\")) {\n      stop(\"`input` must be the HTML version of the slides.\")\n    }\n    input &lt;- paste0(\"file://\", fs::path_abs(input))\n  }\n\n  b &lt;- chromote::ChromoteSession$new()\n  on.exit(b$close(), add = TRUE)\n\n  b$Page$navigate(input, wait_ = TRUE)\n  b$Page$loadEventFired()\n\n  has_remark &lt;- b$Runtime$evaluate(\"typeof slideshow !== 'undefined'\")$result$value\n  if (!has_remark) {\n    stop(\"Input does not appear to be xaringan slides: \", input)\n  }\n\n  current_slide &lt;- function() {\n    x &lt;- b$Runtime$evaluate(\"slideshow.getCurrentSlideIndex()\")$result$value\n    as.integer(x) + 1L\n  }\n\n  slide_is_continuation &lt;- function() {\n    b$Runtime$evaluate(\n      \"document.querySelector('.remark-visible').matches('.has-continuation')\"\n    )$result$value\n  }\n\n  hash_current_slide &lt;- function() {\n    digest::digest(b$Runtime$evaluate(\n      \"document.querySelector('.remark-visible').innerHTML\"\n    )$result$value)\n  }\n\n  get_ratio &lt;- function() {\n    r &lt;- b$Runtime$evaluate('slideshow.getRatio()')$result$value\n    r &lt;- lapply(strsplit(r, \":\"), as.integer)\n    width &lt;- r[[1]][1]\n    height &lt;- r[[1]][2]\n    page_width &lt;- 8/width * width\n    list(\n      width = as.integer(908 * width / height),\n      height = 681L,\n      page = list(width = page_width, height = page_width * height / width)\n    )\n  }\n\n  slide_size &lt;- get_ratio()\n\n  expected_slides &lt;- as.integer(\n    b$Runtime$evaluate(\"slideshow.getSlideCount()\")$result$value\n  )\n\n  max_slides &lt;- expected_slides * 4\n\n  b$Browser$setWindowBounds(1, bounds = list(\n    width = slide_size$width,\n    height = slide_size$height\n  ))\n\n  b$Emulation$setEmulatedMedia(\"print\")\n  b$Runtime$evaluate(paste0(\n    \"let style = document.createElement('style')\\n\",\n    \"style.innerText = '@media print { \",\n    \".remark-slide-container:not(.remark-visible){ display:none; }\",\n    if (include_partial_slides) \" .has-continuation { display: block }\",\n    \"}'\\n\",\n    \"document.head.appendChild(style)\"\n  ))\n\n  pb &lt;- progress::progress_bar$new(\n    format = \"Slide :slide (:part) [:bar] Eta: :eta\",\n    total = expected_slides\n  )\n\n  idx_slide &lt;- current_slide()\n  last_hash &lt;- \"\"\n  idx_part &lt;- 0L\n  pdf_files &lt;- c()\n  for (i in seq_len(max_slides)) {\n    if (i &gt; 1) {\n      b$Input$dispatchKeyEvent(\n        \"rawKeyDown\",\n        windowsVirtualKeyCode = 39,\n        code = \"ArrowRight\",\n        key = \"ArrowRight\",\n        wait_ = TRUE\n      )\n    }\n\n    if (current_slide() == idx_slide) {\n      step &lt;- 0L\n      idx_part &lt;- idx_part + 1L\n    } else {\n      step &lt;- 1L\n      idx_part &lt;- 1L\n    }\n    idx_slide &lt;- current_slide()\n    pb$tick(step, tokens = list(slide = idx_slide, part = idx_part))\n\n    if (!isTRUE(include_partial_slides) && slide_is_continuation()) next\n    Sys.sleep(delay)\n\n    this_hash &lt;- hash_current_slide()\n    if (identical(last_hash, this_hash)) break\n    last_hash &lt;- this_hash\n\n    pdf_file_promise &lt;- b$Page$printToPDF(\n      landscape = TRUE,\n      printBackground = TRUE,\n      paperWidth = 12,\n      paperHeight = 9,\n      marginTop = 0,\n      marginRight = 0,\n      marginBottom = 0,\n      marginLeft = 0,\n      pageRanges = \"1\",\n      preferCSSPageSize = TRUE,\n      wait_ = FALSE\n    )$then(function(value) {\n      filename &lt;- tempfile(fileext = \".pdf\")\n      writeBin(jsonlite::base64_dec(value$data), filename)\n      filename\n    })\n    pdf_files &lt;- c(pdf_files, b$wait_for(pdf_file_promise))\n  }\n\n  pdftools::pdf_combine(pdf_files, output = output_file)\n  fs::file_delete(pdf_files)\n\n  invisible(output_file)\n}"
  },
  {
    "objectID": "blog/print-xaringan-chromote/index.html#footnotes",
    "href": "blog/print-xaringan-chromote/index.html#footnotes",
    "title": "Printing xaringan slides with chromote",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI wasn‚Äôt really sure where to put this function. Maybe I‚Äôll eventually add it to [xaringanExtra, but for now it‚Äôll live here where hopefully it can still be useful to you!‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/popular-letters-in-babynames/index.html",
    "href": "blog/popular-letters-in-babynames/index.html",
    "title": "Popular Letters in Baby Names, Animated",
    "section": "",
    "text": "Earlier this week, a tweet from Kieran Healy caught my attention with a neat animation of the popularity of the final letters of baby names.\nI‚Äôm also a big fan of gganimate] - check out my first project with [gganimate, a collection of join animations called tidyexplain. And the babynames package by Hadley Wickham makes it pleasantly easy to work with the baby names data reported by the U.S. Social Security Administration.\nKieran‚Äôs animations inspired several questions that I hope to answer (or at least visualize) in this post:\nRather than answer these questions definitively or scientifically, I‚Äôve stuck with the fun parts and made a few visualizations. I‚Äôll let you decide how effective they are. (And feel free to let me know on Twitter at @grrrck.)"
  },
  {
    "objectID": "blog/popular-letters-in-babynames/index.html#getting-started",
    "href": "blog/popular-letters-in-babynames/index.html#getting-started",
    "title": "Popular Letters in Baby Names, Animated",
    "section": "Getting Started",
    "text": "Getting Started\nTo get started, I loaded the following packages, all installed from CRAN with install.packages().\n\nlibrary(tidyverse)\nlibrary(gganimate)\nlibrary(babynames)\n\nNext, I set up a base ggplot2 theme that I‚Äôll use throughout. Note that you can also set the ggplot2 theme globally with theme_set(), but I‚Äôm not doing that here for complicated reasons related to my use of knitr caching for faster rendering between post drafts.\nI also used the showtext and sysfonts packages. These two sister packages are my go-to packages for reliably being able to use Google Fonts]google-fonts with [ggplot2 on any system.\n\nshowtext::showtext_auto()\nsysfonts::font_add_google(\"PT Sans\")\nsysfonts::font_add_google(\"PT Sans Narrow\")\nbase_theme &lt;-\n  theme_minimal(base_size = 16, base_family = \"PT Sans\") +\n  theme(\n    legend.position      = c(0.5, 0.9),\n    legend.text          = element_text(margin = margin(r = 10)),\n    legend.background    = element_rect(fill = \"white\", color = \"white\"),\n    legend.direction     = \"horizontal\",\n    legend.justification = \"center\",\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    axis.text     = element_text(family = \"PT Sans Narrow\"),\n    axis.text.x   = element_text(vjust = 0.9, face = \"bold\"),\n    axis.title.y  = element_text(margin = margin(r = 20)),\n    plot.subtitle = element_text(\n      size = rel(1.5), hjust = 0.5, margin = margin(t = 10)\n    ),\n    plot.caption  = element_text(color = \"grey40\", lineheight = 1.1)\n  )\n\nsex_colors &lt;- c(\"Male\" = \"#00589A\", \"Female\" = \"#EB1455\")\ncaption_text &lt;- paste(\n  \"Source: babynames, U.S. Social Security Administration\",\n  \"@grrrck\", \"garrickadenbuie.com\",\n  sep = \" | \"\n)"
  },
  {
    "objectID": "blog/popular-letters-in-babynames/index.html#how-popular-are-letters-used-anywhere-in-baby-names",
    "href": "blog/popular-letters-in-babynames/index.html#how-popular-are-letters-used-anywhere-in-baby-names",
    "title": "Popular Letters in Baby Names, Animated",
    "section": "How Popular are Letters Used Anywhere in Baby Names",
    "text": "How Popular are Letters Used Anywhere in Baby Names\n\nLetters in Baby Names\nTo answer the first question, I needed to first establish what letters are used in a name, regardless of the letter‚Äôs position in the name, and not counting duplicates. Rather than repeatedly calculate this information for every year, sex, and name pair in babynames, I used distinct() from dplyr to obtain the list of unique names.\n\nbabynames_and_letters &lt;-\n  babynames %&gt;%\n  distinct(name) %&gt;%\n  mutate(letter = strsplit(tolower(name), character())) %&gt;%\n  # strsplit() returns a list for each name,\n  # so 'letter' is a list-column that can be converted to a\n  # normal column with unnest()\n  unnest(letter) %&gt;%\n  # count each letter once\n  distinct()\n\nbabynames_and_letters %&gt;%\n  filter(name == \"Garrick\")\n\n# A tibble: 6 √ó 2\n  name    letter\n  &lt;chr&gt;   &lt;chr&gt; \n1 Garrick g     \n2 Garrick a     \n3 Garrick r     \n4 Garrick i     \n5 Garrick c     \n6 Garrick k     \n\n\nThen I joined babynames with the babynames_and_letters table to get the sum of the proportions of the population (by year and sex) that have each letter in their name.\n\nbabynames_containing &lt;-\n  left_join(babynames, babynames_and_letters, by = \"name\") %&gt;%\n  group_by(letter, year, sex) %&gt;%\n  summarize(prop = sum(prop)) %&gt;%\n  ungroup() %&gt;%\n  filter(year &gt;= 1900) %&gt;%\n  mutate(sex = recode(sex, M = \"Male\", F = \"Female\"))\n\nbabynames_containing %&gt;%\n  filter(letter == \"g\") %&gt;%\n  head()\n\n# A tibble: 6 √ó 4\n  letter  year sex      prop\n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;   &lt;dbl&gt;\n1 g       1900 Female 0.0800\n2 g       1900 Male   0.0632\n3 g       1901 Female 0.0827\n4 g       1901 Male   0.0615\n5 g       1902 Female 0.0831\n6 g       1902 Male   0.0618\n\n\n\n\nPlot and Animate\nAt this point, my typical gganimate workflow is to first create a static ggplot2 plot as a sanity check for the animation. If the static plot works with facet_wrap(~ state_column), then using transition_state(state_column) is likely to work well (although you may need to filter the data to preview only a few states). In this case, I used year as the state column.\nI generally try to structure my ggplot2 code in a consistent way (future blog post?) so I prefer having the gganimate specific parts at the end. I also directly called gganimate::animate() so that I could control specific parameters of the output, namely the number of frames and the size of the image. The default number of frames is 100 but I‚Äôm visualizing 117 years and gganimate will complain (i.e.¬†throw an error) if there aren‚Äôt enough frames to cover the number of states.\n\nga_pop_letter &lt;-\n  ggplot(babynames_containing) +\n  aes(letter, prop, fill = sex) +\n  geom_col(position = \"identity\", alpha = 0.6) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 10),\n    expand = c(0, 0)\n  ) +\n  scale_fill_manual(values = sex_colors) +\n  labs(\n    x        = NULL,\n    y        = \"Percent of Population\",\n    fill     = NULL,\n    title    = \"How many babies have the letter ____ in their name?\",\n    subtitle = \"{closest_state}\",\n    caption  = caption_text\n  ) +\n  base_theme +\n  ease_aes(\"linear\") +\n  transition_states(\n    year, transition_length = 1, state_length = 0, wrap = FALSE\n  )\n\nga_pop_letter_animated &lt;- animate(\n  ga_pop_letter,\n  nframes = 117*2+10,\n  end_pause = 10,\n  width = 1024,\n  height = 512\n)\n\nThe resulting animation, below, shows the proportion of babies given a name containing (at least one of) each letter of the alphabet since 1900."
  },
  {
    "objectID": "blog/popular-letters-in-babynames/index.html#first-and-last-letters-of-baby-names",
    "href": "blog/popular-letters-in-babynames/index.html#first-and-last-letters-of-baby-names",
    "title": "Popular Letters in Baby Names, Animated",
    "section": "First and Last Letters of Baby Names",
    "text": "First and Last Letters of Baby Names\nTo extract the first and last letter of each name, I wrote two small functions, first_letter() and last_letter() that use substring() to pull out the first and last letter of a string. These are reasonably fast when applied to all of the names using map_chr() from purrr within mutate() to add new columns first_letter and last_letter.\n\nfirst_letter &lt;- function(x) substring(x, 1, 1)\nlast_letter  &lt;- function(x) substring(x, nchar(x), nchar(x))\n\nbabynames_first_last &lt;-\n  babynames %&gt;%\n  mutate(\n    first_letter = map_chr(name, first_letter),\n    last_letter  = map_chr(name, last_letter),\n  ) %&gt;%\n  mutate_at(vars(contains(\"letter\")), tolower)\n\nset.seed(42)\nbabynames_first_last %&gt;% sample_n(6)\n\n# A tibble: 6 √ó 7\n   year sex   name         n      prop first_letter last_letter\n  &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;    &lt;int&gt;     &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;      \n1  1991 M     Bobby     1508 0.000712  b            y          \n2  1900 F     Pamela       5 0.0000157 p            a          \n3  1964 F     Marline     21 0.0000107 m            e          \n4  1992 F     Carlos      31 0.0000155 c            s          \n5  1991 F     Charlene   531 0.000261  c            e          \n6  1985 F     Mariya      27 0.0000146 m            a          \n\n\n\nAnimated\nFirst, let‚Äôs look at the animated version of my remix of Kieran‚Äôs plots. You can still see the change in the use of N as a final letter in the names given to baby boys, as he described, but you also see the changes in female names as well.\n\nHere‚Äôs the code I used to produce the plot above.\n\ngb_last &lt;-\n  babynames_first_last %&gt;%\n  filter(year &gt;= 1900) %&gt;%\n  mutate(sex = recode(sex, M = \"Male\", F = \"Female\")) %&gt;%\n  group_by(year, sex, last_letter) %&gt;%\n  summarize(prop = sum(prop)) %&gt;%\n  ggplot() +\n  aes(last_letter, prop, fill = sex) +\n  geom_col(position = \"identity\", alpha = 0.6) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 5),\n    expand = c(0, 0)\n  ) +\n  scale_fill_manual(values = sex_colors) +\n  labs(\n    x = NULL,\n    y = \"Percent of Population\",\n    fill = NULL,\n    title = \"How many baby names end with the letter ____?\",\n    subtitle = \"{closest_state}\",\n    caption = caption_text\n  ) +\n  base_theme +\n  theme(legend.position = c(0.8, 0.9)) +\n  ease_aes(\"linear\") +\n  transition_states(\n    year,\n    transition_length = 1,\n    state_length = 0, wrap = FALSE\n  )\n\ngb_last_animated &lt;- animate(\n  gb_last,\n  nframes = 117*2+10,\n  end_pause = 10,\n  width = 1024, height = 512\n)\n\nThen I also created a similar visualization for the starting letters of baby‚Äôs names.\n\nAnd here‚Äôs the code to create the above animation.\n\ngb_first &lt;-\n  babynames_first_last %&gt;%\n  filter(year &gt;= 1900) %&gt;%\n  mutate(sex = recode(sex, M = \"Male\", F = \"Female\")) %&gt;%\n  group_by(year, sex, first_letter) %&gt;%\n  summarize(prop = sum(prop)) %&gt;%\n  ggplot() +\n  aes(first_letter, prop, fill = sex) +\n  geom_col(position = \"identity\", alpha = 0.6) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 5),\n    expand = c(0, 0)\n  ) +\n  scale_fill_manual(values = sex_colors) +\n  labs(\n    x = NULL,\n    y = \"Percent of Population\",\n    fill = NULL,\n    title = \"How many baby names start with the letter ____?\",\n    subtitle = \"{closest_state}\",\n    caption = caption_text\n  ) +\n  base_theme +\n  theme(legend.position = c(0.8, 0.9)) +\n  ease_aes(\"linear\") +\n  transition_states(\n    year,\n    transition_length = 1,\n    state_length = 0,\n    wrap = FALSE\n  )\n\ngb_first_animated &lt;- animate(\n  gb_first,\n  nframes = 117*2+10,\n  end_pause = 10,\n  width = 1024, height = 512\n)\n\n\n\nStatic\nI‚Äôll admit, I think the animated plots are cool, but they also make it hard to reason about overall trends. You have to watch the animation loop over and over, trying to watch one letter or one sex specifically. I feel like I‚Äôm seeing the movement but missing the picture.\nI thought it would be interesting to compare the animated plots with line charts showing the same information, so I swapped gganimate‚Äôs transition_state(year) for ggplot2‚Äôs facet_wrap(~ letter).\nI somewhat like these plots more than their animated versions. I get the sense that I‚Äôm seeing a fuller picture (or more easy-to-compare picture) of the overall trends in starting and ending letters of baby names.\n\n\nHere‚Äôs the code to produce the static image of the trends in the last letter of baby names.\n\nbabynames_first_last %&gt;%\n  filter(year &gt;= 1900) %&gt;%\n  mutate(sex = recode(sex, M = \"Male\", F = \"Female\")) %&gt;%\n  group_by(year, sex, last_letter) %&gt;%\n  summarize(prop = sum(prop)) %&gt;%\n  ungroup() %&gt;%\n  mutate(last_letter = toupper(last_letter)) %&gt;%\n  ggplot() +\n  aes(year, prop) +\n  geom_text(\n    data = tibble(\n      last_letter = LETTERS,\n      x = 1900+117/2,\n      prop = 0\n    ),\n    aes(label = last_letter, x = x),\n    size = rel(15),\n    vjust = -0.12,\n    color = \"grey75\",\n    family = \"PT Sans\"\n  ) +\n  geom_line(aes(color = sex)) +\n  facet_wrap(~ last_letter) +\n  scale_y_continuous(\n    labels = scales::percent_format(5),\n    breaks = c(0, 0.3)\n  ) +\n  scale_x_continuous(breaks = c(1900, 2000)) +\n  scale_color_manual(values = sex_colors) +\n  labs(\n    x = NULL,\n    y = \"Proportion of Population\",\n    title = \"How many babies have names ending with the letter ____?\",\n    caption = caption_text,\n    color = NULL\n  ) +\n  base_theme +\n  theme(\n    strip.text = element_blank(),\n    axis.text.x = element_text(face = \"plain\"),\n    legend.position = c(0.7, 0.025),\n    panel.grid.minor.y = element_blank()\n  )\n\nAnd here is the code to produce the plot of trends in the first letter of baby names.\n\nbabynames_first_last %&gt;%\n  filter(year &gt;= 1900) %&gt;%\n  mutate(sex = recode(sex, M = \"Male\", F = \"Female\")) %&gt;%\n  group_by(year, sex, first_letter) %&gt;%\n  summarize(prop = sum(prop)) %&gt;%\n  ungroup() %&gt;%\n  mutate(first_letter = toupper(first_letter)) %&gt;%\n  ggplot() +\n  aes(year, prop) +\n  geom_text(\n    data = tibble(\n      first_letter = LETTERS,\n      x = 1900+117/2,\n      prop = 0\n    ),\n    aes(label = first_letter, x = x),\n    size = rel(15),\n    vjust = -0.2,\n    color = \"grey75\",\n    family = \"PT Sans\"\n  ) +\n  geom_line(aes(color = sex)) +\n  facet_wrap(~ first_letter) +\n  scale_y_continuous(\n    labels = scales::percent_format(5),\n    breaks = c(0, 0.2)\n  ) +\n  scale_x_continuous(breaks = c(1900, 2000)) +\n  scale_color_manual(values = sex_colors) +\n  labs(\n    x = NULL,\n    y = \"Proportion of Population\",\n    title = \"How many babies have names starting with the letter ____?\",\n    caption = caption_text,\n    color = NULL\n  ) +\n  base_theme +\n  theme(\n    strip.text = element_blank(),\n    axis.text.x = element_text(face = \"plain\"),\n    legend.position = c(0.7, 0.025),\n    panel.grid.minor.y = element_blank()\n  )\n\n\nIf you made it this far, thanks for reading! I‚Äôd love to hear your opinion on these plots, or see your own versions ‚Äì animated or not! Just drop me a line on Twitter at @grrrck."
  },
  {
    "objectID": "blog/my-ggridges-twitter-header/index.html",
    "href": "blog/my-ggridges-twitter-header/index.html",
    "title": "My ggridges Twitter Header",
    "section": "",
    "text": "First, I created a 1500 x 500 pixel image with the letter g.\n\nThen I made it fancy.\n\n# Requires\nlibrary(png)\nlibrary(ggplot2)\nlibrary(ggridges)\nlibrary(dplyr)\n# also: purrr and reshape2\nset.seed(4242)\n\ntheme_color &lt;- \"#002b36\"\n\nreadPNG(image_file) %&gt;% \n  .[, , 4] %&gt;% \n  reshape2::melt() %&gt;% \n  mutate(\n    value = value + rnorm(length(value), sd = 0.25),\n    value = case_when(value &gt; 0 ~ value, TRUE ~ 0)\n  ) %&gt;% \n  filter(Var1 %in% seq(0, 500, 15)) %&gt;% \n  group_by(Var1) %&gt;% \n  split(.$Var1) %&gt;% \n  purrr::map_df(~ {\n    mutate(., value = zoo::rollmean(value, k = 20, fill = 0.1))\n  }) %&gt;% \n  ggplot() + \n  aes(Var2, -Var1, height = value, group = Var1) + \n  geom_ridgeline(\n    scale = 30, \n    fill = theme_color, \n    alpha = 0.5, \n    color = \"#cccccc\") +\n  theme_minimal() +\n  theme(\n    axis.text = element_blank(),\n    panel.grid = element_blank(),\n    panel.grid.major.x = element_blank(),\n    panel.grid.minor.x = element_blank(),\n    axis.ticks = element_blank(),\n    axis.line = element_blank(), axis.title = element_blank(),\n    plot.background = element_rect(fill = theme_color, color = NA), \n    plot.margin = margin(32, 0, 32, 0))\n\n\n\n\n\n\n\n\nSave the image at 1500x500, the preferred size for Twitter headers.\nggsave(\"new-twitter-header.png\", \n       width = 15, height = 5, \n       units = 'in', dpi = 100)\n\nAccidental Art\nWhile hacking on the above, I ran into this @accidental_aRt:\n\nset.seed(4242)\nreadPNG(image_file) %&gt;% \n  .[, , 4] %&gt;% \n  reshape2::melt() %&gt;% \n  mutate(value = value + rnorm(length(value), sd = 0.25)) %&gt;% \n  filter(Var1 %in% seq(0, 500, 25)) %&gt;% \n  mutate(Var2 = floor(Var2/20)*20) %&gt;%\n  ggplot(aes(Var2, -Var1, height = value, group = Var1)) + \n  geom_ridgeline_gradient(scale = 40, fill = \"#394e5a\") +\n  theme_void()"
  },
  {
    "objectID": "blog/little-inline-color-boxes/index.html",
    "href": "blog/little-inline-color-boxes/index.html",
    "title": "Little Inline Color Boxes",
    "section": "",
    "text": "Sharla Gelfand (@sharlagelfand) March 12, 2021"
  },
  {
    "objectID": "blog/little-inline-color-boxes/index.html#color-boxes-with-r",
    "href": "blog/little-inline-color-boxes/index.html#color-boxes-with-r",
    "title": "Little Inline Color Boxes",
    "section": "Color Boxes with R",
    "text": "Color Boxes with R\n\ncolor_preview &lt;- function(color) {\n  htmltools::tagList(\n    htmltools::span(\n      class = \"color-preview\",\n      style = paste(\"background-color:\", color),\n      .noWS = \"outside\"\n    ),\n    htmltools::code(color, .noWS = \"outside\"),\n    color_preview_dep()\n  )\n}\n\n\n\n\n\n\n\nCSS Dependency\n\n\n\n\n\nYou‚Äôll need to copy this function too, and feel free to tweak it if you want. For example, remove the border-radius line to get squares instead of circles. Or remove the .color-preview:hover rule to have static previews.\n\ncolor_preview_dep &lt;- function() {\n  htmltools::htmlDependency(\n    name = \"color_preview\",\n    version = \"0.0.1\",\n    src = \".\",\n    all_files = FALSE,\n    head = \"\n&lt;style&gt;.color-preview {\n  display: inline-block;\n  width: 1em;\n  height: 1em;\n  border-radius: 50%;\n  margin: 0 0.33em;\n  vertical-align: middle;\n  transition: transform 100ms ease-in-out;\n}\n\n.color-preview:hover {\n  cursor: pointer;\n  transform: scale(2);\n  transform-origin: 50% 50%;\n}&lt;/style&gt;\"\n  )\n}\n\n\n\n\nOne of my favorite color resources coolors.co. It gives you a palette of random colors, like #414073 or #70a37F. You can press the space bar to get new colors, or you can lock in colors you like to find new ones that work with colors you‚Äôve already picked out.\nHere‚Äôs another color coolors picked for me:\n\ncolor_preview(\"rgb(114, 9, 183)\")\n\nrgb(114, 9, 183)\n\n\nYou can even find color palettes, like this one.\n\nR code‚Ä¶\n\n\n\n# https://coolors.co/ef476f-ffd166-06d6a0-118ab2-073b4c\ncolors &lt;- c(\n  \"#ef476f\",\n  \"#ffd166\",\n  \"#06d6a0\",\n  \"#118ab2\",\n  \"#073b4c\"\n)\n\nitems &lt;- lapply(colors, function(color) {\n  htmltools::tags$li(color_preview(color))\n})\nhtmltools::tags$ul(items)\n\n\n\n\n\n#ef476f\n#ffd166\n#06d6a0\n#118ab2\n#073b4c"
  },
  {
    "objectID": "blog/knitr-custom-class-output/index.html",
    "href": "blog/knitr-custom-class-output/index.html",
    "title": "Style knitr Code Output Appearance in HTML with Custom CSS Classes",
    "section": "",
    "text": "Create awesome-looking, content-dependent output styles in HTML with knitr‚Äôs new class.* chunk options.\n\n\nLast week, I learned that you can apply a custom CSS class to code chunk outputs using knitr‚Äôs class.output, thanks to a two-year-old pull request from Ian Lyttle.\nAt the time, I was working on customizing CSS classes of the code chunks in my blog after being inspired by the impeccable styling of Brodie Gaslam‚Äôs blog. What I like most are the subtle visual clues that link code inputs and outputs by keeping both source and output inside the same box. I have a plan to do something similar on this blog using custom source and output classes via the class.output and class.source chunk options.\nBut I quickly discovered that the class.output class is only applied to standard code output, and not the ‚Äúside effect‚Äù chunk outputs, such as messages, warnings and errors.\nI opened an issue in knitr and, amazingly, three days later my wishes were granted: You can now use the chunk options class.message, class.warning, and class.error to customize the CSS class of outputs of each type.\nThe new feature will be available in version 1.22 when it makes it to CRAN, or now from GitHub.\nUsing this feature, you can get nicely formatted chunk outputs. Here‚Äôs a minimal example generated from this rmarkdown source.\n\n\n\n\n\n\n\nCreate awesome-looking, content-dependent output styles in HTML with knitr‚Äôs new class.* chunk options."
  },
  {
    "objectID": "blog/highlight-lines-without-breaking-the-code-in-xaringan/index.html",
    "href": "blog/highlight-lines-without-breaking-the-code-in-xaringan/index.html",
    "title": "Highlight lines without breaking the code in Xaringan",
    "section": "",
    "text": "Update 2: This feature has been added to the latest version of xaringan! See it in action: https://slides.yihui.name/xaringan/#29\nUpdate: I went ahead and submitted a PR with this new feature to xaringan: https://github.com/yihui/xaringan/pull/103\nHave you met xaringan yet? It‚Äôs yet another fantastic package from Yihui Xie that makes it easy to blend R code and text into presentations that look great on the web, in print and on screens. Check out the demo/intro slides!\nIt‚Äôs built on remark.js with few extra features, and one of my favorite features is the ability to highlight specific lines of code. In presentations, this draws attention to the most important part of the code demonstration, but doesn‚Äôt break the reproducibility.\n\n\n\nThe line highlighting example from the xaringan demo slides.\n\n\nBasically, if you wrap a line in your code with {..code..}, that line will be highlighted in the slides. This works because {x} is a valid expression in R that just returns x, so the source code in the chunk runs correctly and an output hook cleans up the line.\nI love the feature, but it feels a little clunky in practice. When you add the braces into your code, you can‚Äôt rely on RStudio‚Äôs auto-indenter to get the code alignment right. The alignment in the chunk is fine after compiling, with the second line highlighted, but it looks a little odd in the source code.\n```{r} \npaste(\"This looks\",\n     {{\"a little odd\"}},\n      \"but it's right\")\n```\nAlso, the braces only work when wrapped around expressions ‚Äì like {\"a little odd\"} ‚Äì so you have to pick out the part of the line that is a valid R expression.\n```{r} \n{{paste(}}\n  \"This won't work\"\n)\n```\n\n```{r} \n{{paste}}(\n  \"But this works\"\n)\n```\nInstead, I thought it might be easier to mark the line with a code comment on the right-hand side. Like this\n```{r}\npaste(\"This looks\",\n      \"kinda normal\",  #&lt;&lt;\n      \"and it is\")\n```\nSidenote: I picked #&lt;&lt; because it kinda looks like hashtag looking left (#&lt;_&lt;) but is easier to type.\nTo make this work, just add the following lines to your setup chunk:\nhook_source &lt;- knitr::knit_hooks$get('source')\nknitr::knit_hooks$set(source = function(x, options) {\n  x &lt;- stringr::str_replace(x, \"^[[:blank:]]?([^*].+?)[[:blank:]]*#&lt;&lt;[[:blank:]]*$\", \"*\\\\1\")\n  hook_source(x, options)\n})\nThis add a source hook that processes the source code of the code chunk on its way into the output document after it has been evaluated. Basically, any lines in the source code with the #&lt;&lt; mark at the end of the line are modified to have the remark.js style leading * highlight indicator.\n\nlines &lt;- c('paste(\"This looks\",',\n           '      \"kinda normal\", #&lt;&lt;',\n           '      \"and it is\")')\n\nlines &lt;- stringr::str_replace(lines, \"^[[:blank:]]?([^*].+?)[[:blank:]]*#&lt;&lt;[[:blank:]]*$\", \"*\\\\1\")\ncat(lines, sep = '\\n')\n\npaste(\"This looks\",\n*     \"kinda normal\",\n      \"and it is\")\n\n\nHere‚Äôs a real example of it in practice with a code chunk from a recent presentation:\n```{r example-plot}\nggplot(tips) +\n  aes(x = tip) +\n  geom_histogram(   #&lt;&lt;\n    binwidth = 0.25 #&lt;&lt;\n  )                 #&lt;&lt;\n```\n\nNotice that the code in the source chunk and the output are both lined up! Here‚Äôs a full slide with a few more examples.\n\n\n\n\nThe line highlighting example from the xaringan demo slides."
  },
  {
    "objectID": "blog/greatest-twitter-scheme/index.html",
    "href": "blog/greatest-twitter-scheme/index.html",
    "title": "The Greatest Twitter Scheme of All Time?",
    "section": "",
    "text": "I found this tweet today and I was intrigued.\nWhat exactly had this person pulled off? What was this all-caps GREATEST TWITTER SCHEME OF ALL TIME?\nI wanted to know. But I didn‚Äôt want to scroll through endless tweets. Jump ahead to the answer if you‚Äôre in a hurry yourself.\nTo figure out what exactly was going on on Twitter, I turned to my favorite Twitter-related package: rtweet. Getting all of @CostcoRiceBag‚Äôs recent tweets was suprisingly simple ‚Äî all it takes is a single call to get_timeline():\nlibrary(rtweet)\nlibrary(dplyr)\n\ncrb_tweets &lt;- get_timeline(\"costcoricebag\", n = 3200)\nFrom here, I simply filtered out replies and straight-up retweets (but not quote tweets), and then extracted the first word in the tweet text using a little regex. Upon arranging the tweets in reverse chronological order, the pattern in the first_word column is immediately apparent.\nfirst_words &lt;- crb_tweets %&gt;%\n  filter(\n    !is_retweet,\n    is.na(reply_to_status_id),\n    created_at &lt;= lubridate::ymd_hms(\"2018-08-23 18:43:27\"),\n    created_at &gt;= lubridate::ymd_h(\"2018-05-07 15\"),\n    !grepl(\"^@\", text)\n  ) %&gt;%\n  mutate(\n    first_word = sub(\"^\\\\W*([\\\\w'‚Äô]+)[\\\\S\\\\s]+\", \"\\\\1\", text, perl = TRUE)\n  ) %&gt;%\n  arrange(desc(created_at))\n\nfirst_words %&gt;%\n  select(created_at, text, first_word)\n\n# A tibble: 376 √ó 3\n   created_at          text                                              first‚Ä¶¬π\n   &lt;dttm&gt;              &lt;chr&gt;                                             &lt;chr&gt;  \n 1 2018-08-23 18:43:27 \"IS IT JUST ME, OR DID I JUST PULL OFF THE GREAT‚Ä¶ IS     \n 2 2018-08-23 18:42:49 \"This is the moment I‚Äôve been waiting for for fo‚Ä¶ This   \n 3 2018-08-23 17:53:19 \"The best state fair food is corn on the cob don‚Ä¶ The    \n 4 2018-08-23 17:46:29 \"Real talk: idk what I‚Äôm going to do when my fri‚Ä¶ Real   \n 5 2018-08-23 04:35:54 \"Life was so much easier when my school supply l‚Ä¶ Life   \n 6 2018-08-23 01:43:50 \"IS THERE A MORE ACCURATE REPRESENTATION OF ME??‚Ä¶ IS     \n 7 2018-08-23 00:36:12 \"This is the 9th time I‚Äôve heard Africa today an‚Ä¶ This   \n 8 2018-08-22 17:22:21 \"Just told an 11 year old boy what‚Äôs up bc he tr‚Ä¶ Just   \n 9 2018-08-22 13:56:58 \"Fantasy football:\"                               Fantasy\n10 2018-08-22 13:53:41 \"Caught me https://t.co/SvUL450t3D\"               Caught \n# ‚Ä¶ with 366 more rows, and abbreviated variable name ¬π‚Äãfirst_word"
  },
  {
    "objectID": "blog/greatest-twitter-scheme/index.html#final-result",
    "href": "blog/greatest-twitter-scheme/index.html#final-result",
    "title": "The Greatest Twitter Scheme of All Time?",
    "section": "Queen of the First Word Tweets",
    "text": "Queen of the First Word Tweets\nThe final result is amazing and definitely pretty much the greatest Twitter scheme ever. Hover over each word to see the text of the full tweet, or click on the word to go to the tweet.\n\n\nIS This The Real Life IS This Just Fantasy Caught In A Landslide No Escape From Reality Open Your Eyes Look Up To The Skies And See I‚Äôm Just A Poor Boy I Need No Sympathy Because I‚Äôm EASY Come Easy Go Little High Little Low Any Way The Wind blows doesn‚Äôt Really Matter To Me To Me Mama Just Killed A Man Put A Gun Against His Head Pulled My Trigger Now He‚Äôs Dead Mama Life Had Just Begun But Now I‚Äôve Gone And Thrown It All Away Mama Ooh Didn‚Äôt Mean To make You Cry If I‚Äôm Not Back AGAIN This Time Tomorrow Carry On Carry On As If Nothing Really Matters Too Late My Time Has Come sends shivers Down My Spine Body‚Äôs Aching All The Time Goodbye EVERYBODY I‚Äôve Got To GO Gotta Leave You All Behind And Face The Truth Mama Ooh Any Way The wind Blows I Don‚Äôt WANNA Die I Sometimes Wish I‚Äôd Never Been Born At All I See A Little Shiloetto Of A Man scaramouche Scaramouche Will You Do The Fandango Thunderbolt And Lightning Very Very Frightening Me Galileo Galileo Galileo Galileo Galileo Figaro Magnifico I‚Äôm JUST A Poor Boy Nobody loves Me He‚Äôs Just A Poor Boy From A Poor Family Spare Him His Life From This Monstrosity Easy Come Easy Go Will You Let Me Go BISMILLAH No We Will Not Let You Go Let Him Go Bismillah We Will Not Let You GO Let Him Go Bismillah We Will Not Let You GO Let Me Go Will Not Let You Go Let Me Go NEVER Let You Go Never Never Never Never Let Me Go Oh O Oh Oh NO No No No No No No Oh MAMA Mia Mama M Mama Mia Let Me Go Beezlebub Has A Devil Put Aside For Me For Me For Me So You Think You Can Stone Me And Spit In My Eye So You Think You Can Love Me And Leave Me To Die Oh Baby Can‚Äôt Do This To Me Baby JUST Gotta Get Out Just Gotta Get Right Outta Here oOooOoOo Oooh Yeah Ooh Yeah Nothing Really Matters Anyone Can See Nothing Really Matters Nothing Really Matters To Me Any Way The Wind Blows\n\n\nIn total, writing out the lyrics to Bohemian Rhapsody in reverse order took 376 tweets over 108 days.\nWhen did @CostcoRiceBag do most of their Queen-related tweeting? To get an idea of how often they tweeted, I created a calendar heatmap (or GitHub-style square tile plot) of their daily tweeting activities.\n\n\n\n\n\n\n\n\n\nWhat‚Äôs really impressive is that, except for a few Bismillah and Scaramouche tweets, most of the tweets are really just normal everyday tweeting. I‚Äôd love to get into a textual analysis, but it‚Äôs late so I‚Äôll leave you with this:\n\nRock on! ü§ò"
  },
  {
    "objectID": "blog/find-blogdown-tags/index.html",
    "href": "blog/find-blogdown-tags/index.html",
    "title": "Find, count and list tags in all blogdown posts",
    "section": "",
    "text": "I‚Äôve been using blogdown for a while now and have basically been randomly selecting tags as I write each post without putting too much thought into it. Tonight I was searching for a method to list all of the tags I‚Äôve used across my blogdown posts and I rolled up the following solution.\nlibrary(tidyverse)\nblogdown_content_path &lt;- here::here(\"content\")\n\n# Scan yaml of all posts (run at root of blogdown project)\nblogdown:::scan_yaml(blogdown_content_path) %&gt;%\n  # Pull out the tags\n  map(\"tags\") %&gt;%\n  # Drop results without any tags\n  discard(is.null) %&gt;%\n  # Turn into a nice tibble (can stop here if you want tags + files)\n  map_df(~ tibble::data_frame(tag = .), .id = \"file\") %&gt;%\n  # Summarize (group and count)\n  group_by(tag) %&gt;%\n  count(sort = TRUE) %&gt;%\n  # Starts with uppercase?\n  mutate(starts_upper = substr(tag, 1, 1) %in% LETTERS)\n\n## # A tibble: 50 x 3\n## # Groups:   tag [50]\n##    tag               n starts_upper\n##    &lt;chr&gt;         &lt;int&gt; &lt;lgl&gt;\n##  1 R                19 TRUE\n##  2 Data Analysis     6 TRUE\n##  3 Markdown          6 TRUE\n##  4 Research          6 TRUE\n##  5 Visualization     6 TRUE\n##  6 R Package         5 TRUE\n##  7 Scripts           5 TRUE\n##  8 pandoc            4 FALSE\n##  9 ggplot2           3 FALSE\n## 10 INFORMS           3 TRUE\n## # ... with 40 more rows\nNote that you can stop at the map_df() line and get a list of tags with the associated files in which they appear.\nAt this point, I decided I‚Äôd write this quick post to remind future me when I decide to actually standardize my tags. That‚Äôs when I realized that the ‚ÄúNew Post‚Äù addin in blogdown lists all of the previously used tags. A little digging in the addin script (inst/scripts/new_post.R) revealed the function behind the dropdown menu.\nblogdown:::collect_yaml(dir = blogdown_content_path)\n\n## $categories\n## [1] \"Blog\"    \"Music\"   \"Photos\"  \"Project\"\n##\n## $tags\n##  [1] \"Academia\"                \"Addin\"\n##  [3] \"Ambient Assisted Living\" \"Ambient Intelligence\"\n##  [5] \"Apps\"                    \"blogdown\"\n##  [7] \"Data Analysis\"           \"Differential Equations\"\n##  [9] \"Dynamic Systems\"         \"emoji\"\n## [11] \"Gadget\"                  \"Gerontechnology\"\n## [13] \"ggplot2\"                 \"git\"\n## [15] \"Google Trends\"           \"Gun Control\"\n## [17] \"Healthcare\"              \"IIE\"\n## [19] \"INFORMS\"                 \"Interesting Articles\"\n## [21] \"ISERC\"                   \"LaTeX\"\n## [23] \"Markdown\"                \"Math\"\n## [25] \"MySQL\"                   \"Note to Self\"\n## [27] \"pandoc\"                  \"Personal Data\"\n## [29] \"Predictive Analytics\"    \"Presentation\"\n## [31] \"Productivity\"            \"Quotes\"\n## [33] \"R\"                       \"R Markdown\"\n## [35] \"R Package\"               \"Research\"\n## [37] \"RStudio\"                 \"Scripts\"\n## [39] \"Shiny\"                   \"Smart Home\"\n## [41] \"SQL\"                     \"Status\"\n## [43] \"Test Theory\"             \"Tips\"\n## [45] \"Tricks\"                  \"Tutorials\"\n## [47] \"Visualization\"           \"Workflow\"\n## [49] \"Writing\"                 \"xaringan\"\nFinally, when you want to open the files containing a particular tag, you can use blogdown‚Äôs find_tags() function with the option open = TRUE.\nblogdown::find_tags(\"Note to Self\", open = TRUE)"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "",
    "text": "In this post I demonstrate how the ref.label knitr chunk option can be used to decouple code chunks and their outputs in xaringan presentations. I give two examples where this could be useful, namely by showing ggplot2 code and plots side-by-side on the same slide or by placing the plot output picture-in-picture style in the bottom corner of the slide.\nYou can see this technique in action in my presentation on ggplot2. Or you can download the R Markdown source for a minimal xaringan slide deck that demonstrates the whole process.\nUpdate: Yihui Xie (the author of knitr and xaringan) pointed out on Twitter that another valid (and maybe better) option is to use knitr::fig_chunk(), and I‚Äôve added a demonstration of that approach to this post. Honestly, if I had known about this function before, it would have been the centerpiece of this blog post!"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#summary",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#summary",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "",
    "text": "In this post I demonstrate how the ref.label knitr chunk option can be used to decouple code chunks and their outputs in xaringan presentations. I give two examples where this could be useful, namely by showing ggplot2 code and plots side-by-side on the same slide or by placing the plot output picture-in-picture style in the bottom corner of the slide.\nYou can see this technique in action in my presentation on ggplot2. Or you can download the R Markdown source for a minimal xaringan slide deck that demonstrates the whole process.\nUpdate: Yihui Xie (the author of knitr and xaringan) pointed out on Twitter that another valid (and maybe better) option is to use knitr::fig_chunk(), and I‚Äôve added a demonstration of that approach to this post. Honestly, if I had known about this function before, it would have been the centerpiece of this blog post!"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#background",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#background",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Background",
    "text": "Background\nA recent tweet by Gina Reynolds reminded me that I‚Äôve been sitting on this blog post for a while.\n{{ tweet EvaMaeRey 1029104656763572226 &gt;}}\nI learned a few xaringan tricks1 when creating my presentation on ggplot2 for the Tampa R Users Group, and hopefully this blog post makes it easier to replicate than digging through the messy source of that presentation.\nTo help teach the ggplot2 syntax, I thought it was important to see the code and the plot at the same time, side-by-side. Unfortunately, the standard appearance in R Markdown is for the code output to appear immediately following the code chunk that created it, like this.\n\nlibrary(ggplot2)\nggplot(iris) +\n  aes(Sepal.Length, Sepal.Width, color = Species) +\n  geom_point()"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#side-by-side",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#side-by-side",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Code and Figure Side-by-Side",
    "text": "Code and Figure Side-by-Side\nWhile this looks great on the web or in documents, you quickly run out of vertical space when presenting with the limited screen real estate of a wide-screen television. What I wanted were slides that look more like this:\n\n\nWarning: `data_frame()` was deprecated in tibble 1.1.0.\n‚Ñπ Please use `tibble()` instead.\n\n\nWarning: The `&lt;scale&gt;` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\n\n\n\nIn general, with xaringan, you use a two column layout by placing the left and right column content inside .pull-left[] and .pull-right[] respectively.\n.pull-left[\n```{r}\n# plot code here\n```\n]\n\n.pull-right[\nPlot output here!\n]\nBut the default action of knitr will place the plot output inside the .pull-left[] block, keeping it in the left column.\nTo solve this problem, we need to tell knitr to hold off on evaluating the code output and to place the results in a different chunk. We can accomplish this by setting eval=FALSE in the first chunk and using the ref.label code chunk option with echo = FALSE to output the result in the second:\n.pull-left[\n```{r plot-label, eval=FALSE}\n# code chunk here\nggplot(iris) +\n  aes(Sepal.Length,\n      Sepal.Width,\n      color = Species) +\n  geom_point()\n```\n]\n\n.pull-right[\n```{r plot-label-out, ref.label=\"plot-label\", echo=FALSE}\n```\n]\n\nThis works pretty well, but the plots ended up being somewhat squished, so I created two CSS classess for the left and right columns.\n/* custom.css */\n.left-code {\n  color: #777;\n  width: 38%;\n  height: 92%;\n  float: left;\n}\n.right-plot {\n  width: 60%;\n  float: right;\n  padding-left: 1%;\n}\nI then used the following options in the YAML header of xaringan\noutput:\n  xaringan::moon_reader:\n    css: [\"default\", \"custom.css\"]\n    nature:\n      ratio: 16:9\nand changed .pull-left[] ‚û° .left-code[] and .pull-right[] ‚û° .right-plot[].\n.left-code[\n```{r plot-label, eval=FALSE}\n# code chunk here\nggplot(iris) +\n  aes(Sepal.Length,\n      Sepal.Width,\n      color = Species) +\n  geom_point()\n```\n]\n\n.right-plot[\n```{r plot-label-out, ref.label=\"plot-label\", echo=FALSE, fig.dim=c(4.8, 4.5), out.width=\"100%\"}\n```\n]\n\nFor best results, notice that I set the figure dimentions to 4.8 x 4.5 ‚Äì and aspect ratio of approximately 9 / (16 * 0.6) ‚Äì to match the .right-plot width in the CSS. I also added out.width=\"100%\" so that the image is automatically scaled to fill the column width.\nYou can set this once in your setup chunk to apply these settings to all plots so that you don‚Äôt need to repeat yourself each time.\n```{r setup, include=FALSE}\nknitr::opts_chunk$set(fig.dim=c(4.8, 4.5), fig.retina=2, out.width=\"100%\")\n```"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#pip",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#pip",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Plot-In-Picture - Plot in Small Callout Box",
    "text": "Plot-In-Picture - Plot in Small Callout Box\nThe side-by-side layout works well when the code is small, but for a plot that requires longer blocks of code, I wanted to be able to see all of the code while still retaining the connection to the plot we were building up.\nThe inspiration for this layout is the ‚ÄúPicture in Picture‚Äù TV feature, where the changes to the plot appear in a small callout image in the slide to preview the changes at each step. Then, at the end, we can reveal the final plot in full screen.\nThe xaringan portion looks like this\n```{r large-plot, eval=FALSE}\nggplot(iris) +\n  aes(Sepal.Length,\n      Sepal.Width,\n      color = Species) +\n  geom_point(size = 4) +\n  labs(x = 'Sepal Length',\n       y = 'Sepal Width') +\n  theme_minimal() +\n  theme(\n    text = element_text(size = 24, family = \"PT Sans\")\n  )\n```\n\n.plot-callout[\n```{r large-plot-callout, ref.label=\"large-plot\", fig.callout=TRUE}\n```\n]\nThe fig.callout=TRUE is a custom knitr chunk option I created that sets some default chunk values for the callout chunks so that I don‚Äôt have to repeat these every time I use this layout.\n```{r setup, include=FALSE}\nknitr::opts_hooks$set(fig.callout = function(options) {\n  if (options$fig.callout) {\n    options$echo &lt;- FALSE\n    options$out.height &lt;- \"99%\"\n    options$fig.width &lt;- 16\n    options$fig.height &lt;- 8\n  }\n  options\n})\n```\nAnd then finally, I used the following CSS to place the callout in the bottom right corner, set the size of the plot and style the plot image inside.\n/* custom.css */\n.plot-callout {\n  height: 225px;\n  width: 450px;\n  bottom: 5%;\n  right: 5%;\n  position: absolute;\n  padding: 0px;\n  z-index: 100;\n}\n.plot-callout img {\n  width: 100%;\n  border: 4px solid #23373B;\n}\n\nThen the final plot is revealed on the next slide using fig.callout=TRUE but without wrapping the result chunk in side .plot-callout[].\n```{r large-plot-full-output, ref.label=\"large-plot\", fig.callout=TRUE}\n```"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#using-knitr-fig-chunk",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#using-knitr-fig-chunk",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Using knitr‚Äôs fig_chunk()",
    "text": "Using knitr‚Äôs fig_chunk()\nYihui Xie pointed out on Twitter that we can use the chunk option fig.show=\"hide\" for the source chunk and then call knitr::fig_chunk() directly wherever we want to embed the plot. What‚Äôs nice about this approach is fig_chunk() outputs the path to the image, so we are completely in control of how that image is embedded into our document.\nHe also wrote a helpful blog post about fig_chunk() where he describes his motivation for creating this function. (Spoiler alert: it is exactly the use case described in this blog post!) The help text for the function also helpfully describes our situation to a T:\n\nThis function can be used in an inline R expression to write out the figure filenames without hard-coding them. ‚Ä¶ You can generate plots in a code chunk but not show them inside the code chunk by using the chunk option fig.show = 'hide'. Then you can use this function if you want to show them elsewhere.\n\n\n.left-code[\n\n```{r plot-label-fc, fig.show=\"hide\"}\n# code chunk here\nggplot(iris) +\n  aes(Sepal.Length,\n      Sepal.Width,\n      color = Species) +\n  geom_point()\n```\n\n]\n\n.right-plot[\n![](`r knitr::fig_chunk(\"plot-label-fc\", \"png\")`)\n]"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#wrap-up",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#wrap-up",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Wrap Up",
    "text": "Wrap Up\nIf you want to see the whole process in action, I‚Äôve compiled a minimal xaringan presentation that you can download and use as a starting point.\nLet me know if this was helpful on Twitter at @grrrck and happy presenting!"
  },
  {
    "objectID": "blog/decouple-code-and-output-in-xaringan-slides/index.html#footnotes",
    "href": "blog/decouple-code-and-output-in-xaringan-slides/index.html#footnotes",
    "title": "Decouple Code and Output in xaringan slides",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOkay, really these are R Markdown and knitr tricks and if you want to learn more you should definitely check out R Markdown: The Definitive Guide.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/cream-with-your-coffee/index.html",
    "href": "blog/cream-with-your-coffee/index.html",
    "title": "Cream with your coffee?",
    "section": "",
    "text": "Good morning coffee by mrmatt on flickr\n\n\nYou receive an excessively hot cup of coffee at your local coffee shop. As it‚Äôs the first cup of the day, your main objective is to consume the caffeine as quickly as possible. Unfortunately, if you were to gulp down the coffee the barista just handed you now, you would most certainly end up taking a trip to the hospital for second-degree burns.\nFortunately you have at your disposal a caraffe of properly chilled cream and a dreamy appreciation for dynamic systems. The question is: to reach your ideal coffee-consumption temperature as quickly as possible, should you mix the cream immediately into the coffee or should you wait a certain amount of time?\nAssuming you have (groggily) estimated the following variables:\n\n\n\nVariable\nMeaning\n\n\n\n\n\\(T_{Cof}\\)\nTemperature of the coffee\n\n\n\\(T_{D}\\)\nDesired temperature for the coffee\n\n\n\\(T_{R}\\)\nTemperature of the room\n\n\n\\(T_{Cr}\\)\nTemperature of the cream\n\n\n\\(k\\)\nCooling rate coefficient\n\n\n\\(r\\)\nPercentage of coffee in final mixture\n\n\n\nYou can use Newton‚Äôs law of cooling to get started:\n\\[\\dot{T}(t) = -k (T(t) - T_R)\\]\nThis tells you that the change in surface temperature of an object is proportional to difference between the object‚Äôs temperature and the surrounding environment.\nFrom this you know that the temperature of the coffee at time \\(t\\) is given by the following solution to the above differential equation:\n\\[T(t) = T_R + \\left(T_0 - T_R \\right)e^{-kt}\\]\nWhere \\(T_0\\) represents the initial temperature of an object and \\(T_R\\) the temperature of the surrounding environment.\nTwo strategies come to mind: immediately add the cream to the coffee, or wait until adding the cream will reduce the temperature just enough to achieve the desired temperature. But which will bring you your caffeine fix fastest? \nWe‚Äôll make the simplifying assumption that the mixing process is instantaneous and that the temperature of the final mixture is a weighted average of the temperatures of the two liquids, relative to their volume. We‚Äôll further simplify this step by expressing our result in terms of the percentage of coffee in the final mixture, \\(r\\).\n\n\nI made an interactive plot where you can dynamically alter (play with) the problem parameters using RStudio‚Äôs Shiny App. If you have R 3.x and Shiny installed, you can run the app by simply calling runGist(9370271) after loading Shiny. The app is available as a Github gist here.\n\n\n\nIf the cream is added immediately, then the effective initial temperature of the coffee is \\(rT_{Cof}+(1-r)T_{Cr}\\) and this mixture will reach the desired temperature in time \\(\\tau_1\\) units:\n\\[T_D = T_R + \\left(rT_{Cof}+(1-r)T_{Cr} - T_R \\right)e^{-k\\tau_1}\\]\n\n\n\n\nIf instead the cream is added at just the right time so that, when the coffee is combined with the cream, the resultant mixture will have the desired temperature, then the time at which the cream should be added (and also the time at which \\(T_D\\) is achieved) is \\(\\tau_2\\), given as follows:\n\\[T_D = \\left[ T_R + \\left( T_{Cof} - T_R \\right) e^{-k\\tau_2} \\right] r + (1-r)T_{Cr}\\]\n\n\n\n\nThe right hand side of the above equations are equivalent, so the question becomes which is smaller, \\(\\tau_1\\) or \\(\\tau_2\\)? Solving for the waiting time of each yields the following equations:\n\\[\\begin{aligned}\n\\tau_1 &= - \\frac 1 k \\ln \\left[ \\frac{T_D - T_R}{rT_{Cof} +(1-r)T_{Cr} - T_R} \\right] \\\\\\\n& \\\\\\\n\\tau_2 &= -\\frac 1 k \\ln \\left[ \\frac{T_D - (1-r)T_{Cr} - rT_R}{rT_{Cof} - rT_R} \\right]\\\\\\\n\\end{aligned}\\]\nBecause the question is which waiting time is shorter and \\(\\ln(x) \\to - \\infty\\) as \\(x \\to 0\\), the question then becomes which fraction inside the \\(\\ln\\) functions is smaller. In this, we will assume that, given the physical characteristics of the problem, \\(T_{Cr} &lt; T_R &lt; T_D &lt; T_{Cof}\\), and that \\(0 \\leq r \\leq 1\\).\nTo give away the punchline a little, what we‚Äôll find is that by using the simple assumptions above we can show that the numerator in the \\(\\tau_1\\) expression is smaller than the numerator in the \\(\\tau_2\\) expression, and that the denominator in \\(\\tau_1\\) is bigger than the denominator in \\(\\tau_2\\). If this is true, then clearly \\(\\tau_1 &gt; \\tau_2\\) as \\(- \\ln \\left( \\frac{-}{+} \\right) &lt; - \\ln \\left( \\frac{+}{-} \\right)\\).\nLet‚Äôs first consider the numerators. \\(T_D\\) is the same in both, so we need to compare the amount subtracted from it: \\(T_R\\) vs \\((1-r)T_{Cr} + rT_rR\\).\nNotice that because \\(T_{Cr} &lt; T_R\\) \\[T_R = (1-r)T_R + rT_R &gt; (1-r)T_{Cr} + rT_R\\] and thus \\(T_D - T_R &lt; T_D - (1-r)T_{Cr} - rT_R\\), indicating that the numerator in the expression for \\(\\tau_1\\) is less than that of the expression for \\(\\tau_2\\).\nSecond, consider the denominators, specifically the amount subtracted from \\(rT_{Cof}\\) in both: \\(T_R - (1-r)T_{Cr}\\) vs \\(rT_R\\).\nHere notice that \\(rT_R = T_R - (1-r)T_R\\). Then, from \\(T_{Cr} &lt; T_R\\) we can conclude that \\((1-r)T_{Cr} &lt; (1-r)T_R\\), which further implies that \\(T_R - (1-r)T_{Cr} &gt; T_R - (1-r) T_R = rT_R\\). Thus the denominator in the expression for \\(\\tau_1\\) is greater than the denominator in the expression of \\(\\tau_2\\).\n\\[\\begin{aligned}\nT_D - T_R &&lt; T_D - (1-r)T_{Cr} - rT_R \\\\\\\n& \\\\\\\nrT_{Cof} +(1-r)T_{Cr} - T_R &&gt; rT_{Cof} - rT_R \\\\\\\n\\end{aligned}\\]\nFrom this we can finally conclude that the fraction in the expression for \\(\\tau_1\\) has a smaller numerator and larger denominator than that of \\(\\tau_2\\). The interpretation of this result is that waiting until \\(\\tau_2\\) to allows the coffee to reach the desired temperature faster than adding the cream immediately. The reduction in waiting time is a function of initial conditions and depends on the temperature differential, in particular between the cream and the room and coffee.\nSo, if you need faster caffeine intake: wait a bit before adding your cold cream (or almond milk). On the flip side, if you want to keep your coffee hotter for longer, add your cream right away. Or get a real coffee habit and skip the cream entirely1.\n\n\n\nGood morning coffee by mrmatt on flickr"
  },
  {
    "objectID": "blog/cream-with-your-coffee/index.html#imagine-this-scenario",
    "href": "blog/cream-with-your-coffee/index.html#imagine-this-scenario",
    "title": "Cream with your coffee?",
    "section": "",
    "text": "Good morning coffee by mrmatt on flickr\n\n\nYou receive an excessively hot cup of coffee at your local coffee shop. As it‚Äôs the first cup of the day, your main objective is to consume the caffeine as quickly as possible. Unfortunately, if you were to gulp down the coffee the barista just handed you now, you would most certainly end up taking a trip to the hospital for second-degree burns.\nFortunately you have at your disposal a caraffe of properly chilled cream and a dreamy appreciation for dynamic systems. The question is: to reach your ideal coffee-consumption temperature as quickly as possible, should you mix the cream immediately into the coffee or should you wait a certain amount of time?\nAssuming you have (groggily) estimated the following variables:\n\n\n\nVariable\nMeaning\n\n\n\n\n\\(T_{Cof}\\)\nTemperature of the coffee\n\n\n\\(T_{D}\\)\nDesired temperature for the coffee\n\n\n\\(T_{R}\\)\nTemperature of the room\n\n\n\\(T_{Cr}\\)\nTemperature of the cream\n\n\n\\(k\\)\nCooling rate coefficient\n\n\n\\(r\\)\nPercentage of coffee in final mixture\n\n\n\nYou can use Newton‚Äôs law of cooling to get started:\n\\[\\dot{T}(t) = -k (T(t) - T_R)\\]\nThis tells you that the change in surface temperature of an object is proportional to difference between the object‚Äôs temperature and the surrounding environment.\nFrom this you know that the temperature of the coffee at time \\(t\\) is given by the following solution to the above differential equation:\n\\[T(t) = T_R + \\left(T_0 - T_R \\right)e^{-kt}\\]\nWhere \\(T_0\\) represents the initial temperature of an object and \\(T_R\\) the temperature of the surrounding environment.\nTwo strategies come to mind: immediately add the cream to the coffee, or wait until adding the cream will reduce the temperature just enough to achieve the desired temperature. But which will bring you your caffeine fix fastest? \nWe‚Äôll make the simplifying assumption that the mixing process is instantaneous and that the temperature of the final mixture is a weighted average of the temperatures of the two liquids, relative to their volume. We‚Äôll further simplify this step by expressing our result in terms of the percentage of coffee in the final mixture, \\(r\\).\n\n\nI made an interactive plot where you can dynamically alter (play with) the problem parameters using RStudio‚Äôs Shiny App. If you have R 3.x and Shiny installed, you can run the app by simply calling runGist(9370271) after loading Shiny. The app is available as a Github gist here.\n\n\n\nIf the cream is added immediately, then the effective initial temperature of the coffee is \\(rT_{Cof}+(1-r)T_{Cr}\\) and this mixture will reach the desired temperature in time \\(\\tau_1\\) units:\n\\[T_D = T_R + \\left(rT_{Cof}+(1-r)T_{Cr} - T_R \\right)e^{-k\\tau_1}\\]\n\n\n\n\nIf instead the cream is added at just the right time so that, when the coffee is combined with the cream, the resultant mixture will have the desired temperature, then the time at which the cream should be added (and also the time at which \\(T_D\\) is achieved) is \\(\\tau_2\\), given as follows:\n\\[T_D = \\left[ T_R + \\left( T_{Cof} - T_R \\right) e^{-k\\tau_2} \\right] r + (1-r)T_{Cr}\\]\n\n\n\n\nThe right hand side of the above equations are equivalent, so the question becomes which is smaller, \\(\\tau_1\\) or \\(\\tau_2\\)? Solving for the waiting time of each yields the following equations:\n\\[\\begin{aligned}\n\\tau_1 &= - \\frac 1 k \\ln \\left[ \\frac{T_D - T_R}{rT_{Cof} +(1-r)T_{Cr} - T_R} \\right] \\\\\\\n& \\\\\\\n\\tau_2 &= -\\frac 1 k \\ln \\left[ \\frac{T_D - (1-r)T_{Cr} - rT_R}{rT_{Cof} - rT_R} \\right]\\\\\\\n\\end{aligned}\\]\nBecause the question is which waiting time is shorter and \\(\\ln(x) \\to - \\infty\\) as \\(x \\to 0\\), the question then becomes which fraction inside the \\(\\ln\\) functions is smaller. In this, we will assume that, given the physical characteristics of the problem, \\(T_{Cr} &lt; T_R &lt; T_D &lt; T_{Cof}\\), and that \\(0 \\leq r \\leq 1\\).\nTo give away the punchline a little, what we‚Äôll find is that by using the simple assumptions above we can show that the numerator in the \\(\\tau_1\\) expression is smaller than the numerator in the \\(\\tau_2\\) expression, and that the denominator in \\(\\tau_1\\) is bigger than the denominator in \\(\\tau_2\\). If this is true, then clearly \\(\\tau_1 &gt; \\tau_2\\) as \\(- \\ln \\left( \\frac{-}{+} \\right) &lt; - \\ln \\left( \\frac{+}{-} \\right)\\).\nLet‚Äôs first consider the numerators. \\(T_D\\) is the same in both, so we need to compare the amount subtracted from it: \\(T_R\\) vs \\((1-r)T_{Cr} + rT_rR\\).\nNotice that because \\(T_{Cr} &lt; T_R\\) \\[T_R = (1-r)T_R + rT_R &gt; (1-r)T_{Cr} + rT_R\\] and thus \\(T_D - T_R &lt; T_D - (1-r)T_{Cr} - rT_R\\), indicating that the numerator in the expression for \\(\\tau_1\\) is less than that of the expression for \\(\\tau_2\\).\nSecond, consider the denominators, specifically the amount subtracted from \\(rT_{Cof}\\) in both: \\(T_R - (1-r)T_{Cr}\\) vs \\(rT_R\\).\nHere notice that \\(rT_R = T_R - (1-r)T_R\\). Then, from \\(T_{Cr} &lt; T_R\\) we can conclude that \\((1-r)T_{Cr} &lt; (1-r)T_R\\), which further implies that \\(T_R - (1-r)T_{Cr} &gt; T_R - (1-r) T_R = rT_R\\). Thus the denominator in the expression for \\(\\tau_1\\) is greater than the denominator in the expression of \\(\\tau_2\\).\n\\[\\begin{aligned}\nT_D - T_R &&lt; T_D - (1-r)T_{Cr} - rT_R \\\\\\\n& \\\\\\\nrT_{Cof} +(1-r)T_{Cr} - T_R &&gt; rT_{Cof} - rT_R \\\\\\\n\\end{aligned}\\]\nFrom this we can finally conclude that the fraction in the expression for \\(\\tau_1\\) has a smaller numerator and larger denominator than that of \\(\\tau_2\\). The interpretation of this result is that waiting until \\(\\tau_2\\) to allows the coffee to reach the desired temperature faster than adding the cream immediately. The reduction in waiting time is a function of initial conditions and depends on the temperature differential, in particular between the cream and the room and coffee.\nSo, if you need faster caffeine intake: wait a bit before adding your cold cream (or almond milk). On the flip side, if you want to keep your coffee hotter for longer, add your cream right away. Or get a real coffee habit and skip the cream entirely1.\n\n\n\nGood morning coffee by mrmatt on flickr"
  },
  {
    "objectID": "blog/cream-with-your-coffee/index.html#footnotes",
    "href": "blog/cream-with-your-coffee/index.html#footnotes",
    "title": "Cream with your coffee?",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI can‚Äôt believe I made it through this whole explanation without mentioning almond milk. I‚Äôm lactose intolerant. Almond milk is great. But coffee is best black. Not black as in ‚Äúno cream‚Äù. Black as in ‚Äúdark matter‚Äù or ‚Äúblack hole‚Äù.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/convert-r-markdown-rmd-files-to-r-scripts/index.html",
    "href": "blog/convert-r-markdown-rmd-files-to-r-scripts/index.html",
    "title": "Convert R Markdown (Rmd) Files to R Scripts",
    "section": "",
    "text": "tl; super dr: I‚Äôm really not sure how knitr::purl() escaped my attention ‚Äì maybe I thought it didn‚Äôt do something I felt was necessary at the time ‚Äì but if you‚Äôve stumbled on this page looking for a way to convert an R Markdown file into an R script, then the function you are looking for is called knitr::purl().\nTry knitr::purl(input, output, documentation = 2). It‚Äôs exactly what you‚Äôre looking for.\n\n\n\ntl;dr: A function called backstitch that backstitches knitr::knitable R Markdown files to knitr::spinable R Scripts.\n\nThere are two great ways of writing R Markdown reports. The most well known way is to use ‚Äúliterate programming‚Äù, where the writing and the code are intermingled an .Rmd file. This is the style of file you get when you create a new ‚ÄúR Markdown‚Äù file inside RStudio.\nThere‚Äôs another way of mixing code and writing inside a script, and it‚Äôs essentially the inverse of an .Rmd file.\nIn an R Markdown file, text is considered to be writing unless you wrap it in decoration, by adding backticks around inline code or by putting code in a ‚Äúcode chunk‚Äù:\n```{r chunk-name}\ntable(mtcars$cyl, mtcars$gear)\n```\nTo get your final report, you call knitr‚Äôs knit function, which runs the code chunks, knits the results into the text, and writes an output file (PDF, HTML, Word, etc.).\nIn the inverse universe, you write your code and text in regular R scripts, mark specific lines as regular text by starting the lines with #', and you spin your code and text together instead of knitting.\nThis format is great for computationally-heavy scripts. The other advantage is that you can call the script directly to run all the code directly, ignoring the text aspect. I also use it a lot when I want to quickly write up a report on a set of scripts that I‚Äôve been working with.\nDean Attali has a great write up from a couple years ago about spin that I highly recommend. And there‚Äôs a quick intro to spin in the knitr documentation, too.\nI usually try to keep computation and reporting scripts separate. But writing up the results of your code while putting it together is an incredible paradigm for data analysis‚Ä¶and sometimes I keep digging and digging while writing and exploring. And then I end up with a very ‚Äúheavy‚Äù R Markdown (or notebook), where a lot of the data processing code really should be run separately from the reporting and visualization code.\nBut how do you convert an R Markdown file to a regular R script (or one that you could spin if you wanted to)?\nI couldn‚Äôt find the answer online, so I wrote a function called backstitch that does the conversion. It only goes one way, for now: from .Rmd to .R. But it lets you convert the whole R Markdown document to an R script, or just pull out the code chunks into a script (or both!).\nBecause it‚Äôs just a function, I made it available as a gist, which you can source directly with devtools.\n\ndevtools::source_gist('284671997992aefe295bed34bb53fde6', filename = 'backstitch.R')\n\nGive it an input file or connection (infile), an output file name (outfile, leave as NULL to return as text vector), choose output_type from script, code, both and it does the rest of the work. (There‚Äôs also an extra option called chunk_header, for you to set the initial characters for chunk sections.)\nFor example, using Yihui‚Äôs knitr-spin.Rmd example, but in reverse, we start with this file:\n\nThis is a special R script which can be used to generate a report. You can\nwrite normal text in roxygen comments.\n\nFirst we set up some options (you do not have to do this):\n\n\n```{r setup, include=FALSE}\nlibrary(knitr)\nopts_chunk$set(fig.path = 'figure/silk-')\n```\n\n\nThe report begins here.\n\n\n```{r test-a, cache=FALSE}\n# boring examples as usual\nset.seed(123)\nx = rnorm(5)\nmean(x)\n```\n\n\nYou can use the special syntax {{code}} to embed inline expressions, e.g.\n`r mean(x) + 2`\nis the mean of x plus 2.\nThe code itself may contain braces, but these are not checked.  Thus,\nperfectly valid (though very strange) R code such as `{2 + 3} - {{4 - 5}}`\ncan lead to errors because `2 + 3}} - {{4 - 5` will be treated as inline code.\n\nNow we continue writing the report. We can draw plots as well.\n\n\n```{r test-b, fig.width=5, fig.height=5}\npar(mar = c(4, 4, .1, .1)); plot(x)\n```\n\n\nActually you do not have to write chunk options, in which case knitr will use\ndefault options. For example, the code below has no options attached:\n\n\n```{r }\nvar(x)\nquantile(x)\n```\n\n\nAnd you can also write two chunks successively like this:\n\n\n```{r test-chisq5}\nsum(x^2) # chi-square distribution with df 5\n```\n\n```{r test-chisq4}\nsum((x - mean(x))^2) # df is 4 now\n```\n\n\nDone. Call spin('knitr-spin.R') to make silk from sow's ear now and knit a\nlovely purse.\n\nand backstitch it into this file:\n\ninfile &lt;- url('https://raw.githubusercontent.com/yihui/knitr/master/inst/examples/knitr-spin.Rmd')\noutput &lt;- backstitch(infile, output_type = 'script', chunk_header = \"#+\")\ncat(\"```r\", output, \"```\", sep = \"\\n\")\n#' This is a special R script which can be used to generate a report. You can\n#' write normal text in roxygen comments.\n#' \n#' First we set up some options (you do not have to do this):\n\n#+ setup, include=FALSE\nlibrary(knitr)\nopts_chunk$set(fig.path = 'figure/silk-')\n\n\n#' The report begins here.\n\n#+ test-a, cache=FALSE\n# boring examples as usual\nset.seed(123)\nx = rnorm(5)\nmean(x)\n\n\n#' You can use the special syntax {{code}} to embed inline expressions, e.g.\n#' {{mean(x) + 2}}\n#' is the mean of x plus 2.\n#' The code itself may contain braces, but these are not checked.  Thus,\n#' perfectly valid (though very strange) R code such as `{2 + 3} - {{4 - 5}}`\n#' can lead to errors because `2 + 3}} - {{4 - 5` will be treated as inline code.\n#' \n#' Now we continue writing the report. We can draw plots as well.\n\n#+ test-b, fig.width=5, fig.height=5\npar(mar = c(4, 4, .1, .1)); plot(x)\n\n\n#' Actually you do not have to write chunk options, in which case knitr will use\n#' default options. For example, the code below has no options attached:\n\n#+ \nvar(x)\nquantile(x)\n\n\n#' And you can also write two chunks successively like this:\n\n#+ test-chisq5\nsum(x^2) # chi-square distribution with df 5\n\n#+ test-chisq4\nsum((x - mean(x))^2) # df is 4 now\n\n\n#' Done. Call spin('knitr-spin.R') to make silk from sow's ear now and knit a\n#' lovely purse."
  },
  {
    "objectID": "blog/branchmover/index.html",
    "href": "blog/branchmover/index.html",
    "title": "branchMover: A Shiny app for moving the default branch of your GitHub repos",
    "section": "",
    "text": "Branch Mover"
  },
  {
    "objectID": "blog/branchmover/index.html#moving-to-main-street",
    "href": "blog/branchmover/index.html#moving-to-main-street",
    "title": "branchMover: A Shiny app for moving the default branch of your GitHub repos",
    "section": "Moving to main street",
    "text": "Moving to main street\nOver the past year, there‚Äôs been a concerted effort among people who create and manage git repositories to move away from the default branch name of master to something more intentional: typically main.\nRStudio and the tidyverse team recently undertook the giant challenge of changing the default branch of RStudio‚Äôs approximately 350 public repositories (most of which are all open source!). Jenny Bryan wrote about the branch-changing experience on the tidyverse blog.\nWatching Jennys‚Äôs superb stewardship of the change inspired a new app branchMover. Or is it named Branch Mover? Admittedly, I didn‚Äôt spend much time thinking about the name because the app won‚Äôt be in your life for very long.\nThe goal of branchMover is to help you coordinate a default branch change across the repos you maintain. The app shows you all of the repos associated with your GitHub account and their current default branch. Because you might want to start with your less popular repos, you can sort by number of forks and stars on each repo.\nThere‚Äôs also a button to change the default branch. When you click the button, the app clones your repo and uses the usethis package and the recently added usethis::git_default_branch_rename() function to update the default branch of your repo.\nI followed Jenny‚Äôs lead and the app will create an issue announcing the change. If all goes well, the issue is closed a few seconds later with instructions for your users on how to update any local copies of your repo. If it doesn‚Äôt go well, the issue stay open as a reminder to you to finish the process.\nUnfortunately, branchMover doesn‚Äôt update the default branch in your local copies of your repos. Thankfully, this is relatively pain-free with the usethis::git_default_branch_rediscover() function, added in usethis version 2.1.2.\nThe next time you find yourself in your local copy of your repo, run git_default_branch_rediscover() to reconfigure your branch situation.\ngit_default_branch_rediscover()\n#&gt; ‚Ñπ Default branch of the source repo 'jennybc/happy-git-with-r': 'main'\n#&gt; ‚úì Default branch of local repo has moved: 'master' --&gt; 'main'"
  },
  {
    "objectID": "blog/branchmover/index.html#installation",
    "href": "blog/branchmover/index.html#installation",
    "title": "branchMover: A Shiny app for moving the default branch of your GitHub repos",
    "section": "Installation",
    "text": "Installation\nYou can install branchMover from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/branchMover\")\nThe app uses the usethis and gh packages. You need to configure gh with a Personal Access Token to be able to authenticate with the GitHub API. Read more about setting up a PAT in one of these places:\n\nManaging Git(Hub) Credentials usethis article\nPersonal access token for HTTPS guidance from Happy Git and GitHub for the useR\nManaging Personal Access Tokens gh article\n\nThen, in RStudio, run the app with:\nbranchMover::app()\nIf you‚Äôd like to explore or reconfigure the default branch of repositories that you manage in other organizations, provide app() with the user or organization name. Branch Mover will tell you how many repos you have access to in the organization and it won‚Äôt let you update branch names for repos where you don‚Äôt have admin permissions.\nbranchMover::app(\"rstudio-education\")\n#&gt; ‚Ñπ @rstudio-education has 57 total repositories (including forks)\n#&gt; ‚Ä¢ 57 public repos\n#&gt; ‚Ä¢ 0 private repos\n#&gt; ‚Ñπ 57 non-fork repositories have the following default branches:\n#&gt; x master: 51 repos\n#&gt; ‚úì main: 6 repos\n#&gt; ‚Ñπ You have admin rights on 1 repo"
  },
  {
    "objectID": "blog/branchmover/index.html#why-change-branches",
    "href": "blog/branchmover/index.html#why-change-branches",
    "title": "branchMover: A Shiny app for moving the default branch of your GitHub repos",
    "section": "Why change branches?",
    "text": "Why change branches?\nIf you want to learn more about how git‚Äôs default branch works and why many are opting to choose a more intentional default, I highly recommend Jenny‚Äôs detailed article Renaming the default branch, which I‚Äôll quote directly:\n\nTechnically, Git has no official concept of the default branch. But in practice, most Git repos have an effective default branch. If there‚Äôs only one branch, this is it! It is the branch that most bug fixes and features get merged in to. It is the branch you see when you first visit a repo on a site such as GitHub. On a Git remote, it is the branch that HEAD points to. The default branch may not be precisely defined in Git itself, but most of us know it when we see it.\nHistorically, master has been the most common name for the default branch, but main is an increasingly popular choice. There is coordinated change across the Git ecosystem that is making it easier for users to make this switch, for example:\n\nRegarding Git and Branch Naming, statement from the Git project and the Software Freedom Conservancy regarding the new init.defaultBranch configuration option\nRenaming the default branch frommaster, GitHub‚Äôs roadmap for supporting the shift away from master\nThe new Git default branch name, same, but for GitLab\n\nJenny Bryan, Renaming the default branch\n\n\nBranch Mover was built by Garrick Aden-Buie. Come say hi to me on Twitter at @grrrck."
  },
  {
    "objectID": "blog/better-progressive-xaringan/index.html",
    "href": "blog/better-progressive-xaringan/index.html",
    "title": "Better Progressive xaringan Slides with CSS and :last-of-type",
    "section": "",
    "text": "Here‚Äôs a quick tip for making your xaringan slides shine with a little CSS. Specifically, I‚Äôm going to show you how to use the :last-of-type pseudo-class to highlight the current bullet in progressive slides. We can also use the :last-of-type selector to show only the output of the last R chunk in a slide full of many R chunks. In each case, these techniques work best for progressive slides, or slides with content that builds up slowly.\nIn this post, I‚Äôll demonstrate how :last-of-type can be used to highlight the last list item, bold the last list item, or reveal only the last R code chunk output."
  },
  {
    "objectID": "blog/better-progressive-xaringan/index.html#progressive-list-slides",
    "href": "blog/better-progressive-xaringan/index.html#progressive-list-slides",
    "title": "Better Progressive xaringan Slides with CSS and :last-of-type",
    "section": "Progressive List Slides",
    "text": "Progressive List Slides\nTo create progressive slides in xaringan, use two dashes --, all alone on their own line, to indicate a pause in the current slide.\n---\nclass: highlight-last-item\n\n# Best Brownies, Ingredients\n\n- 1 cup milk chocolate chips\n\n--\n\n- 2 large eggs\n\n--\n\n- 2 teaspoons vanilla extract\nxaringan actually creates new slides for each pause, where each slide shows the content up to the pause. So the markdown below creates three slides, the first having one bullet point, the second having two bullet points, and the third having the full list.\nWhen rendered, three slides are created and the final slide contains the following HTML.\n&lt;div class=\"remark-slide-content highlight-last-item\"&gt;\n  &lt;h1 id=\"best-brownies-ingredients\"&gt;Best Brownies, Ingredients&lt;/h1&gt;\n  &lt;ul&gt;\n    &lt;li&gt;&lt;p&gt;1 cup milk chocolate chips&lt;/p&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;p&gt;2 large eggs&lt;/p&gt;&lt;/li&gt;\n    &lt;li&gt;&lt;p&gt;2 teaspoons vanilla extract&lt;/p&gt;&lt;/li&gt;\n  &lt;/ul&gt;\n  &lt;div class=\"remark-slide-number\"&gt;3 / 3&lt;/div&gt;\n&lt;/div&gt;\nThe first and second partial slides look exactly the same, except that the &lt;ul&gt; unordered list element contains only the first one or first two &lt;li&gt; list items.\nIf you‚Äôre building up a slide full of bullet points, you‚Äôre probably talking about the last element in the list as you reveal each new list item. We can create a neat effect where the last list item ‚Äî hence the :last-of-type pseudo-class ‚Äî is highlighted by softening the previous list items or by changing the styling of the last item.\nIn HTML, lists are unordered &lt;ul&gt; or ordered &lt;ol&gt; lists containing list elements created with the &lt;li&gt; tag. Here‚Äôs a small example, similar to the structure of the HTML and CSS we‚Äôll use for xaringan.\n\n\nHTML\n&lt;ul class=\"demo\"&gt;\n¬†¬†&lt;li&gt;item one&lt;/li&gt;\n¬†¬†&lt;li&gt;item two&lt;/li&gt;\n¬†¬†&lt;li&gt;item three&lt;/li&gt;\n&lt;ul&gt;\n\n\nCSS\n.demo &gt; li {\n¬†¬†color: gray;\n}\n.demo &gt; li:last-of-type {\n¬†¬†color: purple;\n¬†¬†font-weight: bold;\n}\n\n\nResult\n\nitem one\nitem two\nitem three\n\n\n\n\n\n\nThe .demo &gt; li rule styles the list items under the &lt;ul&gt; tag with the .demo class, setting the text color to a muted gray. The .demo &gt; li:last-of-type rule styles the last &lt;li&gt; that‚Äôs one level below (that‚Äôs what the &gt; means) the .demo element."
  },
  {
    "objectID": "blog/better-progressive-xaringan/index.html#highlight-last-list-item",
    "href": "blog/better-progressive-xaringan/index.html#highlight-last-list-item",
    "title": "Better Progressive xaringan Slides with CSS and :last-of-type",
    "section": "Highlight Last List Item",
    "text": "Highlight Last List Item\nUse the following CSS chunk ‚Äî you can just copy and paste the chunk below into your slides‚Äô Rmd file ‚Äî to highlight the last list item by reducing the opacity of the other list items.\n```{css echo=FALSE}\n.highlight-last-item &gt; ul &gt; li,\n.highlight-last-item &gt; ol &gt; li {\n  opacity: 0.5;\n}\n.highlight-last-item &gt; ul &gt; li:last-of-type,\n.highlight-last-item &gt; ol &gt; li:last-of-type {\n  opacity: 1;\n}\n```\nThen, add the highlight-last-item class to any progressively revealed slide to focus on the current list item.\nHere‚Äôs a complete example. Click into the Slides tab to preview the style in an embedded xaringan presentation.\n\n\n\nR Markdown\n\nclass: highlight-last-item\n\n# Best Brownies, Ingredients\n\n- 1 cup milk chocolate chips\n\n--\n\n- 2 large eggs\n\n--\n\n- ... more list items...\n\n\n\nSlides\n\nClick inside the slides below and press the ‚Üê/‚Üí arrows to progressively reveal the bullet points.\n\n\n\n\n\n\nAs written above, the last list item of each list on the slide will be highlighted, which may not be what you want if you have multiple lists on the slide. You could also add the :last-of-type pseudo-class to the ul and ol elements as well to target the last item of the last list on the slide."
  },
  {
    "objectID": "blog/better-progressive-xaringan/index.html#bold-last-item",
    "href": "blog/better-progressive-xaringan/index.html#bold-last-item",
    "title": "Better Progressive xaringan Slides with CSS and :last-of-type",
    "section": "Bold Last Item",
    "text": "Bold Last Item\nYou can use this pattern to style progressive lists any way you want. Here‚Äôs another example to do something similar, this time simply making the last list items bold.\n```{css eval=FALSE}\n.bold-last-item &gt; ul &gt; li:last-of-type,\n.bold-last-item &gt; ol &gt; li:last-of-type {\n  font-weight: bold;\n}\n```\nDrop the CSS chunk above into your slides, to create slides like the example below.\n\n\n\nR Markdown\n\nclass: bold-last-item\n\n# Best Brownies, Steps\n\n1. Preheat oven to 350 degrees F. Line a metal 9x9 pan with parchment paper.\n--\n\n1. Pour melted butter into a large mixing bowl.\n    1. Whisk in sugar by hand until smooth, 30 seconds.\n--\n1. Add in eggs and vanilla extract. Whisk 1 minute.\n-\n\n1. ... More Steps ...\n\n\n\nSlides"
  },
  {
    "objectID": "blog/better-progressive-xaringan/index.html#show-only-last-code-output",
    "href": "blog/better-progressive-xaringan/index.html#show-only-last-code-output",
    "title": "Better Progressive xaringan Slides with CSS and :last-of-type",
    "section": "Show Only Last Code Output",
    "text": "Show Only Last Code Output\nAs a final example, we can also apply this trick to slides with multiple R code chunks. I sometimes want to demonstrate multiple R commands on a slide, but only the output of the last example matters.\nThis example is a little bit more complicated, but you can drop the CSS chunk below into your slides to create a show-only-last-code-result class.\n```{css eval=FALSE}\n.show-only-last-code-result pre + pre:not(:last-of-type) code[class=\"remark-code\"] {\n    display: none;\n}\n```\nHere‚Äôs a complete example demonstrating a random sample of random sampling functions in R and only showing the output from the last command.\n\n\nR Markdown\n\nclass: show-only-last-code-result\n\n# Random Sampling in R\n\n```{r}\nrunif(5)\n```\n--\n\n```{r}\nrnorm(5)\n```\n--\n\n```{r}\nrbinom(5, 1, 0.5)\n```\n--\n\n```{r}\nrcauchy(5)\n```\n\n\nSlides\n\n\n\n\n\n\n\nIf you like xaringan, you should check out my package, xaringanthemer!\nIf you really like xaringan, you might also enjoy another package I‚Äôve created: xaringanExtra. It‚Äôs also how I created the panelsets above, which work in blogdown as well!"
  },
  {
    "objectID": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html",
    "href": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html",
    "title": "Add a Generated Table of Contents Anywhere in RMarkdown",
    "section": "",
    "text": "Links: Github Gist\nGitHub user @stanstrup posted a question today on the blogdown GitHub repo about manually positioning a table of contents in blogdown:\nI don‚Äôt use the academic theme for Hugo (I use a modified version of hyde), so I‚Äôm not entirely sure if I can completely solve stanstrup‚Äôs problems, but I know I‚Äôve run into something similar recently.\nAnd while Yihui is probably right that the effort isn‚Äôt worth it when fiddling with trivial aesthetics, I use R Markdown in enough places and have run into this a few times. Knowing that someone else out there felt the same pain was enough to push me to code up a quick solution.\nThe function I‚Äôve worked up is called render_toc() and it allows you to drop in a table of contents anywhere inside an R Markdown document. This means you can use it to manually position a table of contents in:\nand many more places."
  },
  {
    "objectID": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#get-it",
    "href": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#get-it",
    "title": "Add a Generated Table of Contents Anywhere in RMarkdown",
    "section": "Get It",
    "text": "Get It\nI‚Äôve posted the function and an example document as a GitHub Gist. To use it in your document, choose one of the following:\n\nDownload render_toc.R and source(\"render_toc.R\") in your project or script\nCopy the function code into your RMarkdown document\nSource the function from GitHub using devtools:\ndevtools::source_gist(\"c83e078bf8c81b035e32c3fc0cf04ee8\",\n                      filename = 'render_toc.R')"
  },
  {
    "objectID": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#use-it",
    "href": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#use-it",
    "title": "Add a Generated Table of Contents Anywhere in RMarkdown",
    "section": "Use It",
    "text": "Use It\nI included an example file in the GitHub Gist. Essentially, you just need to source render_toc.R somewhere (such as a setup chunk) and then call it in the document where you want to render the table of contents.\nThe output will just be a markdown list, so if you want to give the table of contents it‚Äôs own header, you‚Äôll have to include that in the document.\nHere‚Äôs what a simple R Markdown document would look like.\n```{r setup, include=FALSE} \nknitr::opts_chunk$set(echo = TRUE)\ndevtools::source_gist(\"c83e078bf8c81b035e32c3fc0cf04ee8\",\n                      filename = 'render_toc.R')\n```\n\n## Table of Contents\n\n```{r toc, echo=FALSE} \nrender_toc(\"blogdown-toc-example.Rmd\")\n```\n\n# Writing\n\n## R Markdown\n\nThis is an R Markdown document...\n\n```{r cars} \n# This is not a header\nsummary(cars)\n```\n\n## Regular Code\n\n```r\n# Regular markdown code (not run)\nplot(pressure)\n```\n\n# Plots\n\n## Including Plots {#plots-are-here .class-foo}\n\nYou can also embed plots, for example:\n\n```{r pressure, echo=FALSE} \nplot(pressure)\n```\nwhich outputs as this document (click to view image)."
  },
  {
    "objectID": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#behind-the-scenes",
    "href": "blog/add-a-generated-table-of-contents-anywhere-in-rmarkdown/index.html#behind-the-scenes",
    "title": "Add a Generated Table of Contents Anywhere in RMarkdown",
    "section": "Behind the Scenes",
    "text": "Behind the Scenes\nThe function simply reads through the lines of the RMarkdown document and strips out any code blocks. The supported code fencing style is three or more ` characters in a row.\nThen I extract the headers, which must be in the hashtag-style to work. In other words headers like this\n## A Nice Header\nwork well, while headers like these won‚Äôt be processed\nA Not So Nice Header\n====================\nThe function creates the header anchor if not manually specified ‚Äì see the pandoc header identifiers help page for more information ‚Äì or uses the identifier if it is included.\nThe example above would link to #a-nice-header and the example below links to #my-shortcut\n## An Overly Wordy Header Title {#my-shortcut}\nAny headers with a higher depth than the toc_depth parameter (default is 3) are discarded. Also any initial headers prior to the first base level header with higher levels (say ### when the base level is ##) are discarded as well.\nFinally, if toc_header_name is set, the header with that name is discarded so that the TOC itself isn‚Äôt included in the TOC.\nThe end result is a simple markdown list that can be rendered anywhere!\n\ndevtools::source_gist(\"c83e078bf8c81b035e32c3fc0cf04ee8\",\n                      filename = 'render_toc.R')\n\n# `this_post` is set in the setup chunk,\n# points to the Rmd file for this post\nrender_toc(this_post)\n\n\nGet It\nUse It\nBehind the Scenes\n\n\n\nWhich, underneath, is just markdown.\n\n\n- [Get It](#get-it)\n- [Use It](#use-it)\n- [Behind the Scenes](#behind-the-scenes)\n\n\n\nLet me know on twitter @grrrck if you found this helpful or run into any issues!"
  },
  {
    "objectID": "about/index.html",
    "href": "about/index.html",
    "title": "Garrick Aden-Buie",
    "section": "",
    "text": "Fosstodon\n  \n  \n    \n     Twitter\n  \n  \n    \n     GitHub\n  \n\n  \n  \n\nüëã Hey there!\n\n\nI‚Äôm Garrick Aden-Buie. I‚Äôm a Software Engineer for Shiny at Posit (the company formerly known as RStudio). I build tools in R, R Markdown, Shiny to help you do data science with R.\nBefore Shiny, I helped build Posit Academy, an online, immersive, data science apprenticeship for professional teams."
  },
  {
    "objectID": "about/index.html#about-me",
    "href": "about/index.html#about-me",
    "title": "Garrick Aden-Buie",
    "section": "About Me",
    "text": "About Me\nPrior to working at RStudio, I was a data scientist at the Moffitt Cancer Center where I work in the Collaborative Data Services Core. Previously, I was a Ph.D.¬†candidate at the University of South Florida in Tampa, FL in the Department of Industrial and Management Sciences Engineering where I helped develop a smart home sensor technology system to enable healthy aging in-place.\nI‚Äôm a passionate R user and educator. I build web apps using Shiny, tools and packages for R, and dynamic, interactive, reproducible reports using R Markdown. Browse my list of projects for examples of my work, a selection of educational presentations, or review my full curriculum vitae (resume).\n\nLet‚Äôs do something awesome together!\nIf you‚Äôre interested in working with me, please drop me a line at garrick@adenbuie.com!\n\n\nA little bit more about me‚Ä¶\nAs an undergrad, I studied at¬†Lehigh University, in¬†Bethlehem, PA, only twenty minutes from where I grew up. There, I received a B.S in Applied Mathematics. I also spent a year living and studying in Madrid, Spain, which helped me earn a B.A. in Spanish at Lehigh.\nI am a¬†Returned Peace Corps Volunteer. I lived in small town outside of Cuenca, Ecuador where I taught Math, English and life and parenting skills.\nI also write songs and play acoustic guitar, sometimes¬†in public (though not as much as I would like to)."
  },
  {
    "objectID": "blog/animate-xaringan-slide-transitions/index.html",
    "href": "blog/animate-xaringan-slide-transitions/index.html",
    "title": "Animate Xaringan Slide Transitions",
    "section": "",
    "text": "xaringan is an excellent package for creating slideshows with remark.js using R Markdown. For an example presentation showing off all of xaringan‚Äôs ninja presentation skills, take a look at the introductory presentation.\nYou can easily add slide transitions and animations to your xaringan presentation using animate.css. It turns out that remark.js supports animations via animate.css, which means that xaringan does, too!\ntl;dr: Add animate.css to your slide‚Äôs CSS and add animated and the animation class to a slide‚Äôs class to add a transition. Check out this gist for a quick example."
  },
  {
    "objectID": "blog/animate-xaringan-slide-transitions/index.html#add-animate.css-to-your-slides-css",
    "href": "blog/animate-xaringan-slide-transitions/index.html#add-animate.css-to-your-slides-css",
    "title": "Animate Xaringan Slide Transitions",
    "section": "Add animate.css to your slide‚Äôs css",
    "text": "Add animate.css to your slide‚Äôs css\nThe first thing you need to do to add animations is to include animate.css in the css argument to moon_reader(). You can download the animate.css file into your slides directory\ndownload.file(\n  \"https://raw.githubusercontent.com/daneden/animate.css/master/animate.css\",\n  \"animate.css\"\n)\nand then list animate.css in the css YAML section.\noutput:\n  xaringan::moon_reader:\n    lib_dir: libs\n    css: [default, default-fonts, animate.css]\nOr if you‚Äôll have reliable internet during your presentation you can link directly to a CDN.\noutput:\n  xaringan::moon_reader:\n    lib_dir: libs\n    css:\n      - default\n      - default-fonts\n      - \"https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.7.0/animate.min.css\""
  },
  {
    "objectID": "blog/animate-xaringan-slide-transitions/index.html#add-animation-classes-to-your-slides-class",
    "href": "blog/animate-xaringan-slide-transitions/index.html#add-animation-classes-to-your-slides-class",
    "title": "Animate Xaringan Slide Transitions",
    "section": "Add animation classes to your slide‚Äôs class",
    "text": "Add animation classes to your slide‚Äôs class\nAnimations are specified on a per-slide basis and are applied to partial slide reveals as well. You can also use layout: true to apply animations to multiple slides, but I‚Äôm not aware of a way to set a default transition for all slides. Here‚Äôs a short gist as an example to get you started.\nTo animate a slide‚Äôs transition, add animated and the animation type of your choice to the slide‚Äôs class.\n---\nclass: center, middle, animated, slideInRight\n\n# xaringan\n\n### / É√¶.'ri≈ã.…°√¶n/\n\n---\nclass: inverse, center, middle, animated, bounceInDown\n\n# Get Started\nThe end result will look something like this. Have fun! üòé\n\n\n\nAnimated xaringan slides"
  },
  {
    "objectID": "blog/animate-xaringan-slide-transitions/index.html#more-xaringan-fun",
    "href": "blog/animate-xaringan-slide-transitions/index.html#more-xaringan-fun",
    "title": "Animate Xaringan Slide Transitions",
    "section": "More xaringan fun",
    "text": "More xaringan fun\nThis topic came up in a xaringan GitHub issue, where pzhaonet shared a link to a demonstration of all 77 available transitions.\nIf you like xaringan, you might also like my package for customizing its colors and themes: xaringanthemer.\n\n\n\nAnimated xaringan slides"
  },
  {
    "objectID": "blog/blogdown-netlify-new-post-workflow/index.html",
    "href": "blog/blogdown-netlify-new-post-workflow/index.html",
    "title": "A Blogdown New Post Workflow with Github and Netlify",
    "section": "",
    "text": "This post presents my workflow for writing new posts for a blogdown website hosted on GitHub and served through Netlify.\nHere‚Äôs a quick overview of the workflow:\n\nDraft the post in a new git branch, using blogdown::serve_site() to preview locally.\nPush the branch to GitHub and create a pull request.\nPreview and test the draft post using Netlify‚Äôs ‚Äúdeploy preview‚Äù feature.\nPush additional updates to the post branch as needed and review the updated preview.\nPublish the final draft by merging the pull request to the master branch.\n\nThe rest of this post describes this workflow in more detail, including how to configure critical settings for Netlify that make the process easier."
  },
  {
    "objectID": "blog/blogdown-netlify-new-post-workflow/index.html#overview",
    "href": "blog/blogdown-netlify-new-post-workflow/index.html#overview",
    "title": "A Blogdown New Post Workflow with Github and Netlify",
    "section": "",
    "text": "This post presents my workflow for writing new posts for a blogdown website hosted on GitHub and served through Netlify.\nHere‚Äôs a quick overview of the workflow:\n\nDraft the post in a new git branch, using blogdown::serve_site() to preview locally.\nPush the branch to GitHub and create a pull request.\nPreview and test the draft post using Netlify‚Äôs ‚Äúdeploy preview‚Äù feature.\nPush additional updates to the post branch as needed and review the updated preview.\nPublish the final draft by merging the pull request to the master branch.\n\nThe rest of this post describes this workflow in more detail, including how to configure critical settings for Netlify that make the process easier."
  },
  {
    "objectID": "blog/blogdown-netlify-new-post-workflow/index.html#pre-reqs-workflow-setup",
    "href": "blog/blogdown-netlify-new-post-workflow/index.html#pre-reqs-workflow-setup",
    "title": "A Blogdown New Post Workflow with Github and Netlify",
    "section": "Pre-reqs: Workflow Setup",
    "text": "Pre-reqs: Workflow Setup\n\nBlogdown, GitHub, and Netlify, oh my!\nTo get started you need three things:\n\na blogdown website\nhosted on GitHub and\npublished via Netlify.\n\nThere are a lot of great resources for setting up and connecting these components if you haven‚Äôt already, but the best place to start is the blogdown book. The process for setting up Netlify to serve your GitHub-hosted blogdown site is described in detail in the Netlify section of the Deployment chapter of the blogdown book. Alison Presmanes Hill‚Äôs Up and running with blogdown is another excellent guide for getting started down this path.\nI‚Äôm a huge fan of GitHub (or really open sharing of code) and I highly recommend using Netlify for a number of reasons. The main benefit of this combination is that Netlify‚Äôs continuous deployment builds your website for you whenever you update your source files. Netlify also makes it easy to set up your website for https with free, managed certificates]netlify-https, and their integration with GitHub makes [blogdown, GitHub, and Netlify excellent partners.\nNote part of setup should include configuring the baseurl option in your config.toml file. This is the base of URLs used in your website wherever an absolute URL (i.e.¬†the full URL rather than a relative or partial URL) is created. This is somewhat template-dependent, but this URL is used wherever a link is parsed with hugo‚Äôs absURL command.\nIn my case, baseurl is configured like this:\nbaseurl = \"https://www.garrickadenbuie.com\"\n\n\nEnable Deploy Previews\nNetlify provides a feature called deploy contexts that allows you to build multiple versions of your site. For example, Netlify can automatically build a deploy preview of your website for all pull requests. When enabled, a preview version of your website is automatically built when a pull request is created in the site‚Äôs GitHub repo. The preview is also updated whenever additional commits are added to the pull request.\nTo turn on this feature, select your website from your list of sites hosted with Netlify. Then click on Site settings and find Build & deploy on the left menu bar. Under this settings group, click the Edit settings button and select Automatically build deploy previews for all pull requests next to Deploy previews.\n\n\n\nEnable automatic deploy previews for pull requests in your site‚Äôs settings.\n\n\n\n\nSet up netlify.toml\nFinally, you need to create a file called netlify.toml in your website‚Äôs root directory. This file allows you to very specifically customize your Netlify settings in addition to, or in place of, the settings available through the Netlify web app.\nTwo modifications from the default hugo command used to build the deploy preview improve the workflow:\n\nAdding -b $DEPLOY_PRIME_URL ensures that URLs generated by hugo on the deploy preview point to the deploy preview. Without this, absolute URLs created by your hugo template (or theme) will point to your baseurl (your primary site) rather than the deploy preview, meaning that it will occasionally be impossible or difficult to test that your links work as expected in the preview version.\nAdding --buildFuture ensures that posts scheduled in the future are also rendered regardless of publication date. Without this, posts scheduled for future publication dates won‚Äôt be displayed in the preview. You may also wish to enable --buildDrafts as well (but see the side note on drafts below).\n\nWe can apply these settings in the context of deploy previews using the context.deploy-preview header, and if you‚Äôve enabled branch deploys in the step above, you can also enable these features under context.branch-deploy.\nAltogether, my netlify.toml file looks like this.\n# netlify.toml\n[context.deploy-preview]\ncommand = \"hugo -b $DEPLOY_PRIME_URL --buildFuture\"\n\n[context.branch-deploy]\ncommand = \"hugo -b $DEPLOY_PRIME_URL --buildFuture\"\n\nSide note: Drafts\nYou can mark a post as a draft by setting draft: true in the post‚Äôs YAML. This might even be the default when you create a new post (depending on your theme and settings).\nBut I don‚Äôt recommend using this flag for two reasons.\nFirst, it‚Äôs likely that you‚Äôll forget to remove it before publishing. The local live preview will show your post, so it‚Äôs easy to push your post only to discover that you forgot to set draft: false when your post doesn‚Äôt appear on your site (not that I‚Äôve ever done that before.)\nSecond, you can achieve the same results by writing and preparing your post in a post-specific branch and pull request. This keeps your source code, writing, and image in a self-contained branch in your repository (so you can get back to it later if it takes some time to finish it) and it allows you to take advantage of Netlify‚Äôs deploy preview feature.\nIf you do want to use hugo‚Äôs draft posts, you can add --buildDrafts to the hugo command in your netlify.toml so that Netlify renders draft posts on deploy previews. Read more in the Building a website for local preview section of the blogdown book."
  },
  {
    "objectID": "blog/blogdown-netlify-new-post-workflow/index.html#workflow",
    "href": "blog/blogdown-netlify-new-post-workflow/index.html#workflow",
    "title": "A Blogdown New Post Workflow with Github and Netlify",
    "section": "Workflow",
    "text": "Workflow\nOkay, now that everything is set up, we‚Äôre ready to dive into the workflow.\n\nStart in a new branch\nCreate a new branch for your post. Give your branch a meaningful name ‚Äî consider using the slug (short title) for the post. I wrote this post in a branch called post-new-post-workflow.\n\n\n\nCreate a New Branch with an informative name, like post-&lt;slug&gt;.\n\n\n\n\nCreate a new post\nCreate a new post in your blog using blogdown‚Äôs New Post addin. This is generally the easiest way to get started with a post, although you can also manually call blogdown::new_post() from the R command prompt.\n\n\n\nOpening the New Post RStudio addin.\n\n\nAt this step, the default date of the post is set to the current date. If you‚Äôd like to ‚Äúschedule‚Äù your post for a day in the future, you set the date now. (Remind yourself it‚Äôs an aspirational goal and not a hard deadline.) (And see below for the reason for the scare quotes around schedule. Spoiler: it‚Äôs not automatic.)\n\n\n\nSet the post date to be sometime in the future. (It was 2019-03-15 when I took this picture.)\n\n\nNote that you can also use publishDate or separately set both publishDate and date. If you use publishDate, the post will not be rendered until on or after the publishDate, but once published the post will appear to have been written on date (although this depends on the settings of your hugo theme). This configuration parameter needs to be set in your post‚Äôs YAML header.\nIf you‚Äôre writing your posts in R Markdown with the .Rmd extension, another option is to set date in the post YAML header to\ndate: '``r 'r'` Sys.Date()`'\nto make the post‚Äôs date reflect the day your .Rmd was rendered to hugo‚Äôs HTML. While I like this idea in theory, you may later need to re-render your post due to changes on your site. If you use your post‚Äôs date in your site‚Äôs permalinks1 ‚Äî for example, with URLs like /2019/03/18/blogdown-netlify-new-post-workflow ‚Äî then this change may inadvertently change your site‚Äôs URLs and invalidate links you‚Äôve previously shared.\n\n\n\nFill out the rest of your post information.\n\n\nYour blank page is ready! Run blogdown::serve_site() and write your post draft, previewing locally as you write.\n\n\n\nWriting this post in RStudio with the Source and Viewer panes maximized for ‚Äúlive preview‚Äù feel.\n\n\n\n\nCommit and Push\nCommit your post when it‚Äôs complete or after you‚Äôve written a section or a draft version (commits are cheap!). When you have at least one commit in your post branch, say your draft post, push those commits to GitHub. Navigate to the GitHub page for your website repo and open a pull request from your post branch.\nWhen you do you‚Äôll see a yellow dot next to the most recent commit. When it turns into a green check mark, your preview is ready.\n\n\n\nYour deploy preview is ready on Netlify!\n\n\nClick on the check mark and then click on Details. This will take you to a preview of your website at a URL like\nhttps://deploy-preview-&lt;pr#&gt;--&lt;website-name&gt;.netlify.com/\nThis site works exactly like it will when fully deployed, except for the two details that we changed above in netlify.toml:\n\nInternal links produced by Hugo will point to deploy-preview-NN...netlify.com rather than your baseurl address.\nFuture posts (and draft posts, if enabled) will be rendered as well.\n\n\n\nFinal Checks\nI usually (read: when I remember) try to pause here and run a few quick tests and checks on the post, either in RStudio or using the deploy preview link to the post.\n\nRun Check Spelling‚Ä¶ in RStudio (under Edit menu)\nRun xfun::optipng() on the directory where the post‚Äôs images are stored (including plots output by R) for lossless reduction of the size of .png images\nRun the W3C Link Checker on the post preview to make sure all links are valid.\nCheck YAML metadata is filled out, including title, description, categories, tags, etc.\nCheck that all images have alt text. A web accessibility evaluation tool can be helpful here.\n\n\n\nPublish\nThe final step is to publish your post ‚Äî merge your pull request to master and Netlify will deploy your site!\nOf course, if you‚Äôve scheduled your post for a future release date, it‚Äôs slightly more complicated. Hugo sites ‚Äî and by extension blogdown sites ‚Äî are static. The entire site is compiled and rendered once instead of every time a visitor access a page (like WordPress).\nAs far as I know, there‚Äôs no built-in mechanism to schedule the re-rendering of your site at a future date, so you‚Äôll need to manually trigger the rendering. In my workflow, this means choosing from the following two options:\n\nWait until on or after the date of your post to merge the pull request to master. Netlify will build and deploy your website immediately.\nMerge your pull request, but then later use the Netlify settings page for your site to trigger a rebuild. This seems more complicated to me, so I recommend using the first option.\n\nBut if you‚Äôre determined to fully automate this process, Netlify does integrate with Zapier, an online tool for automating tasks.\nThat‚Äôs it! Once you‚Äôve merged your post branch to the master branch, your post is out there in the world, just as soon as Netlify finishes building your site.\n\n\n\nEnable automatic deploy previews for pull requests in your site‚Äôs settings.\nCreate a New Branch with an informative name, like post-&lt;slug&gt;.\nOpening the New Post RStudio addin.\nSet the post date to be sometime in the future. (It was 2019-03-15 when I took this picture.)\nFill out the rest of your post information.\nWriting this post in RStudio with the Source and Viewer panes maximized for ‚Äúlive preview‚Äù feel.\nYour deploy preview is ready on Netlify!"
  },
  {
    "objectID": "blog/blogdown-netlify-new-post-workflow/index.html#footnotes",
    "href": "blog/blogdown-netlify-new-post-workflow/index.html#footnotes",
    "title": "A Blogdown New Post Workflow with Github and Netlify",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nSide note: Permalinks\nAnother quick side note to say that I highly recommend setting your permalinks to simply refer to your post‚Äôs slugs. For some reason, I used the full year, month, and day! of my post in my permalinks. Oh, the optimism!\nI certainly do not post often enough that I would ever end up with a name clash that could only be resolved by the full date of the post. There is an incredibly small (and only slightly non-zero) chance I‚Äôll use the same slug for two posts. In my view, it‚Äôs a worthwhile risk and much nicer to\n\nnot need to worry too much about the date in the post‚Äôs metadata and\nbe able to share links like https://garrickadenbuie.com/blog/blogdown-netlify-new-post-workflow/ than https://garrickadenbuie.com/blog/2019/03/18/blogdown-netlify-new-post-workflow/.\n\n‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/colors-of-xcolor/index.html",
    "href": "blog/colors-of-xcolor/index.html",
    "title": "The Colors of xcolor",
    "section": "",
    "text": "Today I‚Äôm working on the final touches of a Shiny app called ShinyDAG. The goal of the app is to help users create DAGs for causal inference with a drag-and-drop interface. Way down deep underneath the hood, the DAG is rendered using TikZ and LaTeX (via the texPreview package), and the app allows the user to tweak the appearance of the DAG without having to learn TikZ.\nOne of the appearance changes that the user can make is to change the color of the graph‚Äôs edges or nodes, using the colors defined in the xcolor LaTeX package. Rather than provide an open-ended text box, I wanted to give the user a dropdown menu containing the available colors.\nIt turned out to be just a few lines of code to grab the .def files from the xcolor package page, strip out the non-color related TeX lines, and create a simple tibble of the provided colors.\nQuick sidenote: the .def files are actually .def.gz (or gzipped files), but we can read these directly into R using url() inside gzcon(), which is then passed to readLines() to read the uncompressed text. I wrapped this up into a simple helper function, read_gz().\nread_gz &lt;- function(x) readLines(gzcon(url(x)))\nNow we can grab those files and extract the color definitions.\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(readr)\nlibrary(stringr)\n\nread_gz &lt;- function(x) readLines(gzcon(url(x)))\n\nxcolor &lt;-\n  list(\n    svg = \"http://www.ukern.de/tex/xcolor/tex/svgnam.def.gz\",\n    x11 = \"http://www.ukern.de/tex/xcolor/tex/x11nam.def.gz\"\n  ) %&gt;%\n  map(read_gz) %&gt;%\n  flatten_chr() %&gt;%\n  str_subset(\"^(%%|\\\\\\\\| )\", negate = TRUE) %&gt;%\n  str_remove(\"(;%|\\\\})$\") %&gt;%\n  paste(collapse = \"\\n\") %&gt;%\n  read_csv(col_names = c(\"color\", \"r\", \"g\", \"b\")) %&gt;%\n  arrange(color)\n\nhead(xcolor)\n\n# A tibble: 6 √ó 4\n  color             r     g     b\n  &lt;chr&gt;         &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 AliceBlue     0.94  0.972 1    \n2 AntiqueWhite  0.98  0.92  0.844\n3 AntiqueWhite1 1     0.936 0.86 \n4 AntiqueWhite2 0.932 0.875 0.8  \n5 AntiqueWhite3 0.804 0.752 0.69 \n6 AntiqueWhite4 0.545 0.512 0.47"
  },
  {
    "objectID": "blog/colors-of-xcolor/index.html#a-shiny-fixed-color-picker",
    "href": "blog/colors-of-xcolor/index.html#a-shiny-fixed-color-picker",
    "title": "The Colors of xcolor",
    "section": "A Shiny fixed-color picker",
    "text": "A Shiny fixed-color picker\nI haven‚Äôt finished incorporating this into the app yet, but this is the how the color selector will look when I do."
  },
  {
    "objectID": "blog/colors-of-xcolor/index.html#all-of-the-xcolor-colors",
    "href": "blog/colors-of-xcolor/index.html#all-of-the-xcolor-colors",
    "title": "The Colors of xcolor",
    "section": "All of the xcolor colors",
    "text": "All of the xcolor colors\nHere are all of the 468 colors in the xcolor package. (And man, it‚Äôs hard to sort colors.) If you‚Äôre interested, you can download the final list as a csv file.\n\n\n\nMaroon\nBrown4\nDarkRed\nFirebrick4\nIndianRed4\nRed4\nBrown\nFireBrick\nBrown3\nFirebrick3\nIndianRed\nIndianRed3\nRed3\nBrown2\nFirebrick2\nIndianRed2\nRed2\nBrown1\nFirebrick1\nIndianRed1\nRed\nRed1\nSalmon\nTomato3\nTomato2\nTomato4\nTomato\nTomato1\nCoral3\nCoral4\nCoral2\nCoral1\nSalmon2\nSalmon4\nSalmon3\nSalmon1\nOrangeRed4\nOrangeRed3\nOrangeRed2\nOrangeRed\nOrangeRed1\nCoral\nLightSalmon4\nSienna3\nSienna\nSienna1\nSienna2\nSienna4\nChocolate4\nSaddleBrown\nChocolate\nChocolate3\nChocolate1\nChocolate2\nSandyBrown\nTan4\nPeru\nTan3\nTan1\nTan2\nDarkOrange4\nDarkOrange3\nDarkOrange2\nDarkOrange1\nDarkOrange\nOrange4\nOrange3\nOrange\nOrange1\nOrange2\nDarkGoldenrod1\nGoldenrod4\nDarkGoldenrod3\nDarkGoldenrod4\nDarkGoldenrod\nDarkGoldenrod2\nGoldenrod1\nGoldenrod2\nGoldenrod\nGoldenrod3\nGold\nGold1\nGold4\nGold3\nGold2\nOlive\nYellow4\nYellow3\nYellow2\nYellow\nYellow1\nOliveDrab\nOliveDrab4\nOliveDrab1\nOliveDrab3\nYellowGreen\nOliveDrab2\nDarkOliveGreen1\nDarkOliveGreen3\nDarkOliveGreen2\nDarkOliveGreen\nDarkOliveGreen4\nGreenYellow\nChartreuse\nChartreuse1\nChartreuse2\nChartreuse3\nChartreuse4\nLawnGreen\nDarkGreen\nGreen\nForestGreen\nGreen4\nGreen3\nLimeGreen\nGreen2\nGreen0\nGreen1\nLime\nSeaGreen3\nSeaGreen\nSeaGreen4\nSeaGreen2\nSeaGreen1\nMediumSeaGreen\nSpringGreen4\nSpringGreen3\nSpringGreen2\nSpringGreen\nSpringGreen1\nMediumSpringGreen\nTurquoise\nLightSeaGreen\nMediumTurquoise\nTeal\nCyan4\nDarkCyan\nCyan3\nCyan2\nAqua\nCyan\nCyan1\nDarkTurquoise\nTurquoise2\nTurquoise4\nTurquoise3\nTurquoise1\nDeepSkyBlue3\nDeepSkyBlue\nDeepSkyBlue1\nDeepSkyBlue2\nDeepSkyBlue4\nSteelBlue2\nSteelBlue3\nSteelBlue\nSteelBlue4\nSteelBlue1\nDodgerBlue3\nDodgerBlue\nDodgerBlue1\nDodgerBlue2\nDodgerBlue4\nCornflowerBlue\nRoyalBlue1\nRoyalBlue3\nRoyalBlue4\nRoyalBlue2\nRoyalBlue\nMidnightBlue\nNavy\nNavyBlue\nBlue4\nDarkBlue\nBlue3\nMediumBlue\nBlue2\nBlue\nBlue1\nSlateBlue3\nSlateBlue1\nLightSlateBlue\nSlateBlue\nSlateBlue2\nDarkSlateBlue\nMediumSlateBlue\nSlateBlue4\nBlueViolet\nPurple1\nPurple3\nPurple4\nPurple2\nIndigo\nPurple0\nDarkOrchid2\nDarkOrchid4\nDarkOrchid\nDarkOrchid1\nDarkOrchid3\nDarkViolet\nMediumOrchid3\nMediumOrchid2\nMediumOrchid1\nMediumOrchid\nMediumOrchid4\nPurple\nDarkMagenta\nMagenta4\nMagenta3\nMagenta2\nFuchsia\nMagenta\nMagenta1\nVioletRed\nMaroon4\nMaroon3\nMaroon2\nMediumVioletRed\nMaroon1\nDeepPink2\nDeepPink3\nDeepPink\nDeepPink1\nDeepPink4\nHotPink\nHotPink4\nHotPink1\nHotPink2\nVioletRed1\nVioletRed2\nVioletRed4\nVioletRed3\nHotPink3\nMaroon0\nCrimson\nBlack\nDimGray\nDimGrey\nGray\nGrey\nRosyBrown4\nSnow4\nDarkGray\nDarkGrey\nRosyBrown\nGray0\nGrey0\nSilver\nRosyBrown3\nSnow3\nLightGray\nLightGrey\nGainsboro\nRosyBrown2\nSnow2\nLightCoral\nWhiteSmoke\nRosyBrown1\nSnow\nSnow1\nWhite\nMistyRose3\nMistyRose\nMistyRose1\nMistyRose4\nMistyRose2\nDarkSalmon\nLightSalmon2\nLightSalmon\nLightSalmon1\nLightSalmon3\nSeashell3\nSeashell\nSeashell1\nSeashell4\nSeashell2\nPeachPuff2\nPeachPuff3\nPeachPuff\nPeachPuff1\nPeachPuff4\nLinen\nBisque3\nBisque\nBisque1\nAntiqueWhite1\nAntiqueWhite3\nBisque2\nBurlywood4\nBurlywood2\nBurlyWood\nAntiqueWhite\nBisque4\nAntiqueWhite4\nBurlywood1\nTan\nBurlywood3\nAntiqueWhite2\nBlanchedAlmond\nNavajoWhite\nNavajoWhite1\nNavajoWhite2\nNavajoWhite3\nNavajoWhite4\nPapayaWhip\nMoccasin\nWheat1\nWheat4\nOldLace\nWheat\nWheat3\nWheat2\nFloralWhite\nCornsilk\nCornsilk1\nCornsilk4\nCornsilk3\nCornsilk2\nLightGoldenrod1\nLightGoldenrod3\nLightGoldenrod4\nLightGoldenrod2\nLightGoldenrod\nLemonChiffon2\nKhaki\nLemonChiffon\nLemonChiffon1\nLemonChiffon3\nLemonChiffon4\nKhaki4\nPaleGoldenrod\nKhaki1\nKhaki3\nKhaki2\nDarkKhaki\nIvory4\nLightYellow4\nIvory3\nLightYellow3\nIvory2\nLightYellow2\nBeige\nLightGoldenrodYellow\nIvory\nIvory1\nLightYellow\nLightYellow1\nDarkSeaGreen4\nHoneydew4\nPaleGreen4\nDarkSeaGreen\nDarkSeaGreen3\nHoneydew3\nPaleGreen3\nDarkSeaGreen2\nHoneydew2\nLightGreen\nPaleGreen2\nPaleGreen\nDarkSeaGreen1\nHoneydew\nHoneydew1\nPaleGreen1\nMintCream\nAquamarine\nAquamarine1\nAquamarine3\nMediumAquamarine\nAquamarine2\nAquamarine4\nDarkSlateGray\nDarkSlateGrey\nAzure4\nDarkSlateGray4\nLightCyan4\nPaleTurquoise4\nAzure3\nDarkSlateGray3\nLightCyan3\nPaleTurquoise3\nAzure2\nDarkSlateGray2\nLightCyan2\nPaleTurquoise\nPaleTurquoise2\nAzure\nAzure1\nDarkSlateGray1\nLightCyan\nLightCyan1\nPaleTurquoise1\nCadetBlue\nCadetBlue2\nCadetBlue4\nPowderBlue\nCadetBlue3\nCadetBlue1\nLightBlue\nLightBlue4\nLightBlue2\nLightBlue1\nLightBlue3\nSkyBlue\nLightSkyBlue4\nLightSkyBlue2\nLightSkyBlue1\nLightSkyBlue3\nLightSkyBlue\nSkyBlue3\nSkyBlue1\nSkyBlue2\nSkyBlue4\nAliceBlue\nSlateGray1\nSlateGray2\nSlateGray4\nSlateGray3\nLightSlateGray\nLightSlateGrey\nSlateGray\nSlateGrey\nLightSteelBlue4\nLightSteelBlue2\nLightSteelBlue\nLightSteelBlue3\nLightSteelBlue1\nLavender\nGhostWhite\nMediumPurple4\nMediumPurple3\nMediumPurple\nMediumPurple2\nMediumPurple1\nPlum4\nThistle4\nPlum3\nThistle3\nThistle\nPlum\nPlum2\nThistle2\nViolet\nPlum1\nThistle1\nOrchid4\nOrchid3\nOrchid\nOrchid1\nOrchid2\nLavenderBlush4\nLavenderBlush2\nLavenderBlush3\nLavenderBlush\nLavenderBlush1\nPaleVioletRed1\nPaleVioletRed2\nPaleVioletRed\nPaleVioletRed3\nPaleVioletRed4\nPink4\nPink1\nPink3\nPink2\nPink\nLightPink\nLightPink2\nLightPink4\nLightPink3\nLightPink1"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html",
    "href": "blog/countdown-v0.4.0/index.html",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "",
    "text": "I‚Äôm stoked to announce that countdown is now available on CRAN! Countdown to something awesome in xaringan, Quarto, R Markdown, or Shiny.\nIn this post, I reflect a bit on the development of countdown, but you can also skip straight to the release notes!"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#what-is-countdown",
    "href": "blog/countdown-v0.4.0/index.html#what-is-countdown",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "What is countdown?",
    "text": "What is countdown?\n\n\n\n\n\n‚àí+\n01:30\n\n\n\n\n\ncountdown() is a simple timer you can use in presentations, documents and Shiny apps. It‚Äôs great for teaching or breakout sessions!\nüëà‚òùÔ∏è Click the timer to start it. Click again to pause. Double click to reset it. Adjust the timer on the fly with the + and ‚àí buttons.\n\n\nEverything you need to know about countdown, you can learn from the docs-slash-presentation at pkg.garrickadenbuie.com/countdown.\n\n\n\n\n\n\n‚àí+\n01:30\n\n\n\n\n\ncountdown::countdown(\n  minutes = 1,\n  seconds = 30,\n  warn_when = 30\n)\n\n\n\npkg.garrickadenbuie.com/countdown"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#installing-countdown",
    "href": "blog/countdown-v0.4.0/index.html#installing-countdown",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "Installing countdown",
    "text": "Installing countdown\nInstalling countdown is now a whole lot easier:\ninstall.packages(\"countdown\")\nAs always, you can still get the latest and greatest in-development versions from GitHub\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/countdown\")\nor from gadenbuie.r-universe.dev.\noptions(repos = c(\n  gadenbuie = 'https://gadenbuie.r-universe.dev',\n  CRAN = 'https://cloud.r-project.org'\n))\n\ninstall.packages('countdown')"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#reflection",
    "href": "blog/countdown-v0.4.0/index.html#reflection",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "A brief history of countdown",
    "text": "A brief history of countdown\nBefore we talk about all the new things in countdown, I want to take a small minute to get nostalgic. I hope you don‚Äôt mind indulging me (or skip ahead if you‚Äôd rather get right to business).\n\nrstudio::conf(2019)\nIn 2019 I went to rstudio::conf in Austin, TX where a highlight of the conference, for me, was the Train-the-Trainer: Tidyverse Track workshop by Garrett Grolemund and Greg Wilson. That workshop specifically marked a turning point in my career and I left rstudio::conf very inspired to build and teach cool things in R.\nI also walked away from rstudio::conf(2019) with another key take away: it was time to learn JavaScript. An odd thing to take away from an R conference, yes. (Although I don‚Äôt think I‚Äôm alone in this kind of realization; this year many people left rstudio::conf(2022) thinking that it‚Äôs time to learn Python.)\nThese two inspirations came together in my first post-conf project: a countdown timer for xaringan slides.\n\n\n\n\nA slide from Garrett‚Äôs workshop materials with a 4-minute timer in the lower right corner.\n\n\n\nGarrett used timers extensively to pace break out sessions and they worked surprisingly well to keep everyone on track. One funny thing I noticed during our workshop session was that Garrett would frequently have to switch to slide-edit mode (in Keynote, I think) to fiddle with the timer as he adjusted the length of the ‚Äúyour turn‚Äù session. This is pretty normal; an instructor probably has a sense of approximately how long an activity will take and we‚Äôll often will adjust the time spent on the activity based on how the audience is doing, how well the material is working, or how close to lunch or a break we are in the session.\nSo my idea was to build a countdown timer that you could drop into a slide and easily use to time an event. I also wanted to make it easy to adjust the time, but my JavaScript skills were limited to what I could learn from StackOverflow, so I compromised and decided that you could only bump the timer up. After all it‚Äôs not like you have to end the timer, you can always just move on in your slides.\n\n\nIt becomes an R package\nI cobbled together an R package that was a fairly decent R interface around a collection of lines of JavaScript that I barely understood, that somehow assembled into an actual working timer. I made a cool intro-slash-docs presentation and would probably have sat on it for a while longer if it weren‚Äôt for Mara Averick who spotted my GitHub activity and soft-announced the package for me.\nNot long after that, and slightly to my horror (please don‚Äôt go looking at my JavaScript code), Hadley submitted an issue. Actually, two issues. Obviously, that was an exciting turn of events. His suggestions were solid and helped improve the quality of the timer: he suggested a warning state and a full-screen view/app.\nAmazingly, the package worked! People really seemed to like it, it solved a niche but useful need that many people have when teaching, and it let me learn a ton about how to build htmlwidgets in R. I‚Äôm proud of the R interface ‚Äî it‚Äôs easy to use and configure ‚Äî and I think the feature set hits the right balance of looking good right out of the box without doing too much.\n\n\nBut that JavaScript code‚Ä¶\nSince I wrote the first version of countdown, I‚Äôve learned a whole lot more JavaScript and I know a whole lot more about how to build web things in R. countdown‚Äôs underlying code has always haunted me a little, but on the other hand it was chugging away, still working fine for most people in most situations.\nSo I left it alone‚Ä¶\n\n\n\nScreenshot of the countdown GitHub repository page where the phrase ‚Äú3 years ago‚Äù is highlighted. That is GitHub‚Äôs summary of the last time I updated countdown.\n\n\n‚Ä¶for almost 3 years.\nAnd wow how much has changed in the three plus years since rstudio::conf(2019). Not only did I lead a workshop about JavaScript for Shiny users at rstudio::conf(2020) (hashtag js4shiny), and not only do I now work for RStudio1, but I was also part of the program committee for conference planning. Which means I saw colleagues were still using my countdown timer in workshop slides.\nAnd that old franken-JavaScript code still haunted me.\nSo this year, in part inspired by the return of the final rstudio::conf, I decided that finally rewriting that JavaScript would be the perfect conference side-hack project.\nWhich led to countdown v0.4.0 arriving on CRAN!"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#release",
    "href": "blog/countdown-v0.4.0/index.html#release",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "coundown v0.4.0",
    "text": "coundown v0.4.0\n\n\n\n\nThe Old JavaScript\nMy first implementation relied heavily on the JavaScript function setTimeout, which takes a function and a delay in milliseconds: setTimeout(function, delay). When called, the browser waits until the delay is over and then calls the function.\nA neat trick with setTimeout is that you can call it recursively inside a function as a way to run that function repeatedly. Below I‚Äôve defined a function timerTick() that moves the timer forward one tick. It also uses setTimeout to schedule the next tick of the timer. And by using a delay of 1000 milliseconds, I‚Äôve set up a function that runs once per second ‚Äî just like a clock üòâ.\nThis is, essentially, how countdown worked before. For each run of timerTick(), I would decrement the number of remaining seconds by one and update the timer. If there‚Äôs time left on the timer, then timerTick() shcedules another update for 1 second later. If there isn‚Äôt any time left, we can stop the timer by simply not scheduling any more timer updates.\n\nfunction timerTick() {\n  const timer = document.getElementById('timer')\n\n  // update the timer\n  timer.value -= 1\n  console.log(`${timer.value}s remaining...`)\n\n  if (timer.value &gt; 0) {\n    // there's time left, schedule next tick\n    setTimeout(timerTick, 1000)\n  } else {\n    // time is up, reset the timer\n    console.log(`Time's up!`)\n    timer.classList.remove('running')\n    timer.innerText = 'Start Timer'\n    // notice we don't schedule another tick\n  }\n}\n\nAnd this works*! Try it out by clicking the button below.\nStart Countdown\n\n\n\n\n\n\n*Almost. This almost works. It works pretty well if you start the timer and then don‚Äôt touch the browser window or switch to another tab. So it does usually work fine when you‚Äôre presenting slides.\nBut it turns out that setTimeout() is more like suggestThatThisRunsLater(). There‚Äôs really no guarantee that the function you scheduled to run 1,000 milliseconds from now is actually going to run in 1,000 milliseconds.\nThere are many things that can get in the way of that function being run when you expect it. If you move to a different tab and come back, for example, there‚Äôs no guarantee that the background tab would keep chugging along, running my function every seconds. Browsers have better things to do and they‚Äôll de-prioritize pages that aren‚Äôt being actively shown to users. This means that sometimes setTimeout(fn, 1000) runs fn 1 second from now, but depending on what else the browser is doing it could be a lot longer than that.\nSo how do we get around this? ü§î\n\n\nAll New JavaScript\nThe new JavaScript version of countdown does something really simple. It doesn‚Äôt rely on setTimeout() directly to keep track of the time.\nYes, it still schedules the next tick on 1 second intervals, but it doesn‚Äôt trust that exactly one second has passed. Now, when the user starts the timer, countdown will note when the timer should end and recalculates the remaining time with each tick. This means the updates are always accurate, even if there happen to be 4 seconds between consecutive ticks.\nIt also means that we can bump a running timer up or down by moving that end time later or earlier. To stop the timer, we just note how much time is left and to restart it again we recalculate the end time based on how much time was left when we paused.\nThere‚Äôs a small amount of internal state to keep track of, which happens to basically cry out for a JavaScript class. So the new countdown timer is implemented via a CountdownTimer class.\nHere‚Äôs a sketch of the class containing three core methods:\n\ntick() runs the timer, like above, except this time we calculate the remaining number of seconds on each tick. When there are less than 0 seconds left, we call the finish() method.\nstart() gets things started by calculating when the timer should end and kicking off the tick() method.\nfinish() wraps up by resetting the timer.\n\n\nclass Timer {\n  constructor(el, duration) {\n    // The timer's attached to a button\n    this.element = el\n    // it has a duration that's set when initiated\n    this.duration = duration\n    // and it will have an end when running\n    this.end = null\n  }\n\n  tick () {\n    // decide and report how much time is left\n    const remaining = this.end - Date.now()\n    console.log(`${remaining / 1000}s remaining...`)\n\n    // and then schedule the next tick or finish up\n    if (remaining &gt; 0) {\n      setTimeout(this.tick.bind(this), 1000)\n    } else {\n      this.finish()\n    }\n  }\n\n  start () {\n    if (this.end) return\n\n    console.clear()\n    this.element.innerText = 'Timer is running...'\n    // the timer ends duration (s) * 1000 (ms) from now\n    this.end = Date.now() + this.duration * 1000\n    this.tick()\n  }\n\n  finish () {\n    this.end = null\n    this.element.innerText = 'Start Timer'\n    console.log(`Time's up!`)\n  }\n}\n\nStart Countdown\n\n\n\n\n\n\nRun the 5-second timer by clicking the button above. Notice that even though we used the same setTimeout(code, 1000) as before to schedule each tick for one second later, because this version precisely reports how much time is left you can see that our timer drifts a bit away from running perfectly once per second.\n\n\nNew buttons and keyboard interactions\nBeyond the improved timer, the new CountdownTimer class makes it a whole lot easier to add additional features that need to build on the timer‚Äôs internal state.\nFor example, you can now\n\nClick to start or stop the timer\nDouble click to reset\nBump the timer up or down using the + and ‚àí buttons\nDo all of the above with keyboard shortcus:\n\nSpace or Enter to start or stop the timer\nEsc to reset\n‚Üë or ‚Üì to bump up or down\n\n\n\n\nShiny!\nThe shiny new countdown package also has plenty of Shiny features. Countdown timers can be controlled directly from Shiny with countdown_action() or countdown_update() and timers are now also inputs that report their state!\nYou can find an example Shiny app with a timer, plus an explanation of how it all works, by running\nto launch an example app. The example app is also available on my website at apps.garrickadenbuie.com/countdown-shiny-example.\nIn a nutshell, the timer will report its state using its input id. For example, countdown(id = \"timer\") will report its state to Shiny via input$timer. The input reports the event that caused the state to change and the state of the timer:\nHere‚Äôs another small app that demonstrate how you could use a button to toggle the state of the timer.\n\n\nImproved countdown App\n\n\n\n\nA screenshot of the full screen countdown timer app.\n\n\n\nAll of the Shiny updates mentioned above are used to power countdown_app(), a full screen Shiny app for running timers. These work really well for timing speakers at conferences or for a quick way to keep track of a break out session in workshops or meetings.\nThe app itself received a few upgrades, most importantly is the ability to share a timer with the settings you want using the URL. This uses Shiny‚Äôs Bookmarking state features to save your settings in the URL and restore them when you load that link.\nFor example, this timer is a 20 minute timer with a warning at 5 minutes that updates every 10 seconds.\n\n\nNew Options\nFinally, countdown gained a new option. You can now start the timer as soon as it is visible by setting start_immediately = TRUE. The ‚Äúas as soon as it‚Äôs visible‚Äù works pretty well: in xaringan and Quarto slides it starts when you land on the slide and in regular HTML documents the timer starts when you scroll the timer into view.\nIt‚Äôs also worth mentioning that countdown now uses prismatic for color calculations. I was really happy to see that Emil added best_contrast() and switching to use that function cleaned up a lot of internal code for me!"
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#thank-you",
    "href": "blog/countdown-v0.4.0/index.html#thank-you",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "Thank you!",
    "text": "Thank you!\nHuge thanks to the many people who opened issues or contributed code to countdown over these years. You all rock üß°\n@andrewpbray, @apreshill, @ConnorJPSmith, @csgillespie, @Dr-Joe-Roberts, @fvitalini, @hadley, @HaoZeke, @jhelvy, @jvcasillas, @moshpirit, @rtheodoro, @sje30, @spcanelon,and @thiyangt.\nIf you‚Äôve read this far, thank you! Thanks for using countdown and making developing R packages fun. Reach out in the comments or on Twitter (I‚Äôm @grrrck) with any questions or thoughts ‚ò∫Ô∏è\n\n\n\n\n\n\n\n\n\n\n\n\nA slide from Garrett‚Äôs workshop materials with a 4-minute timer in the lower right corner.\nScreenshot of the countdown GitHub repository page where the phrase ‚Äú3 years ago‚Äù is highlighted. That is GitHub‚Äôs summary of the last time I updated countdown.\nA screenshot of the full screen countdown timer app."
  },
  {
    "objectID": "blog/countdown-v0.4.0/index.html#footnotes",
    "href": "blog/countdown-v0.4.0/index.html#footnotes",
    "title": "countdown v0.4.0 ‚Äì Now on CRAN!",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAt least until October: RStudio is becoming Posit.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "",
    "text": "This is a quick post demonstrating a custom discrete color scale for ggplot2. The goal is to create a branded color scale that we can apply to a ggplot2 plot with + scale_color_branded().\nI‚Äôm going to demonstrate how to customize the order of the colors used in the palette by showcasing a neat setup for setting the colors of binary variables. Whenever two discrete values are used for the color scale, the palette will automatically choose a primary color and a softer secondary (or other) color. Both will be parameterized so that we can change the colors as needed, choosing automatically from a branded color palette."
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html#a-color-palette-for-our-brand",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html#a-color-palette-for-our-brand",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "A color palette for our ‚Äúbrand‚Äù",
    "text": "A color palette for our ‚Äúbrand‚Äù\nSuppose we have color palette for our brand or organization. I just grabbed a random color palette from coolors.co (but I think it actually looks okay!). We‚Äôll store this in a list called branded_colors, that you would ideally export from the package containing your brand‚Äôs ggplot2 themes.\n\nbranded_colors &lt;- list(\n  \"blue\"   = \"#00798c\",\n  \"red\"    = \"#d1495b\",\n  \"yellow\" = \"#edae49\",\n  \"green\"  = \"#66a182\",\n  \"navy\"   = \"#2e4057\",\n  \"grey\"   = \"#8d96a3\"\n)"
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html#create-a-palette-function",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html#create-a-palette-function",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "Create a palette function",
    "text": "Create a palette function\nNext we create the palette function. Ultimately, what we need from a palette function is a function that takes a single argument n and returns n colors.\nBut in our case, we want to give the user some control over which colors are used, so our palette function needs to have some additional parameters. To balance both needs, we‚Äôll use a closure, which is fancy word for a function that returns another function. The outer function sets up the color choices and the inner function returns a simple function of n that gives ggplot2 our brand‚Äôs colors.\nWhat‚Äôs great is that we can do whatever we want inside these functions. You can use this opportunity to re-order the colors for specific values of n, for example.\nWe‚Äôre going to make specific decisions about the colors used when n == 2. We want the palette to return two colors, branded_colors[primary] and another color. The other argument specifies the name of the second (or other) color, and we‚Äôll first try to lookup the color name from the brand colors, but we‚Äôll also let the user specify a manual color.\n\nbranded_pal &lt;- function(\n  primary = \"blue\",\n  other = \"grey\",\n  direction = 1\n) {\n  stopifnot(primary %in% names(branded_colors))\n\n  function(n) {\n    if (n &gt; 6) warning(\"Branded Color Palette only has 6 colors.\")\n\n    if (n == 2) {\n      other &lt;- if (!other %in% names(branded_colors)) {\n        other\n      } else {\n        branded_colors[other]\n      }\n      color_list &lt;- c(other, branded_colors[primary])\n    } else {\n      color_list &lt;- branded_colors[1:n]\n    }\n\n    color_list &lt;- unname(unlist(color_list))\n    if (direction &gt;= 0) color_list else rev(color_list)\n  }\n}\n\nHere are a few examples of the colors given by the pallete function returned by branded_pal() for various values of n.\n\nbranded_pal()(2)\n\n[1] \"#8d96a3\" \"#00798c\"\n\nbranded_pal(other = \"green\")(2)\n\n[1] \"#66a182\" \"#00798c\"\n\nbranded_pal()(3)\n\n[1] \"#00798c\" \"#d1495b\" \"#edae49\"\n\nbranded_pal(direction = -1)(3)\n\n[1] \"#edae49\" \"#d1495b\" \"#00798c\""
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html#create-a-discrete-color-scale",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html#create-a-discrete-color-scale",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "Create a discrete color scale",
    "text": "Create a discrete color scale\nNow, we wrap this palette into a scale_colour_branded() function, using ggplot2::discrete_scale() to turn our palette into a ggplot2 scale. Note that ggplot2 convention is to spell colour with a u and to create an alias to the American spelling.\n\nscale_colour_branded &lt;- function(\n  primary = \"blue\",\n  other = \"grey\",\n  direction = 1,\n  ...\n) {\n  ggplot2::discrete_scale(\n    \"colour\", \"branded\",\n    branded_pal(primary, other, direction),\n    ...\n  )\n}\n\nscale_color_branded &lt;- scale_colour_branded"
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html#demonstration",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html#demonstration",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "Demonstration",
    "text": "Demonstration\nLet‚Äôs see our new discrete color scale in action. We‚Äôll create a simple plot using mtcars using the binary variable vs (engine shape, V or straight) for the point colors.\nHere‚Äôs our plot using the standard ggplot2 colors.\n\nlibrary(ggplot2)\n\n# Convert vs, gear to character so ggplot2 uses discrete scales\nmtcars$vs   &lt;- paste(mtcars$vs)\nmtcars$gear &lt;- paste(mtcars$gear)\n\ng &lt;- ggplot(mtcars) +\n  aes(mpg, wt, color = vs) +\n  geom_point(size = 3) +\n  theme_bw()\n\ng\n\n\n\n\n\n\n\n\nUsing our discrete color scale automatically uses our brand‚Äôs primary color with the brand‚Äôs grey color we chose as the default other value.\n\ng + scale_color_branded()\n\n\n\n\n\n\n\n\nThe default value is designed to highlight TRUE values and soften FALSE values, but you may want complementary colors instead.\n\ng + scale_color_branded(other = \"yellow\")\n\n\n\n\n\n\n\n\nWhen the level ordering doesn‚Äôt match the colors, we let the user reverse the direction of the palette by setting direction = -1.\n\ng + scale_color_branded(other = \"yellow\", direction = -1)\n\n\n\n\n\n\n\n\nIf you‚Äôd rather use a custom color for the other color, we‚Äôve given the user a small amount of leeway to deviate from the brand colors.\n\ng + scale_color_branded(other = \"#a2d729\")\n\n\n\n\n\n\n\n\nBut when there are more than 2 categorical levels, the brand color palette is used‚Ä¶\n\ng + aes(color = gear) + scale_color_branded()\n\n\n\n\n\n\n\n\n‚Ä¶and primary and other options are ignored‚Ä¶\n\ng + aes(color = gear) + scale_color_branded(other = \"yellow\")\n\n\n\n\n\n\n\n\n‚Ä¶but the direction argument is still helpful.\n\ng + aes(color = gear) + scale_color_branded(direction = -1)"
  },
  {
    "objectID": "blog/custom-discrete-color-scales-for-ggplot2/index.html#final-thoughts",
    "href": "blog/custom-discrete-color-scales-for-ggplot2/index.html#final-thoughts",
    "title": "Custom Discrete Color Scales for ggplot2",
    "section": "Final thoughts",
    "text": "Final thoughts\nI used this technique to create a branded ggplot2 theme at work and I‚Äôve found that this special treatment of binary categorical variables is incredibly helpful.\nI frequently need to communicate two values or trends in a way that allows for comparisons but clearly highlights one category. A common example would be comparing local cancer rates with statewide averages, and in these cases having a muted color for the comparison is incredibly helpful.\nHere‚Äôs an example using the Texas housing sales data that ships with ggplot2 to showcase monthly total home sales in Austin with Dallas sale volume shown for reference.\n\n\n\n\n\n\n\n\n\n\nIndicate discrete/continuous in the function name\nIf you‚Äôre using this as guidance for building your own discrete color scale, my final tip would be to modify the name of the scale function and append _d to the end to indicate that the scale is discrete.\nscale_color_branded_d()\nYou‚Äôll want to leave space in your package for a continuous color scale that will receive a _c() suffix.\n\n\nCreate fill scale functions, too\nFinally, you‚Äôll also want to create scale_fill_...() functions as well. You can create those using the same branded_palette() functions you used for scale_color_branded(), with the small tweak of replacing \"color\" with \"fill\" as the first argument to ggplot2::discrete_scale()\n\n\nWhat about three colors?\nEmily Riederer has a neat function in her Rtistic package template that I highly recommend you check out if you‚Äôre making a package of branded ggplot2 and rmarkdown themes.\nShe calls it scale_color_opinionated() and it works similarly to the functions I‚Äôve laid out, except that it provides a color scale specifically for categorical variables with three levels: \"good\", \"neutral\", and \"bad\".\nIf this sounds like something you do frequently, consider adding an opinionated function to your package!\n\n\nThanks\nThanks for reading! Find me on Twitter @grrrck to let me know if this post was helpful.\nAnd thanks to Benjamin Wolfe for inspiring this post!"
  },
  {
    "objectID": "blog/dry-vignette-and-readme/index.html",
    "href": "blog/dry-vignette-and-readme/index.html",
    "title": "Reuse Rmd fragments in package vignettes, README, blog posts and more",
    "section": "",
    "text": "Updated on December 4, 2019 with new advice that will most likely satisfy R CMD check.\nJonathan Carroll (@carroll_jono) posted a twitter poll that turned out to be quite interesting this weekend:"
  },
  {
    "objectID": "blog/dry-vignette-and-readme/index.html#what-i-love-to-see-in-a-readme",
    "href": "blog/dry-vignette-and-readme/index.html#what-i-love-to-see-in-a-readme",
    "title": "Reuse Rmd fragments in package vignettes, README, blog posts and more",
    "section": "What I love to see in a README",
    "text": "What I love to see in a README\nPersonally, I usually find out about a package while browsing GitHub or a blog post that leads me to check out the package on GitHub. So I‚Äôm very partial to a highly explanatory README.\nWhen I run into a new package, I‚Äôm hoping the README answers the following questions\n\nWhy would I want to use this package?\nWhat does it look like to use this package?\n\nSo basically: an explanation of the problem the package solves and at least a short introduction to the functions or syntax of the package.\nThere are a lot of READMEs out there that just answer the first question with a very basic description of the package, or maybe even a detailed overview of the problem the package solves, but they don‚Äôt showcase the package in action. I might not be the typical user, but this always seems like a missed opportunity to me.\nOf course, writing good documentation is tricky. And considering that a good package also has vignettes, a README, a related (blogdown) blog post, and possibly even a pkgdown site, making sure the documentation is up-to-date in all of these places can put undue burden on the package developers."
  },
  {
    "objectID": "blog/dry-vignette-and-readme/index.html#dont-repeat-yourself-clone-yourself",
    "href": "blog/dry-vignette-and-readme/index.html#dont-repeat-yourself-clone-yourself",
    "title": "Reuse Rmd fragments in package vignettes, README, blog posts and more",
    "section": "Don‚Äôt Repeat Yourself, Clone Yourself",
    "text": "Don‚Äôt Repeat Yourself, Clone Yourself\n\nIn the spirit of Don‚Äôt Repeat Yourself and maximizing the potential of knitr and R Markdown ‚Äì and the fact that you can use R Markdown for all of the above pieces ‚Äì I remembered recently reading about child documents in knitr.\nI posted my idea to Jonathan‚Äôs thread and shortly afterwards @BrodieGaslam wrote back with an idea that really makes the best of child documents. Here‚Äôs the full idea:\n\nWrite repeatable sections in short .Rmd files.\nAdapting from Brodie‚Äôs vetr package as an example, these files are stored in man/fragments:\nvignettes/\n‚îú‚îÄ‚îÄ alike.Rmd\n‚îú‚îÄ‚îÄ styles.css\n‚îî‚îÄ‚îÄ vetr.Rmd\nman/\n‚îî‚îÄ‚îÄ fragments/\n    ‚îú‚îÄ‚îÄ declarative-checks.Rmd\n    ‚îú‚îÄ‚îÄ microbenchmark.Rmd\n    ‚îú‚îÄ‚îÄ related-packages.Rmd\n    ‚îú‚îÄ‚îÄ trust-but-verify.Rmd\n    ‚îú‚îÄ‚îÄ valaddin.Rmd\n    ‚îî‚îÄ‚îÄ vetting-expressions.Rmd\nNotice man/fragments/related-packages.Rmd. It‚Äôs a short R Markdown file with a list of (not surprisingly) related packages ‚Äì the kind of section that might be included in both the package overview vignette and the README.\n\nman/fragments/related-packages.Rmd &gt;\n* [`vetr`](https://github.com/brodieG/vetr) by Yours Truly\n* [`asserthat`](https://github.com/hadley/assertthat) by Hadley Wickham\n* [`assertive`](https://www.r-pkg.org/pkg/assertive) by Richie Cotton\n* [`checkmate`](https://github.com/mllg/checkmate) by Michel Lang\n\nThe following packages also perform related tasks ...\nCaution: If the fragments are stored in a sub-folder of vignettes/, R CMD check may try to render them and can throw an error when they fail to render because they aren‚Äôt complete documents.\n\n\n\nReference the repeatable sections using the child chunk option.\nknitr provides a child document chunk option that you can use to embed R Markdown from an external file. Anywhere that you would re-use the documentation, you simply include the following, such as in the vetr package vignette. Again, the following are from the vetr package documentation files.\n\nvignettes/vetr.Rmd &gt;\n## Alternatives\n\nThere are many alternatives available to `vetr`.  We do a survey of the\nfollowing in our [parameter validation functions][4] review:\n\n```{r child=\"../man/fragments/related-packages.Rmd\"} `r ''`\n```\nThis R Markdown ‚Äúchunk‚Äù can be used anywhere else you need it, such as in the package README.Rmd file.\n\n\nREADME.Rmd &gt;\n## Alternatives\n\nThere are many alternatives available to `vetr`.  We do a survey of the\nfollowing in our [parameter validation functions][5] review:\n\n```{r child=\"man/fragments/related-packages.Rmd\"} `r ''`\n```\nThe major advantage here is to be able to update the documentation in one place and have those changes propagate to ‚Äúparent‚Äù documents. It‚Äôs also useful to be able to arrange or choose the content shown in certain places differently depending on the location (or even during editing!). For example, READMEs typically include installation instructions, but these would be redundant if included in the package vignettes.\nThe above examples can be extended for use in pkgdown articles (which are essentially an extension of vignettes) or for blogdown posts if you develop your package and blog source on the same machine.\n\n\nUpdate: December 4, 2019\nMa√´lle Salmon helpfully pointed out and then tracked down the solution to an issue that may pop up with the method I originally proposed in this post.\nRather than storing your R Markdown fragments in a subfolder in vignettes/, such as vignettes/fragments, they should instead be stored in man/fragments.\nI updated the post above to match Ma√´lle‚Äôs advice. Thanks to Ma√´lle Salmon for the helpful advice that satisfies R CMD Check!\n\nThanks @BrodieGaslam for the tip and @carroll_jono for kicking off this thread!"
  },
  {
    "objectID": "blog/ggplot2-weekly-planner/index.html",
    "href": "blog/ggplot2-weekly-planner/index.html",
    "title": "A Printable Custom Weekly Planner with ggplot2",
    "section": "",
    "text": "I was working on prioritizing some long term projects today and decided that the one thing that would help me gain some clarity would be a weekly planner. Rather than waste hours of productive time fighting popups and banner adds on the million and a half SEO-fueled malware-laden ‚Äúfree printable calendar‚Äù websites, I decided to waste not quite as many hours of productive time creating the exact calendar I wanted using ggplot2.\nHere‚Äôs the end result: a simple calendar where each week is a row. Weeks start on Mondays because that‚Äôs when a new week starts. Important dates can be highlighted, for holidays or other days relevant to your projects.\nI doubt it‚Äôs bullet journal certified, but it worked for me and maybe it will for you too.\nI‚Äôll break down the pieces that went into the calendar, but if you just want to make your own you can jump to the end use the ggweekly package I shared on GitHub and get straight to calendar printing and project planning.\nUpdate: I realized it would be easier to share this code as a small R package rather than a gist or as a script embedded here. You can now install ggweekly from github.com/gadenbuie/ggweekly and use the ggweek_planner() function to make your own custom, printable calendars."
  },
  {
    "objectID": "blog/ggplot2-weekly-planner/index.html#the-making-of-a-calendar",
    "href": "blog/ggplot2-weekly-planner/index.html#the-making-of-a-calendar",
    "title": "A Printable Custom Weekly Planner with ggplot2",
    "section": "The Making of a Calendar",
    "text": "The Making of a Calendar\n\nLoad the tidyverse\nFirst, we need to load the usual suspects from the tidyverse], plus the [lubridate package (because dates).\n\n# library(tidyverse)\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(tidyr)\nlibrary(forcats)\nlibrary(ggplot2)\nlibrary(lubridate)\n\nLet‚Äôs also save ourselves some extra typing and tell lubridate to always start weeks with Monday.\n\noptions(\"lubridate.week.start\" = 1)\n\n\n\nCreate a tibble of dates\nNext, I set up a tibble of dates and associated information (day of the week, month, year, etc.) that I‚Äôll need for the calendar grid. I start by finding the nearest previous Monday to the starting date and creating a sequence of dates.\n\nstart_day &lt;- floor_date(ymd(\"2019-06-24\"), \"week\")\nend_day   &lt;- ymd(\"2019-08-16\")\nseq_days  &lt;- seq(start_day, end_day, by = \"day\")\n\nseq_days[1:5]\n\n[1] \"2019-06-24\" \"2019-06-25\" \"2019-06-26\" \"2019-06-27\" \"2019-06-28\"\n\n\nI‚Äôm also taking advantage of the fact that tibble() is similar to mutate() in that it allows you to create new columns that reference previous columns inside the tibble definition, rather than having a separate call to mutate().\n\ndates &lt;-\n  tibble(\n    day       = seq_days,\n    wday_name = wday(day, label = TRUE, abbr = TRUE),\n    weekend   = wday(day) &gt; 5,\n    isoweek   = isoweek(day),\n    month     = month(day, label = TRUE, abbr = FALSE),\n    isoyear   = isoyear(day),\n    week_year = fct_rev(sprintf(\"%s - %s\", isoyear, isoweek))\n  )\n\ndates\n\n# A tibble: 54 √ó 7\n   day        wday_name weekend isoweek month isoyear week_year\n   &lt;date&gt;     &lt;ord&gt;     &lt;lgl&gt;     &lt;dbl&gt; &lt;ord&gt;   &lt;dbl&gt; &lt;fct&gt;    \n 1 2019-06-24 Mon       FALSE        26 June     2019 2019 - 26\n 2 2019-06-25 Tue       FALSE        26 June     2019 2019 - 26\n 3 2019-06-26 Wed       FALSE        26 June     2019 2019 - 26\n 4 2019-06-27 Thu       FALSE        26 June     2019 2019 - 26\n 5 2019-06-28 Fri       FALSE        26 June     2019 2019 - 26\n 6 2019-06-29 Sat       TRUE         26 June     2019 2019 - 26\n 7 2019-06-30 Sun       TRUE         26 June     2019 2019 - 26\n 8 2019-07-01 Mon       FALSE        27 July     2019 2019 - 27\n 9 2019-07-02 Tue       FALSE        27 July     2019 2019 - 27\n10 2019-07-03 Wed       FALSE        27 July     2019 2019 - 27\n# ‚Ä¶ with 44 more rows\n\n\nNote that I‚Äôve used isoweek() and isoyear(), which also follow the convention of starting the week on Monday. This way, I now have the week number to which each day in the sequence belongs, but because we may be interested in creating calendars that span multiple years, the addition of isoyear() protects against repeated week numbers.\nThis week year combination is destined for the y axis as it marks the row to which each day belongs. The y axis is typically increasing, with the smallest value at the bottom. This means that, if left as strings, the week of \"2019 - 25\" would be below the week \"2019 - 26\". Because calendars are typically read top to bottom, I used fct_rev() here to both convert {isoyear} - {isoweek} into a factor and then reverse the factor order so that 2019 - 25 is the last factor.\n\n# shows the _last 6_ week_year factor levels\ndates %&gt;% pull(week_year) %&gt;% levels() %&gt;% tail()\n\n[1] \"2019 - 31\" \"2019 - 30\" \"2019 - 29\" \"2019 - 28\" \"2019 - 27\" \"2019 - 26\"\n\n\nFor a bit of convenience later, I then pull out the rows of dates representing the first day of the month, to use later when adding the colored boxes and text labels marking the start of a new month.\n\nday_one &lt;- dates %&gt;%\n  filter(day(day) == 1)\n\nday_one\n\n# A tibble: 2 √ó 7\n  day        wday_name weekend isoweek month  isoyear week_year\n  &lt;date&gt;     &lt;ord&gt;     &lt;lgl&gt;     &lt;dbl&gt; &lt;ord&gt;    &lt;dbl&gt; &lt;fct&gt;    \n1 2019-07-01 Mon       FALSE        27 July      2019 2019 - 27\n2 2019-08-01 Thu       FALSE        31 August    2019 2019 - 31\n\n\n\n\nBetter week labels\nQuick, what‚Äôs the starting date of week 31 in 2019?\nOk, fine, that was too hard. What month of 2019 does week 31 belong to?\nTrick question: that week starts on July 29, 2019 but ends on August 4th.\nSo‚Ä¶ we need better axis labels than 2019 - 31. A reasonable replacement would be to use the day of the month of the week‚Äôs starting day.\nThe following code filters dates to include the first day of each week (hint: it‚Äôs Monday). Then, I use month(day, label = TRUE) to get the abbreviated month name (abbr = TRUE is the default) that I‚Äôll append to the day of the month of each day.\nBut when a given week is preceded by a week from the same month, it would be visually distracting to see Jul repeated with each date ‚Äî Jul 1, Jul 8, Jul 15, and so on ‚Äî in the axis labels. For easy scanning, I only included the month in the label if the month changed from the month before. In other words, when month == lag(month), I just need the day of the month the given week.\n\nweek_start_labels &lt;- dates %&gt;%\n  filter(wday_name == \"Mon\") %&gt;%\n  arrange(day) %&gt;%\n  mutate(\n    month = month(day, label = TRUE),\n    label = case_when(\n      month == lag(month) ~ paste(day(day)),\n      TRUE ~ sprintf(\"%s %4i\", month, day(day))\n    )\n  ) %&gt;%\n  select(label, week_year) %&gt;%\n  reduce(setNames)\n\nThe last two lines there are a neat trick to take a two column tibble (or a two-element list) and convert it into a named vector using purrr::reduce(). The first argument becomes the vector values and second argument becomes the vector names:\n\nlist(1:5, letters[1:5]) %&gt;% purrr::reduce(setNames)\n\na b c d e \n1 2 3 4 5 \n\n\n\n\nA special tibble for special days\nI used yet another tibble to store holidays and other important dates related to the project. Each day can have a label, color, and/or fill.\n\nhighlight_days &lt;- tribble(\n         ~ day,            ~ label,   ~ color,    ~ fill,\n  \"2019-07-02\", \"Project Kick Off\", \"#02307a\", \"#02307a\",\n  \"2019-07-04\",         \"July 4th\", \"#b4436c\", \"#b4436c\",\n  \"2019-07-12\",          \"LOI Due\", \"#02307a\", \"#02307a\",\n  \"2019-07-26\",      \"First Draft\", \"#02307a\", \"#02307a\",\n  \"2019-08-05\",        \"Work week\", \"#02307a\", \"#02307a\",\n  \"2019-08-06\",                 \"\",        NA, \"#02307a\",\n  \"2019-08-07\",                 \"\",        NA, \"#02307a\",\n  \"2019-08-08\",                 \"\",        NA, \"#02307a\",\n  \"2019-08-09\",                 \"\",        NA, \"#02307a\",\n  \"2019-08-16\", \"Final Submission\", \"#02307a\", \"#02307a\"\n) %&gt;%\n  mutate_at(vars(day), ymd)\n\n\n\nFinally, ggplot the calendar\nFinally, we arrive at the main event, the actual creation of the calendar with ggplot2.\nHere I use geom_tile() for each day, and then overlay tiles for the start-of-the-month days and the highlighted holiday and project-specific days. I also used geom_text() to add annotations to the special days, which I pushed to the top or bottom left corner of the day box.\n\n\nCode to produce the calendar\ngcal &lt;-\n  dates %&gt;%\n  mutate(\n    # Softly fill in the weekend days\n    weekend = case_when(weekend ~ \"#f8f8f8\", TRUE ~ \"#FFFFFF\")\n  ) %&gt;%\n  ggplot() +\n  aes(wday_name, week_year) +\n  # the calendar grid\n  geom_tile(aes(fill = weekend), color = \"#aaaaaa\") +\n  # highlight first day of each month\n  geom_tile(\n    data = day_one,\n    fill = \"#f78154\",\n    alpha = 0.25,\n    width = 1,\n    height = 1\n  ) +\n  # add name of month to the first day\n  geom_text(\n    data = day_one,\n    aes(label = month),\n    family = \"PT Sans Narrow\",\n    color = \"#f78154\",\n    size = 4,\n    # push text to the top left corner\n    hjust = 0,\n    nudge_x = -0.45,\n    vjust = 1,\n    nudge_y = 0.45\n  ) +\n  # highlight project-specific days\n  geom_tile(\n    data = dates %&gt;% inner_join(highlight_days, by = \"day\"),\n    aes(fill = fill),\n    alpha = 0.25\n  ) +\n  # add the label from the highlighted days\n  geom_text(\n    data = dates %&gt;% inner_join(highlight_days, by = \"day\"),\n    aes(label = label, color = color),\n    family = \"PT Sans Narrow\",\n    size = 2,\n    # push to bottom left corner\n    hjust = 0,\n    nudge_x = -0.45,\n    vjust = 0,\n    nudge_y = -0.40\n  ) +\n  scale_x_discrete(position = \"top\") +\n  scale_y_discrete(labels = week_start_labels) +\n  scale_fill_identity() +\n  scale_color_identity() +\n  guides(fill = FALSE) +\n  theme_minimal(base_family = \"PT Sans\") +\n  theme(\n    axis.text = element_text(\"PT Sans Narrow\"),\n    axis.title = element_blank(),\n    panel.grid = element_blank(),\n    axis.text.x.top = element_text(face = \"bold\"),\n    axis.title.x.top = element_blank(),\n  )\n\ngcal\n\n\n\n\n\n\n\n\n\n\n\nCalculate month boundaries\nFor a final touch, I wanted stronger differentiation between months. In the following code, I convert wday_name and week_year into integers that indicate the center point of each box.\nThen, using the fact that the top and bottom (and right and left) sides of the box are +/- 0.5 units from the center, I create three line segments. The first extends from the bottom left corner of the day starting the week with the month change (left side of the plot) until the left edge of the box representing the start of the next month. The second segment line travels up the left edge of that box. And the third and final segment travels from the top left corner of the month-changing day to the right edge of the plot.\n\nmonth_boundaries &lt;- day_one %&gt;%\n  select(day, month, wday_name, week_year) %&gt;%\n  mutate_at(vars(wday_name, week_year), as.integer) %&gt;%\n  mutate(\n    left = map2(wday_name, week_year, ~ {\n      # n/a if month changes on first day\n      if (.x == 1) return(tibble(.missing = NA))\n      tibble(\n        x = 0.5,      xend = .x - 0.5,\n        y = .y - 0.5, yend = y\n      )\n    }),\n    up = map2(wday_name, week_year, ~ {\n      # n/a if month changes on first day\n      if (.x == 1) return(tibble(.missing = NA))\n      tibble(\n        x = .x - 0.5, xend = x,\n        y = .y - 0.5, yend = .y + 0.5\n      )\n    }),\n    right = map2(wday_name, week_year, ~ {\n      tibble(\n        x = .x - 0.5, xend = 7.5,\n        y = .y + 0.5, yend = y\n      )\n    })\n  )\n\n\nmonth_boundaries\n\n# A tibble: 2 √ó 7\n  day        month  wday_name week_year left             up       right   \n  &lt;date&gt;     &lt;ord&gt;      &lt;int&gt;     &lt;int&gt; &lt;list&gt;           &lt;list&gt;   &lt;list&gt;  \n1 2019-07-01 July           1         7 &lt;tibble [1 √ó 1]&gt; &lt;tibble&gt; &lt;tibble&gt;\n2 2019-08-01 August         4         3 &lt;tibble [1 √ó 4]&gt; &lt;tibble&gt; &lt;tibble&gt;\n\n\nThen, I use a quick for loop to add each of these segments to the calendar plot.\n\nfor (boundary in c(\"left\", \"up\", \"right\")) {\n  gcal &lt;- gcal +\n    geom_segment(\n      data = month_boundaries %&gt;% unnest(!!rlang::sym(boundary)),\n      aes(x = x, y = y, xend = xend, yend = yend),\n      color = \"#999999\",\n      linetype = 2\n    )\n}\n\ngcal"
  },
  {
    "objectID": "blog/ggplot2-weekly-planner/index.html#ggweek_planner",
    "href": "blog/ggplot2-weekly-planner/index.html#ggweek_planner",
    "title": "A Printable Custom Weekly Planner with ggplot2",
    "section": "A Weekly Planner Package",
    "text": "A Weekly Planner Package\nI originally thought I would simply include the code as a gist and move on with life, but I quickly realized that I might want to a) use this code again sometime and b) find some room for improvement and tweaks.\nSo I created ggweekly, a small package for creating calendars like these. In packaging the code, I made a few tweaks and changes. For example, I scraped the dates of federal holidays from the U.S. Office of Personel Management and separated the highlighted and holiday days. I also tweaked the function signatures a bit to make it more flexible.\nCheck out the package at github.com/gadenbue/ggweekly and happy planning!\ndevtools::install_github(\"gadenbuie/ggweekly\")\n\n# create a calendar for April, May and June\nlibrary(ggweekly)\nggweek_planner(\n  start_day = \"2019-04-01\",\n  end_day = \"2019-06-30\",\n)"
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html",
    "href": "blog/gun-control-google-trends/index.html",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "",
    "text": "Last updated: 2018-03-05 10:00\ntl;dr: Google searches for ‚Äúgun control‚Äù after the shooting in Parkland, Florida seem to be similar to search trends after other shootings, although it could be different this time.\nA civilized, modern society should be able to function nearly entirely without guns. We should be able to go about our lives without ever thinking about guns. We should be able to go the school, to go to church, to go to the grocery store, to leave our house and move about in the world without ever thinking about guns. Without ever having to worry about a gun, by accident or intention, ending your life or the lives of your loved ones.\nWe face a public health crisis unique to our country alone with respect to gun violence. We are inflicting pain and economic burden on ourselves at a yearly cost of $229 billion ‚Äì equivalent to the size of Portgual‚Äôs economy. It is pointless, devastating, entirely unnecessary and utterly heart breaking.\nI very clearly remember Columbine as an inflection point in education in my childhood, bomb threats and fire drills replacing class time like DVDs replacing VHS. Columbine happened 1,700 miles away from my middle school, but we felt it, even within the bubble of privelege that surrounded my community. I cannot even begin to fathom how today‚Äôs children feel the gun violence they see around them.\nIt absolutely breaks my heart that they have to go through this. It breaks my heart that the ‚Äúadults‚Äù in our society can‚Äôt get our shit together. It breaks my heart that they have to fight so hard to be heard and protected, that we need them to keep fighting, that we need them to stand up and speak out when we should be comforting them, when we should have done something sooner.\nIn their darkest hours, we are asking too much of them. And yet we need them. How else will this ever change?\nYesterday, Nate Silver put words to our collective hope that this time something is different, that we‚Äôre getting closer to #NeverAgain.\nMy first thought was how do you know?. What does the ‚Äúfade‚Äù look like? Clearly, I wasn‚Äôt alone as a lot of other people pointed this out in replies.\nI did a quick search and found the gtrendsR package on Github. (Thank you Philippe Massicotte and Dirk Eddelbuettel.) What follows is an analysis of Google Search trends for the term ‚Äúgun control‚Äù before and after other mass shooting events."
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#source-code",
    "href": "blog/gun-control-google-trends/index.html#source-code",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Source Code",
    "text": "Source Code\nA quick note. All of the source code for this post can be found in my Github repo for this website. I didn‚Äôt include it here in part because it‚Äôs a mess and also in part because I used caching and some unusual data types to store the Google Trends results."
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#mass-shootings-database",
    "href": "blog/gun-control-google-trends/index.html#mass-shootings-database",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Mass Shootings Database",
    "text": "Mass Shootings Database\nA dataset on mass shootings in the U.S. is available thanks to the hard work of Kaggle user zusmani. They compiled a list of mass shootings in the U.S. since 1966, using public datasets and webpages including Wikipedia, Mother Jones, Stanford, and USA Today.\nThe data is available on Kaggle at https://www.kaggle.com/zusmani/us-mass-shootings-last-50-years/ and includes a variety of variables.\nFor historical comparison, I selected the 15 most deadly shootings since 2004 (earliest available dates in Google Trends). Note that total victims include casualties and injuries.\n\n\n\nDate\nTitle\nLocation\nVictims\nAR-15\n(or sim.)\nSemi-Automatic\n\n\n\n\n2017-10-01\nLas Vegas Strip mass shooting\nLas Vegas, NV\n585\nYes\nYes\n\n\n2016-06-12\nOrlando nightclub massacre\nOrlando, Florida\n102\nNo\nYes\n\n\n2012-07-20\nAurora theater shooting\nAurora, Colorado\n82\nYes\nYes\n\n\n2007-04-16\nVirginia Tech massacre\nBlacksburg, Virginia\n55\nNo\nYes\n\n\n2017-11-05\nTexas church mass shooting\nSutherland Springs, TX\n46\nYes\nYes\n\n\n2009-11-05\nFort Hood Army Base\nFort Hood, Texas\n45\nNo\nYes\n\n\n2015-12-02\nSan Bernardino, California\nSan Bernardino, California\n35\nNo\nYes\n\n\n2012-12-14\nSandy Hook Elementary School\nNewtown, Connecticut\n29\nYes\nYes\n\n\n2008-02-14\nNorthern Illinois University shooting\nDeKalb, Illinois\n26\nNo\nYes\n\n\n2014-05-23\nIsla Vista mass murder\nSanta Barbara, California\n19\nNo\nYes\n\n\n2014-04-02\nFort Hood\nKilleen, Texas\n19\nNo\nNo\n\n\n2011-01-08\nTucson shooting\nTucson, Arizona\n19\nNo\nNo\n\n\n2009-04-03\nBinghamton shootings\nBinghamton, New York\n18\nNo\nNo\n\n\n2016-02-25\nExcel Industries mass shooting\nHesston, Kansas\n17\nNo\nYes\n\n\n2016-07-07\nDallas police shooting\nDallas, Texas\n16\nNo\nYes"
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#query-google-trends",
    "href": "blog/gun-control-google-trends/index.html#query-google-trends",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Query Google Trends from R with gtrendsR",
    "text": "Query Google Trends from R with gtrendsR\nThen I queried Google Trends via gtrendsR for the search terms \"gun control\" and a reference term for\n\nThe last 7 days (capturing Parkland, FL shooting)\nOne week before and 3 weeks after each of the above events\nAll search interest since 2004.\n\nThere are two points to note when working with data from Google Trends.\nFirst, Google Trends returns search trends relative to the time period queried, so it can be hard to determine the scale of interest when looking at a smaller time period, such as a month. For comparison, I included the reference term \"baseline\" because this is relatively stable at ~10% from 2004 through present day1. Edit 2018-02-20: I replaced \"difficult\" with \"baseline\" as the comparison search term.\nSecond, the data returned by Google Trends is aggregated according to the time window specified. In my tinkering I noticed that hourly trends are only available for the last 7 days. Earlier data is always aggregated at least by day. Longterm trends (such as the all time trend) are aggregated by month.\nThe code below isn‚Äôt exactly the code I used to gather the data, but it should give you an idea for how easy it is to use gtrendsR.\nlibrary(dplyr)\nlibrary(purrr)\nlibrary(gtrendsR)\n\nget_trends_for_event &lt;- function(day) {\n  gtrends(\n      keyword = c(\"gun control\", \"baseline\"),\n      geo = \"US\",\n      time = paste(glue::glue(\"{day - 7} {day + 21}\"))\n    )\n}\n\nguntrends &lt;- selected_dates %&gt;%\n    mutate(gtrends = map(Date, get_trends_for_event))\n\nall_guntrends &lt;- gtrends(c(\"gun control\", \"baseline\"),\n                         geo = \"US\", time = \"all\")\n\nparkland_trends &lt;- gtrends(c(\"gun control\", \"baseline\"),\n                           geo = \"US\", time = \"now 7-d\")"
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#all-time",
    "href": "blog/gun-control-google-trends/index.html#all-time",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "All time search interest in ‚Äúgun control‚Äù",
    "text": "All time search interest in ‚Äúgun control‚Äù\nGoogle searches for ‚Äúgun control‚Äù are relatively low-volume in the United States, with a clear increase around any mass shooting event. The plot below shows search interest in ‚Äúgun control‚Äù since 2004, with the largest peak occurring after the Sandy Hook Elementary School mass shooting."
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#searching-for-gun-control-after-a-mass-shooting",
    "href": "blog/gun-control-google-trends/index.html#searching-for-gun-control-after-a-mass-shooting",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "text": "Searching for ‚Äúgun control‚Äù after a mass shooting\nTo examine Google search trends around individual mass shooting events, I looked at searches for ‚Äúgun control‚Äù within a one month window around the shooting.\nEach subplot shows search trends as reported by Google Trends on a ‚Äúscale‚Äù from 0 to 100. The scale of searching is relative to the time period queried. Events such as the Las Vegas Strip, Orlando Night Club, Aurora Theater shootings show how the events caught the attention of the public and led to questions about our gun laws. Other events, such as the Fort Hood Army Base attack seemed not to have caught public or media attention in the same way.\n\nThe above plot highlights search trends around individual mass shooting events, but it‚Äôs difficult to assess how strong the response to a particular event is relative to previous events.\nThe approach that I worked out is to use a baseline search term that is relatively constant across the entire period. As I discussed above, I picked \"baseline\" for this role, as it nicely fits the bill. For each query of Google Trends, I also requested search trends for \"baseline\". Then I scaled the \"gun control\" search trends relative to the hits on the baseline search.\nWhat this means is that in the following plot, the search volume for \"gun control\" is shown in ‚Äúunits‚Äù of searches for \"baseline\". A value of 10 means there are 10 times more search for \"gun control\", whereas a value of 1 means that the search volumen is roughly equivalent."
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#this-time",
    "href": "blog/gun-control-google-trends/index.html#this-time",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Is this time different?",
    "text": "Is this time different?\nI certainly hope so. If we isolate other events with a similar profile in terms of public perception, it seems possible that this time will be different. But it also seems too early to tell.\nIn the mean time, just remember that Google searches aren‚Äôt real things. If you want to make a difference or a change, support a local politician, donate to gun violence research, and register your friends to vote. For more ideas, take a look at Everytown‚Äôs Action Plan at https://everytown.org/throwthemout/.\n\nI‚Äôll close with this tweet from @davepell.\nBut first, to the victims in Parkland, Florida and the victims of gun violence across the United States, I want you to know that I hear you, and I stand with you.\n\n\nEdits\n2018-02-20: I changed the comparison term from \"difficult\" to \"baseline\". Also updated the scripts to gather data from the week prior to Feb 14, 2018.\n\n\n\nSource: Mother Jones"
  },
  {
    "objectID": "blog/gun-control-google-trends/index.html#footnotes",
    "href": "blog/gun-control-google-trends/index.html#footnotes",
    "title": "Searching for ‚Äúgun control‚Äù after a mass shooting",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIt turns out that it‚Äôs actually rather tough to find a ‚Äústable‚Äù search term within the same general order of magnitude of searches as ‚Äúgun control‚Äù. The term \"difficult\" was not selected un-ironically (initally). Later I decided there was too much variation in the search trends for \"difficult\" and thought that following the irony was a good idea. So I changed the term to \"baseline\". Anyway, try it for yourself ‚Äì go to Google Trends and see if you can find another non-seasonal, nearly zero-growth search term.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "My Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\nAdd last rendered or modified time to Quarto\n\n\n\n\n\n\nQuarto\n\n\nExtensions\n\n\n\nIntroducing now, a Quarto extension that adds the time right now, anywhere in your document. \n\n\n\n\n\nMar 29, 2024\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Image Overflow Detection for xaringan or remark Slides\n\n\n\n\n\n\nR\n\n\nSlides\n\n\nxaringan\n\n\n\nUsing chromote and a little JavaScript to detect image overflow issues in {xaringan} or remark slides. \n\n\n\n\n\nJul 23, 2023\n\n\n9 min\n\n\n\n\n\n\n\n\n\n\n\n\nRead and Visualize your Twitter Archive\n\n\n\n\n\n\nR\n\n\nTwitter\n\n\nPersonal Data\n\n\n\nUsing R to read and visualize my Twitter archive data. Featuring {ggiraph}, {ggplot2}, {jsonlite}, {dplyr} and more‚Ä¶ \n\n\n\n\n\nDec 7, 2022\n\n\n34 min\n\n\n\n\n\n\n\n\n\n\n\n\ncountdown v0.4.0 ‚Äì Now on CRAN!\n\n\n\n\n\n\nR\n\n\nMy Projects\n\n\nSlides\n\n\ncountdown\n\n\nShiny\n\n\nJavaScript\n\n\nApps\n\n\nAnnouncement\n\n\nxaringan\n\n\nQuarto\n\n\n\ncountdown v0.4.0 is now available on CRAN with a ton of new features! \n\n\n\n\n\nAug 15, 2022\n\n\n15 min\n\n\n\n\n\n\n\n\n\n\n\n\nProcess Profile Pictures with magick\n\n\n\n\n\n\nR\n\n\nImages\n\n\nInteresting Uses of R\n\n\n\nProcess a directory full of profile pictures, resizing and cropping the images to be centered around faces. \n\n\n\n\n\nJul 12, 2022\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nxaringanExtra v0.6.0 ‚Äî Now on CRAN!\n\n\n\n\n\n\nR\n\n\nMy Projects\n\n\nxaringan\n\n\nxaringanExtra\n\n\nSlides\n\n\nAnnouncement\n\n\n\nxaringanExtra v0.6.0 is now available on CRAN! Plus some new features. \n\n\n\n\n\nJun 7, 2022\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nSaving Daylight Time?\n\n\n\n\n\n\nR\n\n\nVisualization\n\n\nggplot2\n\n\n\nHow much daylight do cities across the world get throughout the year? Does Daylight Saving Time really save any daylight? A visualization to explore these questions. \n\n\n\n\n\nMar 12, 2022\n\n\n25 min\n\n\n\n\n\n\n\n\n\n\n\n\nWordle Guess Helper\n\n\n\n\n\n\nR\n\n\nJavaScript\n\n\njs4shiny\n\n\n\nPicking words to guess in Wordle. It‚Äôs only fun if you can solve it with R. \n\n\n\n\n\nFeb 21, 2022\n\n\n28 min\n\n\n\n\n\n\n\n\n\n\n\n\nbranchMover: A Shiny app for moving the default branch of your GitHub repos\n\n\n\n\n\n\nR\n\n\nusethis\n\n\nGitHub\n\n\ngit\n\n\nApps\n\n\nShiny\n\n\nRStudio\n\n\n\nIntroducing branchMover, a Shiny app slash RStudio addin for coordinated default branch changes across your GitHub repositories. \n\n\n\n\n\nNov 2, 2021\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nPull Request Flow with usethis\n\n\n\n\n\n\nR\n\n\nusethis\n\n\nProductivity\n\n\nWorkflow\n\n\n\nChoose your own adventure and get in the ‚Äòusethis‚Äô pull request flow with this flow chart.\n\n\n\n\n\nOct 7, 2021\n\n\n25 min\n\n\n\n\n\n\n\n\n\n\n\n\nSigned and verified: signed git commits with Keybase and RStudio\n\n\n\n\n\n\nR\n\n\ngit\n\n\nGitHub\n\n\nRStudio\n\n\nTutorials\n\n\n\nSetting up signed git commits with a Keybase GPG key that works with RStudio.\n\n\n\n\n\nSep 13, 2021\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nCreate a GitHub issue from a reprex with shrtcts\n\n\n\n\n\n\nR\n\n\nAddin\n\n\nShortcuts\n\n\nGitHub\n\n\nreprex\n\n\n\nTurn a reprex into a GitHub issue using a custom RStudio addin with shrtcts. \n\n\n\n\n\nSep 3, 2021\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nQuestions, answers, and reprexes\n\n\n\n\n\n\nTeaching\n\n\nLearning\n\n\nCSS\n\n\nProgramming\n\n\nreprex\n\n\n\nA ‚ÄúCSS Battle‚Äù YouTube video made me ponder metacognition in programming. I had questions, reprex gave me answers.\n\n\n\n\n\nMar 16, 2021\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nLittle Inline Color Boxes\n\n\n\n\n\n\nR\n\n\nTips\n\n\nColor\n\n\nWeb Development\n\n\nhtmltools\n\n\n\nLittle cirlces with color previews, with R.\n\n\n\n\n\nMar 12, 2021\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nPrinting xaringan slides with chromote\n\n\n\n\n\n\nR\n\n\nxaringan\n\n\nxaringanExtra\n\n\nSlides\n\n\nTips\n\n\nScripts\n\n\n\nCreate PDF versions of complicated xaringan slides using {chromote} and a little magic.\n\n\n\n\n\nJan 25, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nxaringan Playground: Using xaringan to learn web development\n\n\n\n\n\n\nR\n\n\nxaringan\n\n\nPresentation\n\n\nCSS\n\n\nWeb Development\n\n\n\nMaking slides with xaringan is a great way to learn more about CSS and web development. \n\n\n\n\n\nJan 21, 2021\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nSetting up a new MacBook Pro\n\n\n\n\n\n\nR\n\n\nTips\n\n\nProgramming\n\n\nTwitter\n\n\n\nA big post with all the Mac apps and command line utilities I use everyday.\n\n\n\n\n\nDec 1, 2020\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nA Calendar in Your R Console\n\n\n\n\n\n\nR\n\n\nScripts\n\n\nProductivity\n\n\nInteresting Uses of R\n\n\n\nPrint a nicely-formatted calendar in your R console. \n\n\n\n\n\nSep 21, 2020\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nR Colors in CSS for R Markdown HTML Documents\n\n\n\n\n\n\nColor\n\n\nxaringan\n\n\nTips\n\n\nCSS\n\n\nR Markdown\n\n\nR\n\n\nWeb Development\n\n\nShiny\n\n\nhtmltools\n\n\n\nUse R‚Äôs colors in HTML R Markdown documents, slides and Shiny apps with this set of CSS stylesheets.\n\n\n\n\n\nSep 14, 2020\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nSharing Your xaringan Slides\n\n\n\n\n\n\nR\n\n\nxaringan\n\n\nxaringanExtra\n\n\nSlides\n\n\n\nHow to share your xaringan slides in style, on social media sites and embedded in your web page.\n\n\n\n\n\nSep 1, 2020\n\n\n11 min\n\n\n\n\n\n\n\n\n\n\n\n\nVideo: Debugging JavaScript You Wrote in R\n\n\n\n\n\n\nR\n\n\nRStudio\n\n\nJavaScript\n\n\nDebugging\n\n\nWeb Development\n\n\nhtmlwidgets\n\n\nVideo\n\n\n\nA pseudo-live-streamed walkthrough as I debug some buggy JavaScript written in R for a {reactable} htmlwidget.\n\n\n\n\n\nJul 20, 2020\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nLet‚Äôs move on from iris\n\n\n\n\n\n\nR\n\n\nScripts\n\n\n\nAbout iris and how to move on.\n\n\n\n\n\nJun 9, 2020\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nBetter Progressive xaringan Slides with CSS and :last-of-type\n\n\n\n\n\n\nR\n\n\nxaringan\n\n\nxaringan Tip\n\n\nCSS\n\n\nSlides\n\n\n\nA few CSS rules for focused, progressively revealed lists and R code chunks in xaringan slides.\n\n\n\n\n\nMay 20, 2020\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nAnnouncing xaringanthemer v0.3.0!\n\n\n\n\n\n\nMy Projects\n\n\nAnnouncement\n\n\nxaringanthemer\n\n\nxaringan\n\n\nThemes\n\n\n\nxaringanthemer is now on CRAN with lots of new features to make your xaringan slides awesome.\n\n\n\n\n\nMay 8, 2020\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nMake A Shortcut for Anything in RStudio with shrtcts\n\n\n\n\n\n\nRStudio\n\n\nR\n\n\nMy Projects\n\n\nAddin\n\n\nShortcuts\n\n\n\nQuickly turn any R function or code into an RStudio addin with {shrtcts}\n\n\n\n\n\nMay 2, 2020\n\n\n8 min\n\n\n\n\n\n\n\n\n\n\n\n\nXML: The Recursive Programming Workout\n\n\n\n\n\n\nR\n\n\nTips\n\n\nXML\n\n\n\nIt‚Äôs like programming Crossfit but with less sweating.\n\n\n\n\n\nNov 5, 2019\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nxaringan Tip: Add A Logo to All of Your Slides\n\n\n\n\n\n\nR\n\n\nTips\n\n\nxaringan\n\n\n\nAdd a logo to all of your xaringan slides without using a background image.\n\n\n\n\n\nOct 16, 2019\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nShiny Tip: Choose Where to Run App with an Option\n\n\n\n\n\n\nR\n\n\nShiny\n\n\nTips\n\n\n\nQuick Shiny Tip: How to use the shiny.launch.browser option to choose where RStudio runs your app. \n\n\n\n\n\nOct 13, 2019\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nTwitter‚Äôs Feelings About Programming Languages\n\n\n\n\n\n\nR\n\n\nrtweet\n\n\nData Analysis\n\n\nVisualization\n\n\nProgramming\n\n\n\nA deep dive into an informal, free-form survey about experiences with programming languages.\n\n\n\n\n\nOct 8, 2019\n\n\n17 min\n\n\n\n\n\n\n\n\n\n\n\n\nCustom Discrete Color Scales for ggplot2\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nVisualization\n\n\nTips\n\n\n\nBuilding discrete color scales for ggplot2 with some cool features for binary categorical variables. \n\n\n\n\n\nAug 15, 2019\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Colors of xcolor\n\n\n\n\n\n\nR\n\n\nScripts\n\n\nColor\n\n\n\nUsing the tidyverse to gather the colors defined in the LaTeX package xcolor\n\n\n\n\n\nAug 7, 2019\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nA Printable Custom Weekly Planner with ggplot2\n\n\n\n\n\n\nR\n\n\nggplot2\n\n\nProductivity\n\n\nScripts\n\n\n\nUse ggplot2 to organize your life.\n\n\n\n\n\nJun 22, 2019\n\n\n12 min\n\n\n\n\n\n\n\n\n\n\n\n\nPopular Letters in Baby Names, Animated\n\n\n\n\n\n\nR\n\n\ngganimate\n\n\nggplot2\n\n\nVisualization\n\n\n\nAn animation of letter popularity in baby names\n\n\n\n\n\nMay 17, 2019\n\n\n13 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Redacted, Text-Extracted Mueller Report\n\n\n\n\n\n\nR\n\n\nText\n\n\nVisualization\n\n\n\nVisualizing extracted text from the Redacted Mueller Report using ggpage.\n\n\n\n\n\nApr 18, 2019\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nA Blogdown New Post Workflow with Github and Netlify\n\n\n\n\n\n\nblogdown\n\n\nR\n\n\nWriting\n\n\n\nA workflow for writing new posts built around GitHub pull requests and Netlify deploy previews.\n\n\n\n\n\nMar 18, 2019\n\n\n10 min\n\n\n\n\n\n\n\n\n\n\n\n\nStyle knitr Code Output Appearance in HTML with Custom CSS Classes\n\n\n\n\n\n\nR\n\n\nknitr\n\n\nR Markdown\n\n\nTips\n\n\n\nApply custom CSS classes to code chunk outputs to differentiate between regular outputs and messages, warnings, and errors. \n\n\n\n\n\nMar 5, 2019\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nPresident‚Äôs Day (As In: What Does President Trump Do With His Day?)\n\n\n\n\n\n\nR\n\n\nrtweet\n\n\nggplot2\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nFeb 27, 2019\n\n\n34 min\n\n\n\n\n\n\n\n\n\n\n\n\nTrump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game\n\n\n\n\n\n\nR\n\n\nrtweet\n\n\nShiny\n\n\nApps\n\n\n\nA silly game to guess the activity on Trump‚Äôs schedule while he was tweeting.\n\n\n\n\n\nFeb 9, 2019\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nA Holiday RStudio Theme\n\n\n\n\n\n\nR\n\n\nRStudio\n\n\nColor\n\n\nThemes\n\n\n\nBring yuletide cheer and seasons greatings to RStudio.\n\n\n\n\n\nDec 5, 2018\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nAnimate Xaringan Slide Transitions\n\n\n\n\n\n\nxaringan\n\n\nTips\n\n\nR\n\n\n\nAdd animations to xaringan slide transitions with animate.css\n\n\n\n\n\nDec 3, 2018\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Greatest Twitter Scheme of All Time?\n\n\n\n\n\n\nR\n\n\nTwitter\n\n\nrtweet\n\n\n\nIn which I investigate a very cool thing that someone claims to have done on Twitter. Using R and the rtweet package. \n\n\n\n\n\nAug 24, 2018\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nDecouple Code and Output in xaringan slides\n\n\n\n\n\n\nR\n\n\nxaringan\n\n\n\n\n\n\n\n\n\nAug 16, 2018\n\n\n7 min\n\n\n\n\n\n\n\n\n\n\n\n\nPandoc Syntax Highlighting Examples\n\n\n\n\n\n\npandoc\n\n\nWriting\n\n\nColor\n\n\nThemes\n\n\n\n\n\n\n\n\n\nJul 6, 2018\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nFind, count and list tags in all blogdown posts\n\n\n\n\n\n\nblogdown\n\n\nScripts\n\n\nR\n\n\nTips\n\n\n\n\n\n\n\n\n\nApr 29, 2018\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nMy ggridges Twitter Header\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\nMar 30, 2018\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nReuse Rmd fragments in package vignettes, README, blog posts and more\n\n\n\n\n\n\nR\n\n\nTips\n\n\nR Markdown\n\n\nWriting\n\n\n\nUse knitr‚Äôs ‚Äúchild chunks‚Äù to reuse bits of documentation. \n\n\n\n\n\nMar 5, 2018\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nAdd a Generated Table of Contents Anywhere in RMarkdown\n\n\n\n\n\n\nR Markdown\n\n\npandoc\n\n\nknitr\n\n\nR\n\n\nTips\n\n\nblogdown\n\n\nWriting\n\n\n\n\n\n\n\n\n\nFeb 28, 2018\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nSearching for ‚Äúgun control‚Äù after a mass shooting\n\n\n\n\n\n\nData Analysis\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nFeb 19, 2018\n\n\n19 min\n\n\n\n\n\n\n\n\n\n\n\n\nHighlight lines without breaking the code in Xaringan\n\n\n\n\n\n\nR\n\n\nPresentation\n\n\nxaringan\n\n\n\n\n\n\n\n\n\nJan 23, 2018\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nPresenting Smart Home Activity Profiles at INFORMS 2017\n\n\n\n\n\n\nPresentation\n\n\nData Analysis\n\n\nPersonal Data\n\n\nResearch\n\n\n\n\n\n\n\n\n\nOct 26, 2017\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nConvert R Markdown (Rmd) Files to R Scripts\n\n\n\n\n\n\npandoc\n\n\nR\n\n\nScripts\n\n\nWorkflow\n\n\nR Markdown\n\n\n\n\n\n\n\n\n\nOct 17, 2017\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nLookup Citation Counts with R and rcrossref\n\n\n\n\n\n\nR\n\n\nScripts\n\n\nResearch\n\n\nTips\n\n\n\n\n\n\n\n\n\nOct 21, 2014\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nQuote: Albert Einstein\n\n\n\n\n\n\n\n\n\n\n\nSep 9, 2014\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nUpcoming Code & Data Boot Camp\n\n\n\n\n\n\nData Analysis\n\n\nR\n\n\n\n\n\n\n\n\n\nApr 4, 2014\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nCream with your coffee?\n\n\n\n\n\n\nR\n\n\nShiny\n\n\n\n\n\n\n\n\n\nMar 4, 2014\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nRemember markdown compile commands with bash\n\n\n\n\n\n\nScripts\n\n\nTips\n\n\npandoc\n\n\nMarkdown\n\n\n\n\n\n\n\n\n\nJan 30, 2014\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Book of Us\n\n\n\n\n\n\nMusic\n\n\n\n\n\n\n\n\n\nJan 12, 2014\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nSitting by the fire\n\n\n\n\n\n\nPhotos\n\n\n\n\n\n\n\n\n\nJan 11, 2014\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nMath and Code\n\n\n\n\n\n\nR\n\n\nWriting\n\n\n\n\n\n\n\n\n\nJan 11, 2014\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nMinneapolis: INFORMS 2013\n\n\n\n\n\n\nPhotos\n\n\n\n\n\n\n\n\n\nOct 7, 2013\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe pupsters at the window\n\n\n\n\n\n\nPhotos\n\n\n\n\n\n\n\n\n\nSep 12, 2013\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nResponding to peer reviewers with Pandoc\n\n\n\n\n\n\ngit\n\n\nMarkdown\n\n\npandoc\n\n\nProductivity\n\n\nWorkflow\n\n\n\n\n\n\n\n\n\nAug 9, 2013\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe Pandoc Markdown rabbit hole\n\n\n\n\n\n\nApps\n\n\nMarkdown\n\n\nProductivity\n\n\nWorkflow\n\n\nWriting\n\n\n\n\n\n\n\n\n\nJul 31, 2013\n\n\n6 min\n\n\n\n\n\n\n\n\n\n\n\n\nUse Google Forms and R to track data easily\n\n\n\n\n\n\nApps\n\n\nData Analysis\n\n\nPersonal Data\n\n\nR\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nJul 24, 2013\n\n\n5 min\n\n\n\n\n\n\n\n\n\n\n\n\nUp and running‚Ä¶\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2013\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nThe End of Stanford?\n\n\n\n\n\n\n\n\n\n\n\nMay 30, 2013\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nGo Postal Sunset\n\n\n\n\n\n\nPhotos\n\n\n\n\n\n\n\n\n\nMay 28, 2013\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\nVisualizing PhysioNet Challenge Patient Data with R\n\n\n\n\n\n\nData Analysis\n\n\nR\n\n\nVisualization\n\n\n\n\n\n\n\n\n\nApr 11, 2013\n\n\n4 min\n\n\n\n\n\n\n\n\n\n\n\n\nEducating Engineers for Sustainability\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\nOct 3, 2012\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\nNew Website\n\n\n\n\n\n\nBlog\n\n\n\n\n\n\n\n\n\nJul 16, 2012\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/lets-move-on-from-iris/index.html",
    "href": "blog/lets-move-on-from-iris/index.html",
    "title": "Let‚Äôs move on from iris",
    "section": "",
    "text": "It‚Äôs time for iris to go. Use de_iris_my_repos() to help find references to iris in your public GitHub code so you can replace it with something better.\nIt only takes two lines to get started. First, check the source code on https://git.io/de-iris-my-repos. Then run these two lines in your R console:\nsource(\"https://git.io/de-iris-my-repos\")\niris_issues &lt;- de_iris_my_repos()\nFollow @gadenbuie¬† Star de-iris-my-repos¬† Fork de-iris-my-repos\nLast week, motivated by the Black Lives Matter movement and protests around the United States, Daniela Witten wrote a long and insightful Twitter thread about the origins of an often-used and completely boring dataset: iris.\nI‚Äôve long known about Ronald Fisher‚Äôs eugenicist past, but I admit that I have often thoughtlessly turned to iris when needing a small, boring data set to demonstrate a coding or data principle.\nBut Daniella and Timoth√©e Poisot are right: it‚Äôs time to retire iris."
  },
  {
    "objectID": "blog/lets-move-on-from-iris/index.html#other-options",
    "href": "blog/lets-move-on-from-iris/index.html#other-options",
    "title": "Let‚Äôs move on from iris",
    "section": "Other Options",
    "text": "Other Options\nI read Daniella‚Äôs thread and Timoth√©e‚Äôs blog post and immediately realized that I needed to be more thoughtful in my choice of datasets. There is absolutely no need for iris in my examples; there are plenty of other options available.\nI‚Äôm particularly excited about a new penguins dataset announced on Twitter by the amazing Allison Horst.\n\n\nThe Iris dataset feels really gross now.\n\n‚Äî Chris Albon (@chrisalbon) June 4, 2020\n\nHere‚Äôs a short list of other data sets you can turn to instead:\n\nAnything else in data().\nggplot2::mpg\nggplot2::diamonds\ndplyr::starwars\nnycflights13\nfivethirtyeight\nAny of the many #TidyTuesday datasets"
  },
  {
    "objectID": "blog/lets-move-on-from-iris/index.html#de-iris-your-repos",
    "href": "blog/lets-move-on-from-iris/index.html#de-iris-your-repos",
    "title": "Let‚Äôs move on from iris",
    "section": "De-Iris Your Repos",
    "text": "De-Iris Your Repos\nTo help us move on into an iris-free world, I‚Äôve created a small command-line utility to de_iris_my_repos().\nThe code is available on GitHub at gadenbuie/de-iris-my-repos, and it only takes two lines in your console to find any references to iris in your repositories and open an issue in each repo reminding you to kick iris out.\nde_iris_my_repos() won‚Äôt do anything without your explicit consent, but you should still probably check the R script before your source it.\n\nsource(\"https://git.io/de-iris-my-repos\")\niris_issues &lt;- de_iris_my_repos()\n\nWhen you run de_iris_my_repos() it searches your public code for mentions of iris and asks you if you want to open an issue in each repo. If you do, it opens an issue using the template in the screen shot below so that you can remember to remove iris.\n\n\n\nAn example issue opened by de_iris_my_repos().\n\n\n\nOptions\nA few options are available in de_iris_my_repos()\n\nChoose which GitHub user name to review, by default the user associated with the GitHub PAT used by gh\nSet dry_run = TRUE to return results without doing anything\nSet ask = FALSE to go ahead and open issues in all repositories\nUse extensions to provide a list of file types where iris might be found.\n\n\n\n\nAn example issue opened by de_iris_my_repos()."
  },
  {
    "objectID": "blog/math-and-code/index.html",
    "href": "blog/math-and-code/index.html",
    "title": "Math and Code",
    "section": "",
    "text": "This article is just a quick demonstration of the power of Octopress with Pandoc, and uses all of the common elements of a data analysis write up. In fact, I stole most of the content from a paper I‚Äôm working on.\nEverything written in this article could be witten directly in an .Rmd file, interactively written and then compiled in R Studio and published (nearly) straight to the web. This post includes code snippets, citations, tables and math. And it looks beautiful!\np.s. This is just a demo and isn‚Äôt intended to actually make sense ;-)\nThe term reliability refers to the ability of a test to consistently assess or measure the same underlying ability or concept, insofar as in a fully reliable test the only source of measurement error is random error. Cronbach‚Äôs coefficient alpha (Cronbach 1951) is the most popular metric for evaluating reliability, and is considered a measurement of internal consistency, or the level of inter-item correlation within a test administered to a single group.\nIn this study I compared the reliability of three final exam formats using the CTT package in R:\nrequire('CTT')\n\nitems &lt;- complete.all[, c(67, 39, 3:26)]\nitems &lt;- scaleMC(items)\n\n# Run item analysis\nital &lt;- list()\nital.mpgpa &lt;- list()\nfor(level in levels(items$Format)){\n  # Calculate format-level test reliability\n  # (ex: across all 'MC+PC' students)\n  ital[[level]] &lt;- reliability(items[items$Format == level, -1:-2])\n}\n\n# Extract alpha values from item analysis\nital.alpha &lt;- c()\nfor(name in names(ital)){\n  ital.alpha &lt;- c(ital.alpha, ital[[name]]$alpha)\n}\n\n# Print a nice table\nt.alpha &lt;- data.frame(\n  c(\"Partial Credit\", \"\", \"Dichotomous\",\"\"),\n  names(ital),\n  c('Spring 2013', 'Spring 2012', 'Spring 2012', 'Summer 2013'),\n  ital.alpha\n)\ncolnames(t.alpha) &lt;- c(\"Scoring\",'Format', 'Semester', \"Cronbach's Alpha\")\n\nkable(t.alpha)\n\n\nThe coefficient alpha estimation of reliability for each of the examination formats and scoring methods is shown in Table 8. For both the CR and MC+PC examination formats, alpha is near 0.74, while the dichotomously scored MC and MC+PC examination formats demonstrated reliability near 0.68.\n\nTable 8. Cronbach‚Äôs alpha for each final examination format \n\n\nScoring\nFormat\nSemester\nCronbach‚Äôs Alpha\n\n\n\n\nPartial Credit\nCR\nSpring 2013\n0.746\n\n\n\nMC+PC\nSpring 2012\n0.732\n\n\nDichotomous\nMC-PC\nSpring 2012\n0.675\n\n\n\nMC\nSummer 2013\n0.682"
  },
  {
    "objectID": "blog/math-and-code/index.html#reliability",
    "href": "blog/math-and-code/index.html#reliability",
    "title": "Math and Code",
    "section": "",
    "text": "This article is just a quick demonstration of the power of Octopress with Pandoc, and uses all of the common elements of a data analysis write up. In fact, I stole most of the content from a paper I‚Äôm working on.\nEverything written in this article could be witten directly in an .Rmd file, interactively written and then compiled in R Studio and published (nearly) straight to the web. This post includes code snippets, citations, tables and math. And it looks beautiful!\np.s. This is just a demo and isn‚Äôt intended to actually make sense ;-)\nThe term reliability refers to the ability of a test to consistently assess or measure the same underlying ability or concept, insofar as in a fully reliable test the only source of measurement error is random error. Cronbach‚Äôs coefficient alpha (Cronbach 1951) is the most popular metric for evaluating reliability, and is considered a measurement of internal consistency, or the level of inter-item correlation within a test administered to a single group.\nIn this study I compared the reliability of three final exam formats using the CTT package in R:\nrequire('CTT')\n\nitems &lt;- complete.all[, c(67, 39, 3:26)]\nitems &lt;- scaleMC(items)\n\n# Run item analysis\nital &lt;- list()\nital.mpgpa &lt;- list()\nfor(level in levels(items$Format)){\n  # Calculate format-level test reliability\n  # (ex: across all 'MC+PC' students)\n  ital[[level]] &lt;- reliability(items[items$Format == level, -1:-2])\n}\n\n# Extract alpha values from item analysis\nital.alpha &lt;- c()\nfor(name in names(ital)){\n  ital.alpha &lt;- c(ital.alpha, ital[[name]]$alpha)\n}\n\n# Print a nice table\nt.alpha &lt;- data.frame(\n  c(\"Partial Credit\", \"\", \"Dichotomous\",\"\"),\n  names(ital),\n  c('Spring 2013', 'Spring 2012', 'Spring 2012', 'Summer 2013'),\n  ital.alpha\n)\ncolnames(t.alpha) &lt;- c(\"Scoring\",'Format', 'Semester', \"Cronbach's Alpha\")\n\nkable(t.alpha)\n\n\nThe coefficient alpha estimation of reliability for each of the examination formats and scoring methods is shown in Table 8. For both the CR and MC+PC examination formats, alpha is near 0.74, while the dichotomously scored MC and MC+PC examination formats demonstrated reliability near 0.68.\n\nTable 8. Cronbach‚Äôs alpha for each final examination format \n\n\nScoring\nFormat\nSemester\nCronbach‚Äôs Alpha\n\n\n\n\nPartial Credit\nCR\nSpring 2013\n0.746\n\n\n\nMC+PC\nSpring 2012\n0.732\n\n\nDichotomous\nMC-PC\nSpring 2012\n0.675\n\n\n\nMC\nSummer 2013\n0.682"
  },
  {
    "objectID": "blog/math-and-code/index.html#cronbachs-alpha",
    "href": "blog/math-and-code/index.html#cronbachs-alpha",
    "title": "Math and Code",
    "section": "Cronbach‚Äôs Alpha",
    "text": "Cronbach‚Äôs Alpha\nAs described above, Cronbach‚Äôs alpha, \\(\\alpha\\), is really just:\n\\[\\alpha = \\frac{K}{K-1} \\left( 1 - \\frac{\\sum^{K}_{i=1} \\sigma^2_{Y_i}}{\\sigma^2_X} \\right)\\]\nwhere \\(\\sigma^2_X\\) is the variance of the observed total test scores and \\(\\sigma^2_{Y_i}\\) is the variance of component \\(i\\) for the current sample of persons1."
  },
  {
    "objectID": "blog/math-and-code/index.html#footnotes",
    "href": "blog/math-and-code/index.html#footnotes",
    "title": "Math and Code",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFrom http://en.wikipedia.org/wiki/Cronbach's_alpha‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/pandoc-syntax-highlighting-examples/index.html",
    "href": "blog/pandoc-syntax-highlighting-examples/index.html",
    "title": "Pandoc Syntax Highlighting Examples",
    "section": "",
    "text": "The R Markdown book lists many syntax highlighting color schemes:\nWhich is the same as running pandoc --list-highlight-styles (see Syntax Highlighting in the pandoc manual).1\nBut I couldn‚Äôt find a gallery for choosing among these syntax styles, so here‚Äôs a quick comparison.\nUpdate: rmarkdown::pdf_document() doesn‚Äôt currently accept breezedark as a highlight style, but you can use the pandoc_args parameter to request this style (added in pandoc 1.19.2):"
  },
  {
    "objectID": "blog/pandoc-syntax-highlighting-examples/index.html#footnotes",
    "href": "blog/pandoc-syntax-highlighting-examples/index.html#footnotes",
    "title": "Pandoc Syntax Highlighting Examples",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nNote that at the time of this writing 2023-02-05, pandoc has a new highlighting style breezedark that rmarkdown::pdf_document rejects. Also, textmate seems to have been deprecated because it is an HTML higlight style, so it is also rejected by pdf_document.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/presidents-day/index.html",
    "href": "blog/presidents-day/index.html",
    "title": "President‚Äôs Day (As In: What Does President Trump Do With His Day?)",
    "section": "",
    "text": "On February 3rd, Axios released President Trump‚Äôs daily schedule. As in many other areas of his political career, Trump has broken with tradition by hiding his schedule from public view.\nIn addition to a set of re-typed PDF files, Axios also created a Google Spreadsheet containing the president‚Äôs schedule and notes about the activities. If you‚Äôre interesting in reading about how that task could be accomplished, I highly recommend Ma√´lle Salmon‚Äôs post on rectangling the tables in the PDF files.\nThe leak and subsequent release by Axios provide unique insight into Trump‚Äôs daily activities, which are dominated by a large block of time referred to as Executive Time. Reportedly, Trump hated following a strict daily schedule, so former chief-of-staff John Kelly introduced the concept of Executive Time: unstructured time when the president reads watches news, makes phone calls, and writes emails tweets.\nI won‚Äôt comment extensively on what these schedules mean‚Äîfor more on that angle, see reporting from Axios, Vox, Politico and others.\nInstead, I‚Äôll use this post to visualize the president‚Äôs work day and tweeting habits and a demonstrate how to use R, plot.ly and the tools of the tidyverse to create interactive and static visualizations to try to make sense of what the president does on a daily basis."
  },
  {
    "objectID": "blog/presidents-day/index.html#the-presidents-daily-8am-to-5pm-schedule",
    "href": "blog/presidents-day/index.html#the-presidents-daily-8am-to-5pm-schedule",
    "title": "President‚Äôs Day (As In: What Does President Trump Do With His Day?)",
    "section": "The President‚Äôs Daily 8am to 5pm Schedule",
    "text": "The President‚Äôs Daily 8am to 5pm Schedule\nAxios‚Äô article on Trump‚Äôs private schedule includes an interactive view of the president‚Äôs workday schedule from 8 a.m. to 5 p.m. Here, I recreate the same visualization, with each activity colored according to the activity‚Äôs category. (Note these plots look best on desktop devices.)\nHover over any time slot to view more details about the activity at that time. You can also toggle activity categories ‚Äî try removing everything except Meetings, Lunches, and Events, it‚Äôs unbelievable.\n\n\n\n\n\n\nView static image of the plot. Expand the section below for a behind-the-scenes look at this visualization.\n\n\n\n\n\n\nHow This Was Made‚Ä¶\n\n\n\n\n\n\nThe pipeline for building this visualization is a fairly standard loading and transformation of the source data with readr and dplyr, followed by building the visualization in ggplot2 and passing off to plotly for the interactive parts. On the other hand, I created a number of helper functions and constants that I reused throughout this post, so there‚Äôs quite a bit of code and preamble to get to the actual plot making.\nlibrary(tidyverse)\nlibrary(plotly)\nlibrary(lubridate)\nlibrary(glue)\nlibrary(hrbrthemes)\nlibrary(showtext)\nlibrary(sysfonts)\n\nLoad the Axios Data\n\n# Convert datetime to decimal hour of day\nin_hours &lt;- function(x) {\n  hour(x) + minute(x)/60 + second(x)/60^2\n}\n\nexecutive_categories &lt;- c(\n  \"executive_time\" = \"Executive Time\",\n  \"event\"   = \"Event\",\n  \"lunch\"   = \"Lunch\",\n  \"meeting\" = \"Meeting\",\n  \"no_data\" = \"Unknown\",\n  \"travel\"  = \"Travel\"\n)\n\n# Exec Time Downloaded from http://bit.ly/2Sk9Vj7\nexec_time &lt;-\n  read_csv(\n    here::here(\n      \"_data\", \"trump-exec-time\",\n      \"axios_trump_schedule_2018-11-07--2019-02-02.csv\"\n    ),\n    col_types = cols(.default = col_character())\n  ) %&gt;%\n  mutate(\n    # Convert time start/end to datetime\n    event_id   = row_number(),\n    time_start = paste(date, time_start),\n    time_end   = paste(date, time_end),\n    time_start = ymd_hm(time_start, tz = \"America/New_York\"),\n    time_end   = ymd_hm(time_end, tz = \"America/New_York\"),\n    time_end   = if_else(time_start &gt; time_end,\n                         time_end + hours(24), time_end),\n    # Recode the activity category with nicer labels\n    top_category = factor(top_category,\n                          levels = names(executive_categories),\n                          labels = executive_categories)\n  ) %&gt;%\n  mutate(\n    # Create label pieces for plotly hover text\n    label_title    = glue(\"&lt;b&gt;{top_category}&lt;/b&gt;\"),\n    has_uniq_title = tolower(top_category) != tolower(listed_title),\n    has_subtitle   = has_uniq_title & !is.na(listed_title),\n    label_subtitle = if_else(has_subtitle,\n                             glue(\"&lt;br&gt;&lt;em&gt;{listed_title}&lt;/em&gt;\"), \"\"),\n    has_location   = !is.na(listed_location),\n    label_location = if_else(has_location,\n                             glue(\"&lt;br&gt;&lt;em&gt;{listed_location}&lt;/em&gt;\"), \"\"),\n    label_time     = glue(\n      \"&lt;br&gt;&lt;br&gt;{strftime(time_start, '%A, %B %e %H:%M')} \",\n      \"to {strftime(time_end, '%H:%M')}\"),\n    has_notes      = !is.na(notes),\n    label_notes    = if_else(has_notes, paste0(\"&lt;br&gt;&lt;br&gt;\", notes), \"\"),\n    # Compose final tooltip text\n    label = paste0(label_title, label_subtitle, label_location,\n                   label_time, label_notes)\n  ) %&gt;%\n  mutate(\n    # truncate any activities that span 8am or 5pm\n    time_start = if_else(\n      in_hours(time_start) &lt; 8 & in_hours(time_end) &gt; 8,\n      floor_date(time_start, \"day\") + hours(8),\n      time_start\n    ),\n    time_end = if_else(\n      in_hours(time_start) &lt; 17 & in_hours(time_end) &gt; 17,\n      floor_date(time_end, \"day\") + hours(17),\n      time_end\n    ),\n    # create 5 minute increments \"inside\" each activity\n    time_inc   = map2(time_start, time_end, seq, by = \"5 mins\")\n  ) %&gt;%\n  select(event_id, time_start, time_end, time_inc,\n         listed_title, top_category, label)\n\nglimpse(exec_time)\n\n\n\nRows: 577\nColumns: 7\n$ event_id     &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17‚Ä¶\n$ time_start   &lt;dttm&gt; 2018-11-07 08:00:00, 2018-11-07 11:00:00, 2018-11-07 11:‚Ä¶\n$ time_end     &lt;dttm&gt; 2018-11-07 11:00:00, 2018-11-07 11:30:00, 2018-11-07 12:‚Ä¶\n$ time_inc     &lt;list&gt; &lt;2018-11-07 08:00:00, 2018-11-07 08:05:00, 2018-11-07 08‚Ä¶\n$ listed_title &lt;chr&gt; \"Executive time\", \"Meeting with the chief of staff\", \"Exe‚Ä¶\n$ top_category &lt;fct&gt; Executive Time, Meeting, Executive Time, Lunch, Executive‚Ä¶\n$ label        &lt;chr&gt; \"&lt;b&gt;Executive Time&lt;/b&gt;&lt;br&gt;&lt;em&gt;Oval office&lt;/em&gt;&lt;br&gt;&lt;br&gt;Wed‚Ä¶\n\n\n\n\nPrepare to Make a Plot\nTo build the plot, I first created several helper functions for the plot labels, scales, and data filtering. I also set the global plot theme, and created a few constants that I used across several plots in this post.\n\nHelper Functions\n\nThe first helper adds \"am\" or \"pm\" to an integer hour for easy-to-read labels on the x-axis time of day.\n\nam_pm &lt;- function(x) {\n  x &lt;- floor(x)\n  y &lt;- paste(x)\n  y[x &lt; 1] &lt;- \"12 am\"\n  y[x &gt; 1 & x &lt; 12] &lt;- paste(y[x &gt; 1 & x &lt; 12], \"am\")\n  y[x == 12] &lt;- \"12 pm\"\n  y[x &gt; 12] &lt;- paste(x[x &gt; 12] - 12, \"pm\")\n  y\n}\n\nam_pm(seq(8, 17, 3))\n\n[1] \"8 am\"  \"11 am\" \"2 pm\"  \"5 pm\" \n\n\nThe second helper function is copied directly from StackOverflow: Reverse datetime (POSIXct data) axis in ggplot, in one of the rare-but-beautiful moments when directly copying and pasting from SO works out perfectly. This gives me a rev_date() transformer function that can be passed to scale_y_continuous(trans = rev_date) to show the y-axis in chronological order with the earliest date starting at the top.\nA third helper function abstracts the code required to filter out the portion of the data set that belongs to the workday, which I use throughout this post. This function is a nice example of how tidyeval can be used for flexible dplyr wrapper functions.\n\nfilter_workday &lt;- function(\n  df,\n  start = hms::hms(0, 0, 8),\n  end = hms::hms(0, 0, 17),\n  start_var = time_start,\n  end_var = time_end\n) {\n  start_var &lt;- rlang::enquo(start_var)\n  end_var &lt;- rlang::enquo(end_var)\n\n  df %&gt;%\n    filter(\n      date(!!start_var) == date(!!end_var),\n      hms::as_hms(!!start_var) &gt;= start,\n      hms::as_hms(!!end_var) &lt;= end\n    )\n}\n\nFinally, another helper function creates the plot caption credits.\n\ncredit_caption &lt;- function(rtweet = FALSE) {\n  paste0(\n    \"\\nData:   Based on White House schedules released by Axios. http://bit.ly/2UGM0fw\",\n    if (rtweet) \"\\n           Tweets collected with {rtweet}. https://rtweet.info\",\n    \"\\nChart: @grrrck\"\n  )\n}\n\n\n\n\nPlot Themes\n\nI used showtext and sysfonts to match the fonts in the plot to the font used on this blog (PT Mono).\n\nsysfonts::font_add_google(\"PT Sans\")\nsysfonts::font_add_google(\"PT Sans Narrow\")\nsysfonts::font_add_google(\"PT Mono\")\nshowtext::showtext_auto()\n\nAnd I used hrbrthemes‚Äô excellent theme_ipsum() as my theme‚Äôs starting point.\n\ntheme_set(\n  hrbrthemes::theme_ipsum(\n    base_family       = \"PT Sans\",\n    base_size         = 20,\n    axis_title_family = \"PT Sans Narrow\",\n    axis_title_size   = 14,\n    axis_text_size    = 12,\n    axis_title_just   = \"c\"\n  ) +\n  theme(\n    plot.title       = element_text(hjust = 0.5),\n    plot.subtitle    = element_text(hjust = 0.5),\n    plot.margin      = margin(15, 15, 15, 15),\n    panel.grid.minor = element_blank(),\n    panel.background = element_blank(),\n    legend.position  = \"bottom\",\n    legend.key       = element_rect(\n      fill = \"white\", color = \"white\", linewidth = 4),\n    legend.key.width = unit(2, \"cm\"),\n    legend.text      = element_text(size = 9),\n    plot.caption     = element_text(\n      color = \"#85919b\", hjust = 0, size = 12, face = \"plain\")\n  )\n)\n\n\n\n\nPlot Constants\n\nI created a few constants for later reference: one stores date breaks for the time period covered by the Axios schedule, with labels on each Monday; and the other two store the color palette and labels for the executive activity categories. The colors were hand-selected from a picture of the Donald (I was expecting there to be more orange).\n\nplot_date_breaks &lt;- seq(\n  from = ymd_h(\"2018-11-12 0\", tz = \"America/New_York\"),\n  to   = max(exec_time$time_start),\n  by   = \"7 day\"\n)\n\nplot_date_breaks_labels &lt;- strftime(plot_date_breaks, \"%b %e\")\nplot_date_breaks &lt;- as.integer(plot_date_breaks)\n\nevent_type_colors &lt;- c(\n  \"Executive Time\" = \"#445566\",\n  \"Travel\"  = \"#997788\",\n  \"Lunch\"   = \"#7c9393\",\n  \"Meeting\" = \"#b7c6d6\",\n  \"Event\"   = \"#ddbbaa\",\n  \"Unknown\" = \"#d9dde0\")\n\nevent_type_labels &lt;- sub(\" \", \"\\n\", names(event_type_colors))\n\n\n\n\n\n\n\n\nBuild the Actual Plot Already!\nFinally, I pulled the schedule data and all of the above pieces together to build the interactive plot.\n\ng &lt;-\n  exec_time %&gt;%\n  mutate(\n    date = floor_date(time_start, \"day\"),\n    date = as.integer(date)\n  ) %&gt;%\n  filter_workday() %&gt;%\n  mutate_at(vars(time_start, time_end), in_hours) %&gt;%\n  ggplot() +\n  geom_rect(\n    aes(xmin = time_start,\n        xmax = time_end,\n        ymin = date - 3600 * 12,\n        ymax = date + 3600 * 12,\n        fill = top_category\n    )\n  ) +\n  scale_x_continuous(\n    breaks   = seq(8, 17, 3),\n    limits   = c(8, 17),\n    position = \"top\",\n    labels   = am_pm(seq(8, 17, 3)),\n    expand   = expansion(c(0.025, 0), 0)\n  ) +\n  scale_y_reverse(\n    # trans  = rev_date,\n    breaks = plot_date_breaks,\n    labels = plot_date_breaks_labels,\n    expand = expansion(c(0.025, 0), 0)\n  ) +\n  scale_fill_manual(\n    values = event_type_colors,\n    labels = event_type_labels\n  ) +\n  labs(x = \"Hour of the Day\", y = NULL, fill = NULL) +\n  ggtitle(\n    \"President Trump's Daily Schedule\",\n    \"November 7, 2018 through February 2, 2019\"\n  ) +\n  labs(caption = credit_caption(FALSE)) +\n  guides(fill = guide_legend(nrow = 1, label.position = \"bottom\")) +\n  theme(\n    axis.text.y = element_text(family = \"PT Mono\", size = 10),\n    plot.margin = margin(3, 0, 0, 0, unit = \"line\")\n  )\nplotly::ggplotly(g + aes(text = label), tooltip = \"label\") %&gt;%\n  plotly::layout(xaxis = list(side = \"top\", title = \"\"))\n\nAnd that‚Äôs it! Jump back up to see the final product."
  },
  {
    "objectID": "blog/presidents-day/index.html#the-presidents-daily-tweeting-schedule",
    "href": "blog/presidents-day/index.html#the-presidents-daily-tweeting-schedule",
    "title": "President‚Äôs Day (As In: What Does President Trump Do With His Day?)",
    "section": "The President‚Äôs Daily Tweeting Schedule",
    "text": "The President‚Äôs Daily Tweeting Schedule\nDonald Trump tweets about 5.1 tweets per working day within working hours. Why does this number feel so low? Then again, this represents 290 tweets published over 57 workdays and 128 tweets over the 24 weekend days in the same time period. Outside of work hours, the average rises to 8.7 tweets per 24-hour workday, or a total of 546 tweets on workdays and 203 tweets on weekends.\nBelow, each tweet sent by the President is shown as a dot over his private schedule. Hover over a tweet‚Äôs dot to read the text of the tweet.\n\n\n\n\n\n\nView static image of the plot. Expand the section below to learn more about how I gathered tweets from @realDonaldTrump, merged his tweets with the Axios schedules, and added them to the first plot.\nAlso, if you‚Äôre interested in exploring the timeline of tweets rendered as they appear on Twitter, Jonathan Sidi created an awesome Shiny app for exploring Trump‚Äôs tweets by category.\n\n\n\n\n\n\nHow This Was Made‚Ä¶\n\n\n\n\n\nThis visualization required the President‚Äôs tweets, which I downloaded using the excellent rtweet package. After matching the tweets with their corresponding activity, I modified the previous plot to soften the coloring of the presidential activities and added the tweets to the chart.\n\nDownload the President‚Äôs Tweets\nUsing the rtweet package makes downloading the tweets relatively straightforward. I only needed to add a loop to gather tweets beyond Twitter‚Äôs timeline API limits and ensure that I have all the tweets from the time period described in the leaked schedules.\n\n# Change to `if (TRUE)` to run\nif (FALSE) {\n  djt &lt;- NULL\n  keep_going &lt;- TRUE\n  while (keep_going) {\n    max_id &lt;- if (!is.null(djt$status_id)) max(as.numeric(djt$status_id))\n    djt.this &lt;- rtweet::get_timeline(\"realdonaldtrump\", n = 3200, max_id = max_id)\n    djt &lt;- bind_rows(djt, djt.this)\n    keep_going &lt;- min(djt$created_at) &gt; lubridate::ymd_h(\"2018-11-07 0\", tz = \"America/New_York\")\n    cat(\"\\nWe have\", nrow(djt), \"tweets...\")\n    Sys.sleep(15)\n  }\n  saveRDS(djt, here::here(\"_data\", \"djt-tweets-2018-09--2019-02.rds\"))\n}\n\n\n\nJoin Tweets with the President‚Äôs Schedule\nTo align the tweets with the President‚Äôs schedule, I rounded (actually, floored) the time stamp of each tweet down to the nearest 5 minute interval. Then, I joined the tweets to the schedule using the 5 minute intervals I created while importing the schedule (see above). This gives me the category and scheduled activity of each tweet.\n\ndjt_simple &lt;-\n  djt %&gt;%\n  filter(!is_retweet) %&gt;%\n  mutate(\n    created_at = with_tz(created_at, tzone = \"America/New_York\"),\n    time_inc = floor_date(created_at, \"5 min\")\n  ) %&gt;%\n  select(created_at, time_inc, text, status_id)\n\ndjt_joined_all &lt;-\n  exec_time %&gt;%\n  unnest(cols = time_inc) %&gt;%\n  filter(time_end != time_inc) %&gt;%\n  full_join(djt_simple, by = \"time_inc\") %&gt;%\n  select(\n    event_id, starts_with(\"time_\"), created_at,\n    listed_title, top_category, text\n  ) %&gt;%\n  filter(\n    !is.na(text)\n  ) %&gt;%\n  distinct(text, .keep_all = TRUE) %&gt;%\n  mutate(\n    hour = in_hours(created_at),\n    date = floor_date(created_at, \"day\"),\n    top_category = factor(top_category, executive_categories),\n    label_sched = if_else(\n      wday(created_at, abbr = FALSE, week_start = 1) &gt;= 6,\n      glue(\"&lt;br&gt;During: &lt;b&gt;Weekend&lt;/b&gt;\"),\n      glue(\n        \"&lt;br&gt;During: &lt;b&gt;{top_category}&lt;/b&gt;\",\n        \"&lt;br&gt;Sched: {strftime(time_start, '%I:%M')} \",\n        \"to {strftime(time_end, '%I:%M %p')}\")\n    ),\n    label = glue(\"{str_wrap(text, 50)}\",\n                 \"&lt;br&gt;&lt;i&gt;@realDonaldTrump \",\n                 \"{strftime(created_at, '%a, %b %e, %I:%M %p')}&lt;/i&gt;\",\n                 \"{label_sched}\")\n  ) %&gt;%\n  select(-time_start, -time_end, -label_sched) %&gt;%\n  arrange(created_at)\n\ndjt_joined &lt;-\n  djt_joined_all %&gt;%\n  filter(!is.na(top_category))\n\nFinally, I still need to do a little bit of processing to get these tweets to fit into the previous plot.\ndjt_workday &lt;-\n  djt_joined_all %&gt;%\n  filter_workday(\n    start_var = created_at, end_var = created_at\n  ) %&gt;%\n  filter(date &gt;= \"2018-11-07\", date &lt;= \"2019-02-02\") %&gt;%\n  select(-text)\nAt this point, there are a few versions of the tweets data set that I can use in different places. The djt_simple is a basic, bare-bones tibble of tweets.\n\n\n# A tibble: 758 √ó 4\n   created_at          time_inc            text                          statu‚Ä¶¬π\n   &lt;dttm&gt;              &lt;dttm&gt;              &lt;chr&gt;                         &lt;chr&gt;  \n 1 2018-11-07 01:27:01 2018-11-07 01:25:00 ‚ÄúThere‚Äôs only been 5 times i‚Ä¶ 106005‚Ä¶\n 2 2018-11-07 01:37:48 2018-11-07 01:35:00 ....unbelievably lucky to ha‚Ä¶ 106005‚Ä¶\n 3 2018-11-07 01:49:40 2018-11-07 01:45:00 .@DavidAsmanfox  ‚ÄúHow do the‚Ä¶ 106006‚Ä¶\n 4 2018-11-07 06:21:51 2018-11-07 06:20:00 Received so many Congratulat‚Ä¶ 106013‚Ä¶\n 5 2018-11-07 06:55:35 2018-11-07 06:55:00 Ron DeSantis showed great co‚Ä¶ 106013‚Ä¶\n 6 2018-11-07 07:07:51 2018-11-07 07:05:00 Those that worked with me in‚Ä¶ 106014‚Ä¶\n 7 2018-11-07 07:36:28 2018-11-07 07:35:00 I will be doing a news confe‚Ä¶ 106014‚Ä¶\n 8 2018-11-07 07:52:39 2018-11-07 07:50:00 To any of the pundits or tal‚Ä¶ 106015‚Ä¶\n 9 2018-11-07 08:04:02 2018-11-07 08:00:00 If the Democrats think they ‚Ä¶ 106015‚Ä¶\n10 2018-11-07 08:31:24 2018-11-07 08:30:00 In all fairness, Nancy Pelos‚Ä¶ 106016‚Ä¶\n# ‚Ä¶ with 748 more rows, and abbreviated variable name ¬π‚Äãstatus_id\n\n\nThe djt_joined_all variable holds the complete set of all tweets joined with the full schedule, meaning that there will be missing values where no tweets occurred in a 5 minute window or where the schedule data doesn‚Äôt cover a tweet.\n\n\n# A tibble: 1,182 √ó 9\n   time_inc            top_cat‚Ä¶¬π text  event‚Ä¶¬≤ created_at          liste‚Ä¶¬≥  hour\n   &lt;dttm&gt;              &lt;fct&gt;     &lt;chr&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;dbl&gt;\n 1 2018-10-24 08:35:00 &lt;NA&gt;      Bria‚Ä¶      NA 2018-10-24 08:35:15 &lt;NA&gt;     8.59\n 2 2018-11-02 09:45:00 &lt;NA&gt;      Wow!‚Ä¶      NA 2018-11-02 09:46:49 &lt;NA&gt;     9.78\n 3 2018-11-06 01:35:00 &lt;NA&gt;      A fa‚Ä¶      NA 2018-11-06 01:36:22 &lt;NA&gt;     1.61\n 4 2018-11-27 07:30:00 &lt;NA&gt;      The ‚Ä¶      NA 2018-11-27 07:30:37 &lt;NA&gt;     7.51\n 5 2018-11-29 19:00:00 &lt;NA&gt;      As R‚Ä¶      NA 2018-11-29 19:04:23 &lt;NA&gt;    19.1 \n 6 2018-12-15 11:15:00 &lt;NA&gt;      The ‚Ä¶      NA 2018-12-15 11:15:38 &lt;NA&gt;    11.3 \n 7 2018-12-22 20:45:00 &lt;NA&gt;      Bret‚Ä¶      NA 2018-12-22 20:48:23 &lt;NA&gt;    20.8 \n 8 2018-12-23 11:55:00 &lt;NA&gt;      I ju‚Ä¶      NA 2018-12-23 11:59:22 &lt;NA&gt;    12.0 \n 9 2019-01-13 22:15:00 &lt;NA&gt;      ....‚Ä¶      NA 2019-01-13 22:18:31 &lt;NA&gt;    22.3 \n10 2019-01-30 06:30:00 &lt;NA&gt;      ....‚Ä¶      NA 2019-01-30 06:34:31 &lt;NA&gt;     6.58\n# ‚Ä¶ with 1,172 more rows, 2 more variables: date &lt;dttm&gt;, label &lt;glue&gt;, and\n#   abbreviated variable names ¬π‚Äãtop_category, ¬≤‚Äãevent_id, ¬≥‚Äãlisted_title\n\n\nAnd djt_workday contains the tweets within the period covered by the Axios schedules and during workday hours.\n\n\n# A tibble: 418 √ó 9\n   time_inc            top_cat‚Ä¶¬π label event‚Ä¶¬≤ created_at          liste‚Ä¶¬≥  hour\n   &lt;dttm&gt;              &lt;fct&gt;     &lt;glu&gt;   &lt;int&gt; &lt;dttm&gt;              &lt;chr&gt;   &lt;dbl&gt;\n 1 2018-11-07 08:00:00 Executiv‚Ä¶ If t‚Ä¶       1 2018-11-07 08:04:02 Execut‚Ä¶  8.07\n 2 2018-11-07 08:30:00 Executiv‚Ä¶ In a‚Ä¶       1 2018-11-07 08:31:24 Execut‚Ä¶  8.52\n 3 2018-11-07 10:35:00 Executiv‚Ä¶ Acco‚Ä¶       1 2018-11-07 10:39:11 Execut‚Ä¶ 10.7 \n 4 2018-11-07 14:40:00 Executiv‚Ä¶ We a‚Ä¶       5 2018-11-07 14:44:11 Execut‚Ä¶ 14.7 \n 5 2018-11-07 14:40:00 Executiv‚Ä¶ ....‚Ä¶       5 2018-11-07 14:44:12 Execut‚Ä¶ 14.7 \n 6 2018-11-09 09:50:00 Travel    ‚ÄúPre‚Ä¶      22 2018-11-09 09:54:15 Depart‚Ä¶  9.90\n 7 2018-11-09 10:55:00 Travel    .@Br‚Ä¶      22 2018-11-09 10:55:25 Depart‚Ä¶ 10.9 \n 8 2018-11-09 10:55:00 Travel    You ‚Ä¶      22 2018-11-09 10:58:56 Depart‚Ä¶ 11.0 \n 9 2018-11-09 11:50:00 Travel    As s‚Ä¶      22 2018-11-09 11:52:19 Depart‚Ä¶ 11.9 \n10 2018-11-09 12:10:00 Travel    Jeff‚Ä¶      22 2018-11-09 12:10:02 Depart‚Ä¶ 12.2 \n# ‚Ä¶ with 408 more rows, 2 more variables: date &lt;dttm&gt;, weekend &lt;chr&gt;, and\n#   abbreviated variable names ¬π‚Äãtop_category, ¬≤‚Äãevent_id, ¬≥‚Äãlisted_title\n\n\n\n\nAdd Tweets to the Schedule Plot\nTo build the second plot, I had to manually tweak the first plot to adjust the transparency of the geom_rect layer and then overlay the tweets as points.\n# Modify geom_rect (only layer) to reduce transparency\ng_subdued &lt;- g\ng_subdued$layers[[1]]$aes_params$alpha &lt;- 0.6\n\n# Add tweets to the plot\ng_subdued &lt;-\n  g_subdued +\n  ggtitle(\"President Trump's Daily Tweeting\") +\n  geom_point(\n    data = djt_workday,\n    aes(x = hour, y = as.integer(date + 3600), text = label),\n    color = \"#2c3741\",\n    size = 0.8\n  )\nAt this point, the plot is almost ready to go, except for the fact that the tooltip text will appear for the underlying activity layers. Fortunately, once again StackOverflow comes to the rescue. To disable the tooltip, I have to save the plotly object and change the $hoverinfo value to \"none\" for each of the data layers of the activity categories.\ngpltly &lt;-\n  plotly::ggplotly(g_subdued, tooltip = \"label\") %&gt;%\n  plotly::layout(xaxis = list(side = \"top\", title = \"\"))\n\n# remove hover labels for time category layers (6 categories)\n# thanks: https://stackoverflow.com/a/45802923/2022615\nfor (i in 1:6) {\n  gpltly$x$data[[i]]$hoverinfo &lt;- \"none\"\n}\nHead back to the visualization to view the final product and explore Trump‚Äôs delusional ranting tweets."
  },
  {
    "objectID": "blog/presidents-day/index.html#how-much-time-is-spent-in-executive-time",
    "href": "blog/presidents-day/index.html#how-much-time-is-spent-in-executive-time",
    "title": "President‚Äôs Day (As In: What Does President Trump Do With His Day?)",
    "section": "How much time is spent in Executive Time?",
    "text": "How much time is spent in Executive Time?\nLooking at the above plots, it‚Äôs really striking how much time is unstructured Executive Time in Trump‚Äôs schedule. But how much of the day is spent in each activity group?\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\nThe first step is to calculate the total time as a percentage of the 8am to 5pm workday spent in each time category. This data frame will be used for several plots.\nOne tricky point is that there are piece of the schedule that are explicitly marked as ‚ÄúUnknown‚Äù (or ‚Äúno data‚Äù) in the Axios data, so I calculate the total percent of time spent in other categories and subtract this value from 1 to recover the complete unaccounted-for time.\n\nexec_time_total &lt;-\n  exec_time %&gt;%\n  filter(between(hour(time_start), 8, 17), hour(time_start) &lt; 17) %&gt;%\n  mutate(\n    date = floor_date(time_start, \"day\"),\n    n = difftime(time_end, time_start, units = \"mins\"),\n    n = as.numeric(n)\n  ) %&gt;%\n  group_by(date, top_category) %&gt;%\n  summarize(pct = sum(n) / (60 * 9)) %&gt;%\n  ungroup() %&gt;%\n  # Get unaccounted time for each date (unknown or unlabelled)\n  nest(-date) %&gt;%\n  mutate(\n    total = map_dbl(data, ~ {\n      filter(., top_category != \"Unknown\") %&gt;%\n        pull(pct) %&gt;%\n        sum()\n    }),\n    unaccounted = 1 - total,\n  ) %&gt;%\n  unnest() %&gt;%\n  spread(top_category, pct, fill = 0) %&gt;%\n  mutate(`Unknown` = unaccounted) %&gt;%\n  select(-total, -unaccounted) %&gt;%\n  gather(\"top_category\", \"pct\", -date) %&gt;%\n  mutate(top_category = factor(top_category, rev(names(event_type_colors))))\n\nexec_time_total %&gt;%\n  arrange(date, desc(pct))\n\n# A tibble: 378 √ó 3\n   date                top_category      pct\n   &lt;dttm&gt;              &lt;fct&gt;           &lt;dbl&gt;\n 1 2018-11-07 00:00:00 Executive Time 0.833 \n 2 2018-11-07 00:00:00 Lunch          0.111 \n 3 2018-11-07 00:00:00 Meeting        0.0556\n 4 2018-11-07 00:00:00 Event          0     \n 5 2018-11-07 00:00:00 Unknown        0     \n 6 2018-11-07 00:00:00 Travel         0     \n 7 2018-11-08 00:00:00 Executive Time 0.5   \n 8 2018-11-08 00:00:00 Meeting        0.222 \n 9 2018-11-08 00:00:00 Lunch          0.111 \n10 2018-11-08 00:00:00 Unknown        0.0833\n# ‚Ä¶ with 368 more rows\n\n\nThe above tibble contains a summary of time use by day, but the first plot requires a full summary of all days in the schedule. The following code chunk caculates total hours spent in each group and creates a text label that is used to label the regions of the stacked bar in the plot.\n\nexec_time_hours &lt;-\n  exec_time_total %&gt;%\n  # Only the days covered by the schedule\n  filter(!(pct == 1 & top_category == \"Unknown\")) %&gt;%\n  group_by(top_category) %&gt;%\n  summarize(hours = sum(pct * 60 * 90)) %&gt;%\n  arrange(desc(top_category)) %&gt;%\n  mutate(\n    pct = hours / sum(hours),\n    pct_upto = cumsum(pct),\n    label = glue(\"{top_category}\\n\",\n                 \"{scales::percent(pct, accuracy = 1)}\"),\n    label = if_else(top_category == \"Unknown\", \"\", paste(label))\n  )\n\nexec_time_hours\n\n# A tibble: 6 √ó 5\n  top_category    hours    pct pct_upto label                \n  &lt;fct&gt;           &lt;dbl&gt;  &lt;dbl&gt;    &lt;dbl&gt; &lt;chr&gt;                \n1 Executive Time 162650 0.591     0.591 \"Executive Time\\n59%\"\n2 Travel          23350 0.0848    0.675 \"Travel\\n8%\"         \n3 Lunch           23400 0.0850    0.760 \"Lunch\\n8%\"          \n4 Meeting         45350 0.165     0.925 \"Meeting\\n16%\"       \n5 Event           13850 0.0503    0.975 \"Event\\n5%\"          \n6 Unknown          6800 0.0247    1     \"\"                   \n\n\nFinally, I create the plot using geom_col() to create a stacked bar chart, that I then rotate to be horizontal with coord_flip(). The bar labels are added as a text annotation, and I do a little adjustment to make sure the annotations fit in the plot and to hide the axis that aren‚Äôt relevant.\n\nggplot(exec_time_hours) +\n  aes(x = 1,\n      y = pct,\n      fill = top_category) +\n  geom_col() +\n  geom_text(\n    aes(x = 0.35, y = pct_upto - pct/2, label = label),\n    color = \"grey30\",\n    family = \"PT Sans\"\n  ) +\n  scale_fill_manual(\n    values = event_type_colors,\n    labels = rev(event_type_labels),\n    guide = FALSE\n  ) +\n  scale_x_continuous(\n    expand = expansion(0, c(0.2, 0))\n  ) +\n  scale_y_continuous(\n    labels = scales::percent_format(accuracy = 10),\n    expand = expansion(0, 0),\n    position = \"bottom\"\n  ) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    y = \"Percent of Workday Between 8am and 5pm\",\n    fill = NULL\n  ) +\n  ggtitle(\n    \"What Does President Trump Do With His Time?\"\n  ) +\n  labs(caption = credit_caption(FALSE)) +\n  theme(\n    axis.text.y = element_blank(),\n    panel.grid.major = element_blank(),\n    axis.ticks.x.top = element_line(color = \"grey20\")\n  )\n\n\n\n\n\nFor 43 of the 51 workdays (that‚Äôs 84%) covered by the Axios schedules and for which there is schedule information, Trump spent 50% or more of his day in executive time.\nIn other words, there were only 8 days in about 10 work weeks where executive time was not the dominant activity.\nWhen the above time-use summary is expanded into his daily schedule, it‚Äôs clear how unusual it is for Trump to spend a significant portion of his day in structured events.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\nexec_time_total %&gt;%\n  mutate(\n    date = as.integer(date + 3600*12),\n  ) %&gt;%\n  ggplot() +\n  aes(date, pct, fill = top_category) +\n  geom_col(width = 3600*24) +\n  scale_fill_manual(\n    values = event_type_colors,\n    labels = rev(event_type_labels)\n  ) +\n  scale_y_continuous(\n    breaks   = seq(0, 1, .25),\n    labels   = scales::percent_format(accuracy = 25),\n    position = \"right\",\n    expand   = expansion(c(0.025, 0), 0)\n  ) +\n  scale_x_reverse(\n    # trans  = rev_date,\n    breaks = plot_date_breaks,\n    labels = plot_date_breaks_labels,\n    expand = expansion(c(0.025, 0), 0)\n  ) +\n  coord_flip() +\n  labs(\n    x = NULL,\n    y = \"Percent of Workday Between 8am and 5pm\",\n    fill = NULL\n  ) +\n  guides(\n    fill = guide_legend(nrow = 1,\n                        reverse = TRUE,\n                        label.position = \"bottom\")\n  ) +\n  ggtitle(\n    \"What Does President Trump Do With His Time?\"\n  ) +\n  labs(caption = credit_caption(FALSE))\n\n\n\n\n\nIn fact, the largest non-executive time block for the 8 days where executive time isn‚Äôt more than half of Trump‚Äôs workday are almost entirely travel related.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\nexec_time_summary %&gt;%\n  filter(pct &lt; 0.5, weekday) %&gt;%\n  select(date) %&gt;%\n  left_join(exec_time %&gt;% mutate(date = floor_date(time_start, \"day\"))) %&gt;%\n  mutate(duration = difftime(time_end, time_start, unit = \"hours\")) %&gt;%\n  select(date, duration, listed_title) %&gt;%\n  arrange(date, desc(duration)) %&gt;%\n  filter(listed_title != \"Executive time\") %&gt;%\n  group_by(date) %&gt;%\n  slice(1) %&gt;%\n  mutate(duration = round(duration, 2)) %&gt;%\n  knitr::kable(col.names = c(\n    \"Date\", \"Duration\", \"Longest Non-Executive-Time Activity\"\n  ), format = \"html\") %&gt;%\n  kableExtra::column_spec(1:2, width = \"6.5em\")\n\n\n\n\n\n\n\n\nDate\nDuration\nLongest Non-Executive-Time Activity\n\n\n\n\n2018-11-09\n6.50 hours\nDepart Washington, DC en route Orly, France\n\n\n2018-11-26\n2.17 hours\nDepart Gulfport, MS en route Washington, DC\n\n\n2018-11-29\n6.67 hours\nDepart Washington, DC en route Buenos Aires, Argentina\n\n\n2018-11-30\n1.75 hours\nG20 Leaders' dinner\n\n\n2018-12-07\n2.58 hours\nDepart Washington, DC en route Kansas City, MO\n\n\n2018-12-21\n1.00 hours\nLunch\n\n\n2019-01-10\n4.17 hours\nDepart Washington, DC en route McAllen, TX\n\n\n2019-01-14\n2.58 hours\nDepart Washington, DC en route Kenner, LA\n\n\n\n\n\n\n\nTravel seems to be the only activity capable of substantially affecting the amount of time the president spends on his executive time. My (completely speculative) guess is that this is in part due to travel being the only activity with a duration long enough to displace executive time, and also in part that travel probably most resembles executive time.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\nexec_time_total %&gt;%\n  # Drop \"Unkown\" time category, not that important\n  filter(top_category != \"Unknown\") %&gt;%\n  # Spread top_category...\n  spread(top_category, pct) %&gt;%\n  # ...and gather to leave Executive Time in own column\n  gather(other_activity, pct, -date, -`Executive Time`) %&gt;%\n  # Ignore points where both groups are 0% (not informative)\n  filter(pct + `Executive Time` &gt; 0) %&gt;%\n  # Pipe into ggplot\n  ggplot() +\n  aes(`Executive Time`, pct, color = other_activity) +\n  geom_point() +\n  facet_wrap(~ other_activity, nrow = 1) +\n  scale_x_continuous(\n    breaks = c(0, 0.5, 1),\n    labels = scales::percent_format(accuracy = 25),\n    limits = c(0, 1)\n  ) +\n  scale_y_continuous(\n    breaks = c(0, 0.5, 1),\n    labels = scales::percent_format(accuracy = 25),\n    limits = c(0, 1)\n  ) +\n  scale_color_manual(\n    values = event_type_colors,\n    labels = rev(event_type_labels),\n    guide  = FALSE\n  ) +\n  coord_flip() +\n  labs(\n    x = \"Percent of Workday\\nIn Executive Time\",\n    y = \"Percent of Workday Spent in Activity\",\n    caption = credit_caption()\n  ) +\n  theme(\n    axis.title.x = element_text(margin = margin(10)),\n    axis.title.y = element_text(margin = margin(r = 20)),\n  )"
  },
  {
    "objectID": "blog/presidents-day/index.html#tweeter-in-chief",
    "href": "blog/presidents-day/index.html#tweeter-in-chief",
    "title": "President‚Äôs Day (As In: What Does President Trump Do With His Day?)",
    "section": "Tweeter In Chief",
    "text": "Tweeter In Chief\nAt the point, I was very interested in exploring how Trump‚Äôs tweeting relates to his work schedule. The first question to answer is When does he send most of his tweets? And the answer is: primarily on the weekends, during executive time, or before or after work hours.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\n# Start and end dates of Axios-pubslished schedules\n# which I called `exec_time` for some reason and am sticking with\nexec_time_boundaries &lt;-\n  exec_time %&gt;%\n  summarize(min = min(time_start), max = max(time_end))\n\nexec_time %&gt;%\n  # mutate(event_id = row_number()) %&gt;%\n  unnest() %&gt;%\n  filter(time_end != time_inc) %&gt;%\n  full_join(djt_simple, by = \"time_inc\") %&gt;%\n  select(event_id, time_inc, created_at, listed_title, top_category, text) %&gt;%\n  filter(\n    !is.na(text),\n    between(time_inc, exec_time_boundaries$min, exec_time_boundaries$max)\n  ) %&gt;%\n  mutate(\n    wday = wday(created_at, abbr = FALSE, week_start = 1),\n    top_category = case_when(\n      !is.na(top_category) ~ paste(top_category),\n      wday &gt; 5 ~ \"Weekend\",\n      between(wday, 1, 5) & hour(created_at) &lt;  6 ~ \"Early Morning (before 6am)\",\n      between(wday, 1, 5) & hour(created_at) &lt;  8 ~ \"Morning (6-8 am)\",\n      between(wday, 1, 5) & hour(created_at) &gt; 17 ~ \"Evening (after 5pm)\",\n      is.na(top_category) ~ \"Unknown\",\n      TRUE ~ paste(top_category))\n  ) %&gt;%\n  count(top_category) %&gt;%\n  arrange(n) %&gt;%\n  mutate(top_category = fct_inorder(top_category)) %&gt;%\n  ggplot() +\n  aes(top_category, n) +\n  geom_col(fill = \"#445566\") +\n  scale_y_continuous(expand = c(0, 0, 0, 5)) +\n  coord_flip() +\n  theme(panel.grid.major.y = element_blank()) +\n  labs(x = \"Activity or Time of Day\",\n       y = paste(\n         \"Total Tweets Sent Between\",\n         strftime(exec_time_boundaries$min, \"%F\"),\n         \"to\",\n         strftime(exec_time_boundaries$max, \"%F\")\n       ),\n       title = \"Trump Tweet Volume by Scheduled Activity\",\n       caption = credit_caption(rtweet = TRUE))\n\n\n\n\n\nWe can get a sense of the timing of Trump‚Äôs tweeting activities by looking at the time of day of each tweet and the scheduled activity that‚Äôs going on at the time. The following plot shows each tweet as a vertical line and considers only workday tweeting and only for days covered by the Axios schedules.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\nevent_type_colors_extra &lt;- c(event_type_colors, \"Non-Work Hours\" = \"#828486\")\n\ndjt_joined_work_non_work &lt;-\n  djt_joined_all %&gt;%\n  mutate_at(vars(top_category),  as.character) %&gt;%\n  mutate(weekend = wday(created_at, abbr = FALSE, week_start = 1) &gt; 5) %&gt;%\n  filter(\n    !weekend,\n    between(created_at, exec_time_boundaries$min, exec_time_boundaries$max)\n  ) %&gt;%\n  mutate(top_category = if_else(\n    between(in_hours(created_at), 8, 17) & is.na(top_category),\n    \"Unknown\",\n    top_category\n  )) %&gt;%\n  replace_na(list(top_category = \"Non-Work Hours\")) %&gt;%\n  mutate(\n    top_category = fct_infreq(top_category)\n  )\n\n\nggplot(djt_joined_work_non_work) +\n  aes(x = hour, y = 1, color = top_category) +\n  geom_segment(aes(xend = hour, yend = 0), alpha = 0.6, size = 0.5) +\n  facet_wrap(~ top_category, ncol = 1, strip.position = \"left\") +\n  scale_x_continuous(\n    position = \"bottom\",\n    breaks   = seq(0, 24, 4),\n    limits   = c(0, 24),\n    labels   = am_pm(seq(0, 24, 4)),\n    expand   = expansion(c(0.025, 0), 0)\n  ) +\n  scale_color_manual(\n    values = event_type_colors_extra,\n    labels = names(event_type_colors_extra)\n  ) +\n  scale_fill_manual(\n    values = event_type_colors_extra,\n    labels = names(event_type_colors_extra)\n  ) +\n  coord_cartesian(clip = \"off\") +\n  labs(x = NULL, y = NULL, color = NULL) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_blank(),\n    strip.text.y.left = element_text(\n      angle = 0,\n      margin = margin(r = 5, l = 25),\n      hjust = 1\n    ),\n    panel.spacing.y = unit(0, \"pt\")\n  ) +\n  ggtitle(\n    \"What's On His Schedule When He's Tweeting?\",\n    \"Each line represents a tweet, colored by the activity on his White House Schedule\"\n  ) +\n  labs(caption = credit_caption(rtweet = TRUE))\n\n\n\n\n\nMost of Trump‚Äôs tweeting happens betewen 7 and 9 am, but what‚Äôs striking is that it‚Äôs nearly impossible to tell the difference between early morning tweeting and the start of President Trump‚Äôs official workday at 8am.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\ndjt_joined_work_non_work %&gt;%\n  filter(top_category %in% c(\"Non-Work Hours\", \"Executive Time\")) %&gt;%\n  mutate(week = floor_date(created_at, \"week\"),\n         week = strftime(week, \"%F\")) %&gt;%\n  ggplot() +\n  aes(x = hour, y = 1, color = top_category) +\n  geom_segment(aes(xend = hour, yend = 0)) +\n  facet_wrap(~ week, ncol = 1, strip.position = \"left\") +\n  scale_x_continuous(\n    position = \"bottom\",\n    breaks   = seq(0, 24, 2),\n    limits   = c(4, 12),\n    labels   = am_pm(seq(0, 24, 2)),\n    expand   = expansion(c(0.025, 0), 0)\n  ) +\n  scale_color_manual(\n    values = event_type_colors_extra,\n    labels = names(event_type_colors_extra)\n  ) +\n  scale_fill_manual(\n    values = event_type_colors_extra,\n    labels = names(event_type_colors_extra)\n  ) +\n  labs(x = NULL, y = NULL, color = NULL, caption = credit_caption(TRUE)) +\n  guides(color = FALSE, fill = FALSE) +\n  theme(\n    panel.grid.major.y = element_blank(),\n    axis.text.y = element_blank(),\n    strip.text.y.left = element_text(angle = 0, margin = margin(r = 25)),\n    panel.spacing.y = unit(0, \"pt\")\n  ) +\n  ggtitle(\n    \"When Do Official Work Hours Start?\",\n    \"Morning tweets published over one week periods.\\nAccording to the White House Schedule, \\\"Executive Time\\\" starts at 8am in the Oval Office.\"\n  )\n\n\n\n\n\nAs we learned above, Trump sends about 5 tweets per working day within working hours. Naturally, I wondered if he tends to tweet more or less during the day when he has more executive or travel time available. Similarly does he tweet less when he has more strucured time, i.e.¬†metings, events, or lunches?\nSomewhat unsurprisingly, the number of tweets sent during the workday in only very slightly correlated with the amount of unstructured time on Trump‚Äôs calendar. This makes sense: there is very little variation in the amount of the day spent in structured events ‚Äì it‚Äôs never more than half the day.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\ndjt_joined %&gt;%\n  group_by(date) %&gt;%\n  count() %&gt;%\n  rename(tweets = n) %&gt;%\n  left_join(exec_time_total, ., by = \"date\") %&gt;%\n  replace_na(list(tweets = 0)) %&gt;%\n  filter(top_category %in% c(\"Executive Time\", \"Unknown\", \"Travel\", \"Lunch\")) %&gt;%\n  spread(top_category, pct, fill = 0) %&gt;%\n  filter(!Unknown == 1) %&gt;%\n  mutate(pct = Unknown + `Executive Time` + Travel + Lunch) %&gt;%\n  ggplot() +\n  aes(pct, tweets) +\n  geom_smooth(\n    method = \"lm\",\n    color = event_type_colors[\"Executive Time\"],\n    fill = event_type_colors[\"Unknown\"]\n  ) +\n  geom_point(color = event_type_colors[\"Executive Time\"]) +\n  scale_x_continuous(labels = scales::percent_format(10)) +\n  labs(\n    x = \"Percent of Workday Dedicated to Downtime\\n(Executive Time, Travel, Unknown)\",\n    y = \"Number of Tweets\",\n    title = \"Does Trump Tweet More When He Has More Downtime?\",\n    caption = credit_caption(rtweet = TRUE))\n\n\n\n\n\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\ndjt_simple %&gt;%\n  mutate(date = floor_date(created_at, \"day\")) %&gt;%\n  group_by(date) %&gt;%\n  count() %&gt;%\n  rename(tweets = n) %&gt;%\n  left_join(exec_time_total, ., by = \"date\") %&gt;%\n  filter(top_category %in% c(\"Meeting\", \"Event\", \"Lunch\")) %&gt;%\n  group_by(date) %&gt;%\n  summarize(pct = sum(pct), tweets = max(tweets)) %&gt;%\n  filter(pct &gt; 0) %&gt;%\n  ggplot() +\n  aes(pct, tweets) +\n  geom_smooth(\n    method = \"lm\",\n    color = event_type_colors[\"Executive Time\"],\n    fill = event_type_colors[\"Unknown\"]\n  ) +\n  geom_point(color = event_type_colors[\"Executive Time\"]) +\n  scale_x_continuous(labels = scales::percent_format(10)) +\n  labs(x = \"Percent of Workday Dedicated to Meetings, Lunches, or Events\",\n       y = \"Number of Tweets\",\n       title = \"Does Trump Tweet Less When He Does More \\\"Work\\\"?\",\n       caption = credit_caption(rtweet = TRUE))\n\n\n\n\n\nFinally, I wanted to explore the emotional valence of Trump‚Äôs day-time tweeting. Are his morning tweets angrier or more rant-driven? Are his event-related tweets more positive?\nTo this end, I ran Trump‚Äôs tweet text through the NRC sentiment dictionary using get_nrc_sentiment() from the syuzhet package. This function returns an integer score from 0 to 10 for a range of positive and negative emotions.\n\n\n\n\n\n\nR code‚Ä¶\n\n\n\n\n\n\ndjt_sentiment &lt;-\n  djt_joined %&gt;%\n  select(top_category, text) %&gt;%\n  mutate(sentiment = map(text, syuzhet::get_nrc_sentiment)) %&gt;%\n  unnest() %&gt;%\n  gather(emotion, value, -top_category, -text)\n\ndjt_sentiment\n\n# A tibble: 2,950 √ó 4\n   top_category   text                                             emotion value\n   &lt;fct&gt;          &lt;chr&gt;                                            &lt;chr&gt;   &lt;dbl&gt;\n 1 Executive Time If the Democrats think they are going to waste ‚Ä¶ anger       1\n 2 Executive Time In all fairness, Nancy Pelosi deserves to be ch‚Ä¶ anger       0\n 3 Executive Time According to NBC News, Voters Nationwide Disapp‚Ä¶ anger       4\n 4 Executive Time We are pleased to announce that Matthew G. Whit‚Ä¶ anger       1\n 5 Executive Time ....We thank Attorney General Jeff Sessions for‚Ä¶ anger       1\n 6 Travel         ‚ÄúPresidential Proclamation Addressing Mass Migr‚Ä¶ anger       0\n 7 Travel         .@BrianKempGA ran a great race in Georgia ‚Äì he ‚Ä¶ anger       0\n 8 Travel         You mean they are just now finding votes in Flo‚Ä¶ anger       2\n 9 Travel         As soon as Democrats sent their best Election s‚Ä¶ anger       2\n10 Travel         Jeff Flake(y) doesn‚Äôt want to protect the Non-S‚Ä¶ anger       2\n# ‚Ä¶ with 2,940 more rows\n\ndjt_sentiment_mean &lt;-\n  djt_sentiment %&gt;%\n  group_by(top_category, emotion) %&gt;%\n  summarize(value = mean(value)) %&gt;%\n  mutate(emotion = fct_reorder(emotion, value)) %&gt;%\n  filter(top_category != \"Unknown\")\n\ndjt_sentiment_mean\n\n# A tibble: 50 √ó 3\n# Groups:   top_category [5]\n   top_category   emotion      value\n   &lt;fct&gt;          &lt;fct&gt;        &lt;dbl&gt;\n 1 Executive Time anger        0.864\n 2 Executive Time anticipation 0.870\n 3 Executive Time disgust      0.525\n 4 Executive Time fear         0.772\n 5 Executive Time joy          0.654\n 6 Executive Time negative     1.36 \n 7 Executive Time positive     2.01 \n 8 Executive Time sadness      0.562\n 9 Executive Time surprise     0.537\n10 Executive Time trust        1.52 \n# ‚Ä¶ with 40 more rows\n\n\n\nemotions &lt;- c(\n  \"positive\", \"joy\", \"trust\", \"surprise\", \"anticipation\",\n  \"sadness\", \"anger\", \"fear\", \"disgust\", \"negative\"\n)\n\ndjt_sentiment %&gt;%\n  mutate(emotion = factor(emotion, rev(emotions))) %&gt;%\n  ggplot() +\n  aes(y = value, x = emotion, fill = top_category) +\n  # ggridges::geom_density_ridges() +\n  geom_boxplot(alpha = 0.7, color = \"grey20\", outlier.shape = NA) +\n  scale_fill_manual(values = event_type_colors) +\n  guides(fill = FALSE, color = FALSE) +\n  coord_flip() +\n  facet_wrap(~top_category, scales = \"free_y\") +\n  labs(y = \"Sentiment Score\", x = NULL,\n       title = \"Emotions Expressed in Trump Tweets\",\n       caption = credit_caption(rtweet = TRUE))\n\n\n\n\n\nThe result provides something of a profile of Trump‚Äôs tweeting habits, but more analysis is needed to make sense of these sentiment values. I wanted to look further into how these tweets were categorized by the sentiment dictionary, but by this point this post is already far too long and has consumed too much of my evenings and weekends, so I‚Äôll save it for another day.\n\nThanks for reading! I‚Äôd love to hear your thoughts or feedback. I‚Äôm @grrrck on Twitter."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html",
    "href": "blog/process-profile-picture-magick/index.html",
    "title": "Process Profile Pictures with magick",
    "section": "",
    "text": "rstudio::conf(2022) is just around the corner! This year, I‚Äôve been fortunate to be part of the conference program committee, the small group of RStudio people who gather and evaluate talk submissions, make the tough scheduling decisions about the sessions and talks in the conference program, and generally wrangle and herd all the speaker and talk information into the final schedule.\nMy favorite part of the process ‚Äî apart from seeing all of the wonderful and creative ways our community approaches data science with R (okay, and Python too) ‚Äî is finding out how many creative ways we use R to manage the conference. Let‚Äôs just say Jenny Bryan is a literal Google Forms/Sheets/Drive wizard.\nOne of the things I love about R is the cycle of starting a task wondering Can I do this with R? and ending with Wow, I can do this with R! I‚Äôve been using R for a while and I‚Äôm still occasionally surprised when I find myself on this virtuous loop.\nThis post is about an otherwise mundane conference admin task that would have involved a lot of manual labor (in the form of clicks and mouse movements) that I automated with the help of a few R packages. Maybe in future posts I‚Äôll share more cool things that we did with R in the making of rstudio::conf.\nOh and I hope to see you there, either in person, online or on Twitter at #RStudioConf2022! Learn more at rstd.io/conf."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#rstudioconf2022-runs-on-r",
    "href": "blog/process-profile-picture-magick/index.html#rstudioconf2022-runs-on-r",
    "title": "Process Profile Pictures with magick",
    "section": "",
    "text": "rstudio::conf(2022) is just around the corner! This year, I‚Äôve been fortunate to be part of the conference program committee, the small group of RStudio people who gather and evaluate talk submissions, make the tough scheduling decisions about the sessions and talks in the conference program, and generally wrangle and herd all the speaker and talk information into the final schedule.\nMy favorite part of the process ‚Äî apart from seeing all of the wonderful and creative ways our community approaches data science with R (okay, and Python too) ‚Äî is finding out how many creative ways we use R to manage the conference. Let‚Äôs just say Jenny Bryan is a literal Google Forms/Sheets/Drive wizard.\nOne of the things I love about R is the cycle of starting a task wondering Can I do this with R? and ending with Wow, I can do this with R! I‚Äôve been using R for a while and I‚Äôm still occasionally surprised when I find myself on this virtuous loop.\nThis post is about an otherwise mundane conference admin task that would have involved a lot of manual labor (in the form of clicks and mouse movements) that I automated with the help of a few R packages. Maybe in future posts I‚Äôll share more cool things that we did with R in the making of rstudio::conf.\nOh and I hope to see you there, either in person, online or on Twitter at #RStudioConf2022! Learn more at rstd.io/conf."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#send-me-your-profile-picture-please",
    "href": "blog/process-profile-picture-magick/index.html#send-me-your-profile-picture-please",
    "title": "Process Profile Pictures with magick",
    "section": "Send me your profile picture, please",
    "text": "Send me your profile picture, please\nSuppose you‚Äôve asked 100-ish people to send you a profile picture and to your surprise they all followed through and sent you an actual image.\nBut, of course, you now have a new problem. Each of those 100-ish people has used slightly different sizes for their profile picture. They‚Äôre all sorts of different shapes, sizes, and resolutions.\nSome people‚Äôs profile images feature their faces, centered and tightly cropped. Others are photographed at a distance or off-center.\n\n\n\n\n\nAn example profile picture you received.\nImage by christian buehner.\n\n\n\n\nIn their final placement, you want all of the profile images to be circular images centered on the person‚Äôs face as much as possible. If we took the image above and simply centered it inside a circle, we would get something like this:\n\n\nThe example profile image clipped to fit a circular avatar image. The subject appears at the right edge of the circle. About 40% of their face is clipped.\n\n\nObviously, we‚Äôd rather not clip half of the person out of their profile image, so we‚Äôll need to edit this photo. But there are hundreds of them and most of them will need some adjustment.\nGood news! You have access to R, where we can use tools like magick to read and process the images, or face detection with neural networks. So with a few hours of work you can save yourself an hour of mindless clicking. Let‚Äôs do this!"
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#collect-the-profile-pictures",
    "href": "blog/process-profile-picture-magick/index.html#collect-the-profile-pictures",
    "title": "Process Profile Pictures with magick",
    "section": "Collect the Profile Pictures",
    "text": "Collect the Profile Pictures\nTo see how this all works, I‚Äôve downloaded four example profile pictures from unsplash1.\ndir.create(\"profiles\")\nphoto_ids &lt;- c(\"DItYlc26zVI\", \"bpxgyD4YYt4\", \"6anudmpILw4\", \"3dqSZidOkvs\")\n\nfor (id in photo_ids) {\n  download.file(\n    sprintf(\"https://source.unsplash.com/%s\", id),\n    sprintf(\"profiles/%s.jpg\", id)\n  )\n}\nI‚Äôve put the photos in a profiles/ directory so that I can list the them all at once:\n\nfs::dir_ls(\"profiles\")\n## profiles/3dqSZidOkvs.jpg profiles/6anudmpILw4.jpg profiles/DItYlc26zVI.jpg \n## profiles/bpxgyD4YYt4.jpg"
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#magick-with-r",
    "href": "blog/process-profile-picture-magick/index.html#magick-with-r",
    "title": "Process Profile Pictures with magick",
    "section": "Magick with R",
    "text": "Magick with R\nThe first step is to use the magick package to read in our profile pictures.\n\nlibrary(magick)\nlibrary(purrr)\n\nprofiles &lt;-\n  fs::dir_ls(\"profiles\") |&gt;\n  map(image_read)\n\nprofiles\n## $`profiles/3dqSZidOkvs.jpg`\n##   format width height colorspace matte filesize density\n## 1   JPEG  1080    810       sRGB FALSE   135368   72x72\n## \n## $`profiles/6anudmpILw4.jpg`\n##   format width height colorspace matte filesize density\n## 1   JPEG  1080    720       sRGB FALSE    46181   72x72\n## \n## $`profiles/DItYlc26zVI.jpg`\n##   format width height colorspace matte filesize density\n## 1   JPEG  1080    720       sRGB FALSE    87827   72x72\n## \n## $`profiles/bpxgyD4YYt4.jpg`\n##   format width height colorspace matte filesize density\n## 1   JPEG  1080    608       sRGB FALSE    80277   72x72\n\nHere are the four profiles. As you can see, they come in a variety of sizes and the person in the frame is rarely centered."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#finding-faces",
    "href": "blog/process-profile-picture-magick/index.html#finding-faces",
    "title": "Process Profile Pictures with magick",
    "section": "Finding Faces",
    "text": "Finding Faces\nNow for the most fun of this entire post. After a quick search on r-pkg.org, I found a few packages that provide methods for facial detection; I tried image.libfacedetection first and it worked out so well that I didn‚Äôt have to look any further on the list.\nAs it says on the CRAN page, image.libfacedetection is\n\nAn open source library for face detection in images. Provides a pretrained convolutional neural network based on https://github.com/ShiqiYu/libfacedetection which can be used to detect faces which have size greater than 10x10 pixels.\n\nThe best feature ‚Äî apart from reliably detecting faces ‚Äî is that it works really well with magick. The core functionality is all wrapped up in a single function, image.libfacedetection::image_detect_faces(), and the example in the README tells you just about everything you need to know.\nIn short, after reading the image into R with magick::image_read(), you can call image_detect_faces() to find faces in the image. image_detect_faces() returns data about the detected faces, and you can use its plot() method to overlay boxes over the found faces in the image.\n\nlibrary(image.libfacedetection)\nfaces &lt;- all_profiles |&gt; image_detect_faces()\nplot(faces, all_profiles, only_box = TRUE)\n\n\n\n\n\n\n\n\n\n\n\n\nimage_detect_faces() returns some interesting data about the detected faces:\n\nThe data frame detections indicates the locations of these. This data.frame has columns x, y, width and height as well as a column called confidence. The values of x and y are the top left of the start of the box.\n\n\nfaces\n## $nr\n## [1] 4\n## \n## $detections\n##     x   y width height confidence landmark1_x landmark1_y landmark2_x\n## 1 153  48    43     57         99         158          70         175\n## 2 140 239    43     58         99         150         260         171\n## 3 365  64    33     44         99         373          79         387\n##   landmark2_y landmark3_x landmark3_y landmark4_x landmark4_y landmark5_x\n## 1          68         162          80         162          92         177\n## 2         260         160         272         151         282         168\n## 3          80         377          86         372          94         385\n##   landmark5_y\n## 1          89\n## 2         282\n## 3          95\n##  [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]\n## \n## attr(,\"class\")\n## [1] \"libfacedetection\"\n\nSince we asked for a profile picture, we can reasonably expect that there‚Äôs only one person in the image. So we‚Äôll take the detection with the highest confidence (in case something else registers as a face), and find the center of the detected region.\n\nfind_face_center &lt;- function(image) {\n  detections &lt;- image.libfacedetection::image_detect_faces(image)$detections\n  best_face &lt;- which(detections$confidence == max(detections$confidence))\n  dims &lt;- as.list(detections[best_face[[1]], ])\n  list(\n    x = dims$x + dims$width / 2,\n    y = dims$y + dims$height / 2\n  )\n}\n\nSo when applied to our example profile image, we find that our subject‚Äôs face is centered at (697.5, 290).\n\nface_center &lt;- find_face_center(profiles[[3]])\nstr(face_center)\n## List of 2\n##  $ x: num 698\n##  $ y: num 290\n\n\n\n\n\n\n\n\n\n\n\n\nIn the next steps, we‚Äôll resize and crop the photo so that it‚Äôs centered, as much as possible, on this point."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#resize",
    "href": "blog/process-profile-picture-magick/index.html#resize",
    "title": "Process Profile Pictures with magick",
    "section": "Resize",
    "text": "Resize\nOur goal is to resize and crop the photo into an 600px square image. If we start with an image smaller than 600px in either dimension, then we won‚Äôt scale up. We also take another shortcut: since most people will provide a profile image that prominently features their face, we can start by shrinking the smaller side of the image down to match the desired image size.\nThis shortcut keeps us from perfectly framing the person‚Äôs face. Sometimes their face is too close to the edge of the picture, and in other cases there may be negative space around their head that will end up in the cropped profile image. I‚Äôd argue that this is okay. It keeps our cropping from being too perfect and the final images still retain some of the character of the original photo.\nOur example profile image is 1080px wide and 720px tall, so we‚Äôll resize the image proportionally down to an image with height 600px.\n\nresize_fit &lt;- function(image, size = 600) {\n  info &lt;- image_info(image)\n  size &lt;- min(size, info$width, info$height)\n  image_resize(\n    image,\n    geometry_size_pixels(\n      height = if (info$width &gt;= info$height) size,\n      width = if (info$height &gt; info$width) size\n    )\n  )\n}\n\nWhen applied to our example profile image, we end up with a 900px √ó 600px image.\n\nresized_profile &lt;-\n  profiles[[3]] |&gt;\n  resize_fit()\n\nresized_profile |&gt; image_info()\n##   format width height colorspace matte filesize density\n## 1   JPEG   900    600       sRGB FALSE        0   72x72\n\nIn the next step, we‚Äôll figure out which 600px horizontal region best covers the person‚Äôs face."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#find-resized-faces",
    "href": "blog/process-profile-picture-magick/index.html#find-resized-faces",
    "title": "Process Profile Pictures with magick",
    "section": "Find Resized Faces",
    "text": "Find Resized Faces\nWait. I showed the face-center discovery step above because it‚Äôs the coolest part of this pipeline, but we don‚Äôt actually perform the facial detection first. We need to know where the person‚Äôs face is located after we scale down their profile image.\n\nresized_profile |&gt;\n  find_face_center()\n## $x\n## [1] 579\n## \n## $y\n## [1] 240.5"
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#cropping",
    "href": "blog/process-profile-picture-magick/index.html#cropping",
    "title": "Process Profile Pictures with magick",
    "section": "Cropping",
    "text": "Cropping\nNow that we know where the center point of the person‚Äôs face is located in the image, and also because we‚Äôve already resized the image so we don‚Äôt have to worry about its height, we only need to crop the image in one direction. The problem now is that we need to pick a 600px width region within the full 900px range.\n           point\n|------[=====*=====]---|\n       ^~~ width ~~^\n^......................^ range\nThis isn‚Äôt too complicated. There are three cases:\n\nThe point is so close to the start of the range that it we can‚Äôt center the point in our width and instead have to start at 0.\nSimilarly, the point might be so close to the end of the range that our crop width lines up with the end. Or, in other words, the crop width starts at range - width.\nOr finally, we can center the point in our crop width, so it should start at point - width/2.\nOh, and there‚Äôs an edge case: if the width is greater than or equal to the full range, then the offset is 0, too.\n\nThis logic gives us the following crop_offset() function:\n\ncrop_offset &lt;- function(point, range, width) {\n  # 4. Catch the edge case first\n  if (width &gt;= range) return(0)\n\n  if ((point - width / 2) &lt; 0) {\n    # 1. must start at left edge\n    return(0)\n  }\n  if ((point + width / 2) &gt; range) {\n    # 2. must start at right edge\n    return(range - width)\n  }\n  # 3. enough space on both sides to center width in range\n  point - width / 2\n}\n\nWhich in our example case tells us that we could crop our resized profile image to a 600px square, offset by the following amount in the x direction:\n\noffset &lt;- crop_offset(\n  point = 579,\n  range = 900,\n  width = 600\n)\noffset\n## [1] 279\n\nWe can use magick::image_crop() with the magick::geometry_area() helper function:\n\n\n\n\n\n\n\n\n\n\n\nWhen this image is used as a profile or avatar picture, it ends up looking much better than the uncropped and uncentered version!\n\n\nThe example profile image cropped and centered to fit a circular avatar image. The subject appears directly in the middle of the circle."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#put-it-all-together",
    "href": "blog/process-profile-picture-magick/index.html#put-it-all-together",
    "title": "Process Profile Pictures with magick",
    "section": "Put it all together",
    "text": "Put it all together\nThe last step is to put everything we‚Äôve sketched out above into a single function that takes a magick image and returns a new cropped and centered version. And here‚Äôs that function.\n\nresize_crop_to_face &lt;- function(image, size = 600) {\n  image &lt;- resize_fit(image, size)\n  info &lt;- image_info(image)\n\n  # size may have changed after refit\n  size &lt;- min(info$height, info$width)\n\n  is_image_square &lt;- info$width == info$height\n  if (is_image_square) {\n    return(image)\n  }\n\n  face &lt;- find_face_center(image)\n\n  image_crop(\n    image,\n    geometry = geometry_area(\n      width = size,\n      height = size,\n      x_off = crop_offset(face$x, info$width, size),\n      y_off = crop_offset(face$y, info$height, size)\n    )\n  )\n}\n\nStarting over from the beginning, we can read all of the profile images and resize and crop them around the subject‚Äôs face in just a few lines\n\nprofiles &lt;-\n  fs::dir_ls(\"profiles\") |&gt;\n  map(image_read) |&gt;\n  map(resize_crop_to_face)\n\nand then we can write them back into the profiles directory.\n\nfs::dir_create(\"profiles_cropped\")\n\nprofiles |&gt;\n  iwalk(function(image, path) {\n    new_path &lt;- fs::path(\"profiles_cropped\", fs::path_file(path))\n    image_write(image, new_path)\n  })\n\nThe end result is four perfect profile pictures!\n\n A young black woman, centered in the image, against a green background.   An older white man on a gray background, centered in the image.   The example profile: a young white male centered in the image.   A young woman against a tan background, centered in the image."
  },
  {
    "objectID": "blog/process-profile-picture-magick/index.html#footnotes",
    "href": "blog/process-profile-picture-magick/index.html#footnotes",
    "title": "Process Profile Pictures with magick",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nImages by christian buehner, Eunice Litua√±as, Foto Sushi, and Eye for Ebony.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html",
    "href": "blog/questions-answers-and-reprexes/index.html",
    "title": "Questions, answers, and reprexes",
    "section": "",
    "text": "I stumbled into a niche YouTube genre: Web Development online instructors (a.k.a content creators) challenge each other to ‚ÄúCSS Battles‚Äù.\nTurns out they are fascinating videos where experienced programmers talk and fumble their way through their coding.\nAs they talked through their thought processes, I thought about the questions we ask when our code goes wrong and the answers we get when we reprex."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#css-battle-with-the-css-king",
    "href": "blog/questions-answers-and-reprexes/index.html#css-battle-with-the-css-king",
    "title": "Questions, answers, and reprexes",
    "section": "CSS Battle with The CSS King",
    "text": "CSS Battle with The CSS King\n\n\n\nI challenged The CSS King to a CSS Battle on YouTube\n\n\nI‚Äôve thought a lot about this video since I watched it. Kyle Cook and Kevin Powell both make great YouTube videos teaching CSS and front-end web development concepts.\nIn this video, they simultaneously tackle three CSS challenges with a time limit of 10 minutes for each. Both Kyle and Kevin talk through their process and the video switches between the two of them as they build up their solutions."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#writing-code-is-testing-your-theory-of-the-solution",
    "href": "blog/questions-answers-and-reprexes/index.html#writing-code-is-testing-your-theory-of-the-solution",
    "title": "Questions, answers, and reprexes",
    "section": "Writing code is testing your theory of the solution",
    "text": "Writing code is testing your theory of the solution\nThis is the part I loved: beyond confirming that writing CSS involves a lot of let‚Äôs just try width: 100% and I guess it should be 90px‚Ä¶ 85px‚Ä¶ 75px‚Ä¶, it was awesome to see how much of solving a complicated programming problem is about having a vague idea of the structure of a final solution and working toward that goal with many iterations with tiny, confirmatory tests.\n\nIn the first challenge, they made a cute little CSS Christmas tree. There are some tricks in here that you just need to know ‚Äî for example, you can make triangles with CSS using a trick with borders ‚Äî but neither Kyle nor Kevin start out knowing the exact final answer. Kevin narrates:\n\nI have to remember how to do an up arrow‚Ä¶ Let‚Äôs just try‚Ä¶ Is it like this? ‚Ä¶ Ah! I did get it right! Awesome, awesome. I don‚Äôt use this trick too often and I always forget how it works."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#two-roads-diverged-in-a-wood-and-i",
    "href": "blog/questions-answers-and-reprexes/index.html#two-roads-diverged-in-a-wood-and-i",
    "title": "Questions, answers, and reprexes",
    "section": "Two roads diverged in a wood, and I‚Ä¶",
    "text": "Two roads diverged in a wood, and I‚Ä¶\nKyle starts off with the border trick, and actually explains how it works in detail, but pretty quickly his solution goes a little off the rails. This is where I found myself fascinated.\nAt this point, both programmers are on the right track. The video flips back-and-forth between the two and you can see that Kyle has the right idea. But he starts second guessing his approach. He questions whether or not he‚Äôs using the right trick and he almost starts over from scratch.\nWhere it seemed like both programmers were headed for the same solution, Kyle‚Äôs questioning leads him to reverse course and try a radically different approach. Kevin, on the other hand, keeps on pushing forward. A small difference in the path chosen leads to two very different outcomes. In the end Kyle ends up coding in circles, trying to resolve problems that arose because of the circuitous path he chose when he gave up on his original direction."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#writing-code-is-thinking-about-code",
    "href": "blog/questions-answers-and-reprexes/index.html#writing-code-is-thinking-about-code",
    "title": "Questions, answers, and reprexes",
    "section": "Writing code is thinking about code",
    "text": "Writing code is thinking about code\nIn my experience, writing actual code is an improbably small part of programming. I love the feeling of flow when I connect with a problem, when I‚Äôm mostly certain about how I‚Äôm going to solve it, when I can just write code ‚Äî and not boiler plate, I mean real code. But day-to-day, I think about, read about, muse about, wonder about, and puzzle over much more code than I actually write.\n\n\n\nionicons-v5-j\n\n\n\n\nSidenote: Pair Programming\n\nAs a side note, I find that the flow is easier to find when I‚Äôm pair programming. It seems paradoxical, but having another set of eyes and all the extra cycles of the other person watching, always helps me stay on track whenever I would normally get lost in the frustration of a diversion.\nPre-pandemic, I always found it hard to convince others to join in pair-programming. But video conferencing makes it easier than ever to look over someone shoulder while they‚Äôre programming. It also makes it easier to switch roles while pairing, especially when you‚Äôre the navigator (the one watching/guiding) and need to step in to the driver role ‚Äî here, let me control your screen for a minute so I can show you‚Ä¶"
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#questioning-your-questions",
    "href": "blog/questions-answers-and-reprexes/index.html#questioning-your-questions",
    "title": "Questions, answers, and reprexes",
    "section": "Questioning your questions",
    "text": "Questioning your questions\nThe art of question asking while programming is often about understanding where to put your mental break points. Not when to take a break from staring at your screen (that‚Äôs also an important skill, especially when you start flailing1), but points at which you pause and evaluate whether the code in front of you is doing what you think it should be doing. In your binary search of the problem space ‚Äî will my broken code work if I poke this over here ‚Äî choosing where to draw the boxes around your code is a skill that comes with time and experience.\n\n\n\nPhoto by Karolina Grabowska\n\n\nSometimes, it‚Äôs made harder by experience. Is this bug I‚Äôm working on broken because of a local mistake, or is it broken because I‚Äôve installed the latest version of three of this package‚Äôs dependencies from GitHub? Is it because I‚Äôm using the latest preview version of my IDE? Or is it because I was working on another feature for a package called by this package and I‚Äôve installed my locally dev version of that package and this package is unhappy about that?\nWith experience I‚Äôve gotten better at looking at a problem, drawing a dotted line around a section of code, and finding a way to test whether the bug is inside or outside that line. But I can just as easily get distracted by a false positive and spend too much time testing things that are totally unrelated to the actual problem that I was trying to fix.\nOne of the hardest parts of learning how to program is learning about how to draw these invisible lines. When everything is new, it‚Äôs hard to know where to look when something doesn‚Äôt work. It‚Äôs easy to think of questions that lead you further from the truth or that lead to non-local jumps in logic: rather than differentiating between two possibilities A or B, a beginner will jump from A doesn‚Äôt work so the problem must be possibility K.\nOne of the biggest differentiators of experienced programmers from novices is their ability for metacognitive programming. They don‚Äôt just think about code in the sense of remembering a few magical commands, but they have a self-awareness of how they think about code. With experience, programmers move more quickly from what if I try this to what could be going on here and how can I test it?\nNot that we don‚Äôt resort or fall into flailing. I can‚Äôt tell you how many times I get in a fight with my code just before lunch, while having the awareness to say to myself this will be easier if I take a break and eat some food, only to hear the voice on the other shoulder shout keep going, you‚Äôre so close, just try this one last thing."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#a-reprex-is-the-answer",
    "href": "blog/questions-answers-and-reprexes/index.html#a-reprex-is-the-answer",
    "title": "Questions, answers, and reprexes",
    "section": "A reprex is the answer",
    "text": "A reprex is the answer\nHow do you learn and practice the critical skill of asking your code questions? With a reprex.\nA reprex is a small, reproducible example. Typically, it‚Äôs a small little bit of code with a tiny bug. It‚Äôs reproducible, meaning that it‚Äôs designed to work anywhere for anyone, or at least to work with the minimal number of dependencies. It doesn‚Äôt have to be buggy code, it can just be a tiny example.\nAnd it‚Äôs a very powerful technique.\nOn the one hand, a reproducible example makes it easier to get help by making it easier for people to help you. For a great introduction to reprexes from this angle, you should definitely watch Sharla Gelfand‚Äôs talk make a reprex‚Ä¶ please.\nOn the other hand, when you create a reprex you‚Äôre practicing the art and science of asking questions of your code. At every iteration you ask yourself: is this part here essential? Is this package really required? Do I need this much data to make my example reproducible, or can I get to the same place with a smaller data set? Helpfully, you get immediate feedback: if you take out too much, your example doesn‚Äôt do the thing anymore. This skill of editing and question asking is critical ‚Äî and it‚Äôs why the process of creating a reprex so often leads to a discovery of a solution.\nYou don‚Äôt always have to start with a large problem. It can be just as valuable to create a toy problem to play with as you‚Äôre learning a new concept or a programming method. It‚Äôs easier to tinker and explore when it‚Äôs small, just like it‚Äôs easier to be confident you understand what the code or method you‚Äôre learning are actually doing when that‚Äôs the focus of your code.\nSo, the next time you‚Äôre flailing, stop and make a reprex. The next time you‚Äôre learning a new concept, stop and make a reprex. And the next time you‚Äôre teaching beginners how to program, feel free to teach them how to stop and make a reprex2."
  },
  {
    "objectID": "blog/questions-answers-and-reprexes/index.html#footnotes",
    "href": "blog/questions-answers-and-reprexes/index.html#footnotes",
    "title": "Questions, answers, and reprexes",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nflailing is a technical term. If you‚Äôre trying many things but you don‚Äôt have the feeling of getting anywhere, then you‚Äôre flailing. You‚Äôll know you aren‚Äôt flailing any more when you have a feeling of getting somewhere even when your ideas aren‚Äôt panning out ‚Äî because they‚Äôre at least telling you what won‚Äôt work.‚Ü©Ô∏é\nSeriously, teach reprex early. You don‚Äôt have to get into the weeds about environments or file paths or other technical details. Learning to program is learning how to understand code; they‚Äôll either learn how to approach problematic code in a systematic way with a reprex, or they‚Äôll learn how to debug their own code in the wild with fewer guard rails and tools.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/r-console-calendar/index.html",
    "href": "blog/r-console-calendar/index.html",
    "title": "A Calendar in Your R Console",
    "section": "",
    "text": "Today I was nerd sniped by Mike FC who goes by @coolbutuseless on Twitter despite the fact that he makes cool and useful things on the regular.\nIn his tweet, he shows a neat trick that works on Unix or macOS machines. These systems come with a command-line utility called cal (read more here). By calling cal from the R console using system(), you can print a calendar in your console.\nsystem(\"cal\")\n\n   February 2023      \nSu Mo Tu We Th Fr Sa  \n          1  2  3  4  \n 5  6  7  8  9 10 11  \n12 13 14 15 16 17 18  \n19 20 21 22 23 24 25  \n26 27 28\nHere‚Äôs Mike‚Äôs original tweet.\nThis is neat and all, but it doesn‚Äôt work on Windows üò¢ ü§∑‚Äç.\nSo I used lubridate and crayon to recreate cal with an R function cal(). I‚Äôm not going to do a full walk through of the code, but I still wanted to share it. Read on to explore the code or to try out the function yourself."
  },
  {
    "objectID": "blog/r-console-calendar/index.html#tidy-dates",
    "href": "blog/r-console-calendar/index.html#tidy-dates",
    "title": "A Calendar in Your R Console",
    "section": "Tidy Dates",
    "text": "Tidy Dates\nThe first step was to write a function to set up a data frame of dates. This I cribbed heavily from ggweekly.\n\nmake_month_dates &lt;- function(start_date, end_date, week_start = 1) {\n  if (identical(week_start, 7)) {\n    get_week &lt;- lubridate::epiweek\n    get_year &lt;- lubridate::epiyear\n  } else if (identical(week_start, 1)) {\n    get_week &lt;- lubridate::isoweek\n    get_year &lt;- lubridate::isoyear\n  }\n\n  if (!inherits(start_date, \"Date\")) {\n    start_date &lt;- lubridate::ymd(start_date, truncated = 1)\n  }\n  if (!inherits(end_date, \"Date\")) {\n    end_date &lt;- lubridate::ymd(end_date, truncated = 1)\n  }\n\n  start_date &lt;- lubridate::floor_date(start_date, \"month\")\n  end_date &lt;- lubridate::rollback(lubridate::ceiling_date(end_date, \"month\"))\n\n  tibble::tibble(\n    date      = seq(start_date, end_date, by = \"day\"),\n    day       = lubridate::day(date),\n    wday      = lubridate::wday(.data$date, label = FALSE, abbr = TRUE, week_start = week_start),\n    weekend   = lubridate::wday(.data$date, label = FALSE, week_start = 1) %in% 6:7,\n    week      = get_week(.data$date),\n    month     = lubridate::month(.data$date, label = TRUE, abbr = FALSE),\n    month_int = lubridate::month(.data$date, label = FALSE),\n    year      = get_year(.data$date)\n  )\n}\n\nThe make_month_dates() function takes a full year-month-day or a year-month and returns the dates between the month start of the start_date and the month end of the end_date. Weeks can start on Monday (1) or Sunday (7).\n\nmake_month_dates(\"2020-09\", \"2020-11\", week_start = 1)\n\n# A tibble: 91 √ó 8\n   date         day  wday weekend  week month     month_int  year\n   &lt;date&gt;     &lt;int&gt; &lt;dbl&gt; &lt;lgl&gt;   &lt;dbl&gt; &lt;ord&gt;         &lt;dbl&gt; &lt;dbl&gt;\n 1 2020-09-01     1     2 FALSE      36 September         9  2020\n 2 2020-09-02     2     3 FALSE      36 September         9  2020\n 3 2020-09-03     3     4 FALSE      36 September         9  2020\n 4 2020-09-04     4     5 FALSE      36 September         9  2020\n 5 2020-09-05     5     6 TRUE       36 September         9  2020\n 6 2020-09-06     6     7 TRUE       36 September         9  2020\n 7 2020-09-07     7     1 FALSE      37 September         9  2020\n 8 2020-09-08     8     2 FALSE      37 September         9  2020\n 9 2020-09-09     9     3 FALSE      37 September         9  2020\n10 2020-09-10    10     4 FALSE      37 September         9  2020\n# ‚Ä¶ with 81 more rows"
  },
  {
    "objectID": "blog/r-console-calendar/index.html#make-it-a-calendar",
    "href": "blog/r-console-calendar/index.html#make-it-a-calendar",
    "title": "A Calendar in Your R Console",
    "section": "Make it a Calendar",
    "text": "Make it a Calendar\nThe next step is to wrangle the dates into a calendar shape. For this step, I used dplyr, tidyr, and lubridate together.\nThe gist of the process is to\n\nFill in the blank days for ‚Äúmissing‚Äù weekdays in the first or last week of each month\nCreate the month-calendar title and collapse each week into a single line\nDetermine how many calendars fit on each row and paste each nth week together into a single line\nFinally print each line to print rows of calendars!\n\nCheck out the whole function below for the complete details. I used package prefixes (and cur_group_id() from dplyr 1.0.0), and I inlined the code from make_month_dates() above to facilitate copy-pasting-calendaring.\n\nR code\n\n\n\ncal &lt;- function(\n  start_date = lubridate::today(),\n  end_date = start_date + 28,\n  week_start = 1\n) {\n  `%&gt;%` &lt;- dplyr::`%&gt;%`\n\n  if (!inherits(start_date, \"Date\")) {\n    start_date &lt;- lubridate::ymd(start_date, truncated = 1)\n  }\n  if (!inherits(end_date, \"Date\")) {\n    end_date &lt;- lubridate::ymd(end_date, truncated = 1)\n  }\n\n  start_date &lt;- lubridate::floor_date(start_date, \"month\")\n  end_date &lt;- lubridate::rollback(lubridate::ceiling_date(end_date, \"month\"))\n\n  tibble::tibble(\n    date      = seq(start_date, end_date, by = \"day\"),\n    day       = lubridate::day(date),\n    wday      = lubridate::wday(.data$date, label = FALSE, abbr = TRUE, week_start = week_start),\n    weekend   = lubridate::wday(.data$date, label = FALSE, week_start = 1) %in% 6:7,\n    week      = as.integer(lubridate::floor_date(.data$date, unit = \"week\", week_start = week_start)),\n    month     = lubridate::month(.data$date, label = TRUE, abbr = FALSE),\n    month_int = lubridate::month(.data$date, label = FALSE),\n    year      = lubridate::year(lubridate::floor_date(.data$date, unit = \"year\", week_start = week_start))\n  ) %&gt;%\n    dplyr::group_by(month, year) %&gt;%\n    dplyr::mutate(week = week - min(week) + 1) %&gt;%\n    dplyr::ungroup() %&gt;%\n    tidyr::complete(tidyr::nesting(year, month_int, month), wday = 1:7, week) %&gt;%\n    dplyr::arrange(year, month_int, week, wday) %&gt;%\n    dplyr::mutate(\n      day = sprintf(\"%2s\", day),\n      day = dplyr::if_else(weekend, as.character(crayon::silver(day)), day),\n      day = dplyr::if_else(\n        date == lubridate::today(),\n        as.character(crayon::bold(crayon::red(day))),\n        day\n      ),\n      month_label = paste(month, year)\n    ) %&gt;%\n    tidyr::replace_na(list(day = \"  \")) %&gt;%\n    dplyr::group_by(year, month_int, month_label, week) %&gt;%\n    dplyr::summarize(day = paste(day, collapse = \" \"), .groups = \"drop\") %&gt;%\n    dplyr::group_by(month_int) %&gt;%\n    dplyr::mutate(\n      width = max(crayon::col_nchar(day)),\n      day = crayon::col_align(day, width = width, align = \"right\"),\n      month_label = crayon::col_align(month_label, width = width, align = \"center\"),\n      month_label = crayon::bold(month_label)\n    ) %&gt;%\n    dplyr::ungroup() %&gt;%\n    dplyr::bind_rows(\n      dplyr::distinct(., year, month_int, day = month_label, week = 0)\n    ) %&gt;%\n    dplyr::mutate(width = max(crayon::col_nchar(day))) %&gt;%\n    dplyr::arrange(year, month_int, week) %&gt;%\n    dplyr::group_by(year, month_int) %&gt;%\n    dplyr::mutate(\n      row = dplyr::cur_group_id() - 1,\n      row = floor(row / (getOption(\"width\") %/% (width + 2))),\n    ) %&gt;%\n    dplyr::group_by(row, week) %&gt;%\n    dplyr::summarize(text = paste(day, collapse = \"    \"), .groups = \"drop_last\") %&gt;%\n    dplyr::mutate(text = dplyr::if_else(week == max(week), paste0(text, \"\\n\"), text)) %&gt;%\n    dplyr::pull(text) %&gt;%\n    cli::cat_line()\n}\n\nPhew, that‚Äôs a lot. But now I have a function cal() that prints out a calendar in my R console!\n\n\n\ncal(\"2020-09\", \"2020-12\")\n   September 2020           October 2020    \n    1  2  3  4  5  6              1  2  3  4\n 7  8  9 10 11 12 13     5  6  7  8  9 10 11\n14 15 16 17 18 19 20    12 13 14 15 16 17 18\n21 22 23 24 25 26 27    19 20 21 22 23 24 25\n28 29 30                26 27 28 29 30 31   \n                                            \n\n    November 2020           December 2020   \n                   1        1  2  3  4  5  6\n 2  3  4  5  6  7  8     7  8  9 10 11 12 13\n 9 10 11 12 13 14 15    14 15 16 17 18 19 20\n16 17 18 19 20 21 22    21 22 23 24 25 26 27\n23 24 25 26 27 28 29    28 29 30 31         \n30                                          \n\n\n\nEdited on 2021-01-28 to fix a bug that caused days whose ISO weeks occur in an earlier year ‚Äî e.g.¬†2021-01-01 is assigned to week 53 of 2020 ‚Äî to appear in an incorrect year. Thanks @Darkyben!"
  },
  {
    "objectID": "blog/redacted-text-extracted-mueller-report/index.html",
    "href": "blog/redacted-text-extracted-mueller-report/index.html",
    "title": "The Redacted, Text-Extracted Mueller Report",
    "section": "",
    "text": "Earlier today, the redacted Mueller report was released to the public. Only about 12% of the report is redacted, but 100% of it is inside what‚Äôs essentially a scanned PDF.\nThere are many people interested in taking a deeper look at the report, whether within the U.S. government, as citizens, or as data scientists.\nRather than disect the report and its political implications, I‚Äôm going to use open-source tools to extract the text from the report. I‚Äôm also going to take advantage of the opportunity to use a new R package I‚Äôve been wanting to try, ggpage by Emil Hvitfeldt to visualize the report‚Äôs pages and highlight the most-often referenced people in the report."
  },
  {
    "objectID": "blog/redacted-text-extracted-mueller-report/index.html#pdftools",
    "href": "blog/redacted-text-extracted-mueller-report/index.html#pdftools",
    "title": "The Redacted, Text-Extracted Mueller Report",
    "section": "Extracting the report text with pdftools",
    "text": "Extracting the report text with pdftools\nI used the pdftools package by ROpenSci to extract the text from the document, using the report posted by @dataeditor of the Washington Post, available here. Extracting the text was as simple as downloading the PDF and running pdftools::pdf_text(). I added page and line numbers to the extracted text and stored the result as a CSV that you can download from the GitHub repository.\nlibrary(tidyverse)\nlibrary(pdftools)\n\n# Download report from link above\nmueller_report_txt &lt;- pdf_text(\"Redacted-Mueller-Report.pdf\")\n\nmueller_report &lt;- tibble(\n  page = 1:length(mueller_report_txt),\n  text = mueller_report_txt\n) %&gt;%\n  separate_rows(text, sep = \"\\n\") %&gt;%\n  group_by(page) %&gt;%\n  mutate(line = row_number()) %&gt;%\n  ungroup() %&gt;%\n  select(page, line, text)\n\nwrite_csv(mueller_report, \"mueller_report.csv\")\nGrab the code and resulting data from gadenbuie/mueller-report on GitHub."
  },
  {
    "objectID": "blog/redacted-text-extracted-mueller-report/index.html#ggpage",
    "href": "blog/redacted-text-extracted-mueller-report/index.html#ggpage",
    "title": "The Redacted, Text-Extracted Mueller Report",
    "section": "Visualizing the report pages with ggpage",
    "text": "Visualizing the report pages with ggpage\nThe LA Times published an widely-shared piece visualizing each of the pages of the Mueller report, and Nathan Yau of Flowing Data shows how to create this image using pdftools::pdf_convert().\n\nRecently, Emil Hvitfeldt released ggpage, a package that lets you create a page-layout visualization using ggplot2. While the package uses the text content of the document only ‚Äî so the visualized text layout doesn‚Äôt completely match the layout of the original document ‚Äî it does allow you to highlight text elements, like mentions of any of the recurring cast of characters in Stupid Watergate.\nThe first step is to load the text version of the Mueller report. You can see from the first few lines of the data that the OCR really struggled with the header that appears at the top of each page and has been crossed out with a single line. (The redacted text is less confusing to the OCR because it‚Äôs rendered in solid black and generally results in blank space.)\n\nlibrary(tidyverse)\nlibrary(ggpage)\n\nmueller_report_csv &lt;- \"https://raw.githubusercontent.com/gadenbuie/mueller-report/ab74012b0532ffa34f3a45196d2b28004e11b9c2/mueller_report.csv\"\n\nmueller_report &lt;- read_csv(mueller_report_csv)\n\nmueller_report\n\n# A tibble: 19,195 √ó 3\n    page  line text                                             \n   &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;                                            \n 1     1     1 \"U.S. Department of Justice\"                     \n 2     1     2 \"AttarAe:,c\\\\\\\\'erlc Predtiet // Mtt; CeA1:ttiA\" \n 3     1     3 \"Ma1:ertalPrn1:eetedUAder Fed. R. Crhtt. P. 6(e)\"\n 4     1     4 \"Report On The Investigation Into\"               \n 5     1     5 \"Russian InterferenceIn The\"                     \n 6     1     6 \"2016 PresidentialElection\"                      \n 7     1     7 \"Volume I of II\"                                 \n 8     1     8 \"Special Counsel Robert S. Mueller, III\"         \n 9     1     9 \"Submitted Pursuant to 28 C.F.R. ¬ß 600.8(c)\"     \n10     1    10 \"Washington, D.C.\"                               \n# ‚Ä¶ with 19,185 more rows\n\n\nThe core of the next step is to pass the mueller_report to ggpage::ggpage_build(). Before doing that, though, I pad each page to make sure they have the same number of lines. The ggpage_build() function tokenizes the text into individual words, so I then use str_detect() to find mentions of the key players.\n\nmueller_pages &lt;-\n  mueller_report %&gt;%\n  # pad pages with fewer lines than expected\n  complete(\n    page,\n    line = 1:max(mueller_report$line),\n    fill = list(text = \"\")\n  ) %&gt;%\n  # Pre-process for {ggpage}\n  ggpage_build(\n    ncol = 30,\n    bycol = FALSE,\n    page.col = \"page\",\n    wtl = FALSE,\n    x_space_pages = 10,\n    y_space_pages = 100\n  ) %&gt;%\n  mutate(\n    color = case_when(\n      str_detect(word, \"trump|president\") ~ \"Trump\",\n      str_detect(word, \"russia\")     ~ \"Russia\",\n      str_detect(word, \"cohen\")      ~ \"Cohen\",\n      str_detect(word, \"co(m|rn)ey\") ~ \"Comey\",\n      str_detect(word, \"flynn\")      ~ \"Flynn\",\n      str_detect(word, \"manafort\")   ~ \"Manafort\",\n      str_detect(word, \"sessions\")   ~ \"Sessions\",\n      str_detect(word, \"mcgahn\")     ~ \"McGahn\",\n      TRUE ~ \"normal\"\n    ),\n    color = factor(color, c(\n      \"Trump\", \"Russia\", \"Cohen\", \"Comey\",\n      \"Flynn\", \"Manafort\", \"Sessions\", \"McGahn\", \"normal\"\n    ))\n  )\n\nmueller_pages\n\n# A tibble: 207,165 √ó 9\n   word        page  line  xmin  xmax  ymin  ymax index_line color \n   &lt;chr&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;      &lt;fct&gt; \n 1 u.s            1     1   175   172  -204  -207 1-1        normal\n 2 department     1     1   186   176  -204  -207 1-1        normal\n 3 of             1     1   189   187  -204  -207 1-1        normal\n 4 justice        1     1   197   190  -204  -207 1-1        normal\n 5 washington     1    10   182   172  -240  -243 1-10       normal\n 6 d.c            1    10   186   183  -240  -243 1-10       normal\n 7 march          1    11   177   172  -244  -247 1-11       normal\n 8 2019           1    11   182   178  -244  -247 1-11       normal\n 9 attarae        1     2   179   172  -208  -211 1-2        normal\n10 c              1     2   181   180  -208  -211 1-2        normal\n# ‚Ä¶ with 207,155 more rows\n\n\nThe following bit of code sets up the color palette, which is derived from the Libre Office Calc theme provided by ggthemes.\n\n# manually assigned colors from ggthemes::pal_calc()\ncolors &lt;- rep(\"\", length(levels(mueller_pages$color)))\nnames(colors) &lt;- levels(mueller_pages$color)\ncolors[\"Trump\"]    &lt;- \"#FF4023\"\ncolors[\"Russia\"]   &lt;- \"#004983\"\ncolors[\"Cohen\"]    &lt;- \"#FF922E\"\ncolors[\"Comey\"]    &lt;- \"#559B30\"\ncolors[\"Flynn\"]    &lt;- \"#4D276D\"\ncolors[\"Manafort\"] &lt;- \"#7BCAFD\"\ncolors[\"Sessions\"] &lt;- \"#7F1327\"\ncolors[\"McGahn\"]   &lt;- \"#FFD040\"\ncolors[\"normal\"]   &lt;- \"#d0d0d0\"\n\nFinally, ggpage_plot() from ggpage creates the ggplot2 page layout, and adding the fill aesthetic using the manual color scale defined above adds color highlights for mentions of Trump, Russia, and others.\n\nggpage_plot(mueller_pages) +\n  aes(fill = color) +\n  scale_fill_manual(\n    values = colors,\n    breaks = setdiff(names(colors), \"normal\")\n  ) +\n  labs(fill = NULL, caption = \"@grrrck\") +\n  guides(fill = guide_legend(nrow = 1)) +\n  theme(legend.position = \"bottom\")\n\n\n\nClick the image to expand.\n\nIf you use the data for an interesting visualization or analysis, please let me know on Twitter!"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html",
    "href": "blog/saving-daylight-time/index.html",
    "title": "Saving Daylight Time?",
    "section": "",
    "text": "Remember when Daylight Saving Time happened to us again? You know, that day that causes us all to grumble loudly about the ridiculousness of our biannual clock adjustment and loss of sleep?\nIn this post, I engage in some self-care data visualization to explore day light hours in cities across the world and the United States, inspired by an awesome night hours series by Krisztina Szucs."
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#are-we-saving-daylight-in-atlanta-ga",
    "href": "blog/saving-daylight-time/index.html#are-we-saving-daylight-in-atlanta-ga",
    "title": "Saving Daylight Time?",
    "section": "Are we saving daylight in Atlanta, GA?",
    "text": "Are we saving daylight in Atlanta, GA?\nAs a parent, I loathe daylight saving time. Nothing reveals the shared delusion of time like trying to explain to your children why we moved the clock forward an hour when it means they‚Äôll suddenly need to go to bed while it‚Äôs light out or wake up and get ready for school while it‚Äôs dark.\nSo in this spirit, I started to wonder: what kind of returns are we getting on our daylight saving? Except, rather than try to directly answer that question ‚Äî since that‚Äôs way too hard ‚Äî I chose to visualize day light hours to see how they align with the modern work day.\nThe plot below shows the yearly day light schedule for 2022 in Atlanta, GA where I live. We‚Äôll also take a look at the day light schedule in other cities around the world or across the United States. At the end of this post, I‚Äôll share the code I used to make the plot below.\n\n\n  \n  Atlanta, GA. \n\n\n\n\nDate\nSunrise\nSunset\nDaylight\nNon-Work\n\n\n\n\nShortest Day\nDec 21\n7:41 am\n5:38 pm\n9h 56m\n1h 56m\n\n\nLongest Day\nJun 21\n6:32 am\n8:54 pm\n14h 21m\n6h 21m\n\n\n\n\n\n\nIt‚Äôs pretty clear from this visualization that in Atlanta, GA, which is very much on the western edge of the U.S. Eastern time zone, year-round standard time is a decent way to live life. What about other cities in the world?"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#around-the-world",
    "href": "blog/saving-daylight-time/index.html#around-the-world",
    "title": "Saving Daylight Time?",
    "section": "Around the World",
    "text": "Around the World\n\n\n\nPick a city\n\n\nStockholm, Sweden\nLondon, United Kingdom\nCalgary, Canada\nAktobe, Kazakhstan\nRome, Italy\nChicago, USA\nShenyang, China\nNew York City, USA\nMadrid, Spain\nBeijing, China\nSeoul, Korea\nSan Jose, USA\nAlgiers, Algeria\nLos Angeles, USA\nShanghai, China\nAlexandria, Egypt\nChengdu, China\nCairo, Egypt\nHouston, USA\nShenzhen, China\nPort Sudan, Sudan\nMexico City, Mexico\nKano, Nigeria\nHo Chi Minh City, Viet Nam\nCaracas, Venezuela\nLagos, Nigeria\nBogota, Colombia\nJakarta, Indonesia\nSao Paulo, Brazil\nJohannesburg, South Africa\nSydney, Australia\nPunta Arenas, Chile\n\nPrevious city\nNext city\n\n\n\n\n\n\n\n\n\nA sunrise/sunset time plot."
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#across-the-us",
    "href": "blog/saving-daylight-time/index.html#across-the-us",
    "title": "Saving Daylight Time?",
    "section": "Across the US",
    "text": "Across the US\nIt seems that every year we talk about finally doing something about daylight saving time, but this year the U.S. Senate actually went so far as to pass a bill to make Daylight Saving Time permanent. In a suprising-to-no-one twist, the bill is stalled in the House, where representatives are arguing over which of standard or daylight saving time should be permanent.\nWould you prefer standard time or daylight saving time? If you‚Äôre not sure, check out the Daylight Saving Time Gripe Assistant Tool by Andy Woodruff on Observable.\nI thought it‚Äôd be interesting to visualize day light hours for U.S. cities. You can use the dropdown below to choose your city or the nearest city with more than 100,000 residents (or just pick a random city!). Then, toggle between Standard or DST to see how either proposal would affect you. Or choose Both to see what will happen in the unimaginable case that the U.S. Congress doesn‚Äôt actually make DST permanent.\n\n\n\n\nPick a city in the United States (random)\n\n\nWashington\nBirmingham, AL\nHuntsville, AL\nMobile, AL\nMontgomery, AL\nAlhambra, AZ\nChandler, AZ\nDeer Valley, AZ\nGilbert, AZ\nGlendale, AZ\nMaryvale, AZ\nMesa, AZ\nPeoria, AZ\nPhoenix, AZ\nScottsdale, AZ\nSurprise, AZ\nTempe, AZ\nTempe Junction, AZ\nTucson, AZ\nLittle Rock, AR\nAnaheim, CA\nAntioch, CA\nBakersfield, CA\nBerkeley, CA\nBurbank, CA\nCarlsbad, CA\nChico, CA\nChinatown, CA\nChula Vista, CA\nClovis, CA\nConcord, CA\nCorona, CA\nCosta Mesa, CA\nDaly City, CA\nDowney, CA\nEast Los Angeles, CA\nEl Cajon, CA\nEl Monte, CA\nElk Grove, CA\nEscondido, CA\nFairfield, CA\nFontana, CA\nFremont, CA\nFresno, CA\nFullerton, CA\nGarden Grove, CA\nGlendale, CA\nHayward, CA\nHollywood, CA\nHuntington Beach, CA\nInglewood, CA\nIrvine, CA\nKoreatown, CA\nLancaster, CA\nLong Beach, CA\nLos Angeles, CA\nModesto, CA\nMoreno Valley, CA\nMurrieta, CA\nNorwalk, CA\nOakland, CA\nOceanside, CA\nOntario, CA\nOrange, CA\nOxnard, CA\nPalmdale, CA\nPasadena, CA\nPomona, CA\nRancho Cucamonga, CA\nRialto, CA\nRichmond, CA\nRiverside, CA\nRoseville, CA\nSacramento, CA\nSalinas, CA\nSan Bernardino, CA\nSan Diego, CA\nSan Francisco, CA\nSan Jose, CA\nSan Mateo, CA\nSanta Ana, CA\nSanta Clara, CA\nSanta Clarita, CA\nSanta Maria, CA\nSanta Rosa, CA\nSimi Valley, CA\nStockton, CA\nSunnyvale, CA\nTemecula, CA\nThousand Oaks, CA\nTorrance, CA\nUniversal City, CA\nValencia, CA\nVallejo, CA\nVan Nuys, CA\nVictorville, CA\nVisalia, CA\nVista, CA\nWest Covina, CA\nArvada, CO\nAurora, CO\nBoulder, CO\nCentennial, CO\nColorado Springs, CO\nDenver, CO\nFort Collins, CO\nGreeley, CO\nLakewood, CO\nPueblo, CO\nThornton, CO\nWestminster, CO\nBridgeport, CT\nHartford, CT\nNew Haven, CT\nNorth Stamford, CT\nStamford, CT\nWaterbury, CT\nBrandon, FL\nCape Coral, FL\nClearwater, FL\nCoral Springs, FL\nDavie, FL\nFort Lauderdale, FL\nGainesville, FL\nHialeah, FL\nHollywood, FL\nJacksonville, FL\nLakeland, FL\nMiami, FL\nMiami Gardens, FL\nMiramar, FL\nOrlando, FL\nPalm Bay, FL\nPembroke Pines, FL\nPompano Beach, FL\nPort Saint Lucie, FL\nSt. Petersburg, FL\nTallahassee, FL\nTampa, FL\nWest Palm Beach, FL\nAthens, GA\nAtlanta, GA\nColumbus, GA\nSandy Springs, GA\nSavannah, GA\nHonolulu, HI\nBoise, ID\nAurora, IL\nChicago, IL\nElgin, IL\nJoliet, IL\nNaperville, IL\nNorth Peoria, IL\nPeoria, IL\nRockford, IL\nSpringfield, IL\nEvansville, IN\nFort Wayne, IN\nIndianapolis, IN\nSouth Bend, IN\nCedar Rapids, IA\nDavenport, IA\nDes Moines, IA\nKansas City, KS\nOlathe, KS\nOverland Park, KS\nTopeka, KS\nWichita, KS\nIronville, KY\nLexington, KY\nLexington-Fayette, KY\nLouisville, KY\nMeads, KY\nBaton Rouge, LA\nLafayette, LA\nMetairie, LA\nMetairie Terrace, LA\nNew Orleans, LA\nShreveport, LA\nBaltimore, MD\nBoston, MA\nCambridge, MA\nLowell, MA\nNew Bedford, MA\nSouth Boston, MA\nSpringfield, MA\nWorcester, MA\nAnn Arbor, MI\nDetroit, MI\nGrand Rapids, MI\nLansing, MI\nSterling Heights, MI\nWarren, MI\nMinneapolis, MN\nRochester, MN\nSaint Paul, MN\nJackson, MS\nColumbia, MO\nEast Independence, MO\nIndependence, MO\nKansas City, MO\nSpringfield, MO\nSt. Louis, MO\nBillings, MT\nLincoln, NE\nOmaha, NE\nEnterprise, NV\nHenderson, NV\nLas Vegas, NV\nNorth Las Vegas, NV\nParadise, NV\nReno, NV\nSpring Valley, NV\nSunrise Manor, NV\nManchester, NH\nEdison, NJ\nElizabeth, NJ\nJersey City, NJ\nNewark, NJ\nPaterson, NJ\nAlbuquerque, NM\nLas Cruces, NM\nAmherst, NY\nAstoria, NY\nBorough Park, NY\nBrooklyn, NY\nBuffalo, NY\nBushwick, NY\nCorona, NY\nEast Flatbush, NY\nEast Harlem, NY\nEast New York, NY\nElmhurst, NY\nGravesend, NY\nHarlem, NY\nJamaica, NY\nManhattan, NY\nNew York City, NY\nQueens, NY\nRochester, NY\nSheepshead Bay, NY\nStaten Island, NY\nSunset Park, NY\nSyracuse, NY\nThe Bronx, NY\nWashington Heights, NY\nYonkers, NY\nCary, NC\nCharlotte, NC\nDurham, NC\nFayetteville, NC\nGreensboro, NC\nHigh Point, NC\nRaleigh, NC\nWest Raleigh, NC\nWilmington, NC\nWinston-Salem, NC\nFargo, ND\nAkron, OH\nCincinnati, OH\nCleveland, OH\nColumbus, OH\nDayton, OH\nToledo, OH\nBroken Arrow, OK\nNorman, OK\nOklahoma City, OK\nTulsa, OK\nEugene, OR\nGresham, OR\nHillsboro, OR\nPortland, OR\nSalem, OR\nAllentown, PA\nPhiladelphia, PA\nPittsburgh, PA\nProvidence, RI\nCharleston, SC\nColumbia, SC\nNorth Charleston, SC\nSioux Falls, SD\nChattanooga, TN\nClarksville, TN\nEast Chattanooga, TN\nKnoxville, TN\nMemphis, TN\nMurfreesboro, TN\nNashville, TN\nNew South Memphis, TN\nAbilene, TX\nAmarillo, TX\nArlington, TX\nAustin, TX\nBeaumont, TX\nBrownsville, TX\nCarrollton, TX\nCollege Station, TX\nCorpus Christi, TX\nDallas, TX\nDenton, TX\nEl Paso, TX\nFort Worth, TX\nFrisco, TX\nGarland, TX\nGrand Prairie, TX\nHouston, TX\nIrving, TX\nKilleen, TX\nLaredo, TX\nLewisville, TX\nLubbock, TX\nMcAllen, TX\nMcKinney, TX\nMesquite, TX\nMidland, TX\nOdessa, TX\nPasadena, TX\nPearland, TX\nPlano, TX\nRichardson, TX\nRound Rock, TX\nSan Angelo, TX\nSan Antonio, TX\nTyler, TX\nWaco, TX\nWichita Falls, TX\nProvo, UT\nSalt Lake City, UT\nWest Jordan, UT\nWest Valley City, UT\nAlexandria, VA\nArlington, VA\nChesapeake, VA\nEast Hampton, VA\nHampton, VA\nNewport News, VA\nNorfolk, VA\nRichmond, VA\nVirginia Beach, VA\nBellevue, WA\nEverett, WA\nKent, WA\nRenton, WA\nSeattle, WA\nSpokane, WA\nTacoma, WA\nTri-Cities, WA\nVancouver, WA\nGreen Bay, WI\nMadison, WI\nMilwaukee, WI\n\n\n\n\n\n\nUse timezone\n\n\n\n\nStandard\n\n\n\n\nBoth\n\n\n\n\nDST\n\n\n\n\n\n\n\nSunrise and sunset times in Washington, D.C."
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#inspiration",
    "href": "blog/saving-daylight-time/index.html#inspiration",
    "title": "Saving Daylight Time?",
    "section": "Inspiration",
    "text": "Inspiration\nThe layout for this vizualization was heavily inspired by a series by Kristina Szucs that I discovered via r/dataisbeautiful. I loved the aesthetic of Kristina‚Äôs plot and the subtle gradients and shadows of the daylight/twilight hour regions. Her attention to little details such a the sunrise and sunset icon labels and the stars in the night region are just fantastic.\n\n  How long are the nights in New York City? by Krisztina Szucs\n\nIn my version I wanted to draw on a similar structure and style to visualize daylight rather than sunset hours. I also wanted to see how far I could go with my plot without leaving the comfort of ggplot2, so I stopped short of adding the sunrise and sunset icons. (I suppose anything is possible in ggplot2 but IMHO this is a reasonable line to draw.)"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#where-are-you",
    "href": "blog/saving-daylight-time/index.html#where-are-you",
    "title": "Saving Daylight Time?",
    "section": "Where are you?",
    "text": "Where are you?\nTo get accurate sunrise and sunset time data, we first need to figure out where in the world we are. Fortunately, the ipapi package makes it easy to grab key geolocation data from your IP address, like latitude, longitude and time zone. (I‚Äôm adding a little fuzz just to make ipapi a little less accurate.)\n\nlocation &lt;- as.list(ipapi::geolocate(NA, .progress = FALSE))\n\n# find a location nearby but not my actual house, lol\nlocation$lat &lt;- location$lat + runif(1, min = -0.5, max = 0.5)\nlocation$lon &lt;- location$lon + runif(1, min = -0.5, max = 0.5)\n\n\nlocation[c(\"lat\", \"lon\", \"timezone\")]\n## $lat\n## [1] 33.34846\n## \n## $lon\n## [1] -85.17511\n## \n## $timezone\n## [1] \"America/New_York\""
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#sunrise-and-sunset-times",
    "href": "blog/saving-daylight-time/index.html#sunrise-and-sunset-times",
    "title": "Saving Daylight Time?",
    "section": "Sunrise and Sunset Times",
    "text": "Sunrise and Sunset Times\nNext, we take our latitude and longitude to suncalc, an R package port of suncalc.js. We ask getSunlightTimes() for the dawn and dusk related times for every day in 2022.\n\nsun_times &lt;-\n  suncalc::getSunlightTimes(\n    date = seq(\n      as.Date(\"2022-01-01\"),\n      as.Date(\"2023-01-01\"),\n      by = \"day\"\n    ),\n    lat = location$lat,\n    lon = location$lon,\n    tz = location$timezone,\n    keep = c(\"dawn\", \"nauticalDawn\", \"dusk\", \"nauticalDusk\", \"sunrise\", \"sunset\")\n  )\n\nhead(sun_times)\n##         date      lat       lon                dawn        nauticalDawn\n## 1 2022-01-01 33.34846 -85.17511 2022-01-01 07:18:23 2022-01-01 06:47:27\n## 2 2022-01-02 33.34846 -85.17511 2022-01-02 07:18:35 2022-01-02 06:47:41\n## 3 2022-01-03 33.34846 -85.17511 2022-01-03 07:18:45 2022-01-03 06:47:53\n## 4 2022-01-04 33.34846 -85.17511 2022-01-04 07:18:54 2022-01-04 06:48:03\n## 5 2022-01-05 33.34846 -85.17511 2022-01-05 07:19:02 2022-01-05 06:48:12\n##                  dusk        nauticalDusk             sunrise\n## 1 2022-01-01 18:12:28 2022-01-01 18:43:24 2022-01-01 07:45:47\n## 2 2022-01-02 18:13:11 2022-01-02 18:44:05 2022-01-02 07:45:57\n## 3 2022-01-03 18:13:54 2022-01-03 18:44:47 2022-01-03 07:46:06\n## 4 2022-01-04 18:14:39 2022-01-04 18:45:30 2022-01-04 07:46:14\n## 5 2022-01-05 18:15:25 2022-01-05 18:46:14 2022-01-05 07:46:19\n##                sunset\n## 1 2022-01-01 17:45:04\n## 2 2022-01-02 17:45:48\n## 3 2022-01-03 17:46:33\n## 4 2022-01-04 17:47:20\n## 5 2022-01-05 17:48:07\n##  [ reached 'max' / getOption(\"max.print\") -- omitted 1 rows ]\n\nIf you‚Äôre curious about the difference between (civil) dawn, nautical dawn and sunrise, take a stroll through Twilight on Wikipedia."
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#tidy-sun-times",
    "href": "blog/saving-daylight-time/index.html#tidy-sun-times",
    "title": "Saving Daylight Time?",
    "section": "Tidy Sun Times",
    "text": "Tidy Sun Times\nAs cool as it is to so easily get to the point of having this data in hand, we need to do a little bit of tidying up to get it ready for ggplot2. In particular, we need to consolidate all of the timestamps into one column that we can index by date and event (such as dawn, nautical dawn, etc.). I used pivot_longer() to move the column labels for dawn through sunset into an event column with the corresponding values from each row in an adjacent time column.\n\nlibrary(tidyverse)\n\ntidy_sun_times &lt;-\n  sun_times %&gt;%\n  select(-lat, -lon) %&gt;%\n  pivot_longer(-date, names_to = \"event\", values_to = \"time\") %&gt;%\n  mutate(\n    tz = strftime(time, \"%Z\"),\n    time = hms::as_hms(time)\n  )\n\ntidy_sun_times\n## # A tibble: 2,196 √ó 4\n##    date       event        time     tz   \n##    &lt;date&gt;     &lt;chr&gt;        &lt;time&gt;   &lt;chr&gt;\n##  1 2022-01-01 dawn         07:18:23 EST  \n##  2 2022-01-01 nauticalDawn 06:47:27 EST  \n##  3 2022-01-01 dusk         18:12:28 EST  \n##  4 2022-01-01 nauticalDusk 18:43:24 EST  \n##  5 2022-01-01 sunrise      07:45:47 EST  \n##  6 2022-01-01 sunset       17:45:04 EST  \n##  7 2022-01-02 dawn         07:18:35 EST  \n##  8 2022-01-02 nauticalDawn 06:47:41 EST  \n##  9 2022-01-02 dusk         18:13:11 EST  \n## 10 2022-01-02 nauticalDusk 18:44:05 EST  \n## # ‚Ä¶ with 2,186 more rows\n\nThere‚Äôs also a small trick here to use strftime() to extract the short timezone label %Z, e.g.¬†EST or EDT, for each day, which I‚Äôll use later when calling out the time changes. And finally, I used hms::as_hms() to extract the time of day component from each sun event timestamp. The neat thing about the hms class is that while it prints in a readable hours, minutes, seconds format, we can also treat it as an integer number of seconds from midnight. We‚Äôll use this property in just a bit when working on the plot‚Äôs axis labels."
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#first-looks",
    "href": "blog/saving-daylight-time/index.html#first-looks",
    "title": "Saving Daylight Time?",
    "section": "First Looks",
    "text": "First Looks\nNow that we have tidy data ready for ggplot2, let‚Äôs plot it! This plot won‚Äôt look amazing, but it will help us get a sense of the data we have to work with.\n\nggplot(tidy_sun_times) +\n  aes(x = date, y = time, color = event) +\n  geom_line()"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#paired-daily-events",
    "href": "blog/saving-daylight-time/index.html#paired-daily-events",
    "title": "Saving Daylight Time?",
    "section": "Paired Daily Events",
    "text": "Paired Daily Events\nThe plot above reveals our next challenge: I used geom_line() to plot the time of each event as a line, but I want to be able to fill in the region between each pair of events:\n\nsunrise and sunset\ndawn and dusk\nnautical dawn and nautical dusk.\n\nWe can use geom_ribbon() to acheive this look, but it requires a little more transformation. We need the sunrise time in one column called starts and a second column with the sunset time in ends. Then we can map these new columns to the ymin and ymax aesthetics, letting geom_ribbon() fill in space between them.\nThe plan of action is to create a new column that I‚Äôll call period where we‚Äôll choose which of these two new columns a timestamp will be moved to. We‚Äôll identify each pair using the morning event label.\nBecause we need pivot_longer() to create two new columns, starts and ends, from our single period column, we‚Äôll first split the table into a list of two tables, one for each period, and then pivot the timestamp column into a new column. Because we‚Äôre operating on a list, we‚Äôll use purrr::map() to coordinate this action. Then we can merge the two tables back together with left_join(), using purrr::reduce() to apply that action to the list of pivoted tables.\nAfter that, we‚Äôre back in single-table land, and can use mutate() and select() to tweak the final table output to make sure that the morning events are ordered correctly: nautical dawn, then dawn, then sunrise.\n\ntidier_sun_times &lt;-\n  tidy_sun_times %&gt;%\n  mutate(\n    period = case_when(\n      str_detect(event, \"[dD]awn|sunrise\") ~ \"starts\",\n      str_detect(event, \"[dD]usk|sunset\") ~ \"ends\"\n    ),\n    pair = recode(\n      event,\n      nauticalDusk = \"nauticalDawn\",\n      sunset = \"sunrise\",\n      dusk = \"dawn\"\n    )\n  ) %&gt;%\n  group_split(period) %&gt;%\n  map(pivot_wider, names_from = \"period\", values_from = \"time\") %&gt;%\n  reduce(\n    left_join,\n    by = c(\"date\", \"tz\", \"pair\"),\n    suffix = c(\"_ends\", \"_starts\")\n  ) %&gt;%\n  mutate(\n    pair = factor(pair, c(\"nauticalDawn\", \"dawn\", \"sunrise\"))\n  ) %&gt;%\n  select(date, tz, pair, contains(\"starts\"), contains(\"ends\"))\n\ntidier_sun_times\n## # A tibble: 1,098 √ó 7\n##    date       tz    pair         event_starts starts   event_ends   ends    \n##    &lt;date&gt;     &lt;chr&gt; &lt;fct&gt;        &lt;chr&gt;        &lt;time&gt;   &lt;chr&gt;        &lt;time&gt;  \n##  1 2022-01-01 EST   dawn         dawn         07:18:23 dusk         18:12:28\n##  2 2022-01-01 EST   nauticalDawn nauticalDawn 06:47:27 nauticalDusk 18:43:24\n##  3 2022-01-01 EST   sunrise      sunrise      07:45:47 sunset       17:45:04\n##  4 2022-01-02 EST   dawn         dawn         07:18:35 dusk         18:13:11\n##  5 2022-01-02 EST   nauticalDawn nauticalDawn 06:47:41 nauticalDusk 18:44:05\n##  6 2022-01-02 EST   sunrise      sunrise      07:45:57 sunset       17:45:48\n##  7 2022-01-03 EST   dawn         dawn         07:18:45 dusk         18:13:54\n##  8 2022-01-03 EST   nauticalDawn nauticalDawn 06:47:53 nauticalDusk 18:44:47\n##  9 2022-01-03 EST   sunrise      sunrise      07:46:06 sunset       17:46:33\n## 10 2022-01-04 EST   dawn         dawn         07:18:54 dusk         18:14:39\n## # ‚Ä¶ with 1,088 more rows"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#another-plot",
    "href": "blog/saving-daylight-time/index.html#another-plot",
    "title": "Saving Daylight Time?",
    "section": "Another plot",
    "text": "Another plot\nNow we‚Äôre ready to try out our even tidier data set! Okay, it‚Äôs actually less tidy, but more ready for plotting. We‚Äôll swap out geom_line() for geom_ribbon(), and map starts to ymin and ends to ymax, filling in each region by pair.\n\nggplot(tidier_sun_times) +\n  aes(date, ymin = starts, ymax = ends, fill = pair) +\n  geom_ribbon()\n\n\n\n\n\n\n\n\nIt looks terrible, but it‚Äôs more or less what we want to see. The y-axis is a little confusing though because it reads from night at the top to day at the bottom. The trick is to recall that we used hms::as_hms() to turn the time of day into an integer number of seconds from midnight. So we can reverse the y-axis with scale_y_reverse() and then provide our own labels.\n\nggplot(tidier_sun_times) +\n  aes(date, ymin = starts, ymax = ends, fill = pair) +\n  geom_ribbon() +\n  scale_y_reverse(\n    limits = c(24*60^2, 0),\n    breaks = seq(0, 24*60^2, by = 3 * 60^2),\n    label = paste0(seq(0, 24, by = 3), \":00\"),\n    expand = expansion()\n  ) +\n  scale_x_date(\n    breaks = \"3 months\",\n    date_labels = \"%b\"\n  )"
  },
  {
    "objectID": "blog/saving-daylight-time/index.html#make-it-pretty",
    "href": "blog/saving-daylight-time/index.html#make-it-pretty",
    "title": "Saving Daylight Time?",
    "section": "Make it pretty",
    "text": "Make it pretty\nGreat! Now it‚Äôs time to draw the rest of the owl! Which means I‚Äôm now going to include roughly 150 lines of code that take the rough sketch above and make it a pretty ggplot.\nOf course I should mention that what you‚Äôll find below isn‚Äôt even the full story of the plots you see in this post. It turned out to be an intermediate sketch of the code that I actually used to create the plots. It also turns out that I‚Äôm pretty good at writing code that creates more problems that I need to solve with more code.\nA few preliminaries: I‚Äôll use the Outfit font from Google Fonts with the help of the sysfonts package.\n\nsysfonts::font_add_google(\"Outfit\")\n\nWe‚Äôll need a grid for the x- and y-axis that will be used in a few places, so I‚Äôll create them up front. We end up with a vector of dates from January 1, 2022 to January 1, 2023 by 2 months for the x-axis and a vector of times from midnight to midnight by 3 hours for the y-axis.\n\nx_breaks &lt;- seq(\n  from = as.Date(\"2022-01-01\"),\n  to = as.Date(\"2023-01-01\"),\n  by = \"2 months\"\n)\ny_breaks &lt;- seq(0, 24*60^2, by = 3 * 60^2)\n\nFinally, there are a couple of colors I used in more than one place for the foreground and background colors. There are a few other colors that I should have pulled into variables for clarity, but I‚Äôve decided that it‚Äôs not worth the effort to think up variable names for them.\n\ncolor_text &lt;- \"#F2CDB9\"\ncolor_bg &lt;- \"#39304a\"\n\nFinally, as promised, the 150ish lines of ggplot2 code. Enjoy!\n\nggplot(tidier_sun_times) +\n  # The x-axis is always the day of the year\n  aes(x = date) +\n  # Behind everything we add a grid of `+` characters\n  # in place of grid lines, to give a starry feel\n  geom_text(\n    # the data for this layer is our grid of x and y breaks\n    data = cross_df(\n      list(date = x_breaks, time = y_breaks, label = \"+\")\n    ) %&gt;%\n      mutate(across(date, as.Date, origin = \"1970-01-01\")),\n    aes(label = label, y = time),\n    color = \"#C29F5F\"\n  ) +\n  # Here you'll recognize the outlines of our original plot sketch\n  geom_ribbon(\n    aes(ymin = starts, ymax = ends, fill = pair, alpha = pair),\n    show.legend = FALSE\n  ) +\n  # Add dotted horizontal lines at 9am and 5pm\n  geom_hline(\n    yintercept = c(9, 17) * 60^2,\n    color = color_bg,\n    alpha = 0.5,\n    linetype = 2\n  ) +\n  # And a little text to indicate the meaning of those lines\n  annotate(\n    geom = \"text\",\n    x = min(tidier_sun_times$date),\n    y = c(9, 17) * 60^2,\n    label = c(\"9am\", \"5pm\"),\n    color = color_bg,\n    hjust = -0.25,\n    vjust = c(2, -1)\n  ) +\n  # If the timezone changes, it'll be due to daylight saving time\n  # so we'll add a little text to highlight that change\n  geom_text(\n    # This combines my favorite magrittr pipe trick:\n    #   `. %&gt;%` creates a function with a single argument\n    # with my favorite ggplot2 geom trik:\n    #   `data` takes a function with a single argument that\n    #   can be used to filter the global dataset to a smaller subset\n    # The net result here is that we take the global data\n    # and filter down to the two places where the timezone changes\n    data = . %&gt;%\n      filter(tz != coalesce(lag(tz), first(tz))) %&gt;%\n      slice_head(n = 1),\n    aes(y = ends, label = tz),\n    hjust = 1,\n    vjust = 1,\n    nudge_x = -21,\n    nudge_y = -60^2 * 1.5,\n    lineheight = 0.8,\n    color = color_text\n  ) +\n  # These add two little arrows to point from the timezone text\n  # to the notch in the plot where the timezone change happens\n  geom_curve(\n    # Here's the `data = . %&gt;%` trick again\n    data = . %&gt;%\n      filter(pair == \"nauticalDawn\") %&gt;%\n      filter(tz != coalesce(lag(tz), first(tz))) %&gt;%\n      slice_head(n = 1),\n    # This next bit took much fiddling.\n    aes(\n      x = date - 17,\n      xend = date,\n      y = ends - (-60^2 * 1.2),\n      yend = ends + 500\n    ),\n    # If you like it put an arrow on it\n    arrow = arrow(length = unit(0.08, \"inch\")),\n    size = 0.5,\n    color = color_text,\n    curvature = 0.4\n  ) +\n  # The next two geoms highlight the second timezone change\n  # and are copies of the previous two layers but use\n  # `slice_tail()` instead of `slice_head()`.\n  geom_text(\n    data = . %&gt;%\n      filter(tz != coalesce(lag(tz), first(tz))) %&gt;%\n      slice_tail(n = 1),\n    aes(y = starts, label = tz),\n    hjust = 1,\n    nudge_x = -21,\n    nudge_y = 60^2 * 1.5,\n    lineheight = 0.8,\n    color = color_text\n  ) +\n  geom_curve(\n    data = . %&gt;%\n      filter(pair == \"nauticalDawn\") %&gt;%\n      filter(tz != coalesce(lag(tz), first(tz))) %&gt;%\n      slice_tail(n = 1),\n    aes(\n      x = date - 17,\n      xend = date,\n      y = starts - 60^2,\n      yend = starts - 500\n    ),\n    arrow = arrow(length = unit(0.08, \"inch\")),\n    size = 0.5,\n    color = color_text,\n    curvature = -0.4\n  ) +\n  # Finally, we add a little annotation in the left edge of the plot\n  # to serve as a legend for each layer and call out dawn, dusk,\n  # sunrise and sunset, etc. Here I used the `ggrepel` package to\n  # make sure the labels don't overlap, and in hopes that I wouldn't\n  # need to fiddle too much with positioning. Fiddling was required\n  # but I think the end result looks pretty good.\n  ggrepel::geom_label_repel(\n    data = . %&gt;% filter(date == max(date)) %&gt;%\n      pivot_longer(contains(\"event\")) %&gt;%\n      mutate(\n        date = date + 12,\n        time = if_else(value == pair, starts, ends),\n        value = snakecase::to_title_case(value)\n      ),\n    aes(y = time, fill = pair, label = value),\n    color = color_bg,\n    fontface = \"bold\",\n    show.legend = FALSE,\n    # Most of the next few lines are designed to keep the\n    # labels on the right side of the plot as close to the\n    # layers they're supposed to annotate as possible.\n    direction = \"y\",\n    min.segment.length = 20,\n    hjust = 0,\n    label.size = 0,\n    label.padding = 0.33,\n    box.padding = 0.25,\n    xlim = c(as.Date(\"2023-01-07\"), NA)\n  ) +\n  # Next up, deal with our scales.\n  # First up colors are the colors for the ribbon fill.\n  scale_fill_manual(\n    values = c(\n      nauticalDawn = \"#b56576\",\n      dawn = \"#eaac8b\",\n      sunrise = \"#ffd27d\"\n    )\n  ) +\n  # Then add a little opacity, even though ggplot will warn us\n  # that using opacity with a discrete variable isn't a good idea.\n  # (I think it's a fine idea, thank you very much.)\n  scale_alpha_discrete(range = c(0.5, 0.9)) +\n  # Here are the x- and y-axis scales from our original sketch\n  scale_x_date(\n    breaks = x_breaks,\n    date_labels = \"%b\",\n    limits = c(\n      as.Date(\"2022-01-01\"),\n      as.Date(\"2023-03-15\")\n    ),\n    expand = expansion()\n  ) +\n  scale_y_reverse(\n    limits = c(\n      max(tidier_sun_times$ends + 60^2),\n      min(tidier_sun_times$starts - 60^2)\n    ),\n    breaks = y_breaks,\n    labels = paste0(seq(0, 24, by = 3), \":00\"),\n    expand = expansion()\n  ) +\n  # Labels, obvs.\n  labs(\n    x = NULL,\n    y = NULL,\n    title = \"How long are the days near me?\",\n    subtitle = \"Atlanta, GA\",\n    caption = \"garrickadenbuie.com\"\n  ) +\n  # Make sure the sunrise/sunset labels aren't clipped by the plot area\n  coord_cartesian(clip = \"off\") +\n  # Finally, make it pretty. We'll start with a minimal base theme\n  theme_minimal(base_family = \"Outfit\", base_size = 16) +\n  # And then tweak a bunch of little things...\n  theme(\n    plot.title = element_text(\n      color = color_text,\n      hjust = 0,\n      size = 14\n    ),\n    plot.subtitle = element_text(\n      color = color_text,\n      hjust = 0,\n      size = 24,\n      margin = margin(b = 6)\n    ),\n    plot.title.position = \"plot\",\n    plot.background = element_rect(fill = color_bg),\n    plot.margin = margin(20, 0, 20, 10),\n    panel.grid = element_blank(),\n    axis.text = element_text(color = color_text),\n    axis.title = element_text(color = color_text),\n    plot.caption = element_text(\n      color = \"#726194\",\n      hjust = 0.97,\n      vjust = -1\n    ),\n    plot.caption.position = \"plot\"\n  )"
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html",
    "href": "blog/sharing-xaringan-slides/index.html",
    "title": "Sharing Your xaringan Slides",
    "section": "",
    "text": "Showcase your presentations in style with great-looking social media cards and responsive, seamlessly embedded slides in web pages.\nYou put a lot of time and effort into your slides: structuring content, choosing the right gifs, tweaking colors and picking fonts. In short: slidecrafting.\nIn this post, I‚Äôll share some tips and strategies for publishing your xaringan slides online. Use the linked checklist below to get started or for review when prepping your next presentation.\nThis post covers some new features just released in my package xaringanExtra. If you haven‚Äôt used it before, it provides a playground of enhancements for xaringan. It‚Äôs not available on CRAN, so you‚Äôll need to install it from GitHub:\n# install.packages(\"remotes\")\nremotes::install_github(\"gadenbuie/xaringanExtra\")"
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#checklist",
    "href": "blog/sharing-xaringan-slides/index.html#checklist",
    "title": "Sharing Your xaringan Slides",
    "section": "Checklist",
    "text": "Checklist\n\n\n\n\n\n Fill in metadata with metathis jump to section\n Create a social media card jump to section\n Add a ‚Äúshare bar‚Äù with use_share_again() from xaringanExtra jump to section\n Get your slides online jump to section\n Pre-flight checks jump to section\n Embed your slides with embed_xaringan() from xaringanExtra jump to section\n Share with the world! jump to section"
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#fill-in-metadata",
    "href": "blog/sharing-xaringan-slides/index.html#fill-in-metadata",
    "title": "Sharing Your xaringan Slides",
    "section": "Fill in Metadata",
    "text": "Fill in Metadata\nThe first step is to give your slides all the metadata required to be found via search engines or to look great when shared on social media sites.\nTo do this, I recommend using a small package I wrote called metathis. It‚Äôs available on CRAN!\n\ninstall.packages(\"metathis\")\n\nBasically, metathis helps fill out &lt;meta&gt; tags in your HTML document. These tags are used by search engines and social media sites like Twitter and Facebook to describe your page, list the title and author, link to your profile, and show a preview image for the page (we‚Äôll get to this in the next section).\nHere‚Äôs a template you can use for your own slides. I‚Äôm using a recent presentation as an example, or you can reference the example in the metathis documentation.\n```{r metathis, echo=FALSE}\nlibrary(metathis)\nmeta() %&gt;%\n  meta_name(\"github-repo\" = \"gadenbuie/build-your-own-universe\") %&gt;%\n  meta_social(\n    title = \"Build your own universe\",\n    description = paste(\n      \"Scale high-quality research data provisioning with R packages.\",\n      \"Presented at R/Medicine 2020.\"\n    ),\n    url = \"https://build-your-own-universe.netlify.app\",\n    image = \"https://build-your-own-universe.netlify.app/social-card.png\",\n    image_alt = paste(\n      \"Title slide of Build your own universe:\",\n      \"Scale high-quality research data provisioning with R packages,\",\n      \"presented at R/Medicine 2020 by Travis Gerke and Garrick Aden-Buie\"\n    ),\n    og_type = \"website\",\n    og_author = \"Travis Gerke\",\n    twitter_card_type = \"summary_large_image\",\n    twitter_creator = \"@grrrck\",\n    twitter_site = \"@travisgerke\"\n  )\n```\nMost of the arguments are self-explanatory or well-described in ?meta_social. One thing to watch out for is that the image argument must be the full-qualified URL to the image. In other words, the entire URL including the https:// bit, taking into account where the slides will live when you put them online."
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#create-a-social-media-card",
    "href": "blog/sharing-xaringan-slides/index.html#create-a-social-media-card",
    "title": "Sharing Your xaringan Slides",
    "section": "Create a Social Media Card",
    "text": "Create a Social Media Card\n\nWhy should you add a preview image?\nSocial media cards are the rich link previews you see on websites like Twitter and Facebook. I think it‚Äôs worth the extra work to include a preview image for several reasons.\nFirst, it‚Äôs much more likely that your link will be seen, especially if your preview image is interesting or visually compelling. Users are more likely to click through and take a look at your slides when they have some idea of what‚Äôs on the other side of the link.\nSecond, the preview image is a tiny window into your own personal style. You have no control over the rest of the time line where your link is being shared ‚Äî your 280 characters look just like everyone else‚Äôs ‚Äî but your preview image is your space to visually communicate your personal style.\nAnd finally, using a preview image means that your crafted message will appear every time your link is shared, not just the first time. A common alternative is to share the link to the slides, but to add an image to share post. This looks great the first time the link is shared, but when someone else shares your slides‚Äô link, they probably won‚Äôt go to the trouble of including a screenshot.\nHere are three examples of tweets sharing slides that illustrate the various approaches to link previews.\n\n\n\n\n\n{.lightbox description=‚ÄúSlide link with limited metadata. (tweet)‚Äù}\n\n\n{.lightbox description=‚ÄúSlide link with a shared image. (tweet)‚Äù}\n\n\n{.lightbox description=‚ÄúSlide link with a preview image and complete metadata. (tweet)‚Äù}\n\n\n\n\nTaking a screenshot of your slides\nHow do you create an image for your social media cards? I‚Äôm glad you asked! Typically, I like to take a screenshot of the title slide and use that as the preview image.\nTaking a screenshot of your slides is incredibly easy if you‚Äôre using Firefox, which has a built-in screenshot feature. On Chrome, you can install an extension, like Nimbus Capture.\nTo take a screenshot, I open my slides in Firefox and select Take a Screenshot from the three-dots menu in the browser URL bar.\n\n\n\nFirefox‚Äôs Take a Screenshot menu option\n\n\nThen, don‚Äôt click ‚ÄúSave full page‚Äù or ‚ÄúSave visible‚Äù. Instead, click on your slides area so the entire slide is selected and then click ‚ÄúDownload‚Äù.\n\n\n\n\n\nFirefox‚Äôs screenshot feature, step 2. The user needs to click on the slides area to select the entire slide.\n\n\n\n\n\n\n\nFirefox‚Äôs screenshot feature, step 3. The user needs to select ‚ÄòDownload‚Äô to save the image.\n\n\n\n\n\n\nThe perfect share image ratio\nIf you‚Äôre using a 4:3 (the xaringan default) or 16:9 (my personal favorite) slide ratio, chances are that your share image will look okay‚Ä¶ but not perfect. In particular, if you‚Äôre targeting Twitter (for sharing with #rstats), you might find that parts of your preview image are cut off if the image width and height aren‚Äôt just right.\nIt turns out that the best ratio for share card images on Twitter is 1.91:1.\nSo to get the best image possible, you‚Äôll need to temporarily render your slides with this aspect ratio by changing the ratio to 191:100 in your slides‚Äô YAML header. (It turns out that remarkjs doesn‚Äôt like fractional ratio units, hence the need to multiply by 100.)\noutput:\n  xaringan::moon_reader:\n    # ... other xaringan options ...\n    nature:\n      ratio: 191:100\nSet the YAML header, render your slides, open in a browser, and take a screenshot.\nIf this sounds like a hassle, it‚Äôs because it kind of is. Fortunately, we can use the webshot2 package to automate the entire process. Note webshot2 requires that you have Chrome installed on your computer and is only available from GitHub.\n\n# install.packages(\"remotes\")\nremotes::install_github(\"rstudio/webshot2\")\n\nThen, you can use this little function below to render your slides_rmd in the funky ratio needed for the share image, saving a screenshot of the first slide to path.\n\n#' Screenshot Your Title Slide for Share Image\n#'\n#' Takes a screenshot of your title slide for sharing on Twitter\n#' (and other social media sites).\n#'\n#' @param slides_rmd Your slides file\n#' @param path Path to new share image\nscreenshot_share_image &lt;- function(\n  slides_rmd,\n  path_image = \"share-card.png\"\n) {\n  if (!requireNamespace(\"webshot2\", quietly = TRUE)) {\n    stop(\n      \"`webshot2` is required: \",\n      'remotes::install_github(\"rstudio/webshot2\")'\n    )\n  }\n\n  webshot2::rmdshot(\n    doc = slides_rmd,\n    file = path_image,\n    vheight = 600,\n    vwidth = 600 * 191 / 100,\n    rmd_args = list(\n      output_options = list(\n        nature = list(ratio = \"191:100\"),\n        self_contained = TRUE\n      )\n    )\n  )\n\n  path_image\n}\n\nTo use the function, just give it the path to your slides .Rmd and share-card.png will be created in your working directory.\n\nscreenshot_share_image(\"my_slides.Rmd\")"
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#add-a-share-bar",
    "href": "blog/sharing-xaringan-slides/index.html#add-a-share-bar",
    "title": "Sharing Your xaringan Slides",
    "section": "Add a ‚Äúshare bar‚Äù",
    "text": "Add a ‚Äúshare bar‚Äù\nYou‚Äôre almost done prepping your slides for sharing! If you know that you‚Äôll embed your slides on your website or someone else‚Äôs page, you‚Äôll want to add a share bar to your slides using use_share_again() from xaringanExtra.\n```{r xaringanExtra-share-again, echo=FALSE}\nxaringanExtra::use_share_again()\n```\n!Meet share again from xaringanExtra\nThe share again extension adds a small bar at the bottom of your slides ‚Äî but only when the slides are embedded in an &lt;iframe&gt;. The bar contains buttons to move between slides, which often isn‚Äôt obvious when you‚Äôre looking at embedded slides. It also makes it easy to go full screen and there‚Äôs a sharing menu for quickly sharing your slides on social media sites.\nIt turns out that the Viewer pane in RStudio is also an &lt;iframe&gt;, so the share bar will show up when you preview your slides in RStudio, but it won‚Äôt appear if you load your slides directly in a browser window.\nCheck out the full share again documentation for more information."
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#get-your-slides-online",
    "href": "blog/sharing-xaringan-slides/index.html#get-your-slides-online",
    "title": "Sharing Your xaringan Slides",
    "section": "Get Your Slides Online",
    "text": "Get Your Slides Online\nNow that your slides are all set up and ready to be shared (or presented!), you need to get your slides online! For tips on how to best get your slides online, I‚Äôll defer to the excellent presentation, Sharing on Short Notice, by Alison Hill and Desir√©e De Leon.\n\n\n\nSharing on Short Notice by Alison Hill and Desir√©e De Leon\n\n\nThose slides are also available at the short link rstd.io/sharing."
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#pre-flight-checks",
    "href": "blog/sharing-xaringan-slides/index.html#pre-flight-checks",
    "title": "Sharing Your xaringan Slides",
    "section": "Pre-Flight Checks",
    "text": "Pre-Flight Checks\nNow that your slides are online, it‚Äôs time to check that they look as good as you expect before you share them with the world.\nTo check your metadata, you can use Twitter‚Äôs share card validator. Drop in your link and Twitter will show you a preview of the share card for your link. Much better than sending yourself private messages to find out how your share card looks!\nSimilarly, you can also test your Open Graph tags (used by Facebook and other sites) with opengraphcheck.com or on Facebook‚Äôs Sharing Debugger.\nFinally, it‚Äôs a good idea to open your slides in every browser you have on your machine ‚Äî or at the very least in just one browser ‚Äî and walk through your slides to make sure everything works and that you haven‚Äôt forgotten to upload any images or assets."
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#embed-your-slides",
    "href": "blog/sharing-xaringan-slides/index.html#embed-your-slides",
    "title": "Sharing Your xaringan Slides",
    "section": "Embed Your Slides",
    "text": "Embed Your Slides\nNow that your slides are out in the world, you might want to embed them in your web page, for example in a talk page or the talks section of your website.\nTo do this, I recommend using embed_xaringan() from xaringanExtra. It embeds your slides in a responsive, aspect-ratio &lt;iframe&gt;, meaning that the slides are seamlessly embedded in the page and their size is automatically adjusted to maintain the aspect ratio that matches your slides.\nHere‚Äôs an example of embedded slides from a recent talk I gave with Travis Gerke.\n\nxaringanExtra::embed_xaringan(\n  url = \"https://build-your-own-universe.netlify.app\",\n  ratio = \"16:9\"\n)\n\n\n\n\n\n\n\nNotice that if you‚Äôve used share again, your embedded slides will have a nice share bar for navigation and sharing."
  },
  {
    "objectID": "blog/sharing-xaringan-slides/index.html#share-with-the-world",
    "href": "blog/sharing-xaringan-slides/index.html#share-with-the-world",
    "title": "Sharing Your xaringan Slides",
    "section": "Share with the World!",
    "text": "Share with the World!\nYou‚Äôre finally ready! Good luck with your presentation and don‚Äôt forget to tweet out your awesome slides when you‚Äôre done (or right before you start!).\n\n\n\n\n\nvia GIPHY\n\n\n\n\n\n\n\nThanks for reading! Feel free to share your presentation-sharing tips with me on Twitter @grrrck!\n\n\n\nFirefox‚Äôs Take a Screenshot menu option\nFirefox‚Äôs screenshot feature, step 2. The user needs to click on the slides area to select the entire slide.\nFirefox‚Äôs screenshot feature, step 3. The user needs to select ‚ÄòDownload‚Äô to save the image."
  },
  {
    "objectID": "blog/shrtcts/index.html",
    "href": "blog/shrtcts/index.html",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "",
    "text": "Follow@gadenbuie¬† Star¬† Fork\nRStudio‚Äôs many keyboard shortcuts take some time to learn but can save tons of typing in the long run. RStudio addins extend RStudio‚Äôs interface with small apps and actions, and you can assign customized keyboard shortcuts to trigger any addin you have installed quickly from the keyboard.\nInstalling an addin isn‚Äôt hard ‚Äî and if you‚Äôre looking for new addins, Dean Attali‚Äôs addinslist is the place to go. But addins are installed via R packages, so if you want to create your own addin, you‚Äôll have to create a new R package to store your addin. And if you have to create a new R package, you‚Äôll need to think of a name for your R package. But naming is hard, and all the good words starting with or involving the letter R are already taken.\nWhat if all you want to do is run a function from an installed package or a short bit of R code that does something useful and that makes your workflow just a little smoother?\nWhat if you want that function to run whenever you press Control + Alt + Shift + K?\nIt seems like there should be an easier way to do this than to create an R package.\n(Have I convinced you that you also have the same problem I do, or am I the only one?)"
  },
  {
    "objectID": "blog/shrtcts/index.html#update-september-14-2020",
    "href": "blog/shrtcts/index.html#update-september-14-2020",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "Update September 14, 2020",
    "text": "Update September 14, 2020\nshrtcts now has a dedicated site, and a slightly different syntax than the first version presented below. You can now write your shortcut functions in R files and use roxygen2 documentation strings to configure your shortcuts. You can also set keyboard shortcuts for your shrtcts shortcuts directly in the configuration R script."
  },
  {
    "objectID": "blog/shrtcts/index.html#introducing-shrtcts",
    "href": "blog/shrtcts/index.html#introducing-shrtcts",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "Introducing shrtcts",
    "text": "Introducing shrtcts\nshrtcts is a small package I‚Äôve put together with the goal of making it easier to register and manage RStudio addins without having to maintain an R package.\n\nGetting started\nFirst, install shrtcts.\n\nremotes::install_github(\"gadenbuie/shrtcts\")\n\nThen, create a YAML file called .shrtcts.yaml and store it in your home directory1 or in a directory called .config in your home directory.\nThis YAML file holds your shortcuts as a YAML list. Each item looks a lot like the addins.dcf file that is used to register addins in R packages. The only difference is that the Binding entry can be any arbitrary R function or code.\n- Name: Say Something Nice\n  Description: A demo of cool things\n  Binding: praise::praise\n  Interactive: true\nI‚Äôm calling this shortcut Say Something Nice and whenever it is triggered it calls praise() from the praise package.\nTo install your shortcut, run add_rstudio_addin() from shrtcts and restart your R session.\n\nshrtcts::add_rstudio_shortcuts()\nrstudioapi::restartSession()\n\nYou can restart your R session by clicking Session &gt; Restart R. Now you should now be able to find the Say Something Nice addin in your addins list!\n\n\n\nShortcut, meet keyboard\n\nAssigning keyboard shortcuts to your addin shortcuts\nOnce you‚Äôve installed your shortcut addins, you can then assign a keyboard shortcut to run your addin. Select Modify Keyboard Shortcuts‚Ä¶ from the Tools menu\n\nand then search for your shortcut. Click on the blank space in the Shortcut column and press the keys that will be the your new shortcut. Here, I‚Äôm assigning the Say Something Nice addin to Ctrl + Shift + Alt + P.\n\nAfter setting the shortcut, I usually check to make sure my new keyboard shortcut doesn‚Äôt collide with a previously installed shortcut by clearing the search and sorting by the shortcut column.\n\n\nA few details to keep in mind about keyboard shortcuts\nThere are a two things to keep in mind about using keyboard shortcuts with your shrtcts shortcuts.\nFirst, if you re-install or update shrtcts, your currently existing keyboard shortcuts should survive the transition. Make sure that you run add_rstudio_addins() again after updating, and make sure that you re-start your R session.\nSecond, the order of your shortcuts in your .shrtcts.yaml file matters, unless you explicitly set the id entry to a number between 1 and 100. This means that it‚Äôs a good idea to set the id of shortcuts that you‚Äôre going to use with keyboard shortcuts.\n- Name: Say Something Nice\n  Description: A demo of cool things\n  Binding: praise::praise\n  id: 1\n  Interactive: true\n\n\n\nAdding more shortcuts\nTo add more shortcuts, continue adding entries in your .shrtcts.yaml file. If you don‚Äôt want to run add_rstudio_shortcuts() every time you update your shortcuts, you can add the following line in your ~/.Rprofile2.\n\nif (interactive() & requireNamespace(\"shrtcts\", quietly = TRUE)) {\n  shrtcts::add_rstudio_shortcuts()\n}\n\nshrtcts comes with a demonstration .shrtcts.yaml file that you can use for inspiration. Print out the example YAML file contents with:\n\nshrtcts::example_shortcuts_yaml()\n\n\n\nShortcuts can be arbitrary R code\nYour shortcut doesn‚Äôt need to call a function in a package. In fact, you can create shortcuts that run R code simply by putting the code you want to run in the Binding entry.\nHere‚Äôs an example shortcut that picks a number between 0 and 100. (Great for playing what number of am I think of?)\n- Name: I'm thinking of a number...\n  Binding: sample(0:100, 1)\nNotice the binding is just R code (I was thinking of 69, by the way), and the only fields you need to include are the Name and the Binding.\nYour shortcuts don‚Äôt need to fit on a single line either. You can use multi-line literal-style YAML blocks for your R code. In other words, add | after Binding and then indent your R code.\nHere‚Äôs an example shortcut that I use occasionally to create a temporary markdown file so that I can test some markdown or R code and have the file be thrown away when I exit my R session.\n- Name: New Temporary R Markdown Document\n  Binding: |\n    tmp &lt;- tempfile(fileext = \".Rmd\")\n    rmarkdown::draft(\n      tmp,\n      template = \"github_document\",\n      package = \"rmarkdown\",\n      edit = FALSE\n    )\n    rstudioapi::navigateToFile(tmp)\n  Interactive: false"
  },
  {
    "objectID": "blog/shrtcts/index.html#behind-the-scenes",
    "href": "blog/shrtcts/index.html#behind-the-scenes",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "Behind the Scenes",
    "text": "Behind the Scenes\nHow does this all work? shrtcts comes with a minimal addins registry with one addin that browses to the help page ?add_rstudio_addins.\nWhen you run add_rstudio_addins(), shrtcts rewrites it‚Äôs own addins registry using your shortcut title and description. It also assigns each shortcut in .shrtcts.yaml to an id from 1 to 100, which correspond to 100 shortcut functions in the shrtcts package. Each addin is wired to one of these functions, so when you run the associated addin shrtcts looks up the correct shortcut in your .shrtcts.yaml file and runs that shortcut.\nThis why you need to run add_rstudio_addins() whenever you add or modify the order of your shortcuts. Whenever this happens, shrtcts has to re-wire the addins registry to make sure everything is connect.\nThis is also why you need to restart your R session for the addins to be seen by RStudio. RStudio only checks for package addins when R starts up, so the R session restart triggers RStudio to refresh the addin registry.\n\nInspiration\nshrtcts was inspired by rsam, the RStudio Addins Manager by @yonicd. There‚Äôs a lot that rsam can do ‚Äî including helping you manage your keyboard shortcuts ‚Äî and shrtcts is essentially an extension of rsam‚Äôs limited liability addins. rsam provides three slots for custom addins that in turn look for specially-named functions defined in the global environment. In the addins menu, these three custom addins appear as lla1, lla2, and lla3. The upside of rsam is that you don‚Äôt have to write code in YAML (huge plus!), but the downside is that the names of the addins are fixed.\nshrtcts, on the other hand, rewrites its own addin registry so that you can have customized addin names and descriptions. In both packages, the number of custom addins is limited: rsam provides 3 slots, while shrtcts gives you 100."
  },
  {
    "objectID": "blog/shrtcts/index.html#share-your-shortcuts",
    "href": "blog/shrtcts/index.html#share-your-shortcuts",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "Share Your Shortcuts",
    "text": "Share Your Shortcuts\nBecause shrtcts stores your shortcuts in stand-alone(-ish) YAML files, you can share your shortcuts file with others (or yourself) by posting it somewhere online, for example as a Github Gist.\nHere‚Äôs a small collection of shortcuts that I use and that inspired me to create this package so that I didn‚Äôt have to think of another package name.\nI hope shrtcts is helpful to you! Find me on @grrrck and let me know if it is."
  },
  {
    "objectID": "blog/shrtcts/index.html#footnotes",
    "href": "blog/shrtcts/index.html#footnotes",
    "title": "Make A Shortcut for Anything in RStudio with shrtcts",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou can find you home directory quickly using fs::path_home_r() or fs::path_home(). [shrtcts will look in either location.‚Ü©Ô∏é\nA quick way to edit this file is by calling usethis::edit_r_profile().‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html",
    "href": "blog/tweet-archive-in-r/index.html",
    "title": "Read and Visualize your Twitter Archive",
    "section": "",
    "text": "Twitter finds itself in an‚Ä¶ interesting‚Ä¶ transition period. Whether or not you‚Äôre considering jumping ship to another service ‚Äî you can find me lurking on Mastdon ‚Äî you should download an archive of your Twitter data. Not only does the archive include all of your tweets, it also contains a variety of other interesting data about your account: who you followed and who followed you; the tweets you liked; the ads you were served; and much more.\nThis post, very much inspired by the awesome Observable notebook, Planning to leave Twitter?, shows you how to use R to read and explore your archive, using my own archive as an example.\nRead on to learn how to read your Twitter archive into R, or how to tidy your tweets. The second half of the post showcases a collection of plots about monthy tweet volume, popular tweets, the time of day when tweets were sent, and the app used to send the tweet.\nI‚Äôve also included a section on using rtweet to collect a full dataset about the tweets you‚Äôve liked and another section about the advertising data in your Twitter archive."
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#reading-your-twitter-archive",
    "href": "blog/tweet-archive-in-r/index.html#reading-your-twitter-archive",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Reading your Twitter archive",
    "text": "Reading your Twitter archive\n\nGet your Twitter data archive\nFirst things first, you need to have your Twitter data archive. If you don‚Äôt have it yet, go to Settings and Privacy and click Download an archive of your data. After you submit the request, it takes about a day or so for an email to show up in your inbox.\n\n@grrrck your Twitter data is ready\nYour Twitter archive is ready for you to download and view using your desktop browser. Make sure you download it before Nov 12, 2022, 9:46:31 PM\n\nThe archive downloads as a zip file containing a standalone web page ‚Äî called Your archive.html ‚Äî for exploring your data. But the real archive lives in the included data/ folder as a bunch of .js files. I‚Äôve copied that data/ directory into my working directory for this post.\n\n\nSetup\nOn the R side, we‚Äôll need the usual suspects: tidyverse and glue.\n\nlibrary(tidyverse)\n#&gt; ‚îÄ‚îÄ Attaching core tidyverse packages ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n#&gt; ‚úî dplyr     1.0.10     ‚úî readr     2.1.3 \n#&gt; ‚úî forcats   0.5.2      ‚úî stringr   1.5.0 \n#&gt; ‚úî ggplot2   3.4.0      ‚úî tibble    3.1.8 \n#&gt; ‚úî lubridate 1.9.0      ‚úî tidyr     1.2.1 \n#&gt; ‚úî purrr     1.0.1      \n#&gt; ‚îÄ‚îÄ Conflicts ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ tidyverse_conflicts() ‚îÄ‚îÄ\n#&gt; ‚úñ dplyr::filter() masks stats::filter()\n#&gt; ‚úñ dplyr::lag()    masks stats::lag()\n#&gt; ‚Ñπ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(glue)\n\n(I‚Äôm using the dev version of tidyverse (1.3.2.9000), which loads lubridate automatically, and the dev version of purrr that is slated to become version 1.0.0.)\nTo read in the data files, I‚Äôll use jsonlite to read the archive JSON data, with a small assist from brio for fast file reading. I‚Äôm also going to have some fun with ggiraph for turning static ggplot2 plots into interactive plots.\nFinally, the Twitter archive doesn‚Äôt require API access to Twitter, but you can use it to augment the data in the archive. The rtweet package is excellent for this, even though it takes a little effort to get it set up.\n\n\nRead the manifest\nThe data/ folder is surprisingly well structured! There are two key files to help you find your way around the archive. First, the README.txt file explains the structure and layout of the files, and includes descriptions of the data contained in all of the files.\nHere‚Äôs how the README describes the account.js data file:\naccount.js\n- email: Email address currently associated with the account if an email address has been provided.\n- createdVia: Client application used when the account was created. For example: ‚Äúweb‚Äù if the  account was created from a browser.\n- username: The account‚Äôs current @username. Note that the @username may change but the account ID will remain the same for the lifetime of the account.\n- accountId: Unique identifier for the account.\n- createdAt: Date and time when the account was created.\n- accountDisplayName: The account‚Äôs name as displayed on the profile.\nThe data/ folder also contains a manifest.js file that can be used to help read the data included in the archive. Let‚Äôs start by assuming this file is JSON and reading it in.\n\njsonlite::fromJSON(\"data/manifest.js\")\n#&gt; Error in parse_con(txt, bigint_as_char): lexical error: invalid char in json text.\n#&gt;                                        window.__THAR_CONFIG = {   \"use\n#&gt;                      (right here) ------^\n\nHere we hit our first snag. The archive files are packaged as JSON, but they‚Äôre not strictly compliant JSON files; they include some JavaScript to assign JSON objects to the global namespace (called window in the browser). Here‚Äôs the data/manifest.js file as an example.\nwindow.__THAR_CONFIG = {\n  // ... data ...\n}\nIf we just remove everything up to the first the { or sometimes [ on the first line, we can turn the data into valid JSON.\n\nlines[1] &lt;- sub(\"^[^{[]+([{[])\", \"\\\\1\", lines[1])\nmanifest &lt;- jsonlite::fromJSON(lines)\n\nThis worked, but‚Ä¶ jsonlite was designed for statistical work, so it transforms the data structure when reading in the JSON. For example, by default it converts arrays that look like JSON-ified data frames into actual data.frames.\n\nmanifest$dataTypes[1:2] |&gt; str()\n#&gt; List of 2\n#&gt;  $ account          :List of 1\n#&gt;   ..$ files:'data.frame':    1 obs. of  3 variables:\n#&gt;   .. ..$ fileName  : chr \"data/account.js\"\n#&gt;   .. ..$ globalName: chr \"YTD.account.part0\"\n#&gt;   .. ..$ count     : chr \"1\"\n#&gt;  $ accountCreationIp:List of 1\n#&gt;   ..$ files:'data.frame':    1 obs. of  3 variables:\n#&gt;   .. ..$ fileName  : chr \"data/account-creation-ip.js\"\n#&gt;   .. ..$ globalName: chr \"YTD.account_creation_ip.part0\"\n#&gt;   .. ..$ count     : chr \"1\"\n\nThat‚Äôs often quite helpful! But I find it‚Äôs safer, when trying to generalize data reading, to disable the simplification and know for certain that the data strcutre matches the original JSON. For that reason, I tend to disable the matrix and data.frame simplifications and only allow jsonlite to simplify vectors.\nHere‚Äôs a quick helper function that includes those setting changes and the first line substitution needed to read the archive JSON files.\n\nread_archive_json &lt;- function(path) {\n  lines &lt;- brio::read_lines(path)\n  lines[1] &lt;- sub(\"^[^{[]+([{[])\", \"\\\\1\", lines[1])\n\n  jsonlite::fromJSON(\n    txt = lines,\n    simplifyVector = TRUE,\n    simplifyDataFrame = FALSE,\n    simplifyMatrix = FALSE\n  )\n}\n\nNow we‚Äôre ready to read the manifest again.\n\nmanifest &lt;- read_archive_json(\"data/manifest.js\")\nnames(manifest)\n#&gt; [1] \"userInfo\"    \"archiveInfo\" \"readmeInfo\"  \"dataTypes\"\n\nThe manifest file contains some information about the user and the archive,\n\nstr(manifest$userInfo)\n#&gt; List of 3\n#&gt;  $ accountId  : chr \"47332433\"\n#&gt;  $ userName   : chr \"grrrck\"\n#&gt;  $ displayName: chr \"garrick aden-buie\"\n\nplus details about all of the various data included in the archive, like the data about my account.\n\nstr(manifest$dataTypes$account)\n#&gt; List of 1\n#&gt;  $ files:List of 1\n#&gt;   ..$ :List of 3\n#&gt;   .. ..$ fileName  : chr \"data/account.js\"\n#&gt;   .. ..$ globalName: chr \"YTD.account.part0\"\n#&gt;   .. ..$ count     : chr \"1\"\n\nEach dataType in the manifest points us to a file (or files) in the archive and helpfully tells us how many records are included.\nHere are the data files with the most records.\n\n\nCode: Manifest, Top Records\n\n\nmanifest$dataTypes |&gt;\n  # All data types we can read have a \"files\" item\n  keep(~ \"files\" %in% names(.x)) |&gt;\n  # We keep the files objects but still as a list of lists within a list\n  map(\"files\") |&gt;\n  # Turn the files into tibbles (list of tibbles within a list)\n  map_depth(2, as_tibble) |&gt;\n  # Then combine the files tables for each item keeping track of the file index\n  map(list_rbind, names_to = \"index\") |&gt;\n  # And finally combine files for all items\n  list_rbind(names_to = \"item\") |&gt;\n  mutate(across(count, as.integer)) |&gt;\n  select(-globalName, -index) |&gt;\n  slice_max(count, n = 15) |&gt;\n  knitr::kable(\n    format.args = list(big.mark = \",\"),\n    table.attr = 'class=\"table\"',\n    format = \"html\"\n  )\n\n\n\n\n\n\n\n\n\nitem\nfileName\ncount\n\n\n\n\nlike\ndata/like.js\n11,773\n\n\nfollower\ndata/follower.js\n9,030\n\n\ntweetHeaders\ndata/tweet-headers.js\n6,225\n\n\ntweets\ndata/tweets.js\n6,225\n\n\nipAudit\ndata/ip-audit.js\n3,787\n\n\nfollowing\ndata/following.js\n1,519\n\n\ncontact\ndata/contact.js\n645\n\n\nlistsMember\ndata/lists-member.js\n254\n\n\nblock\ndata/block.js\n242\n\n\nadImpressions\ndata/ad-impressions.js\n173\n\n\nadEngagements\ndata/ad-engagements.js\n171\n\n\ndirectMessageHeaders\ndata/direct-message-headers.js\n97\n\n\ndirectMessages\ndata/direct-messages.js\n97\n\n\nuserLinkClicks\ndata/user-link-clicks.js\n67\n\n\nconnectedApplication\ndata/connected-application.js\n63\n\n\n\n\n\n\n\n\n\n\n\nReading the account data file\nFor a first example, let‚Äôs read the data/account.js archive file. We start by inspecting the manifest, where manifest$dataTypes$account tells us which files hold the account data and how many records are in each.\n\nmanifest$dataTypes$account |&gt; str()\n#&gt; List of 1\n#&gt;  $ files:List of 1\n#&gt;   ..$ :List of 3\n#&gt;   .. ..$ fileName  : chr \"data/account.js\"\n#&gt;   .. ..$ globalName: chr \"YTD.account.part0\"\n#&gt;   .. ..$ count     : chr \"1\"\n\nHere there‚Äôs only one file containing a single account record: data/account.js. Inside that file is a small bit of JavaScript. Like the manifest, it‚Äôs almost JSON, except that it assigns the JavaScript object to window.YTD.account.part0.\n\nwindow.YTD.account.part0 = [\n  {\n    \"account\" : {\n      \"email\" : \"my-email@example.com\",\n      \"createdVia\" : \"web\",\n      \"username\" : \"grrrck\",\n      \"accountId\" : \"47332433\",\n      \"createdAt\" : \"2009-06-15T13:21:50.000Z\",\n      \"accountDisplayName\" : \"garrick aden-buie\"\n    }\n  }\n]\n\nAnd again, if we clean up the first line, this is valid JSON that we can read in directly with jsonlite.\n\naccount &lt;- read_archive_json(\"data/account.js\")\nstr(account)\n#&gt; List of 1\n#&gt;  $ :List of 1\n#&gt;   ..$ account:List of 6\n#&gt;   .. ..$ email             : chr \"my-email@example.com\"\n#&gt;   .. ..$ createdVia        : chr \"web\"\n#&gt;   .. ..$ username          : chr \"grrrck\"\n#&gt;   .. ..$ accountId         : chr \"47332433\"\n#&gt;   .. ..$ createdAt         : chr \"2009-06-15T13:21:50.000Z\"\n#&gt;   .. ..$ accountDisplayName: chr \"garrick aden-buie\"\n\nThis leads us to our first fun fact: I created my Twitter account on June 15, 2009, which means that I‚Äôve been using Twitter (on and off) for 13.6 years. That‚Äôs 4,981 days of twittering!\n\n\nRead any archive item\nLet‚Äôs generalize what we learned into a few helper functions we can reuse. I‚Äôve placed everything into a single code block so that you can copy and paste it into your R session or script to use it right away.\n\n#' Read the Twitter Archive JSON\n#'\n#' @param path Path to a Twitter archve `.js` file\nread_archive_json &lt;- function(path) {\n  lines &lt;- brio::read_lines(path)\n  lines[1] &lt;- sub(\"^[^{[]+([{[])\", \"\\\\1\", lines[1])\n\n  jsonlite::fromJSON(\n    txt = lines,\n    simplifyVector = TRUE,\n    simplifyDataFrame = FALSE,\n    simplifyMatrix = FALSE\n  )\n}\n\n#' Read an twitter archive data item\n#'\n#' @param manifest The list from `manifest.js`\n#' @param item The name of an item in the manifest\nread_twitter_data &lt;- function(manifest, item) {\n  manifest$dataTypes[[item]]$files |&gt;\n    purrr::transpose() |&gt;\n    purrr::pmap(\\(fileName, ...) read_archive_json(fileName))\n}\n\n#' Simplify the data, if possible and easy\n#'\n#' @param x A list of lists as returned from `read_twitter_data()`\n#' @param simplifier A function that's applied to each item in the\n#'   list of lists and that can be used to simplify the output data.\nsimplify_twitter_data &lt;- function(x, simplifier = identity) {\n   x &lt;- purrr::flatten(x)\n   item_names &lt;- x |&gt; purrr::map(names) |&gt; purrr::reduce(union)\n   if (length(item_names) &gt; 1) return(x)\n\n   x |&gt;\n    purrr::map(item_names) |&gt;\n    purrr::map_dfr(simplifier)\n}\n\nQuick recap: to use the functions above, load your archive manifest with read_archive_json() and then pass it to read_twitter_data() along with an item name from the archive. If the data in the archive item is reasonably structured, you can call simplify_twitter_data() to get a tidy tibble1.\n\nmanifest &lt;- read_archive_json(\"data/manifest.js\")\naccount &lt;- read_twitter_data(manifest, \"account\")\n\nsimplify_twitter_data(account)\n#&gt; # A tibble: 1 √ó 6\n#&gt;   email              creat‚Ä¶¬π usern‚Ä¶¬≤ accou‚Ä¶¬≥ creat‚Ä¶‚Å¥ accou‚Ä¶‚Åµ\n#&gt;   &lt;chr&gt;              &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;  \n#&gt; 1 my-email@example.‚Ä¶ web     grrrck  473324‚Ä¶ 2009-0‚Ä¶ garric‚Ä¶\n#&gt; # ‚Ä¶ with abbreviated variable names ¬π‚ÄãcreatedVia, ¬≤‚Äãusername,\n#&gt; #   ¬≥‚ÄãaccountId, ‚Å¥‚ÄãcreatedAt, ‚Åµ‚ÄãaccountDisplayName\n\n\n\n\nExample: my followers\nLet‚Äôs use this on another archive item to find the earliest Twitter adopters among my followers.\n\n# These tables are wide, you may need to scroll to see the preview\noptions(width = 120)\n\nfollowers &lt;-\n  read_twitter_data(manifest, \"follower\") |&gt;\n  simplify_twitter_data()\n\nThen we can arrange the rows of followers by accountId as a proxy for date of account creation.\n\nearly_followers &lt;-\n  followers |&gt;\n  arrange(as.numeric(accountId)) |&gt;\n  slice_head(n = 11)\n\n# Top 11 earliest followers\nearly_followers\n#&gt; # A tibble: 11 √ó 2\n#&gt;    accountId userLink                                      \n#&gt;    &lt;chr&gt;     &lt;chr&gt;                                         \n#&gt;  1 1496      https://twitter.com/intent/user?user_id=1496  \n#&gt;  2 11309     https://twitter.com/intent/user?user_id=11309 \n#&gt;  3 37193     https://twitter.com/intent/user?user_id=37193 \n#&gt;  4 716213    https://twitter.com/intent/user?user_id=716213\n#&gt;  5 741803    https://twitter.com/intent/user?user_id=741803\n#&gt;  6 755726    https://twitter.com/intent/user?user_id=755726\n#&gt;  7 774234    https://twitter.com/intent/user?user_id=774234\n#&gt;  8 787219    https://twitter.com/intent/user?user_id=787219\n#&gt;  9 799574    https://twitter.com/intent/user?user_id=799574\n#&gt; 10 860921    https://twitter.com/intent/user?user_id=860921\n#&gt; 11 944231    https://twitter.com/intent/user?user_id=944231\n\n\nAs you can see, some parts of the Twitter archive include the barest minimum amount of data. Thankfully, we can still use rtweet to gather additional data about these users. I‚Äôm looking at a small subset of my 9,030 followers here, but you might want to do this for all your followers and save the collected user data in your archive.\n\nearly_followers_accounts &lt;-\n  early_followers |&gt;\n  pull(accountId) |&gt;\n  rtweet::lookup_users()\n\nearly_followers_accounts |&gt;\n  select(id, name, screen_name, created_at, followers_count, description)\n#&gt; # A tibble: 11 √ó 6\n#&gt;        id name                                    screen_name    created_at          followers_count description        \n#&gt;     &lt;int&gt; &lt;chr&gt;                                   &lt;chr&gt;          &lt;dttm&gt;                        &lt;int&gt; &lt;chr&gt;              \n#&gt;  1   1496 Aelfrick                                Aelfrick       2006-07-16 14:44:05              25 \"\"                 \n#&gt;  2  11309 Aaron Khoo                              aklw           2006-11-02 07:14:47             240 \"I am a weapon of ‚Ä¶\n#&gt;  3  37193 Rob                                     coleman        2006-12-02 11:54:15             654 \"data science / la‚Ä¶\n#&gt;  4 716213 Tim Dennis                              jt14den        2007-01-27 16:54:12             971 \"Data librarian/di‚Ä¶\n#&gt;  5 741803 @AlgoCompSynth@ravenation.club by znmeb znmeb          2007-02-01 00:03:16            9755 \"https://t.co/rZhZ‚Ä¶\n#&gt;  6 755726 Travis Dawry                            tdawry         2007-02-06 23:45:01             274 \"data, politics, o‚Ä¶\n#&gt;  7 774234 Shea's Coach Beard                      mandoescamilla 2007-02-15 13:51:10            1177 \"my anger is a gif‚Ä¶\n#&gt;  8 787219 Jonathan                                jmcphers       2007-02-21 15:56:20             591 \"Software engineer‚Ä¶\n#&gt;  9 799574 @dietrich@mastodon.social               dietrich       2007-02-27 18:41:20            6113 \"A lifestyle brand‚Ä¶\n#&gt; 10 860921 ‚åúwill‚åü                                  wtd            2007-03-09 23:20:43             719 \"üëã I'm an optimis‚Ä¶\n#&gt; 11 944231 Christopher Peters üá∫üá¶                   statwonk       2007-03-11 14:49:39            4476 \"Lead Econometrici‚Ä¶"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#my-tweets",
    "href": "blog/tweet-archive-in-r/index.html#my-tweets",
    "title": "Read and Visualize your Twitter Archive",
    "section": "My tweets",
    "text": "My tweets\nNow we get to the main course: the tweets themselves. We can read them in the same way that we imported accounts and followers with read_twitter_data(), but for now we won‚Äôt simplify them.\nTo see why, let‚Äôs take a look at a single tweet. The file of tweets (outer list, [[1]]) contains an array (inner list, e.g.¬†[[105]]) of tweets (named item, $tweet). Here‚Äôs that example tweet:\n\n# Tweets are a list of a list of tweets...\ntweet &lt;- read_twitter_data(manifest, \"tweets\")[[1]][[105]]$tweet\nstr(tweet, max.level = 2)\n#&gt; List of 16\n#&gt;  $ edit_info         :List of 1\n#&gt;   ..$ initial:List of 4\n#&gt;  $ retweeted         : logi FALSE\n#&gt;  $ source            : chr \"&lt;a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\"&gt;Twitter Web App&lt;/a&gt;\"\n#&gt;  $ entities          :List of 5\n#&gt;   ..$ user_mentions:List of 1\n#&gt;   ..$ urls         :List of 1\n#&gt;   ..$ symbols      : list()\n#&gt;   ..$ media        :List of 1\n#&gt;   ..$ hashtags     :List of 1\n#&gt;  $ display_text_range: chr [1:2] \"0\" \"236\"\n#&gt;  $ favorite_count    : chr \"118\"\n#&gt;  $ id_str            : chr \"1276198597596459018\"\n#&gt;  $ truncated         : logi FALSE\n#&gt;  $ retweet_count     : chr \"33\"\n#&gt;  $ id                : chr \"1276198597596459018\"\n#&gt;  $ possibly_sensitive: logi FALSE\n#&gt;  $ created_at        : chr \"Thu Jun 25 17:00:30 +0000 2020\"\n#&gt;  $ favorited         : logi FALSE\n#&gt;  $ full_text         : chr \"Thanks to prodding from @dsquintana, I added `include_tweet()` to {tweetrmd}. Automatically embed the HTML twee\"| __truncated__\n#&gt;  $ lang              : chr \"en\"\n#&gt;  $ extended_entities :List of 1\n#&gt;   ..$ media:List of 1\n\nThere‚Äôs quite a bit of data in each tweet, so we‚Äôll pause here and figure out how we want to transform the nested list into a flat last that will rectangle nicely.\n\ntidy_tweet_raw &lt;- function(tweet_raw) {\n  basic_items &lt;- c(\n    \"created_at\",\n    \"favorite_count\",\n    \"retweet_count\",\n    \"full_text\",\n    \"id\",\n    \"lang\",\n    \"source\"\n  )\n\n  # start with a few basic items\n  tweet &lt;- tweet_raw[basic_items]\n\n  # and collapse a few nested items into a single string\n  tweet$user_mentions &lt;- tweet_raw |&gt;\n    purrr::pluck(\"entities\", \"user_mentions\") |&gt;\n    purrr::map_chr(\"screen_name\") |&gt;\n    paste(collapse = \",\")\n\n  tweet$hashtags &lt;- tweet_raw |&gt;\n    purrr::pluck(\"entities\", \"hashtags\") |&gt;\n    purrr::map_chr(\"text\") |&gt;\n    paste(collapse = \",\")\n\n  tweet\n}\n\nWhen we apply this function to the example tweet, we get a nice, flat list.\n\ntidy_tweet_raw(tweet) |&gt; str()\n#&gt; List of 9\n#&gt;  $ created_at    : chr \"Thu Jun 25 17:00:30 +0000 2020\"\n#&gt;  $ favorite_count: chr \"118\"\n#&gt;  $ retweet_count : chr \"33\"\n#&gt;  $ full_text     : chr \"Thanks to prodding from @dsquintana, I added `include_tweet()` to {tweetrmd}. Automatically embed the HTML twee\"| __truncated__\n#&gt;  $ id            : chr \"1276198597596459018\"\n#&gt;  $ lang          : chr \"en\"\n#&gt;  $ source        : chr \"&lt;a href=\\\"https://mobile.twitter.com\\\" rel=\\\"nofollow\\\"&gt;Twitter Web App&lt;/a&gt;\"\n#&gt;  $ user_mentions : chr \"dsquintana\"\n#&gt;  $ hashtags      : chr \"rstats\"\n\nThis flattened tweet list will end up becoming a row in a tidy table of tweets thanks to simplify_twitter_data(), which is used to flatten the list of all of the tweets into a tibble. Once combined into a single table, we use our good friends dplyr, lubridate and stringr to convert columns to their correct format and to extract a few features.\n\ntidy_tweets &lt;-\n  read_twitter_data(manifest, \"tweets\") |&gt;\n  simplify_twitter_data(tidy_tweet_raw) |&gt;\n  mutate(\n    across(contains(\"_count\"), as.integer),\n    retweet = str_detect(full_text, \"^RT @\"),\n    reply = str_detect(full_text, \"^@\"),\n    type = case_when(\n      retweet ~ \"retweet\",\n      reply ~ \"reply\",\n      TRUE ~ \"tweet\"\n    ),\n    created_at = strptime(created_at, \"%a %b %d %T %z %Y\"),\n    hour = hour(created_at),\n    day = wday(created_at, label = TRUE, abbr = TRUE, week_start = 1),\n    month = month(created_at, label = TRUE, abbr = FALSE),\n    day_of_month = day(created_at),\n    year = year(created_at)\n  )\n\nThe result‚Ä¶ a nice tidy table of tweets!\n\ntidy_tweets\n#&gt; # A tibble: 6,223 √ó 17\n#&gt;    created_at          favori‚Ä¶¬π retwe‚Ä¶¬≤ full_‚Ä¶¬≥ id    lang  source user_‚Ä¶‚Å¥ hasht‚Ä¶‚Åµ retweet reply type   hour day   month\n#&gt;    &lt;dttm&gt;                 &lt;int&gt;   &lt;int&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;lgl&gt;   &lt;lgl&gt; &lt;chr&gt; &lt;int&gt; &lt;ord&gt; &lt;ord&gt;\n#&gt;  1 2022-11-05 10:02:17        0       0 \"RT @g‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"georg‚Ä¶ \"\"      TRUE    FALSE retw‚Ä¶    10 Sat   Nove‚Ä¶\n#&gt;  2 2022-11-04 19:42:01        4       0 \"@JonT‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"JonTh‚Ä¶ \"\"      FALSE   TRUE  reply    19 Fri   Nove‚Ä¶\n#&gt;  3 2022-11-04 15:21:23        1       0 \"@tjma‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"tjmah‚Ä¶ \"\"      FALSE   TRUE  reply    15 Fri   Nove‚Ä¶\n#&gt;  4 2022-11-03 12:39:09        1       0 \"@trav‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"trave‚Ä¶ \"\"      FALSE   TRUE  reply    12 Thu   Nove‚Ä¶\n#&gt;  5 2022-11-03 06:45:53        5       0 \"@mcca‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"mccar‚Ä¶ \"\"      FALSE   TRUE  reply     6 Thu   Nove‚Ä¶\n#&gt;  6 2022-11-03 06:36:56        2       0 \"@trav‚Ä¶ 1588‚Ä¶ en    \"&lt;a h‚Ä¶ \"trave‚Ä¶ \"\"      FALSE   TRUE  reply     6 Thu   Nove‚Ä¶\n#&gt;  7 2022-11-02 12:26:46        0       0 \"RT @p‚Ä¶ 1587‚Ä¶ en    \"&lt;a h‚Ä¶ \"posit‚Ä¶ \"\"      TRUE    FALSE retw‚Ä¶    12 Wed   Nove‚Ä¶\n#&gt;  8 2022-11-02 12:20:50        4       0 \"And I‚Ä¶ 1587‚Ä¶ en    \"&lt;a h‚Ä¶ \"\"      \"\"      FALSE   FALSE tweet    12 Wed   Nove‚Ä¶\n#&gt;  9 2022-10-31 11:47:57        0       0 \"RT @D‚Ä¶ 1587‚Ä¶ en    \"&lt;a h‚Ä¶ \"Dante‚Ä¶ \"\"      TRUE    FALSE retw‚Ä¶    11 Mon   Octo‚Ä¶\n#&gt; 10 2022-10-30 19:32:22        8       0 \"At fi‚Ä¶ 1586‚Ä¶ en    \"&lt;a h‚Ä¶ \"pomol‚Ä¶ \"\"      FALSE   FALSE tweet    19 Sun   Octo‚Ä¶\n#&gt; # ‚Ä¶ with 6,213 more rows, 2 more variables: day_of_month &lt;int&gt;, year &lt;dbl&gt;, and abbreviated variable names\n#&gt; #   ¬π‚Äãfavorite_count, ¬≤‚Äãretweet_count, ¬≥‚Äãfull_text, ‚Å¥‚Äãuser_mentions, ‚Åµ‚Äãhashtags\n\n\nIf you‚Äôve seen the Observable notebook that inspired this post, you‚Äôll notice that I‚Äôve mostly recreated their data structure, but in R. Next, let‚Äôs recreate some of the plots in that notebook, too!"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#monthly-tweets-replies-and-retweets",
    "href": "blog/tweet-archive-in-r/index.html#monthly-tweets-replies-and-retweets",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Monthly tweets, replies and retweets",
    "text": "Monthly tweets, replies and retweets\n\n\nCode: Set Blog Theme\n\nYeah, so real quick, I‚Äôm going to set up a plot theme for the rest of this post. Here it is, if you‚Äôre interested in this kind of thing!\n\nblog_theme &lt;-\n  theme_minimal(18, base_family = \"IBM Plex Mono\") +\n  theme(\n    plot.background = element_rect(fill = \"#f9fafa\", color = NA),\n    plot.title.position = \"plot\",\n    plot.title = element_text(size = 24, margin = margin(b = 1, unit = \"line\")),\n    legend.position = c(0, 1),\n    legend.direction = \"horizontal\",\n    legend.justification = c(0, 1),\n    legend.title.align = 1,\n    axis.title.y = element_text(hjust = 0),\n    axis.title.x = element_text(hjust = 0),\n    panel.grid.major = element_line(color = \"#d3d9db\"),\n    panel.grid.minor = element_blank()\n  )\n\ntheme_set(blog_theme)\n\n\nThe first chart shows the number of tweets, replies and mentions sent in each month from 2009 to 2022. From 2009 to 2015, I sent about 25 total tweets per month, with one large spike in January 2014 when a grad school course I was taking decided to do a ‚ÄúTwitter seminar.‚Äù My Twitter usage dropped off considerably between 2015 and 2018: the result of a mix of grad school grinding, and then when my son was born in 2016 tweeting practically stopped altogether.\nMy Twitter usage picked up again in 2018, which also coincided with my realization that academia wasn‚Äôt my ideal future. In 2018 and 2019 you can see my baseline usage pick up considerably at the start of the year ‚Äî the effects of a lot of tweeting and networking during rstudio::conf. Since 2019, my usage has been fairly stable; I typically send between 50 and 100 tweets a month. Finally, there‚Äôs a noticeable recent drop in activity: since Twitter changed ownership I still read Twitter but only occasionally tweet.\n\n\n\n\n\n\n\n\n\nHover or tap2 on a bar above to see the top 5 tweets in each segment.\n\n\n\nCode: Plot Monthly Tweets\n\n\ntype_colors &lt;- c(reply = \"#5e5b7f\", tweet = \"#ef8c02\", retweet = \"#7ab26f\")\n\ntop_5_tweets_text &lt;- function(data) {\n  slice_max(\n    data,\n    n = 5,\n    order_by = retweet_count * 2 + favorite_count,\n    with_ties = FALSE\n  ) |&gt;\n    pull(full_text) |&gt;\n    str_trunc(width = 120)\n}\n\nplot_monthly &lt;-\n  tidy_tweets |&gt;\n  # Group nest by month and tweet type ---\n  mutate(dt_month = sprintf(\"%d-%02d\", year, month(created_at))) |&gt;\n  group_nest(dt_month, month, year, type) |&gt;\n  mutate(\n    # Calculate number of tweets per month/type\n    n = map_int(data, nrow),\n    # and extract the top 5 tweets\n    top = map(data, top_5_tweets_text)\n  ) |&gt;\n  select(-data) |&gt;\n  # Then build the tooltip (one row per month/type)\n  rowwise() |&gt;\n  mutate(\n    type_pl = plu::ral(type, n = n),\n    tooltip = glue::glue(\n      \"&lt;p&gt;&lt;strong&gt;{month} {year}: \",\n      \"&lt;span style=\\\"color:{type_colors[type]}\\\"&gt;{n} {type_pl}&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;\",\n      \"&lt;ol&gt;{tweets}&lt;/ol&gt;\",\n      tweets = paste(sprintf(\"&lt;li&gt;%s&lt;/li&gt;\", top), collapse = \"\")\n    ),\n    tooltip = htmltools::HTML(tooltip)\n  ) |&gt;\n  ungroup() |&gt;\n  # Finally ensure the order of factors (including month!)\n  mutate(type = factor(type, rev(c(\"tweet\", \"reply\", \"retweet\")))) |&gt;\n  arrange(dt_month, type) |&gt;\n  mutate(dt_month = fct_inorder(dt_month)) |&gt;\n  # Plot time! ----\n  ggplot() +\n  aes(x = dt_month, y = n, fill = type, color = type, group = type) +\n  ggiraph::geom_col_interactive(\n    width = 1,\n    aes(tooltip = tooltip)\n  ) +\n  scale_fill_manual(values = type_colors) +\n  scale_color_manual(values = type_colors) +\n  # The x-axis is factors for each month,\n  # we need labels for each year, e.g. 2010-01 =&gt; 2010\n  scale_x_discrete(\n    breaks = paste0(seq(2008, 2022, by = 1), \"-01\"),\n    labels = seq(2008, 2022, by = 1)\n  ) +\n  scale_y_continuous(expand = expansion(add = c(1, 1))) +\n  labs(\n    title = \"Tweets per month\",\n    x = \"Month Tweeted ‚Üí\",\n    y = \"Count ‚Üí\",\n    fill = NULL,\n    color = NULL\n  ) +\n  theme(\n    plot.title = element_text(size = 24, margin = margin(b = 2, unit = \"line\")),\n    legend.position = c(0, 1.14)\n  )\n\nggiraph::girafe(\n  ggobj = plot_monthly,\n  width_svg = 14,\n  height_svg = 6,\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#popular-tweets-likes-retweets",
    "href": "blog/tweet-archive-in-r/index.html#popular-tweets-likes-retweets",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Popular tweets, likes & retweets",
    "text": "Popular tweets, likes & retweets\nWhich tweets earned the most internet points? The next plot displays tweets that had at least 5 retweets or 5 favorites. Note that I‚Äôve fiddled with the axis scales; both are log-scales and each break shows (roughly) a doubling of internet points in each direction. Interestingly, for ‚Äúpopular‚Äù tweets (please note the air-quotes) retweets and favorites appear to be log-linear: a doubling of one generally corresponds to a doubling of the other, although my tweets tended to receive about 4 times as many likes as retweets.\nThere‚Äôs also some pretty interesting stuff going on in the low-retweets but high-favorites area. Popular tweets are cool, but the tweets that got lots of likes without being retweeted are the feel-good tweets that made me feel like I was part of a community online.\n\n\n\n\n\n\n\n\n\n\nCode: Plot Popular Tweets\n\n\njitter &lt;- function(x) {\n  spread &lt;- min(1, x * 0.2)\n  x + runif(1, -spread, spread)\n}\n\nplot_popular_tweets &lt;-\n  tidy_tweets |&gt;\n  filter(retweet_count &gt;= 5 | favorite_count &gt;= 5) |&gt;\n  mutate(\n    age = difftime(Sys.time(), created_at, units = \"days\"),\n    age = as.numeric(age) / 365.25,\n    created_at = strftime(created_at, '%a %b %e, %Y'),\n    full_text = str_replace_all(full_text, \"\\n\\n\", \"&lt;/p&gt;&lt;p&gt;\"),\n    full_text = str_replace_all(full_text, \"\\n\", \"&lt;br&gt;\"),\n    tooltip = glue(\n      \"&lt;p&gt;{full_text}&lt;/p&gt;&lt;dl&gt;\",\n      \"&lt;dt&gt;&#9842;&lt;/dt&gt;&lt;dd&gt;{retweet_count}&lt;/dd&gt;\",  # recycling icon\n      \"&lt;dt&gt;&#9829;&lt;/dt&gt;&lt;dd&gt;{favorite_count}&lt;/dt&gt;\", # heart icon\n      \"&lt;dt&gt;&#9998;&lt;/dt&gt;&lt;dd&gt;\", # pencil icon\n      \"&lt;a href=\\\"https://twitter.com/grrrck/status/{id}\\\"&gt;{created_at}&lt;/a&gt;\",\n      \"&lt;/dd&gt;&lt;/dl&gt;\"\n    )\n  ) |&gt;\n  rowwise() |&gt;\n  mutate(across(c(retweet_count, favorite_count), jitter)) |&gt;\n  ungroup() |&gt;\n  ggplot() +\n  aes(\n    x = favorite_count,\n    y = retweet_count,\n    color = age,\n    size = 5 * retweet_count + favorite_count,\n    tooltip = tooltip\n  ) +\n  ggiraph::geom_point_interactive() +\n  scale_color_viridis_c(option = \"C\", direction = -1) +\n  scale_y_continuous(\n    trans = scales::log1p_trans(),\n    breaks = c(10, 25, 50, 100, 200, 400),\n  ) +\n  scale_x_continuous(\n    trans = scales::log1p_trans(),\n    breaks = c(10, 25, 50, 100, 200, 400, 800, 1600)\n  ) +\n  guides(size = \"none\") +\n  labs(\n    title = \"Popular tweets\",\n    x = \"Favorites ‚Üí\",\n    y = \"Retweets ‚Üí\",\n    color = \"Tweet age\\nin years\"\n  ) +\n  theme(\n    legend.title = element_text(size = 12, vjust = 1),\n    legend.position = c(1.0125, 1.08),\n    legend.justification = c(1, 1)\n  )\n\nggiraph::girafe(\n  ggobj = plot_popular_tweets,\n  width_svg = 12,\n  height_svg = 8,\n  options = list(\n    ggiraph::opts_toolbar(position = \"bottomright\"),\n    ggiraph::opts_tooltip(placement = \"container\"),\n    ggiraph::opts_hover_inv(\"color:var(--borderColorCustom, #cfd5d8)\")\n  ),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#tweets-by-time-of-day",
    "href": "blog/tweet-archive-in-r/index.html#tweets-by-time-of-day",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Tweets by time of day",
    "text": "Tweets by time of day\nThe next plot highlights the time of day at which I sent tweets. Each bar show the total number of tweets I‚Äôve written within a given hour of the day. Morning hours are in the top half of each day‚Äôs circular panel and evening hours are in the bottom half. Tuesday at noon seems to be my favorite time to tweet ‚Äî I sent 120 tweets between 12pm and 1pm on Tuesday ‚Äî followed by Friday at 1pm (111 tweets) or at 11am (110 tweets).\n\n\n\n\n\n\n\n\n\nHover or tap on a bar to compare a given time across all days.\n\n\n\nCode: Plot Tweets by Time of Day\n\n\ntweet_count_by_hour &lt;-\n  tidy_tweets |&gt;\n  count(day, hour) |&gt;\n  mutate(\n    hour_label = case_when(\n      hour == 12 ~ \"12pm\",\n      hour == 0 ~ \"12am\",\n      hour &gt; 12 ~ paste0(hour - 12, \"pm\"),\n      hour &lt; 12 ~ paste0(hour, \"am\")\n    ),\n    pct = n / sum(n)\n  )\ntooltip_hour &lt;- function(day, hour_label, ...) {\n  this_hour_count &lt;-\n    tweet_count_by_hour |&gt;\n    filter(hour_label == !!hour_label)\n\n  this_hour_total &lt;- sum(this_hour_count$n)\n  this_hour_pct &lt;- scales::percent(this_hour_total / sum(tweet_count_by_hour$n), 0.1)\n  this_hour_total &lt;- trimws(format(this_hour_total, big.mark = \",\"))\n\n  this_hour_days &lt;-\n    this_hour_count |&gt;\n    mutate(\n      across(pct, scales::percent_format(0.1)),\n      across(n, format, big.mark = \",\"),\n      across(n, trimws),\n      text = glue(\"{day}: {pct} ({n})\"),\n      text = if_else(day == !!day, glue(\"&lt;strong&gt;{text}&lt;/strong&gt;\"), text)\n    ) |&gt;\n    glue_data(\"&lt;li&gt;{text}&lt;/li&gt;\") |&gt;\n    glue_collapse()\n\n  glue::glue(\n    \"&lt;p&gt;&lt;strong&gt;{hour_label}&lt;/strong&gt;&lt;br&gt;&lt;small&gt;{this_hour_pct} of total ({this_hour_total})&lt;/small&gt;&lt;/p&gt;\",\n    \"&lt;ul&gt;{this_hour_days}&lt;/ul&gt;\"\n  )\n}\n\ntweet_count_by_hour$tooltip &lt;- pmap_chr(tweet_count_by_hour, tooltip_hour)\n\nplot_time_of_day &lt;-\n  ggplot(tweet_count_by_hour ) +\n  aes(y = n, fill = day, x = hour, data_id = hour, tooltip = tooltip) +\n  geom_area(\n    data = function(d) {\n      # Shade from midnight-6am and 6pm-midnight, kinda like geom_step_area()\n      max_count &lt;- max(d$n)\n      tibble(\n        day = sort(rep(unique(d$day), 6)),\n        hour = rep(c(0, 6, 6.01, 18, 18.01, 24), 7),\n        n = rep(c(max_count, max_count, 0, 0, max_count, max_count), 7),\n        tooltip = \"\"\n      )\n    },\n    fill = \"#aaaaaa30\",\n  ) +\n  ggiraph::geom_col_interactive(show.legend = FALSE, width = 1) +\n  facet_wrap(vars(day), nrow = 2) +\n  coord_polar(start = pi) +\n  scale_x_continuous(\n    breaks = seq(0, 23, 3),\n    minor_breaks = 0:23,\n    labels = c(\"12am\", paste0(seq(3, 9, 3), \"am\"), \"12pm\", paste0(seq(3, 9, 3), \"pm\")),\n    limits = c(0, 24),\n    expand = expansion()\n  ) +\n  scale_y_continuous(expand = expansion(), breaks = seq(0, 100, 25)) +\n  scale_fill_discrete() +\n  labs(\n    title = \"When do I do my tweeting?\",\n    x = NULL,\n    y = NULL\n  ) +\n  theme(\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size = 10),\n    panel.grid.major.y = element_blank()\n  )\n\nggiraph::girafe(\n  ggobj = plot_time_of_day,\n  width_svg = 12,\n  height_svg = 8,\n  options = list(\n    ggiraph::opts_hover_inv(\"filter: saturate(30%) brightness(125%)\"),\n    ggiraph::opts_hover(css = \"opacity:1\"),\n    ggiraph::opts_tooltip(\n      placement = \"container\",\n      css = \"width: 12rem; font-family: var(--font-monospace, 'IBM Plex Mono');\",\n      # These don't matter, position is set by CSS rules below\n      offx = 600,\n      offy = 260,\n      use_cursor_pos = FALSE\n    )\n  ),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#tweet-source",
    "href": "blog/tweet-archive-in-r/index.html#tweet-source",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Tweet source",
    "text": "Tweet source\nThe tweet archive includes the application used to send the tweet, stored as the HTML that‚Äôs displayed in the tweet text:\n&lt;a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\"&gt;Twitter for iPhone&lt;/a&gt;\nWith a little bit of regex, we can extract the tweet source. Apparently, I‚Äôve used 37 different apps to write my tweets, but 17 were used for no more than 5 tweets. Most often ‚Äî actually, 79% of the time ‚Äî I wrote tweets from the web app or my phone.\n\n\n\n\n\n\n\n\n\n\nCode: Plot Tweet Source\n\n\ntweet_source &lt;-\n  tidy_tweets |&gt;\n  extract(\n    source,\n    into = c(\"source_href\", \"source\"),\n    regex = '&lt;a href=\"([^\"]+)\"[^&gt;]+&gt;([^&lt;]+)&lt;/a&gt;'\n  )\n\ntweet_source_count &lt;- tweet_source |&gt;\n  count(source) |&gt;\n  mutate(pct = n / sum(n))\nplot_tweet_source &lt;-\n  tweet_source |&gt;\n  mutate(\n    source = fct_lump_n(source, n = 15),\n    source = fct_rev(fct_infreq(source))\n  ) |&gt;\n  count(source, type, sort = TRUE) |&gt;\n  pivot_wider(names_from = type, values_from = n, values_fill = 0) |&gt;\n  mutate(\n    total = reply + retweet + tweet,\n    tooltip = pmap_chr(\n      list(source, reply, retweet, tweet, total),\n      function(source, reply, retweet, tweet, total) {\n        x &lt;- glue(\n          '&lt;label for=\"{tolower(label)}\"&gt;{label}&lt;/label&gt;',\n          '&lt;progress id=\"{tolower(label)}\" max=\"{total}\" value=\"{value}\"&gt;{value}&lt;/progress&gt;',\n          label = c(\"Tweets\", \"Replies\", \"Retweets\"),\n          value = c(tweet, reply, retweet)\n        )\n        x &lt;- glue_collapse(x)\n        paste0('&lt;p class=\"b\"&gt;', source, \"&lt;/p&gt;\", x)\n      }\n    )\n  ) |&gt;\n  ggplot() +\n  aes(x = total, y = source, tooltip = tooltip) +\n  ggiraph::geom_col_interactive(show.legend = FALSE) +\n  scale_x_continuous(expand = expansion(add = c(0, 0.01))) +\n  scale_y_discrete(expand = expansion()) +\n  labs(\n    title = \"What app did I use to tweet?\",\n    x = \"Tweets ‚Üí\",\n    y = NULL\n  ) +\n  theme(\n    panel.grid.major.y = element_blank()\n  )\n\nggiraph::girafe(\n  ggobj = plot_tweet_source,\n  width_svg = 10,\n  height_svg = 8,\n  options = list(\n    ggiraph::opts_hover_inv(\"filter: saturate(30%) brightness(125%)\"),\n    ggiraph::opts_hover(css = \"opacity:1\"),\n    ggiraph::opts_tooltip(\n      placement = \"container\",\n      css = \"width: 15rem; font-family: var(--font-monospace, 'IBM Plex Mono');\"\n    )\n  ),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#my-likes",
    "href": "blog/tweet-archive-in-r/index.html#my-likes",
    "title": "Read and Visualize your Twitter Archive",
    "section": "My likes",
    "text": "My likes\nOne huge reason to go through the trouble of requesting and downloading your Twitter archive is to collect a copy of your liked tweets. (Sadly, your bookmarks are not a part of the archive.)\n\nlikes &lt;-\n  read_twitter_data(manifest, \"like\") |&gt;\n  simplify_twitter_data()\n\nlikes |&gt;\n  arrange(as.numeric(tweetId))\n#&gt; # A tibble: 11,773 √ó 3\n#&gt;    tweetId            fullText                                                                                   expan‚Ä¶¬π\n#&gt;    &lt;chr&gt;              &lt;chr&gt;                                                                                      &lt;chr&gt;  \n#&gt;  1 42240201359233024  We just went live with RStudio, a new IDE for R. Try it out and let us know what you thin‚Ä¶ https:‚Ä¶\n#&gt;  2 169437879704092672 RT @DKThomp: Adulthood, Delayed: What the Recession Has Done to Millennials http://t.co/U‚Ä¶ https:‚Ä¶\n#&gt;  3 338425212762738690 Joy! First sighting of NYC's CitiBikes in place! http://t.co/o6VPop4kWZ                    https:‚Ä¶\n#&gt;  4 343026917659791360 What a shitty day to announce my new data analytics project, Prism.                        https:‚Ä¶\n#&gt;  5 343037575889580033 Very cool: DoS using agent-based modeling to understand conflict dynamics in Niger Delta ‚Ä¶ https:‚Ä¶\n#&gt;  6 347931309496213504 BACK TO BACK CHAMPS!!! Going crazy all by myself in my little hotel room in Prague. Effin‚Ä¶ https:‚Ä¶\n#&gt;  7 383071681079549953 The real reason lowering health care costs is hard: Every patient is unique http://t.co/j‚Ä¶ https:‚Ä¶\n#&gt;  8 386857068423938048 Good work on study on admits/length of stay/ 'crowdedness' of ICU &amp; impacts on morbid‚Ä¶ https:‚Ä¶\n#&gt;  9 386862608231325696 I'm giving my presentation on scheduling medical residents at #informs2013 in the Doing G‚Ä¶ https:‚Ä¶\n#&gt; 10 386935928042029056 Gustavo just presented a semicont opt that can B perfectly applied in my supply chain pro‚Ä¶ https:‚Ä¶\n#&gt; # ‚Ä¶ with 11,763 more rows, and abbreviated variable name ¬π‚ÄãexpandedUrl\n\n\nWhile the likes archive includes the full text of each tweet, we can use the lookup_tweets() function from the rtweet package to download complete information about each tweet.\n\nlikes_full &lt;-\n  rtweet::lookup_tweets(likes$tweetId) |&gt;\n  write_rds(\"data/likes.rds\")\n\nGetting all 11,773 tweets takes a few minutes, so I highly recommend saving the data to disk as soon as you‚Äôve collected it.\n\nlikes_full &lt;- read_rds(\"data/likes.rds\")\nlikes_full\n#&gt; # A tibble: 11,385 √ó 43\n#&gt;    created_at               id id_str       full_‚Ä¶¬π trunc‚Ä¶¬≤ displ‚Ä¶¬≥ entities     source in_rep‚Ä¶‚Å¥ in_re‚Ä¶‚Åµ in_re‚Ä¶‚Å∂ in_re‚Ä¶‚Å∑\n#&gt;    &lt;dttm&gt;                &lt;dbl&gt; &lt;chr&gt;        &lt;chr&gt;   &lt;lgl&gt;     &lt;dbl&gt; &lt;list&gt;       &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;     &lt;dbl&gt; &lt;chr&gt;  \n#&gt;  1 2022-11-04 20:35:35 1.59e18 15886914597‚Ä¶ \"Read ‚Ä¶ FALSE       278 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  2 2022-11-05 10:33:18 1.59e18 15889022786‚Ä¶ \"heari‚Ä¶ FALSE       190 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  3 2022-11-05 01:35:38 1.59e18 15887669703‚Ä¶ \"Defen‚Ä¶ FALSE       236 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  4 2022-11-04 14:23:18 1.59e18 15885977742‚Ä¶ \"Pleas‚Ä¶ FALSE        60 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  5 2022-11-04 11:35:40 1.59e18 15885555857‚Ä¶ \"Despe‚Ä¶ FALSE       114 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  6 2022-11-04 16:16:08 1.59e18 15886261683‚Ä¶ \"Here'‚Ä¶ FALSE       269 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  7 2022-11-04 11:46:29 1.59e18 15885583081‚Ä¶ \"@tjma‚Ä¶ FALSE        39 &lt;named list&gt; \"&lt;a h‚Ä¶  1.59e18 158855‚Ä¶  1.29e9 128991‚Ä¶\n#&gt;  8 2022-11-03 10:22:11 1.59e18 15881747079‚Ä¶ \"https‚Ä¶ FALSE         0 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt;  9 2022-11-04 09:48:27 1.59e18 15885286045‚Ä¶ \"One o‚Ä¶ FALSE       188 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt; 10 2022-11-04 13:54:39 1.59e18 15885905619‚Ä¶ \"We‚Äôve‚Ä¶ FALSE       141 &lt;named list&gt; \"&lt;a h‚Ä¶ NA       NA      NA      NA     \n#&gt; # ‚Ä¶ with 11,375 more rows, 31 more variables: in_reply_to_screen_name &lt;chr&gt;, geo &lt;list&gt;, coordinates &lt;list&gt;,\n#&gt; #   place &lt;list&gt;, contributors &lt;lgl&gt;, is_quote_status &lt;lgl&gt;, retweet_count &lt;int&gt;, favorite_count &lt;int&gt;,\n#&gt; #   favorited &lt;lgl&gt;, retweeted &lt;lgl&gt;, lang &lt;chr&gt;, possibly_sensitive &lt;lgl&gt;, quoted_status_id &lt;dbl&gt;,\n#&gt; #   quoted_status_id_str &lt;chr&gt;, quoted_status_permalink &lt;list&gt;, quoted_status &lt;list&gt;, text &lt;chr&gt;, favorited_by &lt;lgl&gt;,\n#&gt; #   scopes &lt;list&gt;, display_text_width &lt;lgl&gt;, retweeted_status &lt;lgl&gt;, quote_count &lt;lgl&gt;, timestamp_ms &lt;lgl&gt;,\n#&gt; #   reply_count &lt;lgl&gt;, filter_level &lt;lgl&gt;, metadata &lt;lgl&gt;, query &lt;lgl&gt;, withheld_scope &lt;lgl&gt;, withheld_copyright &lt;lgl&gt;,\n#&gt; #   withheld_in_countries &lt;lgl&gt;, possibly_sensitive_appealable &lt;lgl&gt;, and abbreviated variable names ¬π‚Äãfull_text, ‚Ä¶\n\n\nAssuming I liked a tweet in the same year it was written (reasonable but not entirely accurate), plotting the source year of the tweet highlights just how much my Twitter usage picked up in 2018.\n\n\n\n\n\n\n\n\nCode: Plot Total Likes\n\n\nplot_liked_tweets &lt;-\n  likes_full |&gt;\n  count(year = year(created_at)) |&gt;\n  mutate(\n    noun = map_chr(n, \\(n) plu::ral(\"tweet\", n = n)),\n    tooltip = paste(format(n, big.mark = \",\"), \"liked\", noun, \"in\", year)\n  ) |&gt;\n  ggplot() +\n  aes(year, n, tooltip = tooltip, group = 1) +\n  geom_line(color = \"#595959\", linewidth = 1.5) +\n  ggiraph::geom_point_interactive(color = \"#595959\", size = 7) +\n  scale_x_continuous(breaks = seq(2008, 2022, 2), expand = expansion(add = 0.25)) +\n  labs(\n    title = \"Tweets I've Liked\",\n    x = \"Year ‚Üí\",\n    y = \"Liked Tweets ‚Üí\"\n  )\n\nggiraph::girafe(\n  ggobj = plot_liked_tweets,\n  width_svg = 12,\n  height_svg = 4,\n  options = list(ggiraph::opts_tooltip()),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#advertising-info",
    "href": "blog/tweet-archive-in-r/index.html#advertising-info",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Advertising info",
    "text": "Advertising info\nThe last thing I want to dive into is a part of the archive that includes information about Twitter‚Äôs perception of you. Or more importantly how they see you in terms of advertising.\n\nImpressions and engagements\nThere are two key items in the archive: ad impressions and engagements. All ads on Twitter are actually tweets that are promoted into your view because an advertiser has paid for Twitter to show you a tweet you wouldn‚Äôt otherwise see.\nAn impression is a promoted tweet you see in your timeline or in tweet replies, but you don‚Äôt interact with the tweet. An engagement is a tweet that you click on or interact with in some way. The definitions (included in the details below) are hazy ‚Äî I‚Äôm fairly certain from looking at my data that some tweets are ‚Äúengaged with‚Äù simply by being visible on my screen for a longer period of time. (In other words, I‚Äôm certain I haven‚Äôt actively engaged with as many tweets as are highlighted below.)\nThe ads data items are imported separately and have a pretty wild nested structure. I used a lot of tidyr‚Äôs tidyr::unnest() and my newest favorite function, unnest_wider().\n\n\nCode: ad_impressions\n\n\nad-impressions.js - ad: Promoted Tweets the account has viewed and any associated metadata. - deviceInfo: Information about the device where the impression was viewed such as its ID and operating system. - displayLocation: Location where the ad was viewed on Twitter. - promotedTweetInfo: Information about the associated tweet such as unique identifier, text, URLs and media when applicable. - advertiserInfo: Advertiser name and screen name. - matchedTargetingCriteria: Targeting criteria that were used to run the campaign. - impressionTime: Date and time when the ad was viewed.\n\n\nad_impressions &lt;-\n  read_twitter_data(manifest, \"adImpressions\") |&gt;\n  simplify_twitter_data() |&gt;\n  unnest(adsUserData) |&gt;\n  unnest(adsUserData) |&gt;\n  unnest_wider(adsUserData) |&gt;\n  unnest_wider(c(deviceInfo, promotedTweetInfo, advertiserInfo)) |&gt;\n  mutate(\n    matchedTargetingCriteria = map(matchedTargetingCriteria, map_dfr, identity),\n    across(impressionTime, ymd_hms)\n  )\n\n\n\n\nCode: ad_engagements\n\n\nad-engagements.js - ad: Promoted Tweets the account has engaged with and any associated metadata. - engagementAttributes: Type of engagement as well as date and time when it occurred.\n\n\nad_engagements &lt;-\n  read_twitter_data(manifest, \"adEngagements\") |&gt;\n  simplify_twitter_data() |&gt;\n  unnest(adsUserData) |&gt;\n  unnest(adsUserData) |&gt;\n  unnest_wider(adsUserData) |&gt;\n  mutate(across(engagementAttributes, map, map_dfr, identity)) |&gt;\n  unnest_wider(impressionAttributes) |&gt;\n  # now the same as the impressions\n  unnest_wider(c(deviceInfo, promotedTweetInfo, advertiserInfo)) |&gt;\n  mutate(\n    matchedTargetingCriteria = map(matchedTargetingCriteria, map_dfr, identity),\n    across(impressionTime, ymd_hms)\n  )\n\n\nOnce you have the impressions and engagements tables, you can combine them together with purrr::list_rbind.\n\nads &lt;-\n  list(\n    impression = ad_impressions,\n    engagement = ad_engagements\n  ) |&gt;\n  list_rbind(names_to = \"type\")\n\nads\n#&gt; # A tibble: 8,599 √ó 16\n#&gt;    type       osType devic‚Ä¶¬π devic‚Ä¶¬≤ displ‚Ä¶¬≥ tweetId tweet‚Ä¶‚Å¥ urls   media‚Ä¶‚Åµ adver‚Ä¶‚Å∂ scree‚Ä¶‚Å∑ matche‚Ä¶‚Å∏ impressionTime     \n#&gt;    &lt;chr&gt;      &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;list&gt; &lt;list&gt;  &lt;chr&gt;   &lt;chr&gt;   &lt;list&gt;   &lt;dttm&gt;             \n#&gt;  1 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 154910‚Ä¶ \"When ‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Chevro‚Ä¶ @chevr‚Ä¶ &lt;tibble&gt; 2022-08-08 14:03:09\n#&gt;  2 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155557‚Ä¶ \"Tune ‚Ä¶ &lt;chr&gt;  &lt;NULL&gt;  Walmart @Walma‚Ä¶ &lt;tibble&gt; 2022-08-08 14:08:07\n#&gt;  3 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155465‚Ä¶ \"Meet ‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Anker   @Anker‚Ä¶ &lt;tibble&gt; 2022-08-08 14:04:17\n#&gt;  4 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155598‚Ä¶ \"This ‚Ä¶ &lt;NULL&gt; &lt;chr&gt;   KESIMP‚Ä¶ @KESIM‚Ä¶ &lt;tibble&gt; 2022-08-08 10:54:28\n#&gt;  5 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ TweetC‚Ä¶ 155507‚Ä¶ \"üéÅüéÅG‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Webull  @Webul‚Ä¶ &lt;tibble&gt; 2022-08-08 10:57:56\n#&gt;  6 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 151472‚Ä¶ \"#1 is‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Financ‚Ä¶ @finan‚Ä¶ &lt;tibble&gt; 2022-08-08 10:56:19\n#&gt;  7 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ TweetC‚Ä¶ 155507‚Ä¶ \"üéÅüéÅG‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Webull  @Webul‚Ä¶ &lt;tibble&gt; 2022-08-08 10:56:57\n#&gt;  8 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155481‚Ä¶ \"Mick.‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  EPIX i‚Ä¶ @EPIXHD &lt;tibble&gt; 2022-08-08 03:33:23\n#&gt;  9 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155407‚Ä¶ \"Watch‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Paper ‚Ä¶ @HowLi‚Ä¶ &lt;tibble&gt; 2022-08-08 03:34:51\n#&gt; 10 impression Ios    2eVW2/‚Ä¶ iPhone‚Ä¶ Timeli‚Ä¶ 155512‚Ä¶ \"Wreck‚Ä¶ &lt;NULL&gt; &lt;NULL&gt;  Mill G‚Ä¶ @Mill_‚Ä¶ &lt;tibble&gt; 2022-08-08 03:25:08\n#&gt; # ‚Ä¶ with 8,589 more rows, 3 more variables: publisherInfo &lt;list&gt;, promotedTrendInfo &lt;list&gt;,\n#&gt; #   engagementAttributes &lt;list&gt;, and abbreviated variable names ¬π‚ÄãdeviceId, ¬≤‚ÄãdeviceType, ¬≥‚ÄãdisplayLocation, ‚Å¥‚ÄãtweetText,\n#&gt; #   ‚Åµ‚ÄãmediaUrls, ‚Å∂‚ÄãadvertiserName, ‚Å∑‚ÄãscreenName, ‚Å∏‚ÄãmatchedTargetingCriteria\n\n\nThe downside of the ads data is that it only includes the last three-ish months. Here are my impressions and engagements for August through early November of 2022.\n\n\n\n\n\n\n\n\nCode: Plot Interactions by Month\n\n\nplot_ads_interactions &lt;-\n  ads |&gt;\n  count(type, month = floor_date(impressionTime, \"month\")) |&gt;\n  mutate(\n    n_str = format(n, big.mark = \",\"),\n    tooltip = pmap_chr(\n      list(type, n, n_str, month),\n      \\(type, n, n_str, month) {\n        glue(\n          \"{n} {type} in {month}\",\n          type = plu::ral(type, n = n),\n          month = month(month, label = TRUE, abbr = FALSE)\n        )\n      })\n  ) |&gt;\n  ggplot() +\n  aes(month, n, fill = type, tooltip = tooltip) +\n  ggiraph::geom_col_interactive() +\n  scale_fill_manual(\n    values = c(\"#97c4ca\", \"#1c7d8b\"),\n    labels = c(\"Engagement\", \"Impression\")\n  ) +\n  labs(\n    title = \"Ad Interactions by Month\",\n    x = NULL,\n    y = \"Promoted Tweets ‚Üí\",\n    fill = NULL\n  ) +\n  theme(\n    panel.grid.major.x = element_blank(),\n    legend.direction = \"vertical\",\n    legend.position = c(0.95, 0.9),\n    legend.justification = c(1, 1)\n  )\n\nggiraph::girafe(\n  ggobj = plot_ads_interactions,\n  width_svg = 12,\n  height_svg = 6,\n  options = list(ggiraph::opts_tooltip()),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)\n\n\n\n\nWho advertized to me?\nFinally, I wanted to know who was advertising to me and which tweets I was seeing. The advertising data includes demographics and keywords used by the advertisers to target you, and I recommend taking a look at that. But I‚Äôm running out of steam in this post, so let‚Äôs just take a look at the promoted content I saw on Twitter over the last few months.\n\n\n\n\n\n\n\n\nCode: Plot Ad Interactions by Advertiser\n\n\nads_advertiser_counts &lt;-\n  ads |&gt;\n  count(advertiserName, type, sort = TRUE) |&gt;\n  pivot_wider(names_from = type, values_from = n) |&gt;\n  slice_max(n = 25, engagement + impression) |&gt;\n  pivot_longer(-1, names_to = \"type\")\n\nads_tweet_examples &lt;-\n  ads |&gt;\n  filter(!is.na(tweetText)) |&gt;\n  semi_join(ads_advertiser_counts) |&gt;\n  group_by(advertiserName, type) |&gt;\n  mutate(tweetText = str_trunc(tweetText, width = 80)) |&gt;\n  summarize(\n    n = n(),\n    tweets = glue_collapse(glue(\n      \"&lt;li&gt;{sample(unique(tweetText), min(5, length(unique(tweetText))))}&lt;/li&gt;\"\n    )),\n    .groups = \"drop\"\n  ) |&gt;\n  mutate(\n    tweets = glue('&lt;ul&gt;{tweets}&lt;/ul&gt;'),\n    tweets = glue(\n      '&lt;p&gt;&lt;strong&gt;{n}&lt;/strong&gt; promoted tweet ',\n      '&lt;strong&gt;{type}s&lt;/strong&gt; ',\n      'by &lt;strong&gt;{advertiserName}&lt;/strong&gt;&lt;/p&gt;',\n      '{tweets}'\n    )\n  )\n\nplot_advertisers &lt;-\n  ads_advertiser_counts |&gt;\n  left_join(ads_tweet_examples) |&gt;\n  mutate(advertiserName = fct_reorder(advertiserName, value, sum)) |&gt;\n  ggplot() +\n  aes(value, advertiserName, fill = type, tooltip = tweets) +\n  ggiraph::geom_col_interactive() +\n  scale_x_continuous(expand = expansion()) +\n  scale_fill_manual(\n    values = c(\"#97c4ca\", \"#1c7d8b\"),\n    labels = c(\"Engagement\", \"Impression\")\n  ) +\n  labs(\n    title = \"Ad Interactions by Advertiser\",\n    x = \"Interactions with Promoted Tweets ‚Üí\",\n    y = NULL,\n    fill = NULL\n  ) +\n  theme(\n    panel.grid.major.y = element_blank(),\n    legend.direction = \"vertical\",\n    legend.position = c(0.99, 0.1),\n    legend.justification = c(1, 0)\n  )\n\nggiraph::girafe(\n  ggobj = plot_advertisers,\n  width_svg = 12,\n  height_svg = 10,\n  options = list(ggiraph::opts_tooltip()),\n  desc = knitr::opts_current$get(\"fig.alt\")\n)"
  },
  {
    "objectID": "blog/tweet-archive-in-r/index.html#footnotes",
    "href": "blog/tweet-archive-in-r/index.html#footnotes",
    "title": "Read and Visualize your Twitter Archive",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nsimplify_twitter_data() is an optional and separate function because it‚Äôs an 80/20 function: it‚Äôs 20% of the code that does the right thing 80% of the time.‚Ü©Ô∏é\nOn mobile devices, tapping on a bar kind of works. But to change focus from one plot element to another, you might need to tap outside of the plot area before tapping on the new element. Sorry! The hover interactions work a whole lot better on desktop.‚Ü©Ô∏é"
  },
  {
    "objectID": "blog/video-debug-js-from-r/index.html",
    "href": "blog/video-debug-js-from-r/index.html",
    "title": "Video: Debugging JavaScript You Wrote in R",
    "section": "",
    "text": "htmlwidgets makes it easy to create awesome web things from R and R Markdown, but sometimes you have to write your own JavaScript code‚Ä¶ in strings‚Ä¶ in R. What do you do if it doesn‚Äôt work? How can you write JavaScript interactively?\n\n\nI ‚Äúlive streamed‚Äù my process as I worked through debugging some buggy JavaScript that Tom Mock shared on twitter, touching on the tools used to debug JavaScript and some features from the js4shiny package that help R users with web development.\nThe example uses the awesome reactable package, which helps you make some incredible HTML interactive HTML tables.\nIf you want to try this at home, I‚Äôve uploaded the code that doesn‚Äôt work and the code that does work as GitHub gists.\nOh and by the way, I‚Äôm using the RStudio theme ‚ÄúFlat White‚Äù from rsthemes.\n\nThis is the first time I‚Äôve made a video like this. If you liked it and want to see more, let me know on Twitter @grrrck."
  },
  {
    "objectID": "blog/xaringan-playground/index.html",
    "href": "blog/xaringan-playground/index.html",
    "title": "xaringan Playground: Using xaringan to learn web development",
    "section": "",
    "text": "This year, I‚Äôm presenting a lightning talk at rstudio::global ‚Äî xaringan Playground: Using xaringan to learn web development.\nThe talk is short and covers just a taste of how xaringan can make learning web development fun. In future posts I‚Äôll dive deeper into CSS and web development basics for xaringan users.\nFor now I just want to share some of the reasons why I love xaringan for tinkering with web development ideas."
  },
  {
    "objectID": "blog/xaringan-playground/index.html#xaringan-css",
    "href": "blog/xaringan-playground/index.html#xaringan-css",
    "title": "xaringan Playground: Using xaringan to learn web development",
    "section": "xaringan ‚ù§Ô∏è CSS",
    "text": "xaringan ‚ù§Ô∏è CSS\nOver the last few years, I‚Äôve built many presentations with xaringan. There are a lot of things to love about xaringan, but one thing I‚Äôve noticed is that xaringan presentations can be a gateway into the world of web development.\nIf you‚Äôve worked with R Markdown to create a report or blog or website to share online, you‚Äôve probably encountered a few stylistic things you‚Äôve wanted to change. These changes tend to be small, like choosing a new font family or changing the color of links. If you don‚Äôt like the look of your report, there are lots of themes to choose from in rmarkdown, or in other packages like prettydocs, rmdformats, or cleanrmd.\nxaringan is a little different. Slides are a visual medium. You probably have an idea of how you want your slides to look as you work on them.\nYou can get really far with plain markdown using the few little extras that xaringan provides, but at a certain point in the process of transferring your vision of your talk to the screen, you‚Äôve probably said, out loud and not without a slight hint of frustration: I just want that thing to go right there.\nIn point-and-click software, this is where you‚Äôd spend some time dragging text and images around or digging through menus to make your slides look awesome. In xaringan, your slides are web page, so we instead need to turn to CSS to style our slides. I‚Äôm not going to say that one method is necessarily better than the other, just that I personally love writing code and I actually enjoy CSS. I might be weird in that respect, but since you‚Äôre still reading this I‚Äôm guessing you are too.\nThis is why I love xaringan. Each slide is a small, self-contained web design project. The constraints are well-defined: you aren‚Äôt building an entire website. You don‚Äôt have to make an app or think about a user interface. You just need to make this slide look great.\nThere are two advantages of using xaringan and CSS for our slides that I think are important. First, knowing CSS is useful in more places than just making slides. Many of the things I‚Äôve designed for a presentation have been useful in other areas of my life as an R Markdown user and person who puts things on the internet for others to enjoy.\nSecond, while CSS can be daunting to learn, the stakes are relatively low with xaringan. You don‚Äôt need to know everything about CSS or web development. When you create a new slide, you only need to worry about the things you‚Äôre going to put in that slide. You don‚Äôt have to think about laying out an entire web page. And as long as you slides look good when you present them, then your job was well done.\nThis is why I see xaringan as a playground for trying new things. It sets you up to play with CSS, to learn something new, and to get quick, immediate feedback. Plus, it feels good to make things that look great and to share them with the world!\nNot only that, xaringan has a few tricks up its sleeve. Catch the talk or wait for the next post in this series to learn more!"
  },
  {
    "objectID": "blog/xaringanthemer-v0-3-0/index.html",
    "href": "blog/xaringanthemer-v0-3-0/index.html",
    "title": "Announcing xaringanthemer v0.3.0!",
    "section": "",
    "text": "Star¬† Fork"
  },
  {
    "objectID": "blog/xaringanthemer-v0-3-0/index.html#new-features-and-now-on-cran",
    "href": "blog/xaringanthemer-v0-3-0/index.html#new-features-and-now-on-cran",
    "title": "Announcing xaringanthemer v0.3.0!",
    "section": "New Features and Now on CRAN! üéâ",
    "text": "New Features and Now on CRAN! üéâ\nThis release has been a long time in the making, and I‚Äôm very excited to share with you all of the cool new things that xaringanthemer can bring to your xaringan slides!\nI started working on one of the key features of this release about a year ago ‚Äî ggplot2 themes that magically match your slide theme ‚Äî but only recently was able to make the time to push the documentation and tests over the CRAN finish line. Equally exciting, xaringanthemer finally has it‚Äôs own hex logo thanks to critical artistic help from my amazingly talented sister Aubrey Aden-Buie!\nThis post walks through the purpose of xaringanthemer and all of the new features in version 0.3.0. You can try out xaringanthemer for your next presentation, right after you install the package:\n\ninstall.packages(\"xaringanthemer\")"
  },
  {
    "objectID": "blog/xaringanthemer-v0-3-0/index.html#what-does-xaringanthemer-do",
    "href": "blog/xaringanthemer-v0-3-0/index.html#what-does-xaringanthemer-do",
    "title": "Announcing xaringanthemer v0.3.0!",
    "section": "What does xaringanthemer do?",
    "text": "What does xaringanthemer do?\nxaringanthemer works hand-in-hand with xaringan, the R package that turns your R Markdown into beautiful HTML slides rendered as web pages using the remarkjs library.\nxaringan slides tend to look like the slides below, and, by default, xaringan uses the default slide theme from remarkjs.\n\nxaringan does come with a collection of user-contributed themes to choose from, but customizing any xaringan slide theme requires working with CSS and learning which CSS rules apply to each element in the slides.\nEven if you love CSS, it can still be difficult and time-consuming to set up your slides to use a consistent color palette or custom fonts.\nThe magic of xaringanthemer is that it grants you the power to quickly set up a complete slide theme, starting from only one or two color choices. You pick how these color choices are applied by choosing from a collection of style_ functions, and you can tweak the default color choices easily by providing alternative values for many theme parameters.\n\n\n\n\nThese slides were styled using the style_duo_accent() function, which applied my primary color and my secondary color consistently throughout the slide theme.\nYou can also easily use fonts from Google Fonts by using the google_font() helper. I used eye-catching fonts in this example that I probably wouldn‚Äôt use in real life (the default fonts used by xaringanthemer are much more readable).\nHere‚Äôs the complete code chunk that I used in my slides.Rmd file to create the example above.\n```{r xaringan-themer, include=FALSE}\nstyle_duo_accent(\n  primary_color = \"#035AA6\",        # blue\n  secondary_color = \"#03A696\",      # sea green\n  header_font_google = google_font(\"Amatic SC\"),\n  text_font_google = google_font(\"Crete Round\"),\n  header_h1_font_size = \"3.5rem\",\n  header_h2_font_size = \"2.75rem\"\n)\n```\nThe slide style functions come in a few flavors. Styles derived from two color choices are prefixed with style_duo_. Slide themes generated from a single color use the style_mono_ prefix. There are also two complete styles based on the solarized color palette: style_solarized_light() and style_solarized_dark(). And finally, you can use the style_xaringan() base theme function directly, which starts from the default xaringan theme.\nAll of the style_ functions write a CSS file containing your complete slide theme. By default, the file is called xaringan-themer.css and you can create your CSS file in a separate R script or you can include the style-generating code in your slides with a chunk like the one above.\nIn either case, in order for your slides to use your new theme, you need to modify the css argument of xaringan::moon_reader in the YAML header of your slides.\noutput:\n  xaringan::moon_reader:\n    css: xaringan-themer.css\nThat‚Äôs xaringanthemer in a nutshell! You can learn more about the features in the package below, or by visiting pkg.garrickadenbuie.com/xaringanthemer."
  },
  {
    "objectID": "blog/xaringanthemer-v0-3-0/index.html#new-features",
    "href": "blog/xaringanthemer-v0-3-0/index.html#new-features",
    "title": "Announcing xaringanthemer v0.3.0!",
    "section": "New Features",
    "text": "New Features\nThere are quite a lot of new features in version 0.3.0 that I‚Äôm very excited to share with you.\n\nConsistent API with style functions\nThis package has been on GitHub for a couple of years, and thank you to everyone who tested and contributed to the development over the years.\nIf you‚Äôve used the GitHub version before, the API has changed slightly, but there should not have been any breaking changes. In short, all of the files that write CSS, for example the functions previouslly called duo_accent() or write_xaringan_theme(), are now prefixed with style_, e.g.¬†style_duo_accent() and style_xaringan().\n\n\nPowered by CSS variables\nxaringanthemer does much of the work on the R side to prepare the theme, but nearly all of the properties of your theme are stored in CSS variables (or custom properties). This makes it possible to re-use colors from your theme, either in custom CSS or as arguments to the style function parameters.\nWhenever a theme parameter is stored in a CSS variable, the documentation of the associated argument in the style function will tell you what CSS variable name is used. For example, the link_color argument is made available in the CSS as var(--link-color).\nIn general, argument names are converted from snake_case_names to kebab-case-names.\n\n\nSetting additional colors\nIf you‚Äôve spent a lot of time picking out a color palette, or if you‚Äôre using a corporate color palette, you‚Äôll likely have more than just two colors that you want to use, and possibly not just in the components of your theme.\nThe markdown syntax used by xaringan (actually remarkjs in this case) allows you to apply a class to text using syntax like this: .class[ ... ]\nBuilding on the use of CSS variables, xaringanthemer helps you add these additional colors to your theme. Using the colors argument, you can specify a vector of named colors.\n\nstyle_xaringan(\n  colors = c(\n    red = \"#f34213\",\n    purple = \"#3e2f5b\",\n    orange = \"#ff8811\",\n    green = \"#136f63\",\n    white = \"#FFFFFF\",\n  )\n)\n\nThe color names are then used in three places. Using the red color as an example, xaringanthemer adds\n\na CSS variable var(--red) that use anywhere in custom CSS\na .red class to set color: var(--red)\na .bg-red class setting background-color: var(--red).\n\nThe named color and background classes are then easy to use in xaringan. Slide text like this\nThis **.red[simple]** .white.bg-purple[demo]\n_.orange[shows]_ the colors .green[in action].\nwill be rendered in HTML as\n\nThis simple demo shows the colors in action.\n\n\n\nMatching ggplot2 themes\nAt this point your slides look a m a z i n g, but your ggplot2 plots stick out like a sore thumb with their sad shades of gray.\nYou want your data visualizations to have the same level of visual appeal as your hand-crafted slide theme, and xaringanthemer can help! I‚Äôll quickly cover some of the new features for styling ggplots here, and you can learn more in the ggplot2 Themes vignette.\n\ntheme_xaringan()\nxaringanthemer provides a ggplot2 theme that knows the styles used in your slides: theme_xaringan(). Let‚Äôs start with a basic, typical ggplot2 plot of fuel efficiency of cars using the ggplot2::mpg dataset. You only need to add + theme_xaringan() to give your plot a makeover.\n\nlibrary(ggplot2)\n\ng_base &lt;- ggplot(mpg) +\n  aes(hwy, cty) +\n  geom_point() +\n  labs(x = \"Highway MPG\", y = \"City MPG\", title = \"Fuel Efficiency\")\n\n# Basic plot with default theme\ng_base\n\n\n\n\n\n# Fancy slide-matching themed plot\ng_base + theme_xaringan()\n\n\n\n\n\nBasic ggplot2 plot\n\n\n\n\n\n\n\nA theme_xaringan() ggplot\n\n\n\ntheme_xaringan() matches the colors used in your slides to the plot and axis titles (slide heading color) and axis tick labels and default text geometries (slide text color). It also uses the showtext by Yixuan Qiu to match the fonts used in your slides ‚Äî this feature works particularly well when you use fonts from Google Fonts. theme_xaringan() also sets the default color, fill and text family aesthetics of many ggplot2 geoms, changing, for example, the color of points to match the primary slide color.\nOur theme_xaringan() themed plot would fit right in on just about any slide in the slide deck we made with style_duo_accent() above, except for our inverse-styled slides‚Ä¶\n\n\ntheme_xaringan_inverse()\nIn xaringan, inverse slides provide a nice way to visually break up your presentation. You can create them using the inverse class:\n---\nclass: inverse\n\n&lt;!-- slide content --&gt;\nxaringanthemer also provide a ggplot2 theme for these slides as well: theme_xaringan_inverse().\n\n# theme_xaringan() on the left,\ng_base + theme_xaringan()\n\n\n# theme_xaringan_inverse() on the right\ng_base + theme_xaringan_inverse()\n\n\n\n\n\ntheme_xaringan()\n\n\n\n\n\n\n\ntheme_xaringan_inverse()\n\n\n\n\n\nMatching color and fill scales\nTo give your plots a little more visual appeal, xaringanthemer includes custom color and fill scales based on the primary slide color. This feature uses colorspace::sequential_hcl() from the colorspace package.\nThe scale functions all follow the naming pattern scale_xaringan_&lt;aes&gt;_&lt;data_type&gt;(), where &lt;aes&gt; is replaced with either color or fill and &lt;data_type&gt; is one of discrete or continuous. For colors scales matching the inverse slide style, set inverse = TRUE. Occasionally, you may want to use a different primary color to generate the color or fill scale using the color argument.\n\nggplot(diamonds, aes(x = cut)) +\n  geom_bar(aes(fill = ..count..), show.legend = FALSE) +\n  labs(x = NULL, y = \"Count\", title = \"Diamond Cut Quality\") +\n  theme_xaringan() +\n  scale_xaringan_fill_continuous()\n\n\n\n\n\nggplot(diamonds, aes(x = cut)) +\n  geom_bar(aes(fill = ..count..), show.legend = FALSE) +\n  labs(x = NULL, y = \"Count\", title = \"Diamond Cut Quality\") +\n  theme_xaringan_inverse() +\n  scale_xaringan_fill_continuous(color = \"#F2B155\")\n\n\n\n\n\nscale_xaringan_fill_continuous()\n\n\n\n\n\n\n\nCustom color with scale_xaringan_fill_continuous()\n\n\n\n\n\nThree ways to use theme_xaringan()\nIn what is likely the most common scenario, theme_xaringan() learns the slide styles when you use any of the style functions in your slides‚Äô source code.\nAlternatively, you may want to create your CSS files in another process or to use a xaringanthemer CSS file that you share between presentations. In these cases, theme_xaringan() will find the CSS file if it‚Äôs in the same folder or a subdirectory of the folder containing your slides source .Rmd. If you have multiple CSS files, or your CSS file is stored elsewhere, you can use the css_file argument to tell theme_xaringan() which file to use. This also means that you can easily match the plots in other R Markdown reports or webpages with theme_xaringan() to the styles used in your presentations by point css_file to the styles used in your slides.\nFinally, you can create themes without calling a style function or a CSS file using the theme_xaringan_base() function. This theme function can be used for complete ggplot2 themes, including Google Fonts. (Note that the text_font and title_font arguments can take a google_font() in all theme_xaringan_ functions.)\n\nggplot(diamonds, aes(x = cut)) +\n  geom_bar() +\n  labs(x = NULL, y = NULL, title = \"Diamond Cut Quality\") +\n  ylim(0, 25000) +\n  theme_xaringan_base(\n    title_font = google_font(\"Merriweather\", 800),\n    title_font_size = 20,\n    text_font = google_font(\"PT Sans\"),\n    text_font_size = 16,\n    background_color = \"#FFFFFF\",\n    text_color = \"#444444\",\n    accent_color = \"#002B36\",\n  ) +\n  theme(plot.title = element_text(face = \"bold\"))\n\n\n\n\nA plot with theme_xaringan_base() styled to match this blog\n\n\n\n\n\n\nLearning more about ggplot2 themes\nTo learn more about the ggplot2 themes, you can reference the ggplot2 themes vignette online or with vignettes(\"ggplot2-themes\").\n\n\n\nOther new things\nThere are a few other new features that are worth a quick mention.\n\nHeader background\nIf you like the metropolis theme in xaringan ‚Äî ported from the classic beamer theme by Patrick Schratz who has a demo slide deck on his site ‚Äî then you might like the header background feature that brings the title bar background to any xaringan presentation.\n\n\n\nSlides with class: header_background\n\n\nThe background is applied to the first level-1 heading on the slide ‚Äî either &lt;h1&gt;Title&lt;/h1&gt; or # Title. There are two modes to the header background: auto and manual.\nManual mode is the default, meaning that for any xaringanthemer slides you can enable the header background using the header_background slide class:\n---\nclass: header_background\n\n# Title with a background\n\n&lt;!-- slide content --&gt;\nAuto mode is invoked by setting header_background_auto = TRUE in the style functions which makes the first level-1 heading of all normal slides into title background. In auto mode, you can disable the header background manually by using class: normal. The header background isn‚Äôt applied to title or inverse slides, slides where the text is aligned middle or bottom, or slides with the normal class.\n\n\nNew default fonts\n\n\n\n\nWhile the default xaringan fonts are eye-catching and interesting when you first see them, I personally think that they don‚Äôt work well in low-visibility settings, like presentations made in person. xaringanthemer therefore uses a different set of default fonts: Cabin for headings and Noto Sans for body text.\n\n\nA Cabin in the Clearing\n\n\nPack my box with five dozen liquor jugs. Amazingly few discotheques provide jukeboxes.\n\n\nThese fonts are easier to read on screens and at a distance during presentations, and they support a wide variety of languages and weights. Another reason for the change is that the xaringan (remarkjs) default body font, Droid Serif, is no longer officially included in Google Fonts."
  },
  {
    "objectID": "blog/xaringanthemer-v0-3-0/index.html#thanks",
    "href": "blog/xaringanthemer-v0-3-0/index.html#thanks",
    "title": "Announcing xaringanthemer v0.3.0!",
    "section": "Thanks",
    "text": "Thanks\nThanks to everyone who sumbitted pull requests, issues, or comments: @Btibert3, @Northbreeze, @pat-s, @PMassicotte, @techisdead, and @TrashBirdEcology\nThanks to Aubrey Aden-Buie for help designing the xaringanthemer hex logo!\n\n\n\nBasic ggplot2 plot\nA theme_xaringan() ggplot\ntheme_xaringan()\ntheme_xaringan_inverse()\nscale_xaringan_fill_continuous()\nCustom color with scale_xaringan_fill_continuous()\nA plot with theme_xaringan_base() styled to match this blog\nSlides with class: header_background"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "\n      Garrick\n      Aden-Buie\n    ",
    "section": "",
    "text": "I‚Äôm a Software Engineer for\n      Shiny at\n      Posit (formerly RStudio). I build tools\n      that help everyone do data science in R\n      with R Markdown and\n      Shiny.\n    \n    About Me ‚Üí\n  \n\n  \n    \n      Go to Home"
  },
  {
    "objectID": "index.html#latest-posts",
    "href": "index.html#latest-posts",
    "title": "\n      Garrick\n      Aden-Buie\n    ",
    "section": "Latest Posts",
    "text": "Latest Posts\n\n\n\n\n\n\n\n\n\n\nAdd last rendered or modified time to Quarto\n\n\nIntroducing now, a Quarto extension that adds the time right now, anywhere in your document.\n\n\n\nMar 29, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAutomated Image Overflow Detection for xaringan or remark Slides\n\n\nUsing chromote and a little JavaScript to detect image overflow issues in {xaringan} or remark slides.\n\n\n\nJul 23, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRead and Visualize your Twitter Archive\n\n\nUsing R to read and visualize my Twitter archive data. Featuring {ggiraph}, {ggplot2}, {jsonlite}, {dplyr} and more‚Ä¶\n\n\n\nDec 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncountdown v0.4.0 ‚Äì Now on CRAN!\n\n\ncountdown v0.4.0 is now available on CRAN with a ton of new features!\n\n\n\nAug 15, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProcess Profile Pictures with magick\n\n\nProcess a directory full of profile pictures, resizing and cropping the images to be centered around faces.\n\n\n\nJul 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxaringanExtra v0.6.0 ‚Äî Now on CRAN!\n\n\nxaringanExtra v0.6.0 is now available on CRAN! Plus some new features.\n\n\n\nJun 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSaving Daylight Time?\n\n\nHow much daylight do cities across the world get throughout the year? Does Daylight Saving Time really save any daylight? A visualization to explore these questions.\n\n\n\nMar 12, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWordle Guess Helper\n\n\nPicking words to guess in Wordle. It‚Äôs only fun if you can solve it with R.\n\n\n\nFeb 21, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nbranchMover: A Shiny app for moving the default branch of your GitHub repos\n\n\nIntroducing branchMover, a Shiny app slash RStudio addin for coordinated default branch changes across your GitHub repositories.\n\n\n\nNov 2, 2021\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-projects",
    "href": "index.html#latest-projects",
    "title": "\n      Garrick\n      Aden-Buie\n    ",
    "section": "Latest Projects",
    "text": "Latest Projects\n\n\n\n\n\n\n\n\n\n\n{epoxy}\n\n\nExtra-strength glue for scripts, reports, and apps\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüßº cleanrmd\n\n\nClean Class-Less R Markdown HTML Documents\n\n\n\nJun 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüîÆ rsthemes\n\n\nFull RStudio IDE and Syntax Themes\n\n\n\nOct 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüç∞ shrtcts\n\n\nMake anything an RStudio shortcut!\n\n\n\nSep 13, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüé° xaringanExtra\n\n\nA playground of enhancements and extensions for xaringan slides.\n\n\n\nJul 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÑπÔ∏è metathis\n\n\nand social media cards for R-made web things\n\n\n\nSep 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚è≤Ô∏è countdown\n\n\nA countdown timer for R Markdown slides and HTML docs\n\n\n\nMay 7, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nü§π tidyexplain\n\n\nAnimations of tidyverse verbs using R, the tidyverse, and gganimate.\n\n\n\nAug 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüé® xaringanthemer\n\n\nGive your xaringan slides some style without (much) CSS\n\n\n\nMay 12, 2018\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html#latest-talks",
    "href": "index.html#latest-talks",
    "title": "\n      Garrick\n      Aden-Buie\n    ",
    "section": "Latest Talks",
    "text": "Latest Talks\n\n\n\n\n\n\n\n\n\n\n{epoxy}\n\n\nSuper glue for data-driven reports and Shiny apps.\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSeamless data-driven reporting with {epoxy}\n\n\n{epoxy} is a new R package that allows report authors to seamlessly blend prose and data in markdown, HTML, and LaTeX reports.\n\n\n\nJun 8, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProfessional, Polished, Presentable\n\n\nA useR!2021 tutorial about making great slides with xaringan.\n\n\n\nJul 7, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSliding in Style\n\n\nMake stylish slides with {xaringanthemer} and a little bit of CSS.\n\n\n\nApr 1, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaking Extra Great Slides\n\n\nA brief introduction to the {xaringan} package and how you can make your slides look great with {xaringanthemer} and stand out with {xaringanExtra}.\n\n\n\nMar 10, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nR Markdown: An Incomplete History\n\n\nAn incomplete history of the literate programming origins of R Markdown. Plus some cool things I‚Äôm tinkering with: {epoxy} and {shinyComponents}.\n\n\n\nFeb 11, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nxaringan Playground\n\n\nMaking slides with xaringan is a great way to learn more about CSS and web development.\n\n\n\nJan 21, 2021\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBuild Your Own Universe\n\n\nScale high-quality research data provisioning with R packages package.\n\n\n\nAug 28, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nYour Slides are So Extra!\n\n\nA presentation writing and benefiting from programming with functions.\n\n\n\nJul 8, 2020\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/countdown/index.html",
    "href": "project/countdown/index.html",
    "title": "‚è≤Ô∏è countdown",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/countdown‚Ä¶"
  },
  {
    "objectID": "project/ermoji/index.html",
    "href": "project/ermoji/index.html",
    "title": "üòÇ ermoji",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork\nSearch, find and copy emojis inside RStudio. Basically a DT + clipr + miniUI wrapper around hadley/emo.\nWhy? Because r \"\\U1F913\". But also because I wanted an easy way to find the Unicode strings for emoji."
  },
  {
    "objectID": "project/ermoji/index.html#installation",
    "href": "project/ermoji/index.html#installation",
    "title": "üòÇ ermoji",
    "section": "Installation",
    "text": "Installation\nInstall ermoji with devtools\ndevtools::install_github(\"gadenbuie/ermoji\")\nOr install using Dean Attali‚Äôs addinlist."
  },
  {
    "objectID": "project/ermoji/index.html#usage",
    "href": "project/ermoji/index.html#usage",
    "title": "üòÇ ermoji",
    "section": "Usage",
    "text": "Usage\nOpen Search and Copy Emoji from the RStudio Addins dropdown.\n\nPick your emoji and use the ‚ÄúCopy‚Äù buttons to copy the emoji to your clipboard.\n\nBrowse the Emoji List\n\n\n\nSearch for Emoji\nYou can use regular expressions to search for any text in the table of emoji.\n\n\n\nSearch by Emoji\nYou can even search by emoji by pasting your emoji into the search field.\n\n\n\nSearch in Specific Columns\nSearch inside individual columns for more specific emoji finding.\n\n\nermoji was built by Garrick Aden-Buie (@grrrck).\nBuilt on the shoulders of giants. Thanks to Hadley Wickham for emo, Yihui Xie and RStudio for DT, Matthew Lincoln for clipr. Thanks to r-lib for devtools and usethis ‚Äî from idea to package in 60 minutes.\nFind more great RStudio addins on the addinlist, like my other addin regexplain.\nFeel free to file an issue if you find a bug or have a theme suggestion ‚Äì or better yet, submit a pull request!"
  },
  {
    "objectID": "project/index.html",
    "href": "project/index.html",
    "title": "Projects",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n{epoxy}\n\n\nExtra-strength glue for scripts, reports, and apps\n\n\n\nSep 20, 2023\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüßº cleanrmd\n\n\nClean Class-Less R Markdown HTML Documents\n\n\n\nJun 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüîÆ rsthemes\n\n\nFull RStudio IDE and Syntax Themes\n\n\n\nOct 1, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüç∞ shrtcts\n\n\nMake anything an RStudio shortcut!\n\n\n\nSep 13, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüé° xaringanExtra\n\n\nA playground of enhancements and extensions for xaringan slides.\n\n\n\nJul 6, 2020\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚ÑπÔ∏è metathis\n\n\nand social media cards for R-made web things\n\n\n\nSep 11, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n‚è≤Ô∏è countdown\n\n\nA countdown timer for R Markdown slides and HTML docs\n\n\n\nMay 7, 2019\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nü§π tidyexplain\n\n\nAnimations of tidyverse verbs using R, the tidyverse, and gganimate.\n\n\n\nAug 27, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüé® xaringanthemer\n\n\nGive your xaringan slides some style without (much) CSS\n\n\n\nMay 12, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüòÇ ermoji\n\n\nRStudio Addin to Search and Copy Emoji\n\n\n\nApr 24, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüïµÔ∏è‚Äç‚ôÇÔ∏è RegExplain\n\n\nAn RStudio addin slash utility belt for regular expressions\n\n\n\nApr 3, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüçë ggpomological: A Pomological ggplot2 Theme\n\n\nA ggplot2 theme based on the USDA Pomological Watercolor Collection\n\n\n\nFeb 16, 2018\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüìö MC Test Analysis\n\n\nApps and reports for multiple-choice test analysis in R with Shiny\n\n\n\nJul 6, 2017\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüêøÔ∏è Sqrrl\n\n\nEasily build bespoke SQL queries programmatically in R\n\n\n\nJun 30, 2017\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "project/metathis/index.html",
    "href": "project/metathis/index.html",
    "title": "‚ÑπÔ∏è metathis",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/metathis‚Ä¶"
  },
  {
    "objectID": "project/rsthemes/index.html",
    "href": "project/rsthemes/index.html",
    "title": "üîÆ rsthemes",
    "section": "",
    "text": "Follow @gadenbuie¬† Star¬† Fork"
  },
  {
    "objectID": "project/rsthemes/index.html#installation",
    "href": "project/rsthemes/index.html#installation",
    "title": "üîÆ rsthemes",
    "section": "Installation",
    "text": "Installation\nYou can install rsthemes from my r-universe with:\ninstall.packages(\n  \"rsthemes\",\n  repos = c(gadenbuie = 'https://gadenbuie.r-universe.dev', getOption(\"repos\"))\n)\nOr you can install rsthemes from GitHub with:\n# install.packages(\"devtools\")\ndevtools::install_github(\"gadenbuie/rsthemes\")\nThen, install the included, hand-crafted themes with:\nrsthemes::install_rsthemes()\nor you can install the themes plus an additional set of base16-based themes with\nrsthemes::install_rsthemes(include_base16 = TRUE)"
  },
  {
    "objectID": "project/rsthemes/index.html#usage",
    "href": "project/rsthemes/index.html#usage",
    "title": "üîÆ rsthemes",
    "section": "Usage",
    "text": "Usage\nThe rsthemes package includes a couple helper functions for exploring the themes.\n# list installed themes\nrsthemes::list_rsthemes()\n\n# Try all themes\nrsthemes::try_rsthemes()\n\n# Try just the light, dark, or base16 themes, e.g.\nrsthemes::try_rsthemes(\"light\")\nUse rstudioapi::applyTheme() to activate a theme from the R console, or use Tools &gt; Global Options &gt; Appearance to interactively select a theme.\n# Use a theme\nrstudioapi::applyTheme(\"One Dark {rsthemes}\")"
  },
  {
    "objectID": "project/rsthemes/index.html#easy-theme-switching",
    "href": "project/rsthemes/index.html#easy-theme-switching",
    "title": "üîÆ rsthemes",
    "section": "Easy Theme Switching",
    "text": "Easy Theme Switching\nrsthemes includes RStudio addins and functions to‚Ä¶ \n\nüåÖ Toggle Dark ModeSwitch between two preferred dark and light themes\nüåÉ Auto Dark ModeAutomatically choose a dark or light theme by time of day\n‚ù§Ô∏è Favorite ThemesSwitch between a few of your favorite themes\nü•± Use Default RStudio ThemeSwitch back to RStudio‚Äôs default theme\n\n\nChoose Your Preferred Themes\nFirst, set a default light and dark theme. For your current R sessions, you can use the Set Default Light Theme to Current addin (or the corresponding dark theme addin), or you can call the set_theme_light() or set_theme_dark() functions:\n# Set current theme to default light or dark theme\nrsthemes::set_theme_light()\nrsthemes::set_theme_dark()\n\n# Set a specific theme to default light or dark theme\nrsthemes::set_theme_light(\"One Light {rsthemes}\")\nrsthemes::set_theme_dark(\"One Dark {rsthemes}\")\nTo create a list of your favorite themes, you can use set_theme_favorite().\n# Add current theme to your list of favorites\nrsthemes::set_theme_favorite()\n\n# Add a list of themes to your favorites\nrsthemes::set_theme_favorite(\n  c(\"GitHub {rsthemes}\", \"One Light {rsthemes}\", \"One Dark {rsthemes}\")\n)\nThese functions only save your preferences for the current R session. To set these defaults for all R sessions, add your preferences to your ~/.Rprofile. (You can use usethis::edit_r_profile() to quickly open your ~/.Rprofile for editing.)\n# ~/.Rprofile\nif (interactive()) {\n  rsthemes::set_theme_light(\"GitHub {rsthemes}\")\n  rsthemes::set_theme_dark(\"Fairyfloss {rsthemes}\")\n  rsthemes::set_theme_favorite(\n    c(\"GitHub {rsthemes}\", \n      \"One Light {rsthemes}\", \n      \"One Dark {rsthemes}\")\n  )\n}\nYou can also set the following global options directly.\n# ~/.Rprofile\noptions(\n  rsthemes.theme_light = \"Nord Snow Storm {rsthemes}\",\n  rsthemes.theme_dark = \"Nord Polar Night Aurora {rsthemes}\",\n  rsthemes.theme_favorite = paste(\"One\", c(\"Light\", \"Dark\"), \"{rsthemes}\")\n)\n\n\nToggle Your Favorite Themes\nUse the Next Favorite Theme addin to walk through your list of favorite themes. Use the Modify Keyboard Shortcuts‚Ä¶ dialog in the Tools menu of RStudio to create a keyboard shortcut to make it easy to quickly switch themes ‚Äî I use Ctrl+ Alt + N. You can also manually call use_theme_favorite() to use the next theme in the your favorites list.\nEach time you run the addin, RStudio switches to the next theme in your favorites list. This is great if you have a few themes that you use in various contexts. For example, I have my personal favorite themes plus a few themes that work well during class or presentation sessions.\n\n\nAutomatic or Manual Light/Dark Mode\nUse the Toggle Dark Mode addin to switch between your default light and dark themes. You can even set a keyboard shortcut in RStudio ‚Äî I used Ctrl + Alt + D ‚Äî to toggle dark mode.\nYou can also automatically choose the dark or light theme by time of day, using the included Auto Choose Dark or Light Theme addin, which requires that you‚Äôve set your preferred light/dark themes (see above).\nIf you would like to automatically choose the dark or light theme by time of day during each new session, you can call rsthemes::use_theme_auto() in your ~/.Rprofile. For best results, use the following template in your ~/.Rprofile to declare your preferred dark and light themes and to choose the correct style when your R session reloads.\nif (interactive() && requireNamespace(\"rsthemes\", quietly = TRUE)) {\n  # Set preferred themes if not handled elsewhere..\n  rsthemes::set_theme_light(\"One Light {rsthemes}\")  # light theme\n  rsthemes::set_theme_dark(\"One Dark {rsthemes}\") # dark theme\n\n  # Whenever the R session restarts inside RStudio...\n  setHook(\"rstudio.sessionInit\", function(isNewSession) {\n    # Automatically choose the correct theme based on time of day\n    rsthemes::use_theme_auto(dark_start = \"18:00\", dark_end = \"6:00\")\n  }, action = \"append\")\n}\n\n\nGo Back to the Default\nSometimes when you‚Äôre teaching or demonstrating RStudio features, you‚Äôd like to have your IDE match the appearance of your learners, or at least the basic theme that everyone starts out with when they install RStudio for the first time.\nUse the Use Default RStudio Theme to quickly switch back to RStudio‚Äôs default theme, Textmate. Or, you can use rsthemes::use_default_rstudio_theme() to initiate the switch, perhaps from within the .Rprofile file of your teaching project."
  },
  {
    "objectID": "project/rsthemes/index.html#uninstall",
    "href": "project/rsthemes/index.html#uninstall",
    "title": "üîÆ rsthemes",
    "section": "Uninstall",
    "text": "Uninstall\nIf you want to uninstall all or some of the themes, you can use\nrsthemes::remove_rsthemes()\n\n# or just the base16 themes, e.g.\nrsthemes::remove_rsthemes(\"base16\")"
  },
  {
    "objectID": "project/rsthemes/index.html#thanks-and-theme-credits",
    "href": "project/rsthemes/index.html#thanks-and-theme-credits",
    "title": "üîÆ rsthemes",
    "section": "Thanks and Theme Credits",
    "text": "Thanks and Theme Credits\n\nPalettes\n\nbase16 (Various Authors)\nFairyfloss (Amy Wibowo (sailorhg))\nFlat White (Dmitry Biletskyy)\nNord (Sven Greb)\nOceanic Plus (Marco Scannadinari)\nAtom One Dark\nAtom One Light\nSolarized (Ethan Schoonover)\nHorizon Dark (Jonathan Olaleye)\na11y-syntax-highlighting (Eric Bailey)\nNight Owl (Sarah Drasner)\n\nwith huge thanks to original Night Owlish implementation in RStudio by Mara Averick\n\nYule RStudio\n\nBased on the Yule tmTheme\nPorted from gadenbuie/yule-rstudio\nFeaturing a background image by Joanna Kosinska\n\nMaterial Theme\n\nContributed to rsthemes by Zac de Lusignan\n\nSerendipity (wickedtemplates)"
  },
  {
    "objectID": "project/sqrrl/index.html",
    "href": "project/sqrrl/index.html",
    "title": "üêøÔ∏è Sqrrl",
    "section": "",
    "text": "UPDATE 10/17/2017: Don‚Äôt use this! I made it for myself so it works for what I needed it for. But you probably shouldn‚Äôt use this package. There are better ways of building SQL queries that are safer and better (and probably even easier). For now, let me just point you in the direction of db.rstudio.com, dplyr/dbplyr, and the recently added glue_sql() function in the glue package.\nProject Links: source, documentation\nsqrrl is a small collection of utility functions that help build text-based SQL queries in an R-style native-feeling and functional manner.\nUnlike other packages that build SQL queries using an object-oriented style, sqrrl provides small functions that produce SQL snippets and can be linked together to compose SQL queries. The result is that the code to produce the SQL statement reads much like the SQL statement iteself. On the other hand, sqrrl doesn‚Äôt know anything about your database and can‚Äôt help you out with completions, etc.\nWhere this package is most useful is with Shiny web apps that interact with a MySQL backend. The utilities are all built so that queries can be built using column names and values stored inside ordinary R data structures.\nThe following is a quick demonstration of how the package works using the nyclights13 dataset. For more information on sqrrl, check out the package documentation."
  },
  {
    "objectID": "project/sqrrl/index.html#setup-flights-database",
    "href": "project/sqrrl/index.html#setup-flights-database",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Setup flights database",
    "text": "Setup flights database\nTo demonstrate the features in sqrrl, let‚Äôs set up an in-memory SQLite database using the nycflights13 dataset featured in dplyr and dbplyr.\nFirst, load (or install) the pacakges and functions that we need.\n\n# ---- Workspace Setup ----\nlibrary('nycflights13') # install.packages('nycflights13')\nlibrary('DBI')          # install.packages('DBI')\nlibrary('dplyr')        # install.packages('dplyr')\nlibrary('dbplyr')       # install.packages('dbplyr')\n\n# Load the sqrrl package\n# devtools::isntall_github('gadenbuie/sqrrl')\nlibrary('sqrrl')\n\n# Alias to create nice tables\nas_table &lt;- function(...) knitr::kable(..., format = 'html')\n\nThen load the flights data frame from nycflights13 into the in-memory SQLite database (this code comes direclty from the dbplyr documentation).\n\n# ---- Example Setup ----\n# Create an in-memory SQLite database\ncon &lt;- dbConnect(RSQLite::SQLite(), path = \":memory:\")\n\n# Use dplyr/dbplyr to copy flights table to the temp db\ncopy_to(con, nycflights13::flights, \"flights\",\n  temporary = FALSE,\n  indexes = list(\n    c(\"year\", \"month\", \"day\"),\n    \"carrier\",\n    \"tailnum\",\n    \"dest\"\n  )\n)\n\n# Show first 5 rows\ndbGetQuery(con, 'SELECT * FROM flights LIMIT 5') %&gt;%\n  as_table\n\n\n\n\n\nyear\nmonth\nday\ndep_time\nsched_dep_time\ndep_delay\narr_time\nsched_arr_time\narr_delay\ncarrier\nflight\ntailnum\norigin\ndest\nair_time\ndistance\nhour\nminute\ntime_hour\n\n\n\n\n2013\n1\n1\n517\n515\n2\n830\n819\n11\nUA\n1545\nN14228\nEWR\nIAH\n227\n1400\n5\n15\n1357034400\n\n\n2013\n1\n1\n533\n529\n4\n850\n830\n20\nUA\n1714\nN24211\nLGA\nIAH\n227\n1416\n5\n29\n1357034400\n\n\n2013\n1\n1\n542\n540\n2\n923\n850\n33\nAA\n1141\nN619AA\nJFK\nMIA\n160\n1089\n5\n40\n1357034400\n\n\n2013\n1\n1\n544\n545\n-1\n1004\n1022\n-18\nB6\n725\nN804JB\nJFK\nBQN\n183\n1576\n5\n45\n1357034400\n\n\n2013\n1\n1\n554\n600\n-6\n812\n837\n-25\nDL\n461\nN668DN\nLGA\nATL\n116\n762\n6\n0\n1357038000"
  },
  {
    "objectID": "project/sqrrl/index.html#querying-flights",
    "href": "project/sqrrl/index.html#querying-flights",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Querying flights",
    "text": "Querying flights\nOften, when I‚Äôm working with a database, I‚Äôll create an alias for dbGetQuery with the database or table name. Inside the alias function I usually add any data type modifications that might need to be applied, and I suppress the warning messages that DBI outputs about data type conversions.\n\nflights &lt;- function(query, ...) {\n  suppressWarnings(dbGetQuery(con, query, ...))\n}\n\nNow we can repeat the above SELECT statement using sqrrl, this time limiting the columns selected.\n\nflight_cols &lt;- c('year', 'month', 'day',\n                 'carrier', 'flight', 'tailnum')\nSELECT(flight_cols) %+%\n  FROM('flights') %+%\n  LIMIT(5) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\n\nyear\nmonth\nday\ncarrier\nflight\ntailnum\n\n\n\n\n2013\n1\n1\nUA\n1545\nN14228\n\n\n2013\n1\n1\nUA\n1714\nN24211\n\n\n2013\n1\n1\nAA\n1141\nN619AA\n\n\n2013\n1\n1\nB6\n725\nN804JB\n\n\n2013\n1\n1\nDL\n461\nN668DN\n\n\n\n\n\n\n\n\nNote that sqrrl provides the %+% infix operator, which is essentially just an alias for paste(x, y).\n\n'a' %+% 'b'\n\n[1] \"a b\"\n\n# or PHP style without a padded space: paste0\n'a' %.% 'b'\n\n[1] \"ab\"\n\n\nWe can also do more complicated queries, like finding the average arrival delay, grouped by tail number:\n\nSELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay')) %+%\n  LIMIT(10) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\n\ntailnum\ndelay\nn\n\n\n\n\nN844MH\n320.0000\n1\n\n\nN911DA\n294.0000\n1\n\n\nN922EV\n276.0000\n1\n\n\nN587NW\n264.0000\n1\n\n\nN851NW\n219.0000\n1\n\n\nN928DN\n201.0000\n1\n\n\nN7715E\n188.0000\n1\n\n\nN654UA\n185.0000\n1\n\n\nN665MQ\n174.6667\n6\n\n\nN427SW\n157.0000\n1\n\n\n\n\n\n\n\n\nsqrrl also provides a wrapper around the python utility sqlformat that can be used to pretty-print SQL formats.\n\nSELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay')) %+%\n  LIMIT(10) %&gt;%\n  sqlformat %&gt;% cat\nSELECT tailnum,\n       avg(arr_delay) AS delay,\n       count(*) AS n\n  FROM flights\n GROUP BY tailnum\n ORDER BY delay DESC\n LIMIT 10\n\nLet‚Äôs use the above as an inner query and filter on n &gt; 100:\n\nquery_all_arr_delay &lt;- SELECT(\n  'tailnum', delay = 'avg(arr_delay)', n = 'count(*)'\n) %+%\n  FROM('flights') %+%\n  GROUP_BY('tailnum') %+%\n  ORDER_BY(DESC('delay'))\n\nSELECT() %+%\n  FROM(delay = parens(query_all_arr_delay)) %+%\n  WHERE(gt(n = 100)) %+%\n  LIMIT(10) %&gt;%\n  flights %&gt;%\n  as_table\n\n\n\n\n\ntailnum\ndelay\nn\n\n\n\n\nN11119\n30.30657\n148\n\n\nN16919\n29.88745\n251\n\n\nN14998\n27.92202\n230\n\n\nN15910\n27.61132\n280\n\n\nN13123\n25.97345\n121\n\n\nN11192\n25.85235\n154\n\n\nN14950\n25.28780\n219\n\n\nN21130\n24.96610\n126\n\n\nN24128\n24.91803\n129\n\n\nN22971\n24.74766\n230"
  },
  {
    "objectID": "project/sqrrl/index.html#queries-are-just-strings",
    "href": "project/sqrrl/index.html#queries-are-just-strings",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Queries are just strings",
    "text": "Queries are just strings\nNotice that unlike other packages, sqrrl can‚Äôt build the nested queries for you. You still need to understand the structure of the database and the structure of the query.\nBut when compared with the final output of the query, the sqrrl version looks a lot like SQL transliterated into R functions.\n\nSELECT() %+%\n  FROM(delay = parens(\n    SELECT('tailnum', delay = 'avg(arr_delay)', n = 'count(*)') %+%\n      FROM('flights') %+%\n      GROUP_BY('tailnum') %+%\n      ORDER_BY(DESC('delay'))\n  )) %+%\n  WHERE(gt(n = 100)) %+%\n  LIMIT(10) %&gt;%\n  sqlformat() %&gt;%\n  cat()\nSELECT *\n  FROM (\n        SELECT tailnum,\n               avg(arr_delay) AS delay,\n               count(*) AS n\n          FROM flights\n         GROUP BY tailnum\n         ORDER BY delay DESC\n       ) delay\n WHERE n&gt;100\n LIMIT 10\n\nFor me, at least, where the goal is to write SQL queries as bare strings, sqrrl lets me write in R and think in SQL without having to add a huge number of paste and paste0 functions.\nEverything in sqrrl takes input data from regular R data types and outputs an SQL snippet.\nFor an example of nearly everything each of the functions can do, see the Getting Started section in the documentation."
  },
  {
    "objectID": "project/sqrrl/index.html#a-more-complicated-select-query",
    "href": "project/sqrrl/index.html#a-more-complicated-select-query",
    "title": "üêøÔ∏è Sqrrl",
    "section": "A more complicated SELECT query",
    "text": "A more complicated SELECT query\nAs a final example, here is a fully-loaded select query.\n\nSELECT('`year`', 'carrier', 'flight', 'dest',\n       n = 'count(*)',\n       avg_dist = 'avg(distance)',\n       avg_air_time = 'avg(air_time)') %+%\n  FROM(f = 'flights') %+%\n  WHERE(\n    BETWEEN('month', 6, 12),\n    'carrier' %IN% c(\"UA\", \"AA\", \"US\", \"WN\"),\n    geq('dep_time' = 800),\n    leq('air_time' = 120),\n    'origin' %LIKE% 'JFK'\n  ) %+%\n  GROUP_BY('`year`', 'carrier', 'flight', 'dest') %+%\n  ORDER_BY(DESC('n')) %+%\n  LIMIT(10) %&gt;%\n  { sqlformat(.) %&gt;% cat; . } %&gt;%\n  flights %&gt;%\n  as_table\nSELECT `year`,\n       carrier,\n       flight,\n       dest,\n       count(*) AS n,\n       avg(distance) AS avg_dist,\n       avg(air_time) AS avg_air_time\n  FROM flights f\n WHERE `month` BETWEEN 6 AND 12\n   AND carrier IN (\"UA\", \"AA\", \"US\", \"WN\")\n   AND dep_time&gt;=800\n   AND air_time&lt;=120\n   AND origin LIKE(\"JFK\")\n GROUP BY `year`,\n          carrier,\n          flight,\n          dest\n ORDER BY n DESC\n LIMIT 10\n\n\n\n\n\nyear\ncarrier\nflight\ndest\nn\navg_dist\navg_air_time\n\n\n\n\n2013\nUS\n1831\nCLT\n178\n541\n86.95506\n\n\n2013\nUS\n425\nCLT\n126\n541\n84.92857\n\n\n2013\nAA\n178\nBOS\n119\n187\n37.94118\n\n\n2013\nAA\n256\nBOS\n117\n187\n39.13675\n\n\n2013\nAA\n2314\nBOS\n115\n187\n37.85217\n\n\n2013\nUS\n1802\nCLT\n112\n541\n87.23214\n\n\n2013\nAA\n84\nBOS\n101\n187\n37.95049\n\n\n2013\nAA\n1850\nBOS\n94\n187\n38.46809\n\n\n2013\nAA\n1838\nBOS\n93\n187\n37.83871\n\n\n2013\nAA\n1762\nBOS\n86\n187\n38.47674\n\n\n\n\n\n\n\n\nThis query and table select the most popular flights from JFK between June and December of 2013 from the carriers UA, AA, US, and WN that depart JFK after 8:00 AM and have an air time of less than 2 hours."
  },
  {
    "objectID": "project/sqrrl/index.html#learn-more",
    "href": "project/sqrrl/index.html#learn-more",
    "title": "üêøÔ∏è Sqrrl",
    "section": "Learn more",
    "text": "Learn more\nThere‚Äôs more that the package can do, like JOINs, INSERTs, and UPDATEs that I haven‚Äôt gone into here.\nThere are also a number of wrappers, comparison operators and concatenators that can be used for wrapping strings in quotes ‚Äî e.g.¬†quotes() ‚Äî comparing columns to values ‚Äî e.g.¬†geq(), eq(), lt(), neq() ‚Äî and stringing together statements ‚Äî e.g.¬†AND(), OR(), %LIKE%, %IN%, BETWEEN().\nThere‚Äôs an example of nearly every single function and each of it‚Äôs possible configurations in the package documentation.\nHopefully this package is useful to someone other than myself (like you!). If you run into any problems, let me know or submit an issue on GitHub."
  },
  {
    "objectID": "project/xaringanExtra/index.html",
    "href": "project/xaringanExtra/index.html",
    "title": "üé° xaringanExtra",
    "section": "",
    "text": "Redirecting to https://pkg.garrickadenbuie.com/xaringanExtra‚Ä¶"
  },
  {
    "objectID": "style-test.html",
    "href": "style-test.html",
    "title": "Style Test",
    "section": "",
    "text": "Zephyr\n        Breezy and beautiful\n      \n      \n        \n          \n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Navbars\n        \n\n        \n          \n            \n              Navbar\n              \n                \n              \n\n              \n                \n                  \n                    Home\n                      (current)\n                    \n                  \n                  \n                    Features\n                  \n                  \n                    Pricing\n                  \n                  \n                    About\n                  \n                  \n                    Dropdown\n                    \n                      Action\n                      Another action\n                      Something else here\n                      \n                      Separated link\n                    \n                  \n                \n                \n                  \n                  Search\n                \n              \n            \n          \n        \n\n        \n          \n            \n              Navbar\n              \n                \n              \n\n              \n                \n                  \n                    Home\n                      (current)\n                    \n                  \n                  \n                    Features\n                  \n                  \n                    Pricing\n                  \n                  \n                    About\n                  \n                  \n                    Dropdown\n                    \n                      Action\n                      Another action\n                      Something else here\n                      \n                      Separated link\n                    \n                  \n                \n                \n                  \n                  Search\n                \n              \n            \n          \n        \n\n        \n          \n            \n              Navbar\n              \n                \n              \n\n              \n                \n                  \n                    Home\n                      (current)\n                    \n                  \n                  \n                    Features\n                  \n                  \n                    Pricing\n                  \n                  \n                    About\n                  \n                  \n                    Dropdown\n                    \n                      Action\n                      Another action\n                      Something else here\n                      \n                      Separated link\n                    \n                  \n                \n                \n                  \n                  Search\n                \n              \n            \n          \n        \n\n      \n    \n  \n\n  \n  \n    \n      \n        \n          Buttons\n        \n      \n    \n\n    \n      \n        \n          Primary\n          Secondary\n          Success\n          Info\n          Warning\n          Danger\n          Light\n          Dark\n          Link\n        \n\n        \n          Primary\n          Secondary\n          Success\n          Info\n          Warning\n          Danger\n          Light\n          Dark\n          Link\n        \n\n        \n          Primary\n          Secondary\n          Success\n          Info\n          Warning\n          Danger\n          Light\n          Dark\n        \n\n        \n          \n            Primary\n            \n              \n              \n                Dropdown link\n                Dropdown link\n              \n            \n          \n\n          \n            Success\n            \n              \n              \n                Dropdown link\n                Dropdown link\n              \n            \n          \n\n          \n            Info\n            \n              \n              \n                Dropdown link\n                Dropdown link\n              \n            \n          \n\n          \n            Danger\n            \n              \n              \n                Dropdown link\n                Dropdown link\n              \n            \n          \n        \n\n        \n          Large button\n          Default button\n          Small button\n        \n      \n      \n        \n          \n            Block button\n            Block button\n          \n        \n\n        \n          \n            \n            Checkbox 1\n            \n            Checkbox 2\n            \n            Checkbox 3\n          \n        \n\n        \n          \n            \n            Radio 1\n            \n            Radio 2\n            \n            Radio 3\n          \n        \n\n        \n          \n            Button\n            Button\n            Button\n            Button\n            Button\n            Button\n          \n        \n\n        \n          \n            Left\n            Middle\n            Right\n          \n        \n\n        \n          \n            \n              1\n              2\n              3\n              4\n            \n            \n              5\n              6\n              7\n            \n            \n              8\n            \n          \n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Typography\n        \n      \n    \n\n    \n\n    \n      \n        \n          Heading 1\n          Heading 2\n          Heading 3\n          Heading 4\n          Heading 5\n          Heading 6\n          \n            Heading\n            with muted text\n          \n          Vivamus sagittis lacus vel augue laoreet rutrum faucibus dolor auctor.\n        \n      \n      \n        \n          Example body text\n          Nullam quis risus eget urna mollis ornare vel eu leo. Cum sociis natoque penatibus et\n            magnis dis parturient montes, nascetur ridiculus mus. Nullam id dolor id nibh ultricies vehicula.\n          This line of text is meant to be treated as fine print.\n          The following is rendered as bold text.\n          The following is rendered as italicized text.\n          An abbreviation of the word attribute is attr.\n        \n      \n      \n        \n          Emphasis classes\n          Fusce dapibus, tellus ac cursus commodo, tortor mauris nibh.\n          Nullam id dolor id nibh ultricies vehicula ut id elit.\n          Pellentesque ornare sem lacinia quam venenatis vestibulum.\n          Etiam porta sem malesuada magna mollis euismod.\n          Donec ullamcorper nulla non metus auctor fringilla.\n          Duis mollis, est non commodo luctus, nisi erat porttitor ligula.\n          Maecenas sed diam eget risus varius blandit sit amet non magna.\n        \n      \n    \n\n    \n\n    \n      \n        Blockquotes\n      \n    \n    \n      \n        \n          \n            \n              Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.\n\n            \n            \n              Someone famous in Source Title\n            \n          \n        \n      \n      \n        \n          \n            \n              Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.\n\n            \n            \n              Someone famous in Source Title\n            \n          \n        \n      \n      \n        \n          \n            \n              Lorem ipsum dolor sit amet, consectetur adipiscing elit. Integer posuere erat a ante.\n\n            \n            \n              Someone famous in Source Title\n            \n          \n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Tables\n        \n\n        \n          \n\n\n\nType\nColumn heading\nColumn heading\nColumn heading\n\n\n\n\nActive\nColumn content\nColumn content\nColumn content\n\n\nDefault\nColumn content\nColumn content\nColumn content\n\n\nPrimary\nColumn content\nColumn content\nColumn content\n\n\nSecondary\nColumn content\nColumn content\nColumn content\n\n\nSuccess\nColumn content\nColumn content\nColumn content\n\n\nDanger\nColumn content\nColumn content\nColumn content\n\n\nWarning\nColumn content\nColumn content\nColumn content\n\n\nInfo\nColumn content\nColumn content\nColumn content\n\n\nLight\nColumn content\nColumn content\nColumn content\n\n\nDark\nColumn content\nColumn content\nColumn content\n\n\n\n\n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Forms\n        \n      \n    \n\n    \n      \n        \n          \n            \n              Legend\n              \n                Email\n                \n                  \n                \n              \n              \n                Email address\n                \n                We'll never share your email with anyone\n                  else.\n              \n              \n                Password\n                \n              \n              \n                Example select\n                \n                  1\n                  2\n                  3\n                  4\n                  5\n                \n              \n              \n                Example multiple select\n                \n                  1\n                  2\n                  3\n                  4\n                  5\n                \n              \n              \n                Example textarea\n                \n              \n              \n                Default file input example\n                \n              \n              \n                Radio buttons\n                \n                  \n                  \n                    Option one is this and that‚Äîbe sure to include why it's great\n                  \n                \n                \n                  \n                  \n                    Option two can be something else and selecting it will deselect option one\n                  \n                \n                \n                  \n                  \n                    Option three is disabled\n                  \n                \n              \n              \n                Checkboxes\n                \n                  \n                  \n                    Default checkbox\n                  \n                \n                \n                  \n                  \n                    Checked checkbox\n                  \n                \n              \n              \n                Switches\n                \n                  \n                  Default switch checkbox input\n                \n                \n                  \n                  Checked switch checkbox input\n                \n              \n              \n                Ranges\n                Example range\n                \n                Disabled range\n                \n                Example range\n                \n              \n              Submit\n            \n          \n        \n      \n      \n        \n          \n            \n              Disabled input\n              \n            \n          \n\n          \n            \n              Readonly input\n              \n            \n          \n\n          \n            Valid input\n            \n            Success! You've done it.\n          \n\n          \n            Invalid input\n            \n            Sorry, that username's taken. Try another?\n          \n\n          \n            Large input\n            \n          \n\n          \n            Default input\n            \n          \n\n          \n            Small input\n            \n          \n\n          \n            Input addons\n            \n              \n                $\n                \n                .00\n              \n              \n                \n                Button\n              \n            \n          \n\n          \n            Floating labels\n            \n              \n              Email address\n            \n            \n              \n              Password\n            \n          \n        \n\n      \n    \n  \n\n  \n  \n    \n      \n        \n          Navs\n        \n      \n    \n\n    \n      \n        Tabs\n        \n          \n            \n              Home\n            \n            \n              Profile\n            \n            \n              Disabled\n            \n            \n              Dropdown\n              \n                Action\n                Another action\n                Something else here\n                \n                Separated link\n              \n            \n          \n          \n            \n              Raw denim you probably haven't heard of them jean shorts Austin. Nesciunt tofu stumptown aliqua, retro\n                synth master cleanse. Mustache cliche tempor, williamsburg carles vegan helvetica. Reprehenderit butcher\n                retro keffiyeh dreamcatcher synth. Cosby sweater eu banh mi, qui irure terry richardson ex squid.\n                Aliquip placeat salvia cillum iphone. Seitan aliquip quis cardigan american apparel, butcher voluptate\n                nisi qui.\n            \n            \n              Food truck fixie locavore, accusamus mcsweeney's marfa nulla single-origin coffee squid. Exercitation\n                +1 labore velit, blog sartorial PBR leggings next level wes anderson artisan four loko farm-to-table\n                craft beer twee. Qui photo booth letterpress, commodo enim craft beer mlkshk aliquip jean shorts ullamco\n                ad vinyl cillum PBR. Homo nostrud organic, assumenda labore aesthetic magna delectus mollit.\n            \n            \n              Etsy mixtape wayfarers, ethical wes anderson tofu before they sold out mcsweeney's organic lomo retro\n                fanny pack lo-fi farm-to-table readymade. Messenger bag gentrify pitchfork tattooed craft beer, iphone\n                skateboard locavore carles etsy salvia banksy hoodie helvetica. DIY synth PBR banksy irony. Leggings\n                gentrify squid 8-bit cred pitchfork.\n            \n            \n              Trust fund seitan letterpress, keytar raw denim keffiyeh etsy art party before they sold out master\n                cleanse gluten-free squid scenester freegan cosby sweater. Fanny pack portland seitan DIY, art party\n                locavore wolf cliche high life echo park Austin. Cred vinyl keffiyeh DIY salvia PBR, banh mi before they\n                sold out farm-to-table VHS viral locavore cosby sweater.\n            \n          \n        \n      \n\n      \n        Pills\n        \n          \n            \n              Active\n            \n            \n              Dropdown\n              \n                Action\n                Another action\n                Something else here\n                \n                Separated link\n              \n            \n            \n              Link\n            \n            \n              Disabled\n            \n          \n        \n        \n        \n          \n            \n              Active\n            \n            \n              Dropdown\n              \n                Action\n                Another action\n                Something else here\n                \n                Separated link\n              \n            \n            \n              Link\n            \n            \n              Disabled\n            \n          \n        \n      \n    \n\n    \n      \n        Breadcrumbs\n        \n          \n            Home\n          \n          \n            Home\n            Library\n          \n          \n            Home\n            Library\n            Data\n          \n        \n      \n\n      \n        Pagination\n        \n          \n            \n              \n                ¬´\n              \n              \n                1\n              \n              \n                2\n              \n              \n                3\n              \n              \n                4\n              \n              \n                5\n              \n              \n                ¬ª\n              \n            \n          \n\n          \n            \n              \n                ¬´\n              \n              \n                1\n              \n              \n                2\n              \n              \n                3\n              \n              \n                4\n              \n              \n                5\n              \n              \n                ¬ª\n              \n            \n          \n\n          \n            \n              \n                ¬´\n              \n              \n                1\n              \n              \n                2\n              \n              \n                3\n              \n              \n                4\n              \n              \n                5\n              \n              \n                ¬ª\n              \n            \n          \n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Indicators\n        \n      \n    \n\n    \n      \n        Alerts\n        \n          \n            \n            Warning!\n            Best check yo self, you're not looking too good. Nulla vitae elit libero, a pharetra augue.\n              Praesent commodo cursus magna, vel scelerisque nisl consectetur et.\n          \n        \n      \n    \n    \n      \n        \n          \n            \n            Oh snap! Change a few things up and try submitting\n            again.\n          \n        \n      \n      \n        \n          \n            \n            Well done! You successfully read this important alert\n              message.\n          \n        \n      \n      \n        \n          \n            \n            Heads up! This alert needs your attention, but it's not\n            super important.\n          \n        \n      \n    \n    \n      \n        \n          \n            \n            Oh snap! Change a few things up and try submitting\n            again.\n          \n        \n      \n      \n        \n          \n            \n            Well done! You successfully read this important alert\n              message.\n          \n        \n      \n      \n        \n          \n            \n            Heads up! This alert needs your attention, but it's not\n            super important.\n          \n        \n      \n    \n    \n      Badges\n      \n        Primary\n        Secondary\n        Success\n        Danger\n        Warning\n        Info\n        Light\n        Dark\n      \n      \n        Primary\n        Secondary\n        Success\n        Danger\n        Warning\n        Info\n        Light\n        Dark\n      \n    \n  \n\n  \n  \n    \n      \n        \n          Progress\n        \n\n        Basic\n        \n          \n            \n          \n        \n\n        Contextual alternatives\n        \n          \n            \n          \n          \n            \n          \n          \n            \n          \n          \n            \n          \n        \n\n        Multiple bars\n        \n          \n            \n            \n            \n          \n        \n\n        Striped\n        \n          \n            \n          \n          \n            \n          \n          \n            \n          \n          \n            \n          \n          \n            \n          \n        \n\n        Animated\n        \n          \n            \n          \n        \n      \n    \n  \n\n  \n  \n    \n      \n        \n          Containers\n        \n      \n    \n\n    \n      \n        List groups\n      \n    \n\n    \n      \n        \n          \n            \n              Cras justo odio\n              14\n            \n            \n              Dapibus ac facilisis in\n              2\n            \n            \n              Morbi leo risus\n              1\n            \n          \n        \n        \n          \n            \n              Cras justo odio\n              14\n            \n            \n              Dapibus ac facilisis in\n              2\n            \n            \n              Morbi leo risus\n              1\n            \n              Cras justo odio\n              5\n            \n            \n              Dapibus ac facilisis in\n              4\n            \n            \n              Morbi leo risus\n              9\n            \n            \n              Morbi leo risus\n              8\n            \n            \n              Morbi leo risus\n              0\n            \n          \n        \n      \n      \n        \n          \n            Cras justo odio\n            Dapibus ac facilisis in\n            Morbi leo risus\n          \n        \n      \n      \n        \n          \n            \n              \n                List group item heading\n                3 days ago\n              \n              Donec id elit non mi porta gravida at eget metus. Maecenas sed diam eget risus varius\n                blandit.\n              Donec id elit non mi porta.\n            \n            \n              \n                List group item heading\n                3 days ago\n              \n              Donec id elit non mi porta gravida at eget metus. Maecenas sed diam eget risus varius\n                blandit.\n              Donec id elit non mi porta.\n            \n          \n        \n      \n    \n\n    \n      \n        Cards\n      \n    \n\n    \n      \n        \n          \n            Header\n            \n              Primary card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Secondary card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Success card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Danger card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Warning card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Info card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Light card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Dark card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n        \n      \n      \n        \n          \n            Header\n            \n              Primary card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Secondary card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Success card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Danger card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Warning card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Info card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Light card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n          \n            Header\n            \n              Dark card title\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n          \n        \n      \n\n      \n        \n          \n            Card header\n            \n              Special title treatment\n              Support card subtitle\n            \n            \n              \n              Image cap\n            \n            \n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n            \n            \n              Cras justo odio\n              Dapibus ac facilisis in\n              Vestibulum at eros\n            \n            \n              Card link\n              Another link\n            \n            \n              2 days ago\n            \n          \n          \n            \n              Card title\n              Card subtitle\n              Some quick example text to build on the card title and make up the bulk of the card's\n                content.\n              Card link\n              Another link\n            \n          \n        \n      \n    \n\n    \n      \n        Accordions\n      \n    \n\n    \n      \n        \n          \n            \n              \n                \n                  Accordion Item #1\n                \n              \n              \n                \n                  This is the first item's accordion body. It is shown by default, until the collapse\n                  plugin adds the appropriate classes that we use to style each element. These classes control the\n                  overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this\n                  with custom CSS or overriding our default variables. It's also worth noting that just about any HTML\n                  can go within the .accordion-body, though the transition does limit overflow.\n                \n              \n            \n            \n              \n                \n                  Accordion Item #2\n                \n              \n              \n                \n                  This is the second item's accordion body. It is hidden by default, until the collapse\n                  plugin adds the appropriate classes that we use to style each element. These classes control the\n                  overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this\n                  with custom CSS or overriding our default variables. It's also worth noting that just about any HTML\n                  can go within the .accordion-body, though the transition does limit overflow.\n                \n              \n            \n            \n              \n                \n                  Accordion Item #3\n                \n              \n              \n                \n                  This is the third item's accordion body. It is hidden by default, until the collapse\n                  plugin adds the appropriate classes that we use to style each element. These classes control the\n                  overall appearance, as well as the showing and hiding via CSS transitions. You can modify any of this\n                  with custom CSS or overriding our default variables. It's also worth noting that just about any HTML\n                  can go within the .accordion-body, though the transition does limit overflow.\n                \n              \n            \n          \n        \n      \n    \n\n  \n\n  \n  \n    \n      \n        \n          Dialogs\n        \n      \n    \n    \n      \n        Modals\n        \n          \n            \n              \n                \n                  Modal title\n                  \n                    \n                  \n                \n                \n                  Modal body text goes here.\n                \n                \n                  Save changes\n                  Close\n                \n              \n            \n          \n        \n        Offcanvas\n        \n          \n            Link with href\n          \n          \n            Button with data-bs-target\n          \n\n          \n            \n              Offcanvas\n              \n            \n            \n              \n                Some text as placeholder. In real life you can have the elements you have chosen. Like, text, images,\n                lists, etc.\n              \n              \n                \n                  Dropdown button\n                \n                \n                  Action\n                  Another action\n                  Something else here\n                \n              \n            \n          \n        \n      \n      \n        Popovers\n        \n          Left\n\n          Top\n\n          Bottom\n\n          Right\n        \n        Tooltips\n        \n          Left\n\n          Top\n\n          Bottom\n\n          Right\n        \n        Toasts\n        \n          \n            \n              Bootstrap\n              11 mins ago\n              \n                \n              \n            \n            \n              Hello, world! This is a toast message.\n            \n          \n        \n      \n    \n  \n\n  \n    \n      \n        \n          Source Code\n           Copy Code"
  },
  {
    "objectID": "talk/epoxy-super-glue/index.html#abstract",
    "href": "talk/epoxy-super-glue/index.html#abstract",
    "title": "{epoxy}",
    "section": "Abstract",
    "text": "Abstract\nR Markdown, Quarto, and Shiny are powerful frameworks that allow authors to create data-driven reports and apps. Authors blend prose and data, without having to copy and paste results. This is fantastic! But truly excellent reports require a lot of work in the final inch to get numerical and stylistic formatting just right.\n{epoxy} is a new package that uses {glue} to give authors templating super powers. First, authors can use epoxy chunks to write sentences or paragraphs in markdown with glue-like inline variables. Then, they can use inline formatting for common numerical or character transformations.\nEpoxy works in R Markdown and Quarto, in markdown, LaTeX and HTML outputs. It also provides easy templating for Shiny apps for dynamic data-driven reporting. Beyond epoxy‚Äôs features, this talk will also touch on tips and approaches for data-driven reporting that will be useful to a wide audience, from R Markdown experts to the Quarto and Shiny curious."
  },
  {
    "objectID": "talk/extra-special-xaringan/index.html#abstract",
    "href": "talk/extra-special-xaringan/index.html#abstract",
    "title": "Your Slides are So Extra!",
    "section": "Abstract",
    "text": "Abstract\n\nThe xaringan package by Yihui Xie lets R users and R Markdown authors easily blend data, text, plots and htmlwidgets into beautiful HTML presentations that look great on the web, in print, and on screens. This lightning talk will highlight a new package for customizing and enhancing xaringan slides: xaringanExtra. This package provides a collection of extensions for xaringan presentations including a tiled slide overview, editable slides, embedded webcam, tabbed panels, slide change sounds, and more. Add something special to your next xaringan presentation with xaringanExtra."
  },
  {
    "objectID": "talk/seamless-epoxy/index.html#abstract",
    "href": "talk/seamless-epoxy/index.html#abstract",
    "title": "Seamless data-driven reporting with {epoxy}",
    "section": "Abstract",
    "text": "Abstract\n\n{epoxy} is a new R package that allows report authors to seamless blend prose and data in markdown, HTML, and LaTeX reports. {epoxy} builds on the excellent tools for data-driven reporting provided by R Markdown, Quarto and Shiny, while saving report authors from tedious and repetitive data formatting tasks. This talk will highlight the many ways that {epoxy} can help data scientists in medicine to streamline reports, articles, and Shiny apps."
  },
  {
    "objectID": "talk/xaringan-playground/index.html#abstract",
    "href": "talk/xaringan-playground/index.html#abstract",
    "title": "xaringan Playground",
    "section": "Abstract",
    "text": "Abstract\n\nxaringan is a quirky package that extends R Markdown to create beautiful web-based HTML slides. Some of xaringan‚Äôs quirks come from the JavaScript library it uses, remarkjs, and some of it from the unusual naming scheme xaringan uses for its functions. But under this quirky exterior lies a powerful tool for learning and practicing web development, especially when combined with infinite_moon_reader() for immediate feedback. In this talk I‚Äôll cover some basic web concepts that illustrate how fun and rewarding it can to learn HTML, CSS and JavaScript while building awesome slides in R Markdown."
  },
  {
    "objectID": "blog/go-postal-sunset/index.html",
    "href": "blog/go-postal-sunset/index.html",
    "title": "Go Postal Sunset",
    "section": "",
    "text": "Post office near my house\n\n\n\n\n\nPost office near my house"
  },
  {
    "objectID": "blog/presenting-smart-home-activity-profiles-at-informs-2017/index.html",
    "href": "blog/presenting-smart-home-activity-profiles-at-informs-2017/index.html",
    "title": "Presenting Smart Home Activity Profiles at INFORMS 2017",
    "section": "",
    "text": "I had a great time connecting with old and new friends and colleagues this past week at the INFORMS 2017 Annual Meeting.\nI was happy to have been invited by Julie Hammett to present in the Remote Patient Monitoring and mHealth Applications session Wednesday afternoon.\nFor those who are interested or couldn‚Äôt make the session due to timing, I‚Äôve posted a copy of my slides ‚Äì Occupant Activity Profiles from Smart Home Sensor Event Streams ‚Äì for you.\nSome of the highlights from this INFORMS include:\n\nDr.¬†Baraniuk‚Äôs talk on Deep Learning, especially his take on how we learn to train deep neural networks.\n\nThe INFORMS Chapter of USF winning Summa Cum Laude by continuing events and programs that I worked on as President of the INFORMS chapter several years ago.\n\n\nSpending a night out in Houston on my birthday, reconnecting with friends who have graduated.\nUsing Houston‚Äôs bike share system to get around.\nAnd all of the many conversations I had with other graduate students.\n\nThanks INFORMS and Houston for a great trip!"
  },
  {
    "objectID": "blog/quote-albert-einstein/index.html",
    "href": "blog/quote-albert-einstein/index.html",
    "title": "Quote: Albert Einstein",
    "section": "",
    "text": "Every day I remind myself that my inner and outer life are based on the labors of other people, living and dead, and that I must exert myself in order to give in the same measure as I have received and am still receiving.\n‚Äî Albert Einstein"
  },
  {
    "objectID": "blog/respond-peer-reviews-with-pandoc/index.html",
    "href": "blog/respond-peer-reviews-with-pandoc/index.html",
    "title": "Responding to peer reviewers with Pandoc",
    "section": "",
    "text": "I‚Äôm in the process of responding to the second round of peer reviews of a paper I‚Äôve spent considerable time working on over the past year. Of course, this time around I‚Äôve learned a few new tricks that make the whole process easier to manage‚Ä¶\n\nI spent an entire weekend converting the paper from Word to LaTeX. By hand. But it‚Äôs now worth it.\nI coerced the other graduate student working on the paper to use Trello, so I can see what he‚Äôs working on now, what he‚Äôs planning to do next and what he‚Äôs already done.\nI‚Äôve learned to use git in combination with BitBucket so individual changes are tracked and it‚Äôs easy to flip between old and current versions of the paper with a simple git checkout.\nI‚Äôve learned how to use the powerful markdown language and document converter, pandoc, which I‚Äôm using to format our response to the reviewers.\n\nI‚Äôm following the format presented by Matt Might in Responding to peer review. It is an excellent guide to writing a response to peer reviewers, and the method he outlines fits perfectly into a pandoc workflow.\nFor example, the journal to which we are submitting is run by Elsevier, who certainly has a platform to coordinate communication between editors, authors, and reviewers. A platform that conveniently strips all formatting from the review text. But, after simply copying and pasting the review text into a text file, I add $ marks around the inline LaTeX and convert to PDF. Just reading the reviews is easier when the math and format is clear.\nConverting to PDF is as simple as:\npandoc response.txt -o response.pdf\nThen, following Matt Might‚Äôs workflow, I indent each reviewer response with a &gt; and prepare our replies underneath each item.\nWe were fortunate in that one reviewer offered a list of polite, meticulously detailed points. However, when converting our responses to PDF, the only difference between regular text and the LaTeX quote environment is increased indentation. When most of a document is normal text with only a few quotes, this is reasonable. But in our case it is very difficult to see, by indentation alone, exactly which text is the reviewer‚Äôs comment and which text is our rebuttal.\nAfter far too many hours digging through LaTeX and pandoc discussion forums and a long process of trial and error, I finally came up with the right commands to alter the quote environment. Simply include these lines at the beginning of your markdown file, and pandoc will apply the LaTeX code when converting to pdf.\n\\let\\quoteOld\\quote\n\\let\\endquoteOld\\endquote\n\\renewenvironment{quote}{\\quoteOld\\itshape}{\\endquoteOld}\nYou can save the above lines in a file called preamble.tex that you can then include in the LaTeX header with the pandoc --include-in-header argument.\npandoc --include-in-header preamble.tex response.txt -o response.pdf\nRather than remember to include this code every time you want italicized block quotes, you can download the pandoc default.latex template file, rename it something memorable ‚Äì like italicquotes.tex ‚Äì and add the above code somewhere near the top. (Somewhere after the first string of \\usepackage commands is probably best.)\nThen, copy the italicquotes.tex to the pandoc templates folder, which I found in the following folder:\ncp italicquotes.tex /usr/local/share/pandoc-1.11.1/data/templates/\nTo use this template, simply add --template=italicquotes.tex when you call pandoc:\npandoc -N --template=italicquotes.tex response.txt -o response.pdf\nOr, with fancy fonts:\npandoc -N --template=italicquotes.tex \\\n          --variable mainfont=Georgia \\\n          --variable sansfont=Arial \\\n          --variable fontsize=12pt \\\n          response.txt --latex-engine=xelatex -o response.pdf"
  },
  {
    "objectID": "blog/the-end-of-stanford/index.html",
    "href": "blog/the-end-of-stanford/index.html",
    "title": "The End of Stanford?",
    "section": "",
    "text": "‚Ä¶the center of gravity at the university appears to have shifted. The school now looks like a giant tech incubator with a football team.\n\n[NY Times]"
  },
  {
    "objectID": "blog/the-end-of-stanford/index.html#the-end-of-stanford",
    "href": "blog/the-end-of-stanford/index.html#the-end-of-stanford",
    "title": "The End of Stanford?",
    "section": "",
    "text": "‚Ä¶the center of gravity at the university appears to have shifted. The school now looks like a giant tech incubator with a football team.\n\n[NY Times]"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html",
    "href": "blog/trump-tweet-time/index.html",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "",
    "text": "Last week, Donald Trump‚Äôs White House schedule was leaked and published online by Axios. One highlight from the released documents is the large amount of unstructured ‚ÄúExecutive Time‚Äù that appears on his schedule.\nThe #rstats Twitter community immediately began to wonder what interesting anaylses could be done in comparing Trump‚Äôs schedule to the tweets he sent out.\n\n\nHere‚Äôs something simple, using tweets from the #TrumpTwitterArchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019\n\nAxios helpfully released a Google Spreadsheet to accompany the PDF version of the schedule, and a curated version has also been posted on Data World. Jonathan Sidi also built a cool Shiny app for viewing Trumps tweets on a time line over his schedule.\nI started to pull together an analysis for an upcoming blog post, and here‚Äôs a little sneak peak.\n\n\nHere's something simple, using tweets from the #trumptwitterarchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#trumps-excutive-time",
    "href": "blog/trump-tweet-time/index.html#trumps-excutive-time",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "",
    "text": "Last week, Donald Trump‚Äôs White House schedule was leaked and published online by Axios. One highlight from the released documents is the large amount of unstructured ‚ÄúExecutive Time‚Äù that appears on his schedule.\nThe #rstats Twitter community immediately began to wonder what interesting anaylses could be done in comparing Trump‚Äôs schedule to the tweets he sent out.\n\n\nHere‚Äôs something simple, using tweets from the #TrumpTwitterArchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019\n\nAxios helpfully released a Google Spreadsheet to accompany the PDF version of the schedule, and a curated version has also been posted on Data World. Jonathan Sidi also built a cool Shiny app for viewing Trumps tweets on a time line over his schedule.\nI started to pull together an analysis for an upcoming blog post, and here‚Äôs a little sneak peak.\n\n\nHere's something simple, using tweets from the #trumptwitterarchive so limited to midterms to end of 2018. pic.twitter.com/CdRxUNwyq2\n\n‚Äî Garrick Aden-Buie (@grrrck) February 4, 2019"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#an-8-bit-distraction",
    "href": "blog/trump-tweet-time/index.html#an-8-bit-distraction",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "An 8-bit Distraction",
    "text": "An 8-bit Distraction\nBut then I got distracted. Colin Fay recently released a port of ness-css for Shiny called nessy, and it looks awesome. I just needed a good reason to create an awesome 8-bit retro Shiny app.\nThe idea came to me during the analysis. Can you tell what Trump is doing (or is supposed to be doing) by the tweets he sends? Why not put your intuition to the test?"
  },
  {
    "objectID": "blog/trump-tweet-time/index.html#trump-tweet-time",
    "href": "blog/trump-tweet-time/index.html#trump-tweet-time",
    "title": "Trump Tweet Time: An 8-bit ‚ÄúExecutive Time‚Äù Game",
    "section": "Trump Tweet Time",
    "text": "Trump Tweet Time\nSo I built a simple Shiny game called Trump Tweet Time that you can play right now. An 8-bit Trump shouts a tweet at you and you have to guess what was on his schedule while he was tweeting.\n\n\n\n\n\nA screenshot of a SuperNES-styled Donald Trump with a speach bubble containing a random tweet. Three buttons offer the options for ‚Äúmeeting‚Äù, ‚Äútravel‚Äù or ‚Äúexecutive time‚Äù\n\n\n\n\n\n\n\nA screenshot after the user has clicked ‚Äúexecutive time‚Äù revealing that Trump tweeted during Executive Time.\n\n\n\n\nThanks to Colin Fay for nessy and Mike Kearney for rtweet! Your packages made this fun and easy.\nNow go enjoy some executive time!\n\n\n\nA screenshot of a SuperNES-styled Donald Trump with a speach bubble containing a random tweet. Three buttons offer the options for ‚Äúmeeting‚Äù, ‚Äútravel‚Äù or ‚Äúexecutive time‚Äù\nA screenshot after the user has clicked ‚Äúexecutive time‚Äù revealing that Trump tweeted during Executive Time."
  },
  {
    "objectID": "blog/upcoming-code-and-data-boot-camp/index.html",
    "href": "blog/upcoming-code-and-data-boot-camp/index.html",
    "title": "Upcoming Code & Data Boot Camp",
    "section": "",
    "text": "Today, Dr.¬†Shabbir Ahmed spoke at USF at our lecture series on Stochastic Integer Programming methods. It was high-level and broad and unfortunately he didn‚Äôt get into many of the ‚Äúnitty-gritty‚Äù details, but it was still fascinating. Clearly integer programming ‚Äì and SIP more specifically ‚Äì is going to be an even more important area in OR and optimization in the very near future.\nAt the end of the talk, in answer to one of the questions, Dr.¬†Ahmed spoke a bit about his advice to current and future students of industrial engineering. He advised young students to learn programming skills and to embrace what is traditionally thought of as ‚Äúcomputer science‚Äù. They are important skills too often left out of IE curricula but that are highly valuable and relevant to the work of IEs in the field.\nIt was a heartening statement to hear, given that our INFORMS student chapter has organized a two-day intense introduction to programming ‚Äúboot camp‚Äù we‚Äôll be running next week called the‚Ä¶"
  },
  {
    "objectID": "blog/upcoming-code-and-data-boot-camp/index.html#power-up-code-data-boot-camp",
    "href": "blog/upcoming-code-and-data-boot-camp/index.html#power-up-code-data-boot-camp",
    "title": "Upcoming Code & Data Boot Camp",
    "section": "Power Up! Code & Data Boot Camp",
    "text": "Power Up! Code & Data Boot Camp\nI‚Äôm very happy to see this vision realized and to be a part of the boot camp. I love talking about code ‚Äì not something that I get to do everyday, at least not without a few hairy eyeballs.\nAs the first time hosting this, I think we have a great spread of topics and a great lineup of USF IMSE graduate students. Presentations will include\n\nMatlab\nR\nMinitab\nExcel\nand SAS\n\nwith at least one introductory session and one advanced ‚Äúhands-on‚Äù session for each. I already have some ideas about how we host this again next year, but for now I‚Äôve got to focus on getting my three sessions together.\nI‚Äôll be talking motivating students to use R, talking about the fundamentals of R for data anayltics, and using R, knitr and pandoc for reproducible research. I‚Äôm excited to get people talking about R, but I‚Äôm most excited about getting my fellow graduate students into using pandoc and knitr. Because they‚Äôre awesome."
  },
  {
    "objectID": "blog/visualize-physionet-data-with-r/index.html",
    "href": "blog/visualize-physionet-data-with-r/index.html",
    "title": "Visualizing PhysioNet Challenge Patient Data with R",
    "section": "",
    "text": "In working with the PhysioNet Challenge 2012 data set, it can often be very difficult to assess the condition of a given patient, or the trends within those the time series variables provided.\nThere is a lot of variability between the number of variables recorded (and the number of observations per variable) for each patient. As a medical data set, the data is characterized by highly non-linear trends, and it can be difficult to get a handle on it in a table format. Worse, the training set is nearly 2 million rows long when training patient data is joined together ‚Äî a result of presenting patient data in three rows: Time, Parameter, Value.\nFurthermore, there is a large variation in the reliability of the data recorded in each variable. A machine-read variable may be more reliable than a variable whose observations are recorded by hand by a human.\nThus, in exploring the data set, it may be useful at times to visually see the input data validate model output or to explore unusual cases or values. R provides a straight-forward language with good packages for pretty graphs, making it a good choice for this type of visualization.\n\nA nice looking plot\nThis post will help you learn to run R code that produce graphs like this. (Note: learn to run, not learn to write‚Ä¶ that‚Äôs a much longer post and maybe I‚Äôll get to it later.)\n\nThe image shows all of the time-series variables available for patients in Set A, ordered alphabetically, with a fixed time scale in minutes after arrival in the ICU. Descriptive variables, including some calculated variables, are printed at the top of the plot.\nThe plot is generated by sending a list of RecordID‚Äôs to a function, plotByID(), which will either display the plot on the screen, or save it to the working directory.\n\n\nGetting Started\nFirst, download and install RStudio. This should be relatively painless. You‚Äôll also need the code and the data set. The original data set is from the PhysioNet 2012 Computing in Cardiology. I‚Äôve simply pulled each individual patient file into one dataset and added a new column for RecordID.\nExtract plotByID.zip somewhere where you‚Äôll find it and fire up RStudio. You should see a screen that looks a lot like this:\n\nYou‚Äôve got the Console on the left, Workspace and Files on the right. This code uses Hadley Wickham‚Äôs excellent plotting package ggplot2, which isn‚Äôt installed by default. To install it, click on Install packages¬†under the¬†Tools menu, type ggplot2 in the text box and hit enter. Everything should install fine.\nTo load the code, click on the ‚Ä¶¬†in the Files pane and open the folder where you extracted the data set. To make sure everything runs within this directory, click¬†‚ÄúSet working directory‚Äù under the More¬†button. Open plotByID.R. Now you should see this:\n\nThe code to load and plot the data is now open in the upper left window. Take a look at it and read through it if you want. To load it up, simply select everything (Ctrl/‚åò+A) and then click Run¬†or hit Ctrl/‚åò+Enter. The data set and necessary functions will load, and the demo plot above will appear, like magic.\n\n\nUsing plotByID()\nThe plotting function is pretty self-explanatory. It takes a primary argument of a RecordID or a vector of RecordIDs and returns a plot. There are also arguments to save the plot to a particular path and to control whether or not the plot displays on the screen.\nTo plot input patient data to the screen you only have to enter one RecordID, by simply typing\nplotByID(133966)\nin the console and hitting enter. To plot multiple patients, use a vector, which in R is denoted by the command c(). Thus,\nplotByID( c(133966, 140334) )\nwill plot the input data for two patients. To plot a random sample of 10 patients use the sample() function:\nplotByID( sample(seta$RecordID, 10 )\nIf you want the images to save to the working directory, use\nplotByID(133966, save=TRUE, path=path)\nYou don‚Äôt have to manually specify the path variable, it‚Äôs been set to the working directory. If you want to change the saving path, set\npath=\"~/Your/Directory/Here\"\nThat‚Äôs it. I hope this makes it a little easier to see what you‚Äôre working with! ;)"
  },
  {
    "objectID": "colophon/index.html",
    "href": "colophon/index.html",
    "title": "Made with üíô",
    "section": "",
    "text": "Made with  Quarto, which is powered by pandoc.\nThe previous version of this blog was made with  Hugo Ap√©ro , which is based on  Blogophonic  by Formspree and was powered by blogdown and built by Hugo.\nThe source for this blog can be found online at GitHub gadenbuie/garrickadenbuie-com."
  },
  {
    "objectID": "colophon/index.html#made-with-quarto",
    "href": "colophon/index.html#made-with-quarto",
    "title": "Made with üíô",
    "section": "",
    "text": "Made with  Quarto, which is powered by pandoc.\nThe previous version of this blog was made with  Hugo Ap√©ro , which is based on  Blogophonic  by Formspree and was powered by blogdown and built by Hugo.\nThe source for this blog can be found online at GitHub gadenbuie/garrickadenbuie-com."
  },
  {
    "objectID": "colophon/index.html#usesgarrick",
    "href": "colophon/index.html#usesgarrick",
    "title": "Made with üíô",
    "section": "/uses/garrick",
    "text": "/uses/garrick\nI don‚Äôt have a /uses page (yet!), but I did live tweet and blog about my MacBook Pro setup. That should get you pretty close to a full accounting of the software and tools I use on a daily basis."
  },
  {
    "objectID": "colophon/index.html#license",
    "href": "colophon/index.html#license",
    "title": "Made with üíô",
    "section": "License",
    "text": "License\nMy blog posts are released under a Creative Commons Attribution-ShareAlike 4.0 International License.\n\n\n\nUnless otherwise specified, code presented in blog posts are released under the MIT license."
  },
  {
    "objectID": "talk/gentle-ggplot2-usf-asu/index.html",
    "href": "talk/gentle-ggplot2-usf-asu/index.html",
    "title": "A Gentle Guide to the Grammar of Graphics with ggplot2",
    "section": "",
    "text": "An intruction to data visualization with ggplot2 presented at the ‚ÄúWorkshop on Data Analysis Using R‚Äù hosted by the ASA student chapter at USF."
  },
  {
    "objectID": "talk/iie-iserc-2015/index.html",
    "href": "talk/iie-iserc-2015/index.html",
    "title": "Ambient Intelligence Applications in Healthcare",
    "section": "",
    "text": "In the past century, the world has experienced unprecedented growth in life expectancy concurrent with a growth in elderly population. Between 2010 and 2050, the number of people aged 65 and older is expected to more than double to exceed 88 million by 2050 in the United States. Ambient intelligence merges ubiquitous computing, embedded sensors, and artificial intelligence to monitor, adjust and respond to the environment of the user. This presentation will explore the potential of ambient intelligence for applications in health care, primarily with a focus on senior health care management."
  },
  {
    "objectID": "talk/informs-2017/index.html",
    "href": "talk/informs-2017/index.html",
    "title": "Occupant Activity Profiles from Smart Home Sensor Event Streams",
    "section": "",
    "text": "Faced with a growing elderly population, learning and characterizing activity profiles of smart home occupants will support senior health care management for older adults living in homes augmented by ambient intelligence solutions that combine ubiquitous computing and artificial intelligence. In this work, we explore a bag of n-grams approach for creating occupant-specific activity profiles from event streams collected from passive, embedded sensors in real-world sensor networks in the homes of several older adults."
  },
  {
    "objectID": "talk/js4shiny/index.html",
    "href": "talk/js4shiny/index.html",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "talk/js4shiny/index.html#abstract",
    "href": "talk/js4shiny/index.html#abstract",
    "title": "JavaScript for Shiny Users",
    "section": "",
    "text": "Shiny gives users a powerful toolkit to create interactive web applications. As a result, Shiny users are also web developers! Inevitably, an intermediate Shiny user will want to create a visualization or user interface that isn‚Äôt available in the shiny package. Fortunately, we can use the building blocks of the web ‚Äì JavaScript, HTML, and CSS ‚Äì to extend Shiny‚Äôs capabilities and create engaging Shiny apps.\nThis two-day, hands-on workshop will introduce Shiny users to JavaScript, the ubiquitous scripting language that powers the modern web. We will explore JavaScript‚Äôs syntax and will discover its functional programming style to be refreshingly familiar to tidyverse R users. We will learn how to use JavaScript to manipulate HTML and how Shiny uses JavaScript to communicate between the browser and Shiny server. Together, we will build an htmlwidget and learn how to incorporate our own or packaged JavaScript code into Shiny apps and [R Markdown] documents, and how to simultaneously manage JavaScript and R dependencies.\nThis workshop is for the Shiny user who boldly waded into the Customizing Shiny section of RStudio‚Äôs Shiny Articles and quickly wished they had more experience with JavaScript. This user recognizes the benefits of learning JavaScript, but they are overwhelmed by the sheer number of packages, tutorials, and StackOverflow questions that exist in the world about JavaScript, HTML, and CSS. The goal of this workshop is to meet the Shiny user where they are now to learn the best parts of JavaScript that will provide the most value and facilitate learning and exploration after the workshop."
  },
  {
    "objectID": "talk/presentable-user2021/index.html",
    "href": "talk/presentable-user2021/index.html",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "talk/presentable-user2021/index.html#abstract",
    "href": "talk/presentable-user2021/index.html#abstract",
    "title": "Professional, Polished, Presentable",
    "section": "",
    "text": "The xaringan package brings professional, impressive, and visually appealing slides to the powerful R Markdown ecosystem. Through our hands-on tutorial, you will learn how to design highly effective slides that support presentations for teaching and reporting alike. Over three hours, you will learn how to create an accessible baseline design that matches your institution or organization‚Äôs style guide. Together we‚Äôll explore the basics of CSS‚Äîthe design language of the internet‚Äîand how we can leverage CSS to produce elegant slides for effective communication."
  },
  {
    "objectID": "talk/presentable-user2021/index.html#why-xaringan",
    "href": "talk/presentable-user2021/index.html#why-xaringan",
    "title": "Professional, Polished, Presentable",
    "section": "Why xaringan?",
    "text": "Why xaringan?\nEffective communication is the keystone of impactful data science. Whether teaching data-related skills or reporting the latest modelling results, by and large R users are expected to communicate highly complex topics to students and stakeholders. Furthermore, our computational data work requires that our presentations and reports are both reproducible when we need to recreate today‚Äôs work in the future, as well as adaptable when tomorrow‚Äôs data changes today‚Äôs results. And, not least of all, effective communication demands that our medium of communication is accessible to all, regardless of socio-economic status, activity limitations or disability.\nCreating presentations with the xaringan package embodies all of these requisite skills: built on the literate programming markdown syntax familiar to users of R Markdown, it produces reproducible HTML slides that enable effective, accessible communication across sectors, disciplines, and experiences.\nAlong the way, working with xaringan fosters a level of web literacy that is immensely useful in many other venues of online communication such as with web-based documents and apps created using R Markdown and Shiny."
  },
  {
    "objectID": "talk/trug-extra-awesome-xaringan/index.html",
    "href": "talk/trug-extra-awesome-xaringan/index.html",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "talk/trug-extra-awesome-xaringan/index.html#description",
    "href": "talk/trug-extra-awesome-xaringan/index.html#description",
    "title": "Extra Awesome xaringan Presentations",
    "section": "",
    "text": "Learn how to make extra awesome xaringan presentations with a few new packages\n\nxaringanthemer\nxaringanExtra\nmetathis\n\nthat add the extra touches needed to personalize your slides and make them stand out from the crowd."
  },
  {
    "objectID": "blog/quarto-now/index.html",
    "href": "blog/quarto-now/index.html",
    "title": "Add last rendered or modified time to Quarto",
    "section": "",
    "text": "Generated with DALL-E 3."
  },
  {
    "objectID": "blog/quarto-now/index.html#a-blog-is-a-perpetual-side-project-machine",
    "href": "blog/quarto-now/index.html#a-blog-is-a-perpetual-side-project-machine",
    "title": "Add last rendered or modified time to Quarto",
    "section": "A blog is a perpetual side-project machine",
    "text": "A blog is a perpetual side-project machine\nThey say that if you copy-paste the same code three times, write a function. I‚Äôve also heard that if you send the same email more than once, turn that email into a blog post.\nBut all the real work in life happens on Slack. So if a friend asks for your advice and you brain dump everything you know about the easiest way to install and manage Python, then you‚Äôve got a first draft blog post on your hands!\nThey also say the hardest part of writing is staring at the blank page. But they are wrong. The hardest part of writing is figuring out how to start a new .qmd file in your blog repo without bumping into 3 to 10 other things you have been meaning to do.\nOr worse, you might encounter that draft post you‚Äôve been working on for months. Learn from my mistakes: it‚Äôs okay to stash that post, you can always tell yourself you‚Äôll come back to it later!\nYou can probably tell by now that this is not a post about Python tooling for a happy setup. It‚Äôs also not a post about the few CSS tweaks I made while trying to open up this editor.\nThis post is sponsored by this a bit of YAML that caught my eye in my _quarto.yml file in the split second before I closed all my open tabs.\npage-footer:\n    left: &gt;-\n      ¬© 2023 Garrick Aden-Buie\nThis is not acceptable. It has been 2024 for a whole 89 days and that little ¬© 2023 has been sitting in my page footer the entire time. I‚Äôm lucky I haven‚Äôt gotten any angry emails about it!\nNow the fix could be easy. Consider this: I could change that file, commit it, and push it.\npage-footer:\n  left: &gt;-\n-    ¬© 2023 Garrick Aden-Buie\n+    ¬© 2024 Garrick Aden-Buie\nOne GitHub Action, several minutes, and two Netlify notifications later my blog would be back to the future.\nBut this obviously won‚Äôt work. Time stops for no one. What will I do in March of 2025? Come back to this file and edit it by hand? Again? Like a caveman? Hard no.\nWouldn‚Äôt it be awesome if I could replace that 2023 that should be 2024 with something that turns into the current year whenever my blog rebuilds? I could save minutes in the entire lifetime of my blog! Imagine replacing the 2023 with something that would update itself automatically, like this:\npage-footer:\n  left: &gt;-\n    ¬© {{&lt; now year &gt;}} Garrick Aden-Buie\nIt would be awesome, but that syntax doesn‚Äôt exist in Quarto. Or it didn‚Äôt until I my productive procrastination instincts kicked in!\nIntroducing now, a quarto extension for easily adding the time right now ‚Äì err‚Ä¶ the time right now when your Quarto blog or document is rendered."
  },
  {
    "objectID": "blog/quarto-now/index.html#hello-now",
    "href": "blog/quarto-now/index.html#hello-now",
    "title": "Add last rendered or modified time to Quarto",
    "section": "Hello, now",
    "text": "Hello, now\nTo start using now in your own Quarto projects, just install the extension with this command.\nquarto add gadenbuie/quarto-now\nYou can read all about the extension on its (quarto-built) page here: pkg.garrickadenbuie.com/quarto-now. Or keep reading this post for a quick intro."
  },
  {
    "objectID": "blog/quarto-now/index.html#using-now",
    "href": "blog/quarto-now/index.html#using-now",
    "title": "Add last rendered or modified time to Quarto",
    "section": "Using now",
    "text": "Using now\nnow, the extension, comes with two shortcodes you can use just about anywhere: {{&lt; now &gt;}} and {{&lt; modified &gt;}}. Both work in the same way, except that {{&lt; modified &gt;}} will show the last modified time of the document, either by using the modified metadata field or the last modified timestamp of the file (on macOS and Linux only, sorry).\nHere‚Äôs a quick example of the shortcodes in use. Note that in this post I added the modified date, which gives me a bit more control over what counts as a ‚Äúmodification‚Äù.\n---\ntitle: Add last rendered or modified time to Quarto\nmodified: 2024-03-29\n---\n\nThis document was last modified at {{&lt; modified &gt;}}\nand it was last rendered at {{&lt; now &gt;}}.\n\nThis document was last modified at 2024-03-29 00:00:00 and it was last rendered at 2024-03-29 10:13:58."
  },
  {
    "objectID": "blog/quarto-now/index.html#formatting-the-time-output",
    "href": "blog/quarto-now/index.html#formatting-the-time-output",
    "title": "Add last rendered or modified time to Quarto",
    "section": "Formatting the time output",
    "text": "Formatting the time output\nBy default, now uses ISO 8601 (ish) formatting, but that‚Äôs not usually the most human-readable format. now comes with a few built-in aliases for common date and time parts.\n\n\n\n\n\n\n\n\nShortcode\nResult\nFormat String\n\n\n\n\n{{&lt; now &gt;}}\n2024-03-29 10:13:58\n\"%F %T\"\n\n\n{{&lt; now year &gt;}}\n2024\n\"%Y\"\n\n\n{{&lt; now month &gt;}}\nMarch\n\"%B\"\n\n\n{{&lt; now day &gt;}}\n29\n\"%d\"\n\n\n{{&lt; now weekday &gt;}}\nFriday\n\"%A\"\n\n\n{{&lt; now hour &gt;}}\n10\n\"%I\"\n\n\n{{&lt; now minute &gt;}}\n13\n\"%M\"\n\n\n{{&lt; now ampm &gt;}}\nAM\n\"%p\"\n\n\n{{&lt; now date &gt;}}\n03/29/24\n\"%x\"\n\n\n{{&lt; now time &gt;}}\n10:13:58\n\"%X\"\n\n\n{{&lt; now datetime &gt;}}\nFri Mar 29 10:13:58 2024\n\"%c\"\n\n\n{{&lt; now isodate &gt;}}\n2024-03-29\n\"%F\"\n\n\n{{&lt; now isotime &gt;}}\n10:13:58\n\"%T\"\n\n\n{{&lt; now isodatetime &gt;}}\n2024-03-29T10:13:58-0400\n\"%FT%T%z\"\n\n\n{{&lt; now timestamp &gt;}}\n2024-03-29 10:13:58\n\"%F %T\"\n\n\n\nNote that the shortcodes only accept a single format argument, so you‚Äôd need to write {{&lt; modified month &gt;}} {{&lt; modified year &gt;}} instead of {{&lt; modified month year &gt;}}.\nThat said, you can always use the format strings supported by Lua‚Äôs os.date() function, so {{&lt; modified \"%B %Y\" &gt;}} gives you the month and year: March 2024. Note that because the format string has a space, it needs to be quoted \"%B %Y\".\nYou can find the complete list of accepted format strings in the now extension docs."
  },
  {
    "objectID": "blog/quarto-now/index.html#have-a-good-day-meow",
    "href": "blog/quarto-now/index.html#have-a-good-day-meow",
    "title": "Add last rendered or modified time to Quarto",
    "section": "Have a good day, meow!",
    "text": "Have a good day, meow!\nThis was a fun excursion into the world of Quarto extensions! Thanks for reading and I hope you find now useful in your own projects. May you benefit from my inability to do the thing I‚Äôm ‚Äúsupposed to do‚Äù (hey, it‚Äôs my free time!).\n\n\nThe feature image was generated with DALL-E 3 and the following prompt: an m.c. escher style pencil sketch of a dreamy clock face."
  }
]